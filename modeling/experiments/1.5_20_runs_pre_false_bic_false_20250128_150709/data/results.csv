run_number,average_bic,model_specification,model_summary,timestamp,self_interest_weight_recovery,fairness_sensitivity_recovery,fairness_weight_recovery,alpha_recovery,beta_recovery,self_interest_scale_recovery,unfairness_scale_recovery,weight_fairness_recovery,weight_self_interest_recovery,min_acceptable_perc_recovery,self_interest_sensitivity_recovery,inequity_aversion_recovery,gamma_recovery,contribution_sensitivity_recovery
6,30.733372602013244,U_accept = fairness_weight * (split_self - (combined_earning * (token_self / (token_self + token_opp)))) + self_interest_weight * split_self,A linear utility model for accepting offers based on fairness and self-interest. Fairness is calculated as the difference between the proposed split and a proportionally fair split based on token contributions. Self-interest is the proposed amount.  The model has two learnable parameters representing the weights of fairness and self-interest in determining the utility of accepting an offer.,20250128_150709,0.8752591645446628,,0.8659974641517266,,,,,,,,,,,
16,31.693398279025367,"U_accept = split_self + fairness_weight * (split_self - (token_self / (token_self + token_opp)) * combined_earning) - inequity_aversion * max(0, split_opp - split_self)","A utility model for responder acceptance decisions based on self-interest and fairness considerations.  The model incorporates a fairness term representing the deviation from a proportional split based on token contributions and an inequity aversion term penalizing outcomes where the opponent receives more than the responder. Two learnable parameters, `fairness_weight` and `inequity_aversion`, modulate the relative importance of these components.",20250128_150709,,,0.7450265765333619,,,,,,,,,0.8772774793227909,,
12,32.44035850106285,U_accept = fairness_weight * ( (split_self / combined_earning) / ((token_self / (token_self + token_opp)) ) ) + split_self - min_acceptable_perc*combined_earning,"A linear utility model for responder acceptance decisions, combining a fairness term and a self-interest term.  The fairness term is based on the ratio of the participant’s proposed share to their contribution relative to the opponent's. The self-interest term is simply the participant's proposed share. Two learnable parameters weight the importance of fairness and define a minimum acceptable percentage of the combined earnings.",20250128_150709,,,0.6804929359899793,,,,,,,0.9116939819635024,,,,
2,32.55292817308536,U_accept =  self_interest_weight * split_self + fairness_weight * (split_self - (combined_earning * (token_self / (token_self + token_opp)))),"A weighted linear utility model for responder acceptance decisions in an ultimatum game.  Utility is calculated as a weighted sum of self-interest (monetary gain) and a fairness term based on the deviation from an equitable split, proportional to the relative token contributions. Two learnable parameters, `self_interest_weight` and `fairness_weight`, represent the individual's relative prioritization of self-interest and fairness respectively.",20250128_150709,0.5789547129211166,,0.9038255305705752,,,,,,,,,,,
7,33.80397491253036,U = fairness_weight * (1 - abs((splitperc_self - (token_self / (token_self + token_opp)) * 100))) + self_interest_scale * split_self,"A utility model for responder behavior in a bargaining game, combining fairness and self-interest.  Fairness is calculated as the deviation from a split percentage proportional to individual contributions. Utility is a weighted sum of fairness and the monetary amount offered, scaled by two learnable parameters representing the relative importance of fairness and self-interest.",20250128_150709,,,0.5527969183533652,,,0.6902190361157127,,,,,,,,
8,34.04826168934026,U_accept = self_interest_weight * split_self + fairness_weight * ( (split_self / token_self) - (split_opp / token_opp) ),"A linear utility model for responder acceptance decisions, balancing self-interest (gained amount) and fairness (proportional share relative to contributions). Two learnable parameters weight the relative importance of self-interest and fairness.  Negative fairness weights represent a preference for unequal splits that favour the responder.",20250128_150709,0.6982962331764521,,0.9164875432438861,,,,,,,,,,,
14,34.80210249918216,U_accept = split_self * (1 + fairness_weight * ( (splitperc_self / (splitperc_self + splitperc_opp)) - 0.5 ) * fairness_sensitivity),"A multiplicative utility model for responder behavior in an ultimatum game.  Utility is determined by the monetary gain and a fairness term, which is a function of the percentage split received and a sensitivity parameter. Two learnable parameters, `fairness_weight` (weight of fairness) and `fairness_sensitivity` (sensitivity to deviation from equal split), capture individual differences in decision-making.",20250128_150709,,0.8603749548273568,0.42390686569180014,,,,,,,,,,,
9,34.85676301408838,U_accept = split_self + fairness_weight * ( (token_self / (token_self + token_opp)) * combined_earning - split_self) * unfairness_scale,"A linear utility model for responder behavior in an ultimatum game. Utility of accepting is a weighted sum of the monetary gain and a penalty for unfairness, scaled by two learnable parameters: fairness_weight (representing the importance of fairness relative to self-interest) and unfairness_scale (a scaling factor for the magnitude of the fairness penalty). The fairness penalty is calculated as the difference between the participant's proportional share based on token contributions and their actual share of the combined earnings.",20250128_150709,,,0.8753202568440751,,,,0.32349235088635353,,,,,,,
4,35.500511379523935,U_accept = fairness_weight * (split_self / combined_earning - token_self / (token_self + token_opp)) + self_interest_weight * split_self,"A linear utility model for responder acceptance decisions, incorporating fairness and self-interest.  Fairness is calculated as the difference between the proportion of the combined earning received and the proportion of tokens contributed.  The model has two learnable parameters:  `fairness_weight` and `self_interest_weight`, representing the relative importance of fairness and self-interest, respectively.",20250128_150709,0.8196107096446743,,0.11832639743630223,,,,,,,,,,,
11,35.87664271446112,utility_accept = weight_fairness * (splitperc_self - (token_self / (token_self + token_opp)) * 100) + weight_self_interest * split_self,"A linear utility model for responder acceptance decisions, balancing fairness and self-interest.  Fairness is computed as the difference between the proposed percentage and a percentage based on token contribution ratios.  Self-interest is simply the proposed monetary amount. The model has two learnable parameters:  weight_fairness and weight_self_interest, which represent the relative importance of fairness and self-interest, respectively.",20250128_150709,,,,,,,,0.8348135902403763,0.7296827613283466,,,,,
10,42.357556956466006,U_accept =  self_interest_weight * split_self + fairness_weight * ( (split_self / token_self) / ( (split_opp + 0.0001) / (token_opp + 0.0001) ) ),"A utility model for responder behavior in an ultimatum game, considering both self-interest and fairness.  The utility of accepting an offer is a weighted sum of the monetary gain and a fairness term based on the ratio of proposed shares to relative contributions.  The model has two learnable parameters: self_interest_weight and fairness_weight, representing the relative importance of self-interest and fairness in decision-making.  Note that a small value (0.0001) has been added to both token_opp and split_opp to prevent division by zero errors when token_opp is zero.",20250128_150709,0.788433678565303,,0.4998142586600698,,,,,,,,,,,
1,43.84940424012833,utility = self_interest_weight * split_self + fairness_sensitivity * (1 - abs((split_self / split_opp) - (token_self / token_opp))),"A utility model combining self-interest and fairness considerations in the acceptance of an offer.  Self-interest is a direct function of the participant's proposed share, while fairness is measured as the difference between the ratio of participant's and opponent's shares and the ratio of their respective token contributions. Two learnable parameters control the relative weight of self-interest and the sensitivity to perceived unfairness.",20250128_150709,0.7875497092253645,0.36827101243093124,,,,,,,,,,,,
18,44.1967351907992,U_accept = α * (split_self / combined_earning) + γ * ( (split_self / token_self) / ( (combined_earning - split_self) / token_opp) ),"A multiplicative utility model for responder behavior, combining relative gain and equity considerations.  The model uses two learnable parameters: `alpha`, representing sensitivity to relative gain, and `gamma`, representing the weight given to equity in the decision.  Utility is calculated based on the proposed share, the total earnings, and the tokens collected by both the participant and the opponent.",20250128_150709,,,,0.3476386145263793,,,,,,,,,0.6920167446472557,
17,44.568319364718995,utility_accept = fairness_weight * (split_self / (token_self * 3)) + self_interest_weight * split_self,"A utility model for responder acceptance decisions based on a weighted sum of fairness and self-interest. Fairness is calculated as the ratio of the responder's share to their contribution. Two learnable parameters, fairness_weight and self_interest_weight, determine the relative importance of each factor.",20250128_150709,0.5970442957328653,,0.20066019981429067,,,,,,,,,,,
19,63.10674163083645,U_accept = fairness_weight * (split_perc_self - (token_self / (token_self + token_opp)) * 100) + self_interest_weight * split_perc_self,"A linear utility model for responder acceptance decisions, combining fairness and self-interest.  Fairness is calculated as the difference between the participant's percentage of the earnings and their proportionally fair share based on token contributions. The model has two learnable parameters representing the weights assigned to fairness and self-interest.",20250128_150709,0.7278954712631897,,0.8076102542285891,,,,,,,,,,,
5,214.99901219397438,U_accept = self_interest_weight * split_self + fairness_weight * (split_self / token_self - split_opp / token_opp),"A linear utility model for responder acceptance decisions, balancing self-interest (weighted by `self_interest_weight`) and fairness (weighted by `fairness_weight`). Fairness is assessed as the difference in the ratio of proposed share to tokens between the participant and the opponent.  The model has two learnable parameters: `self_interest_weight` and `fairness_weight`.",20250128_150709,0.8627649930638326,,0.6227558529561302,,,,,,,,,,,
3,246.3327282561404,U_accept =  alpha * (split_self) + beta * ( (splitperc_self / (token_self / (token_self + token_opp)) ) - (splitperc_opp / (token_opp / (token_self + token_opp))) ),"A linear utility model for accepting an offer, combining the weighted influence of self-interest (monetary gain) and fairness.  Fairness is operationalized as the difference between the percentage share received by each player relative to their contribution. The model uses two learnable parameters: alpha (weight of self-interest) and beta (weight of fairness).",20250128_150709,,,,0.14729363275876653,0.8146858562591207,,,,,,,,,
20,272.3962780037871,U = fairness_weight * (splitperc_self - 50) + contribution_sensitivity * (token_self / token_opp) * (splitperc_self - 50),A linear utility model for responder behavior in an ultimatum game.  Utility is a function of the percentage of earnings offered to the responder and the ratio of the responder's contribution to the opponent's contribution. Two learnable parameters capture the weight given to fairness and the sensitivity to the contribution ratio.  The model assumes that a 50% split is considered neutral in terms of fairness.,20250128_150709,,,0.10954304147708173,,,,,,,,,,,-0.02962659162034509
15,432.2214616840222,U_accept = exp(fairness_weight * log(1 + (combined_earning/2 - split_self)^2)) * exp(self_interest_sensitivity * split_self),"A multiplicative utility model for responder acceptance decisions, incorporating fairness and self-interest. Fairness is modeled as a penalty for deviation from an equal split, while self-interest is a positive function of the responder's proposed share.  The model uses two learnable parameters: a fairness weight and a self-interest sensitivity, both constrained to positive values.",20250128_150709,,,0.17454653666484574,,,,,,,,0.23142291780130614,,,
13,721.3916936359865,U_accept = fairness_weight * (splitperc_self - (combined_earning / (token_self + token_opp) ) * 100) + self_interest_weight * split_self,A linear utility model for responder behavior in a bargaining game. Utility is a weighted sum of fairness and self-interest. Fairness is assessed as the difference between the participant's percentage share and a fair share based on token contributions. Self-interest is simply the proposed amount for the participant.  Two learnable parameters represent the weights assigned to fairness and self-interest.,20250128_150709,-0.03160623289118586,,0.14905290778448785,,,,,,,,,,,
