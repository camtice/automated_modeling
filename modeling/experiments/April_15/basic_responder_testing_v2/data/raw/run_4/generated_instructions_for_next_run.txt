```text
Instructions:
<think>
The previous model had good recovery for alpha and beta, but poor recovery for kappa, and the accuracy was middling, though the BIC score was the best so far. While this run was very good, and represents the current best, it is important to improve more and to not be content with the current best model. It seems that adding kappa did not really improve the model's accuracy, recovery, or BIC by very much. Therefore, it might be best to remove kappa, and add a new parameter that would have a higher likelihood of improving the performance. The current model also had issues with fair share, so that is a good place to add more complexity.

Here's what I'll do:

1. **Rethink the Status Quo Bias:** The status quo bias (kappa) didn't seem to add much value. Instead of a simple binary status quo, explore a continuous measure of relative contribution. For example, the *difference* between the participant's tokens and the opponent's tokens (token_self - token_opp) could directly modulate the utility.
2. **Fairness and Trial Type Interaction:** Trial type clearly influences fairness perception. Directly incorporate trial_type into the FairShare calculation. Instead of just using the token ratio, add a trial_type-dependent offset to the fair share. This could be implemented with learnable parameters for each trial type.
3. **Non-Linear Amount Sensitivity:** Consider that the effect of split_self on utility might not be linear. Explore a non-linear transformation of split_self, perhaps using a power law or logarithmic function, controlled by a learnable parameter 'xi'.
4. **Prior Knowledge on Parameter Ranges:** Alpha and beta are fairness and amount sensitivity parameters. Given the context, are people more sensitive to fairness or amount? Use this prior knowledge to inform the parameter ranges. For instance, if you believe amount sensitivity is generally higher, set a wider range for beta than for alpha.
5.  **Try hyperbolic aversion, instead of log or linear**: The previous models have only tried log or linear aversion.

</think>

Be VERY considerate of high covariance between learnable parameters in the model. Aim for an appropriate number of learnable parameters, with a slight bias toward fewer if it improves parameter identifiability. The model should propose a significantly different BIC than previous models.

When developing your model, reason step by step about:

*   The key psychological mechanisms involved, including fairness, loss aversion, and amount sensitivity.
*   How these mechanisms interact, including potential multiplicative or non-linear interactions. Specifically, consider interactions between fairness sensitivity (alpha) and amount sensitivity (beta), as well as the role of combined_earning in modulating fairness perception.
*   What mathematical form could capture these interactions, exploring options beyond standard linear or power law functions. Explore non-linear loss aversion functions (e.g., hyperbolic) and alternative ways to model fairness perception, perhaps by incorporating trial_type directly into the FairShare calculation.
*   What parameters would be needed to calibrate the model, carefully considering potential parameter covariance and identifiability issues. What are reasonable estimates of each learnable parameter? What is a reasonable prior range for fairness sensitivity (alpha), and amount sensitivity (beta)?
*   How the model variables map to observable behavior.
*   Incorporate any prior knowledge or constraints that could reduce parameter covariance and improve parameter identifiability. What are reasonable estimates of each learnable parameter? Consider a continuous measure of relative contribution (token_self - token_opp) to modulate utility. Directly incorporate trial_type into the FairShare calculation with learnable offsets. Explore non-linear transformations of split_self.
```