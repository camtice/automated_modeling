```text
Instructions:
<think>
The previous model performed poorly in terms of parameter recovery, accuracy, and BIC. The trial type offsets were not identifiable, and alpha and beta were also poorly recovered. This suggests a problem with the model's structure, likely high covariance between the trial type offsets and potentially with alpha/beta. The hyperbolic aversion formulation may not be ideal, or the way FairShare is calculated.

Here's what I'll do to improve:

1.  **Simplify FairShare:** Revert to a simpler FairShare calculation, focusing on the core token ratio but still incorporating trial_type. Instead of additive offsets, try multiplicative modulation of the token ratio based on trial_type. This might reduce covariance.
2.  **Explore a Different Loss Aversion Function:** The hyperbolic aversion didn't work well. Try a power law function or a simple difference with a threshold. This will give the model more flexibility in capturing loss aversion.
3.  **Interaction between Alpha and Combined Earning:** Explore an explicit interaction between alpha (fairness sensitivity) and combined_earning. People might be *more* fairness-sensitive when *more* is at stake. Try modulating alpha by a function of combined_earning (e.g., alpha * combined_earning^gamma, where gamma is a learnable parameter).
4.  **Amount Sensitivity with Diminishing Returns:** Instead of a linear or simple ratio for amount sensitivity, consider a logarithmic or power function to reflect diminishing returns. The subjective value of an additional dollar decreases as the total amount increases.
5.  **Consider a Hybrid Approach:** Combine elements that worked in past models (e.g., the simpler FairShare from earlier models) with new ideas (e.g., the alpha/combined_earning interaction).
6.   **Focus on Parameter Identifiability**:  Carefully consider which parameters are truly necessary and whether their effects can be disentangled.  If trial-type is causing problems, think about *why*. Is it inherently difficult to quantify these effects, or is it just the *way* they are being included? If the latter, think about better ways to include it.

</think>

Be VERY considerate of high covariance between learnable parameters in the model. Aim for an appropriate number of learnable parameters, with a slight bias toward fewer if it improves parameter identifiability. The model should propose a significantly different BIC than previous models.

When developing your model, reason step by step about:

*   The key psychological mechanisms involved, including fairness, loss aversion, and amount sensitivity.
*   How these mechanisms interact, including potential multiplicative or non-linear interactions. Specifically, consider interactions between fairness sensitivity (alpha) and combined_earning, as well as the role of trial_type in modulating fairness perception.
*   What mathematical form could capture these interactions, exploring options beyond standard linear or power law functions. Explore alternative loss aversion functions (e.g., power law, threshold-based) and alternative ways to model fairness perception, perhaps by incorporating trial_type directly into the token ratio calculation.
*   What parameters would be needed to calibrate the model, carefully considering potential parameter covariance and identifiability issues. What are reasonable estimates of each learnable parameter? What is a reasonable prior range for fairness sensitivity (alpha), amount sensitivity (beta), and the new gamma parameter for alpha/combined_earning interaction?
*   How the model variables map to observable behavior.
*   Incorporate any prior knowledge or constraints that could reduce parameter covariance and improve parameter identifiability. What are reasonable estimates of each learnable parameter? Consider multiplicative modulation of the token ratio based on trial_type. Explore a logarithmic or power function for amount sensitivity.
```