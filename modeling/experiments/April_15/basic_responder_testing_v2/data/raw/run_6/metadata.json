{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "```text\nInstructions:\n<think>\nThe previous model had good recovery for alpha and beta, but poor recovery for kappa, and the accuracy was middling, though the BIC score was the best so far. While this run was very good, and represents the current best, it is important to improve more and to not be content with the current best model. It seems that adding kappa did not really improve the model's accuracy, recovery, or BIC by very much. Therefore, it might be best to remove kappa, and add a new parameter that would have a higher likelihood of improving the performance. The current model also had issues with fair share, so that is a good place to add more complexity.\n\nHere's what I'll do:\n\n1. **Rethink the Status Quo Bias:** The status quo bias (kappa) didn't seem to add much value. Instead of a simple binary status quo, explore a continuous measure of relative contribution. For example, the *difference* between the participant's tokens and the opponent's tokens (token_self - token_opp) could directly modulate the utility.\n2. **Fairness and Trial Type Interaction:** Trial type clearly influences fairness perception. Directly incorporate trial_type into the FairShare calculation. Instead of just using the token ratio, add a trial_type-dependent offset to the fair share. This could be implemented with learnable parameters for each trial type.\n3. **Non-Linear Amount Sensitivity:** Consider that the effect of split_self on utility might not be linear. Explore a non-linear transformation of split_self, perhaps using a power law or logarithmic function, controlled by a learnable parameter 'xi'.\n4. **Prior Knowledge on Parameter Ranges:** Alpha and beta are fairness and amount sensitivity parameters. Given the context, are people more sensitive to fairness or amount? Use this prior knowledge to inform the parameter ranges. For instance, if you believe amount sensitivity is generally higher, set a wider range for beta than for alpha.\n5.  **Try hyperbolic aversion, instead of log or linear**: The previous models have only tried log or linear aversion.\n\n</think>\n\nBe VERY considerate of high covariance between learnable parameters in the model. Aim for an appropriate number of learnable parameters, with a slight bias toward fewer if it improves parameter identifiability. The model should propose a significantly different BIC than previous models.\n\nWhen developing your model, reason step by step about:\n\n*   The key psychological mechanisms involved, including fairness, loss aversion, and amount sensitivity.\n*   How these mechanisms interact, including potential multiplicative or non-linear interactions. Specifically, consider interactions between fairness sensitivity (alpha) and amount sensitivity (beta), as well as the role of combined_earning in modulating fairness perception.\n*   What mathematical form could capture these interactions, exploring options beyond standard linear or power law functions. Explore non-linear loss aversion functions (e.g., hyperbolic) and alternative ways to model fairness perception, perhaps by incorporating trial_type directly into the FairShare calculation.\n*   What parameters would be needed to calibrate the model, carefully considering potential parameter covariance and identifiability issues. What are reasonable estimates of each learnable parameter? What is a reasonable prior range for fairness sensitivity (alpha), and amount sensitivity (beta)?\n*   How the model variables map to observable behavior.\n*   Incorporate any prior knowledge or constraints that could reduce parameter covariance and improve parameter identifiability. What are reasonable estimates of each learnable parameter? Consider a continuous measure of relative contribution (token_self - token_opp) to modulate utility. Directly incorporate trial_type into the FairShare calculation with learnable offsets. Explore non-linear transformations of split_self.\n```",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: ```text\nInstructions:\n<think>\nThe previous model had good recovery for alpha and beta, but poor recovery for kappa, and the accuracy was middling, though the BIC score was the best so far. While this run was very good, and represents the current best, it is important to improve more and to not be content with the current best model. It seems that adding kappa did not really improve the model's accuracy, recovery, or BIC by very much. Therefore, it might be best to remove kappa, and add a new parameter that would have a higher likelihood of improving the performance. The current model also had issues with fair share, so that is a good place to add more complexity.\n\nHere's what I'll do:\n\n1. **Rethink the Status Quo Bias:** The status quo bias (kappa) didn't seem to add much value. Instead of a simple binary status quo, explore a continuous measure of relative contribution. For example, the *difference* between the participant's tokens and the opponent's tokens (token_self - token_opp) could directly modulate the utility.\n2. **Fairness and Trial Type Interaction:** Trial type clearly influences fairness perception. Directly incorporate trial_type into the FairShare calculation. Instead of just using the token ratio, add a trial_type-dependent offset to the fair share. This could be implemented with learnable parameters for each trial type.\n3. **Non-Linear Amount Sensitivity:** Consider that the effect of split_self on utility might not be linear. Explore a non-linear transformation of split_self, perhaps using a power law or logarithmic function, controlled by a learnable parameter 'xi'.\n4. **Prior Knowledge on Parameter Ranges:** Alpha and beta are fairness and amount sensitivity parameters. Given the context, are people more sensitive to fairness or amount? Use this prior knowledge to inform the parameter ranges. For instance, if you believe amount sensitivity is generally higher, set a wider range for beta than for alpha.\n5.  **Try hyperbolic aversion, instead of log or linear**: The previous models have only tried log or linear aversion.\n\n</think>\n\nBe VERY considerate of high covariance between learnable parameters in the model. Aim for an appropriate number of learnable parameters, with a slight bias toward fewer if it improves parameter identifiability. The model should propose a significantly different BIC than previous models.\n\nWhen developing your model, reason step by step about:\n\n*   The key psychological mechanisms involved, including fairness, loss aversion, and amount sensitivity.\n*   How these mechanisms interact, including potential multiplicative or non-linear interactions. Specifically, consider interactions between fairness sensitivity (alpha) and amount sensitivity (beta), as well as the role of combined_earning in modulating fairness perception.\n*   What mathematical form could capture these interactions, exploring options beyond standard linear or power law functions. Explore non-linear loss aversion functions (e.g., hyperbolic) and alternative ways to model fairness perception, perhaps by incorporating trial_type directly into the FairShare calculation.\n*   What parameters would be needed to calibrate the model, carefully considering potential parameter covariance and identifiability issues. What are reasonable estimates of each learnable parameter? What is a reasonable prior range for fairness sensitivity (alpha), and amount sensitivity (beta)?\n*   How the model variables map to observable behavior.\n*   Incorporate any prior knowledge or constraints that could reduce parameter covariance and improve parameter identifiability. What are reasonable estimates of each learnable parameter? Consider a continuous measure of relative contribution (token_self - token_opp) to modulate utility. Directly incorporate trial_type into the FairShare calculation with learnable offsets. Explore non-linear transformations of split_self.\n```\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Okay, let's break down this complex modeling task step by step, incorporating the insights from the previous attempts and focusing on improving parameter recovery and accuracy.\n\n**1. Psychological Mechanisms and Interactions:**\n\n*   **Fairness:**  Fairness remains central. I'll use a \"FairShare\" concept, but make it more context-dependent. The `trial_type` variable will directly influence the perceived fair share.\n*   **Amount Sensitivity:** How sensitive are participants to the absolute amount of money offered? This will be captured by a parameter and how it impacts the utility of `split_self`.\n*   **Loss Aversion:** Rejection of offers can be viewed as avoiding a perceived loss. Instead of a simple difference, I want to try hyperbolic aversion.\n*   **Interaction:** I hypothesize that fairness sensitivity and amount sensitivity interact. A multiplicative interaction will be used. Also, `combined_earning` will play a crucial role in calibrating fairness perception, as equal splits mean different things depending on how much was at stake.\n\n**2. Mathematical Formulation:**\n\n*   **FairShare:** This is the trickiest part. I will calculate it as a function of `token_self`, `token_opp`, `combined_earning`, and, crucially, `trial_type`. Each trial type will have a learnable offset.\n\n*   **Utility Function:** The utility will be a combination of amount received, fairness perception, and potentially a term related to relative contribution. I'll use a logistic function to map utility to probability of acceptance.\n\n*Hyperbolic Aversion:*\n    U(x) = x/(x + alpha), where alpha is a constant that governs the degree of aversion.\n\n**3. Parameters and Ranges:**\n\n*   `alpha` (Fairness Sensitivity): Needs to be bounded, but generously. Since fairness is important, let's give it a larger range.\n*   `beta` (Amount Sensitivity): Also needs to be bounded.\n*   `trial_type_offset_equal` (Trial Type Offset - Equal): a learnable offset applied when `trial_type` is 1 (equal).\n*   `trial_type_offset_opponent_more` (Trial Type Offset - Opponent More): a learnable offset applied when `trial_type` is 2 (opponent more).\n*   `trial_type_offset_self_more` (Trial Type Offset - Self More): a learnable offset applied when `trial_type` is 3 (self more).\n\n**4. Mapping to Observable Behavior:**\n\nThe model predicts the probability of accepting the offer (`accept`).\n\n**5. Model Specification:**\n\n```\n<MODEL>\nFairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))\n</MODEL>\n```\n\n```json\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the offer\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"FairShare\": {\n      \"description\": \"The calculated fair share for the participant, based on tokens and trial type\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"Fairness\": {\n      \"description\": \"The difference between the calculated fair share and the offered split for the participant. Positive value indicates the participant is being offered more than their fair share, negative value indicates they are being offered less.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Fairness sensitivity parameter; governs the degree of hyperbolic aversion to unfairness. Higher values indicate greater sensitivity to deviations from the perceived fair share.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Amount sensitivity parameter; modulates the utility derived from the proposed split_self amount.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"The total amount of money earned in the round (tokens * 3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed amount of money for the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"trial_type\": {\n      \"description\": \"Indicates whether the contribution was equal, opponent more, or participant more.\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 3\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n     \"trial_type_offset_equal\": {\n      \"description\": \"Offset to the fair share when trial_type is equal\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_opponent_more\": {\n      \"description\": \"Offset to the fair share when trial_type is opponent more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_self_more\": {\n      \"description\": \"Offset to the fair share when trial_type is self more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n```\n\n```\n<target_variable>accept</target_variable>\n```\n\n```\n<SUMMARY>\nA utility model predicting acceptance of offers based on a hyperbolic aversion to unfairness. The model calculates a 'FairShare' influenced by token contributions and trial type-specific offsets. The utility is determined by the amount offered (split_self), fairness sensitivity (alpha), amount sensitivity (beta), and the degree of fairness. The model includes learnable parameters for fairness sensitivity (alpha), amount sensitivity (beta), and trial type-specific offsets, allowing it to capture context-dependent fairness perceptions.\n</SUMMARY>\n```"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['alpha', 'beta', 'trial_type_offset_equal', 'trial_type_offset_opponent_more', 'trial_type_offset_self_more']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                FairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the offer\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"FairShare\": {\n      \"description\": \"The calculated fair share for the participant, based on tokens and trial type\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"Fairness\": {\n      \"description\": \"The difference between the calculated fair share and the offered split for the participant. Positive value indicates the participant is being offered more than their fair share, negative value indicates they are being offered less.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Fairness sensitivity parameter; governs the degree of hyperbolic aversion to unfairness. Higher values indicate greater sensitivity to deviations from the perceived fair share.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Amount sensitivity parameter; modulates the utility derived from the proposed split_self amount.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"The total amount of money earned in the round (tokens * 3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed amount of money for the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"trial_type\": {\n      \"description\": \"Indicates whether the contribution was equal, opponent more, or participant more.\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 3,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"trial_type_offset_equal\": {\n      \"description\": \"Offset to the fair share when trial_type is equal\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_opponent_more\": {\n      \"description\": \"Offset to the fair share when trial_type is opponent more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_self_more\": {\n      \"description\": \"Offset to the fair share when trial_type is self more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, alpha=1, beta=1, trial_type_offset_equal=0, trial_type_offset_opponent_more=0, trial_type_offset_self_more=0):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n        trial_type = trial.get(\"trial_type\", 1)\n\n        # Calculate FairShare\n        FairShare = (combined_earning * token_self / (token_self + token_opp))\n        if trial_type == 1:\n            FairShare += trial_type_offset_equal\n        elif trial_type == 2:\n            FairShare += trial_type_offset_opponent_more\n        elif trial_type == 3:\n            FairShare += trial_type_offset_self_more\n\n        # Calculate Fairness\n        Fairness = FairShare - split_self\n\n        # Calculate Utility\n        U = beta * (split_self / (split_self + alpha * abs(Fairness)))\n\n        model_predictions.append(U)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '''\n[\n  {\n    \"ID\": 1,\n    \"group\": \"control\",\n    \"trial_number\": 1,\n    \"trial_type\": 1,\n    \"trial_role\": 1,\n    \"token_opp\": 10,\n    \"token_self\": 10,\n    \"combined_earning\": 60,\n    \"split_opp\": 30.0,\n    \"split_self\": 30.0,\n    \"splitperc_opp\": 50,\n    \"splitperc_self\": 50,\n    \"accept\": 1.0,\n    \"accepted_amount\": 30.0,\n    \"accepted_perc\": 50.0,\n    \"proposed_perc\": 50.0,\n    \"proposed_amount\": 30.0\n  },\n  {\n    \"ID\": 2,\n    \"group\": \"control\",\n    \"trial_number\": 2,\n    \"trial_type\": 2,\n    \"trial_role\": 1,\n    \"token_opp\": 15,\n    \"token_self\": 5,\n    \"combined_earning\": 60,\n    \"split_opp\": 40.0,\n    \"split_self\": 20.0,\n    \"splitperc_opp\": 67,\n    \"splitperc_self\": 33,\n    \"accept\": 0.0,\n    \"accepted_amount\": 0.0,\n    \"accepted_perc\": 0.0,\n    \"proposed_perc\": 33.0,\n    \"proposed_amount\": 20.0\n  },\n  {\n    \"ID\": 3,\n    \"group\": \"control\",\n    \"trial_number\": 3,\n    \"trial_type\": 3,\n    \"trial_role\": 1,\n    \"token_opp\": 5,\n    \"token_self\": 15,\n    \"combined_earning\": 60,\n    \"split_opp\": 20.0,\n    \"split_self\": 40.0,\n    \"splitperc_opp\": 33,\n    \"splitperc_self\": 67,\n    \"accept\": 1.0,\n    \"accepted_amount\": 40.0,\n    \"accepted_perc\": 67.0,\n    \"proposed_perc\": 67.0,\n    \"proposed_amount\": 40.0\n  }\n]\n'''\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n```",
      "timestamp": 1744713875.012523
    }
  ],
  "learnable_parameters": {
    "alpha": {
      "description": "Fairness sensitivity parameter; governs the degree of hyperbolic aversion to unfairness. Higher values indicate greater sensitivity to deviations from the perceived fair share.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Amount sensitivity parameter; modulates the utility derived from the proposed split_self amount.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "trial_type_offset_equal": {
      "description": "Offset to the fair share when trial_type is equal",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "trial_type_offset_opponent_more": {
      "description": "Offset to the fair share when trial_type is opponent more",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "trial_type_offset_self_more": {
      "description": "Offset to the fair share when trial_type is self more",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "FairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the offer",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "FairShare": {
      "description": "The calculated fair share for the participant, based on tokens and trial type",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "Fairness": {
      "description": "The difference between the calculated fair share and the offered split for the participant. Positive value indicates the participant is being offered more than their fair share, negative value indicates they are being offered less.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "alpha": {
      "description": "Fairness sensitivity parameter; governs the degree of hyperbolic aversion to unfairness. Higher values indicate greater sensitivity to deviations from the perceived fair share.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Amount sensitivity parameter; modulates the utility derived from the proposed split_self amount.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "token_opp": {
      "description": "Number of tokens found by the opponent",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by the participant",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "The total amount of money earned in the round (tokens * 3)",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "split_self": {
      "description": "The proposed amount of money for the participant",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "trial_type": {
      "description": "Indicates whether the contribution was equal, opponent more, or participant more.",
      "range": {
        "min": 1,
        "max": 3,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "trial_type_offset_equal": {
      "description": "Offset to the fair share when trial_type is equal",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "trial_type_offset_opponent_more": {
      "description": "Offset to the fair share when trial_type is opponent more",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "trial_type_offset_self_more": {
      "description": "Offset to the fair share when trial_type is self more",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_summary": "A utility model predicting acceptance of offers based on a hyperbolic aversion to unfairness. The model calculates a 'FairShare' influenced by token contributions and trial type-specific offsets. The utility is determined by the amount offered (split_self), fairness sensitivity (alpha), amount sensitivity (beta), and the degree of fairness. The model includes learnable parameters for fairness sensitivity (alpha), amount sensitivity (beta), and trial type-specific offsets, allowing it to capture context-dependent fairness perceptions.",
  "target_variable": "accept",
  "full_reasoning": "Okay, let's break down this complex modeling task step by step, incorporating the insights from the previous attempts and focusing on improving parameter recovery and accuracy.\n\n**1. Psychological Mechanisms and Interactions:**\n\n*   **Fairness:**  Fairness remains central. I'll use a \"FairShare\" concept, but make it more context-dependent. The `trial_type` variable will directly influence the perceived fair share.\n*   **Amount Sensitivity:** How sensitive are participants to the absolute amount of money offered? This will be captured by a parameter and how it impacts the utility of `split_self`.\n*   **Loss Aversion:** Rejection of offers can be viewed as avoiding a perceived loss. Instead of a simple difference, I want to try hyperbolic aversion.\n*   **Interaction:** I hypothesize that fairness sensitivity and amount sensitivity interact. A multiplicative interaction will be used. Also, `combined_earning` will play a crucial role in calibrating fairness perception, as equal splits mean different things depending on how much was at stake.\n\n**2. Mathematical Formulation:**\n\n*   **FairShare:** This is the trickiest part. I will calculate it as a function of `token_self`, `token_opp`, `combined_earning`, and, crucially, `trial_type`. Each trial type will have a learnable offset.\n\n*   **Utility Function:** The utility will be a combination of amount received, fairness perception, and potentially a term related to relative contribution. I'll use a logistic function to map utility to probability of acceptance.\n\n*Hyperbolic Aversion:*\n    U(x) = x/(x + alpha), where alpha is a constant that governs the degree of aversion.\n\n**3. Parameters and Ranges:**\n\n*   `alpha` (Fairness Sensitivity): Needs to be bounded, but generously. Since fairness is important, let's give it a larger range.\n*   `beta` (Amount Sensitivity): Also needs to be bounded.\n*   `trial_type_offset_equal` (Trial Type Offset - Equal): a learnable offset applied when `trial_type` is 1 (equal).\n*   `trial_type_offset_opponent_more` (Trial Type Offset - Opponent More): a learnable offset applied when `trial_type` is 2 (opponent more).\n*   `trial_type_offset_self_more` (Trial Type Offset - Self More): a learnable offset applied when `trial_type` is 3 (self more).\n\n**4. Mapping to Observable Behavior:**\n\nThe model predicts the probability of accepting the offer (`accept`).\n\n**5. Model Specification:**\n\n```\n<MODEL>\nFairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))\n</MODEL>\n```\n\n```json\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the offer\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"FairShare\": {\n      \"description\": \"The calculated fair share for the participant, based on tokens and trial type\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"Fairness\": {\n      \"description\": \"The difference between the calculated fair share and the offered split for the participant. Positive value indicates the participant is being offered more than their fair share, negative value indicates they are being offered less.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Fairness sensitivity parameter; governs the degree of hyperbolic aversion to unfairness. Higher values indicate greater sensitivity to deviations from the perceived fair share.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Amount sensitivity parameter; modulates the utility derived from the proposed split_self amount.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"The total amount of money earned in the round (tokens * 3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed amount of money for the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"trial_type\": {\n      \"description\": \"Indicates whether the contribution was equal, opponent more, or participant more.\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 3\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n     \"trial_type_offset_equal\": {\n      \"description\": \"Offset to the fair share when trial_type is equal\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_opponent_more\": {\n      \"description\": \"Offset to the fair share when trial_type is opponent more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"trial_type_offset_self_more\": {\n      \"description\": \"Offset to the fair share when trial_type is self more\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n```\n\n```\n<target_variable>accept</target_variable>\n```\n\n```\n<SUMMARY>\nA utility model predicting acceptance of offers based on a hyperbolic aversion to unfairness. The model calculates a 'FairShare' influenced by token contributions and trial type-specific offsets. The utility is determined by the amount offered (split_self), fairness sensitivity (alpha), amount sensitivity (beta), and the degree of fairness. The model includes learnable parameters for fairness sensitivity (alpha), amount sensitivity (beta), and trial type-specific offsets, allowing it to capture context-dependent fairness perceptions.\n</SUMMARY>\n```",
  "prediction_type": "utility",
  "current_model": "Specification: FairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))\nSummary: A utility model predicting acceptance of offers based on a hyperbolic aversion to unfairness. The model calculates a 'FairShare' influenced by token contributions and trial type-specific offsets. The utility is determined by the amount offered (split_self), fairness sensitivity (alpha), amount sensitivity (beta), and the degree of fairness. The model includes learnable parameters for fairness sensitivity (alpha), amount sensitivity (beta), and trial type-specific offsets, allowing it to capture context-dependent fairness perceptions.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, alpha=1, beta=1, trial_type_offset_equal=0, trial_type_offset_opponent_more=0, trial_type_offset_self_more=0):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n        trial_type = trial.get(\"trial_type\", 1)\n\n        # Calculate FairShare\n        FairShare = (combined_earning * token_self / (token_self + token_opp))\n        if trial_type == 1:\n            FairShare += trial_type_offset_equal\n        elif trial_type == 2:\n            FairShare += trial_type_offset_opponent_more\n        elif trial_type == 3:\n            FairShare += trial_type_offset_self_more\n\n        # Calculate Fairness\n        Fairness = FairShare - split_self\n\n        # Calculate Utility\n        U = beta * (split_self / (split_self + alpha * abs(Fairness)))\n\n        model_predictions.append(U)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.6697191697191697,
  "fitting_results": [
    {
      "alpha": 80.8132931401994,
      "beta": 0.0,
      "trial_type_offset_equal": -28.921252085405147,
      "trial_type_offset_opponent_more": -34.528144559622206,
      "trial_type_offset_self_more": -65.39547856637442,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 91.54576199211246,
      "beta": 48.501249928130235,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -0.1377579555226683,
      "success": true,
      "log_likelihood": -20.5154481240487,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 55.83900274491412,
      "beta": 50.428437602263216,
      "trial_type_offset_equal": 72.58397718762627,
      "trial_type_offset_opponent_more": -92.96144284834318,
      "trial_type_offset_self_more": -0.30645023674391486,
      "success": true,
      "log_likelihood": -19.281789447755024,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 49.40603030677309,
      "trial_type_offset_equal": 78.28948484515503,
      "trial_type_offset_opponent_more": -82.54185580582252,
      "trial_type_offset_self_more": 0.9666009199921632,
      "success": true,
      "log_likelihood": -22.46382159913667,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 70.93051900839029,
      "beta": 100.0,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": -100.0,
      "trial_type_offset_self_more": -0.7331041999155917,
      "success": true,
      "log_likelihood": -18.195627384738756,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 95.07216966096694,
      "beta": 39.38659978888185,
      "trial_type_offset_equal": -1.1321974569245947,
      "trial_type_offset_opponent_more": -1.7728114278801126,
      "trial_type_offset_self_more": -0.11092395797454581,
      "success": true,
      "log_likelihood": -15.992183515101313,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 100.0,
      "trial_type_offset_equal": -91.56771527115102,
      "trial_type_offset_opponent_more": 12.608763091287468,
      "trial_type_offset_self_more": 3.709209114214784,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 52.130971380954485,
      "trial_type_offset_equal": -0.13252535533478238,
      "trial_type_offset_opponent_more": -2.3205006135661055,
      "trial_type_offset_self_more": -0.5843709308937719,
      "success": true,
      "log_likelihood": -15.169159798357374,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 98.827768166904,
      "trial_type_offset_equal": -35.633223323866666,
      "trial_type_offset_opponent_more": -4.280996307959152,
      "trial_type_offset_self_more": 49.569714941864724,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 43.08532421424807,
      "trial_type_offset_equal": -100.0,
      "trial_type_offset_opponent_more": 91.9897609564299,
      "trial_type_offset_self_more": -0.3981766022023744,
      "success": true,
      "log_likelihood": -20.58765171129494,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 89.3816373878737,
      "beta": 54.662601244007355,
      "trial_type_offset_equal": 40.624540548457375,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": 0.054870201176234215,
      "success": true,
      "log_likelihood": -20.445188344643434,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 72.69615553733155,
      "beta": 0.0,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": -75.21486311084176,
      "trial_type_offset_self_more": -100.0,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 41.916676419312495,
      "beta": 14.004387496401716,
      "trial_type_offset_equal": -37.59615045244544,
      "trial_type_offset_opponent_more": 30.748004993949305,
      "trial_type_offset_self_more": -0.22506597048855417,
      "success": true,
      "log_likelihood": -21.437882078347904,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.1269245468603815e-15,
      "beta": 53.035441286521674,
      "trial_type_offset_equal": 31.79693955217217,
      "trial_type_offset_opponent_more": -84.79668232821699,
      "trial_type_offset_self_more": 80.85230807175608,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 100.0,
      "trial_type_offset_equal": 88.04352788192286,
      "trial_type_offset_opponent_more": -8.385071125695024,
      "trial_type_offset_self_more": -79.28556942389902,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.034940544822624986,
      "beta": 100.0,
      "trial_type_offset_equal": -8.774501040502344,
      "trial_type_offset_opponent_more": -2.9890383768161986,
      "trial_type_offset_self_more": -27.940940306492934,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.904821984717732e-15,
      "beta": 56.83862296774023,
      "trial_type_offset_equal": 49.19521226402885,
      "trial_type_offset_opponent_more": 47.25237323035513,
      "trial_type_offset_self_more": -4.165658931887098,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 15.193167312212582,
      "beta": 100.0,
      "trial_type_offset_equal": 5.171757953332301,
      "trial_type_offset_opponent_more": -15.495123694314126,
      "trial_type_offset_self_more": 3.343076458860776,
      "success": true,
      "log_likelihood": -8.980706822754323,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 51.00951131999539,
      "beta": 100.0,
      "trial_type_offset_equal": -1.6233993491884053,
      "trial_type_offset_opponent_more": -0.43898138860565616,
      "trial_type_offset_self_more": -1.2490270560498076,
      "success": true,
      "log_likelihood": -6.634759930009987,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.7721464117700761e-15,
      "beta": 100.0,
      "trial_type_offset_equal": -0.9340995875000047,
      "trial_type_offset_opponent_more": -29.577488784439726,
      "trial_type_offset_self_more": -1.7416002415640033,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 50.24822497521913,
      "trial_type_offset_equal": -0.9347259339802407,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -0.1809577560251305,
      "success": true,
      "log_likelihood": -17.0877792306555,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.671411420590229,
      "beta": 100.0,
      "trial_type_offset_equal": 27.56025037196733,
      "trial_type_offset_opponent_more": 91.91472688548824,
      "trial_type_offset_self_more": -40.06623319629963,
      "success": true,
      "log_likelihood": -10.455798891801477,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 24.611763060179555,
      "trial_type_offset_equal": -0.5184000241851363,
      "trial_type_offset_opponent_more": -63.60519063886311,
      "trial_type_offset_self_more": -77.67176637124874,
      "success": true,
      "log_likelihood": -23.223503336848676,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 99.3375127360343,
      "beta": 29.73778695207166,
      "trial_type_offset_equal": -0.4520494925054057,
      "trial_type_offset_opponent_more": -28.716341418251922,
      "trial_type_offset_self_more": 0.5785984916892679,
      "success": true,
      "log_likelihood": -21.18333637967347,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 67.79029345460744,
      "beta": 100.0,
      "trial_type_offset_equal": 76.89099638965946,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -0.7151280726681624,
      "success": true,
      "log_likelihood": -18.118002545054402,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 84.7428569099606,
      "beta": 42.68528654912682,
      "trial_type_offset_equal": -0.10929466534430388,
      "trial_type_offset_opponent_more": -41.13040943580199,
      "trial_type_offset_self_more": -0.5136472029042699,
      "success": true,
      "log_likelihood": -18.2294671494883,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 94.8927846484673,
      "beta": 23.462411414385503,
      "trial_type_offset_equal": -0.5025880791241505,
      "trial_type_offset_opponent_more": 34.32683572690059,
      "trial_type_offset_self_more": -0.3651616036586311,
      "success": true,
      "log_likelihood": -19.919118273062832,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 81.79622219845544,
      "beta": 0.0,
      "trial_type_offset_equal": -67.30346308756855,
      "trial_type_offset_opponent_more": -82.70616894279861,
      "trial_type_offset_self_more": -65.30361970340418,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 44.270896290191416,
      "beta": 86.86946649642478,
      "trial_type_offset_equal": -0.7086468234286788,
      "trial_type_offset_opponent_more": 0.27200187402191234,
      "trial_type_offset_self_more": -1.245499768158686,
      "success": true,
      "log_likelihood": -8.235684601629057,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 66.36763416830532,
      "trial_type_offset_equal": -0.8989747332238636,
      "trial_type_offset_opponent_more": -1.3084635285186694,
      "trial_type_offset_self_more": -0.7007325444781021,
      "success": true,
      "log_likelihood": -13.592902341280848,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.686732105596328e-16,
      "beta": 100.0,
      "trial_type_offset_equal": 55.26417028943493,
      "trial_type_offset_opponent_more": -19.640266398415918,
      "trial_type_offset_self_more": -65.0702301402912,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 37.84530030068801,
      "beta": 0.0,
      "trial_type_offset_equal": -28.67530087341042,
      "trial_type_offset_opponent_more": 61.396111831700104,
      "trial_type_offset_self_more": -38.69659538402704,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 42.01846290382336,
      "trial_type_offset_equal": -79.79821286383495,
      "trial_type_offset_opponent_more": -2.005070677849409,
      "trial_type_offset_self_more": 100.0,
      "success": true,
      "log_likelihood": -22.86612516427049,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 26.23754936471692,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": -1.788213468918775,
      "trial_type_offset_self_more": 0.4462040348362346,
      "success": true,
      "log_likelihood": -22.01747664579418,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.5525631619973228e-15,
      "beta": 53.32161170968716,
      "trial_type_offset_equal": -82.43588722688386,
      "trial_type_offset_opponent_more": -89.21330626484374,
      "trial_type_offset_self_more": -30.032564003741335,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 57.18348782816127,
      "beta": 26.320947251310823,
      "trial_type_offset_equal": -0.31344159700178015,
      "trial_type_offset_opponent_more": -2.6912875306118234,
      "trial_type_offset_self_more": 0.37009007624349766,
      "success": true,
      "log_likelihood": -16.6451293314561,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 60.191181096374685,
      "trial_type_offset_equal": -1.0899266296223016,
      "trial_type_offset_opponent_more": -1.4420430318392483,
      "trial_type_offset_self_more": -0.011645512499807588,
      "success": true,
      "log_likelihood": -14.224848597068032,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 66.07940591302007,
      "beta": 100.0,
      "trial_type_offset_equal": -100.0,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -0.7088803481645839,
      "success": true,
      "log_likelihood": -18.077672796013687,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 90.28325153027767,
      "beta": 59.777769827733366,
      "trial_type_offset_equal": -0.13792023668054068,
      "trial_type_offset_opponent_more": 57.93306538735325,
      "trial_type_offset_self_more": -0.12542255799580707,
      "success": true,
      "log_likelihood": -17.416561626506844,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 48.5319496957595,
      "beta": 63.03145923057745,
      "trial_type_offset_equal": -1.3756181551161915,
      "trial_type_offset_opponent_more": -2.4461910815221146,
      "trial_type_offset_self_more": -0.752307568968336,
      "success": true,
      "log_likelihood": -6.905019600507992,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 44.32536262347714,
      "trial_type_offset_equal": -1.0900249716192356,
      "trial_type_offset_opponent_more": -100.0,
      "trial_type_offset_self_more": -0.038435854091090085,
      "success": true,
      "log_likelihood": -17.735704083542142,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 74.79002875586535,
      "beta": 0.0,
      "trial_type_offset_equal": -48.62392537973665,
      "trial_type_offset_opponent_more": -78.87063327641977,
      "trial_type_offset_self_more": -66.03072976955929,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.17893259259199237,
      "beta": 5.93772787612438,
      "trial_type_offset_equal": 14.201523448836358,
      "trial_type_offset_opponent_more": -10.136662446661417,
      "trial_type_offset_self_more": -1.2113377634479319,
      "success": true,
      "log_likelihood": -4.715073711030505,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 16.87026894860364,
      "trial_type_offset_equal": -0.4943508045817954,
      "trial_type_offset_opponent_more": -11.087383538129261,
      "trial_type_offset_self_more": -0.22763658621203842,
      "success": true,
      "log_likelihood": -21.28712971652676,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 65.13895564680632,
      "trial_type_offset_equal": -10.764550270032787,
      "trial_type_offset_opponent_more": -15.428298728008691,
      "trial_type_offset_self_more": 0.17591253562200349,
      "success": true,
      "log_likelihood": -20.324925032937447,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.1883469365481427,
      "beta": 92.96516000327443,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": 56.1312228597623,
      "trial_type_offset_self_more": -70.8439327986781,
      "success": true,
      "log_likelihood": -17.832107018547372,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 23.15998946915754,
      "trial_type_offset_equal": -1.1186946154984097,
      "trial_type_offset_opponent_more": -83.62554560679187,
      "trial_type_offset_self_more": -0.15436254412001763,
      "success": true,
      "log_likelihood": -20.08628784359521,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 67.05273487304133,
      "beta": 99.66791051551077,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -17.588022100483357,
      "success": true,
      "log_likelihood": -24.78150466578093,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 98.13021012091156,
      "beta": 78.14832429805416,
      "trial_type_offset_equal": -100.0,
      "trial_type_offset_opponent_more": -100.0,
      "trial_type_offset_self_more": -0.40078701092801017,
      "success": true,
      "log_likelihood": -19.481056266870887,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 22.090928407346347,
      "beta": 91.72759037968974,
      "trial_type_offset_equal": -18.2872264190978,
      "trial_type_offset_opponent_more": 62.966785873178175,
      "trial_type_offset_self_more": -100.0,
      "success": true,
      "log_likelihood": -23.50528858801901,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 40.291060277374505,
      "trial_type_offset_equal": -4.870798818664656,
      "trial_type_offset_opponent_more": -3.0950821009689067,
      "trial_type_offset_self_more": -0.12396999011106133,
      "success": true,
      "log_likelihood": -15.54535792432509,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 0.0,
      "trial_type_offset_equal": -58.790148673441365,
      "trial_type_offset_opponent_more": -93.97690023389958,
      "trial_type_offset_self_more": 78.7200988390647,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 30.205556838369787,
      "trial_type_offset_equal": -0.46145603572088995,
      "trial_type_offset_opponent_more": -2.039515779081204,
      "trial_type_offset_self_more": -79.25470778854562,
      "success": true,
      "log_likelihood": -21.5907665260355,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 79.04399460426623,
      "beta": 45.9914418723702,
      "trial_type_offset_equal": -3.3364617256756666,
      "trial_type_offset_opponent_more": -58.593012051104964,
      "trial_type_offset_self_more": -61.171833227520715,
      "success": true,
      "log_likelihood": -21.659868064509002,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.5187947710104142,
      "beta": 3.837835891208515,
      "trial_type_offset_equal": -100.0,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -3.0175160436885364,
      "success": true,
      "log_likelihood": -21.345801877869167,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 35.319175336090964,
      "trial_type_offset_equal": 86.80831802221674,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -0.1621369724674665,
      "success": true,
      "log_likelihood": -21.321463722367085,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 57.4862701074317,
      "beta": 0.0,
      "trial_type_offset_equal": 95.19609741509093,
      "trial_type_offset_opponent_more": -54.4428894597718,
      "trial_type_offset_self_more": -34.2794035705292,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 61.67247218331583,
      "beta": 98.65682318858629,
      "trial_type_offset_equal": -5.17622647373116,
      "trial_type_offset_opponent_more": -4.069738013263408,
      "trial_type_offset_self_more": -4.825616209893398,
      "success": true,
      "log_likelihood": -10.602764468376606,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 0.0,
      "trial_type_offset_equal": 96.33788590680619,
      "trial_type_offset_opponent_more": -66.95371048488576,
      "trial_type_offset_self_more": -81.65169735238854,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 88.77257207355554,
      "beta": 100.0,
      "trial_type_offset_equal": -0.5668188840159785,
      "trial_type_offset_opponent_more": -7.162595293568884,
      "trial_type_offset_self_more": 0.6769293676641456,
      "success": true,
      "log_likelihood": -12.6129151548786,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 32.88253225878375,
      "trial_type_offset_equal": -0.43456619228401283,
      "trial_type_offset_opponent_more": -1.9565733048593175,
      "trial_type_offset_self_more": 0.663923016694582,
      "success": true,
      "log_likelihood": -19.471652484883407,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 38.785990029099004,
      "trial_type_offset_equal": -0.9006698791175013,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -7.673662641283096,
      "success": true,
      "log_likelihood": -22.087106988936725,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 84.82155202109402,
      "beta": 0.0,
      "trial_type_offset_equal": -80.13207859261584,
      "trial_type_offset_opponent_more": 90.62835143691919,
      "trial_type_offset_self_more": -100.0,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 25.485295802445464,
      "trial_type_offset_equal": -0.5119703759443252,
      "trial_type_offset_opponent_more": -1.7854538489588578,
      "trial_type_offset_self_more": -98.70567335166191,
      "success": true,
      "log_likelihood": -22.09902264236031,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 88.13586723706642,
      "beta": 0.0,
      "trial_type_offset_equal": -39.63913468299391,
      "trial_type_offset_opponent_more": -70.31237400334996,
      "trial_type_offset_self_more": 18.659692299401343,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 27.684999079845696,
      "trial_type_offset_equal": -0.475432124402694,
      "trial_type_offset_opponent_more": -2.2228751634124673,
      "trial_type_offset_self_more": -0.3266529055840146,
      "success": true,
      "log_likelihood": -18.106587458760718,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 58.1145951069866,
      "beta": 76.62970682275909,
      "trial_type_offset_equal": -1.3316838135103344,
      "trial_type_offset_opponent_more": -3.084377367823276,
      "trial_type_offset_self_more": -0.7493944130804958,
      "success": true,
      "log_likelihood": -6.078771518981922,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 68.72086345695104,
      "beta": 76.90218796846094,
      "trial_type_offset_equal": -0.9383991812318818,
      "trial_type_offset_opponent_more": -1.1383765142270652,
      "trial_type_offset_self_more": -0.7701103491426861,
      "success": true,
      "log_likelihood": -10.237279614484223,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 33.479241157399706,
      "trial_type_offset_equal": -0.2992501384225,
      "trial_type_offset_opponent_more": -2.1381183068847487,
      "trial_type_offset_self_more": 0.785951641775318,
      "success": true,
      "log_likelihood": -19.596210912884807,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3138217891322121,
      "beta": 6.445543770124979,
      "trial_type_offset_equal": 11.978876099604125,
      "trial_type_offset_opponent_more": 30.551096535993175,
      "trial_type_offset_self_more": -1.3225798184510102,
      "success": true,
      "log_likelihood": -9.059009193743561,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 82.54611312090306,
      "beta": 0.0,
      "trial_type_offset_equal": 92.5690224218128,
      "trial_type_offset_opponent_more": 56.9284384843144,
      "trial_type_offset_self_more": -41.88042171378039,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 0.0,
      "trial_type_offset_equal": 39.41605318814878,
      "trial_type_offset_opponent_more": 60.38621199268138,
      "trial_type_offset_self_more": 63.25892156990976,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 46.53152908999045,
      "trial_type_offset_equal": -23.880216783437817,
      "trial_type_offset_opponent_more": -20.47561962240213,
      "trial_type_offset_self_more": 0.9633592656454016,
      "success": true,
      "log_likelihood": -22.566309296376645,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 76.85863260053331,
      "trial_type_offset_equal": -0.8686321940078439,
      "trial_type_offset_opponent_more": -2.001514083531077,
      "trial_type_offset_self_more": 1.2418742418028201,
      "success": true,
      "log_likelihood": -14.007254352967996,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 19.22124177287422,
      "trial_type_offset_equal": -0.653815669572297,
      "trial_type_offset_opponent_more": 83.02856654742374,
      "trial_type_offset_self_more": 0.3147188854652181,
      "success": true,
      "log_likelihood": -22.15948714474979,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 48.36474588350031,
      "trial_type_offset_equal": -1.0691785934069653,
      "trial_type_offset_opponent_more": -2.9808441950811235,
      "trial_type_offset_self_more": -6.4491336586455805,
      "success": true,
      "log_likelihood": -17.298501678859193,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 13.997323243396512,
      "beta": 88.49897694522814,
      "trial_type_offset_equal": -3.0650503355918977,
      "trial_type_offset_opponent_more": 7.498330625348143,
      "trial_type_offset_self_more": -2.6478030978235636,
      "success": true,
      "log_likelihood": -4.875604878169332,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 0.0,
      "trial_type_offset_equal": -57.20934606599485,
      "trial_type_offset_opponent_more": 87.42765304350507,
      "trial_type_offset_self_more": 77.55216676372171,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 95.72350282958146,
      "beta": 66.86508551398117,
      "trial_type_offset_equal": 100.0,
      "trial_type_offset_opponent_more": -0.13516548760469493,
      "trial_type_offset_self_more": 0.7663970576945718,
      "success": true,
      "log_likelihood": -20.339950025470124,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 0.0,
      "trial_type_offset_equal": 63.705381102431375,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -96.07958377679617,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 4.568497823755768,
      "trial_type_offset_equal": -1.8000000305844268,
      "trial_type_offset_opponent_more": 99.95499653672647,
      "trial_type_offset_self_more": -12.718221520930015,
      "success": true,
      "log_likelihood": -23.010110708766923,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 45.77718965524877,
      "beta": 100.0,
      "trial_type_offset_equal": 1.5552680161601582,
      "trial_type_offset_opponent_more": -4.363457737177509,
      "trial_type_offset_self_more": -3.7539505052985698,
      "success": true,
      "log_likelihood": -8.617694043881471,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 28.901733952665403,
      "beta": 0.0,
      "trial_type_offset_equal": 14.731552448736352,
      "trial_type_offset_opponent_more": -62.594484724277315,
      "trial_type_offset_self_more": -37.599982373687325,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.656935651765918,
      "beta": 100.0,
      "trial_type_offset_equal": 52.0253638276144,
      "trial_type_offset_opponent_more": 100.0,
      "trial_type_offset_self_more": -40.22035249024616,
      "success": true,
      "log_likelihood": -23.037574991556063,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 23.7126820810939,
      "trial_type_offset_equal": -0.5073899008309108,
      "trial_type_offset_opponent_more": -100.0,
      "trial_type_offset_self_more": 0.4124149616807703,
      "success": true,
      "log_likelihood": -21.639285134736944,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 94.94501255439403,
      "beta": 0.0,
      "trial_type_offset_equal": 27.521242546780627,
      "trial_type_offset_opponent_more": 19.413512993157497,
      "trial_type_offset_self_more": 89.1000730377351,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 100.0,
      "beta": 37.363891813426115,
      "trial_type_offset_equal": -0.6117110020682095,
      "trial_type_offset_opponent_more": -1.9122746747503192,
      "trial_type_offset_self_more": -0.22665358767356306,
      "success": true,
      "log_likelihood": -16.915605273367362,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 80.21523773174664,
      "beta": 0.0,
      "trial_type_offset_equal": 70.38064509008036,
      "trial_type_offset_opponent_more": -66.74109285935371,
      "trial_type_offset_self_more": 85.41969214337526,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 11.676514148734249,
      "beta": 100.0,
      "trial_type_offset_equal": -3.1849100295067667,
      "trial_type_offset_opponent_more": 9.76196170650194,
      "trial_type_offset_self_more": -2.777673768106538,
      "success": true,
      "log_likelihood": -4.22310946864388,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 96.83735007848017,
      "beta": 28.339918194868172,
      "trial_type_offset_equal": -0.49417240522552,
      "trial_type_offset_opponent_more": -1.8465340368676904,
      "trial_type_offset_self_more": -53.1071268644022,
      "success": true,
      "log_likelihood": -21.772931069781045,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 80.65061065941585,
      "beta": 32.76385971816485,
      "trial_type_offset_equal": -0.8481832492358042,
      "trial_type_offset_opponent_more": -3.105134707000999,
      "trial_type_offset_self_more": -4.415871945029679,
      "success": true,
      "log_likelihood": -17.378393291317884,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "alpha": {
        "r": 0.2431943322222705,
        "p": 0.014765083767926455
      },
      "beta": {
        "r": 0.21067357339374296,
        "p": 0.035385155050312894
      },
      "trial_type_offset_equal": {
        "r": -0.07992824453015673,
        "p": 0.42923620823573966
      },
      "trial_type_offset_opponent_more": {
        "r": -0.09302654882772798,
        "p": 0.3572760157163943
      },
      "trial_type_offset_self_more": {
        "r": -0.07821498615274605,
        "p": 0.43922516463040545
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 51.78823615280974,
  "bic_results": {
    "average_bic": 51.78823615280974,
    "individual_bics": [
      67.82419167819657,
      58.94849094037795,
      56.48117358779059,
      62.84523789055389,
      54.30884946175806,
      49.90196172248318,
      17.917594685080548,
      48.2559142889953,
      17.917594685080548,
      59.09289811487042,
      58.80797138156741,
      67.82419167819657,
      60.793358848976354,
      17.917594685080548,
      17.917594685080548,
      17.917594685080548,
      17.917594685080548,
      35.879008337789195,
      31.18711455230052,
      17.917594685080548,
      52.093153153591544,
      38.8291924758835,
      64.3646013659779,
      60.284267451627485,
      54.15359978238935,
      54.376528991257146,
      57.755831238406216,
      67.82419167819657,
      34.388963895538666,
      45.10339937484224,
      17.917594685080548,
      67.82419167819657,
      63.64984502082153,
      61.95254798386891,
      17.917594685080548,
      51.20785335519275,
      46.36729188641661,
      54.07294028430792,
      52.75071794529424,
      31.727633893296534,
      53.38900285936484,
      67.82419167819657,
      27.347742114341557,
      60.49185412533407,
      58.567444758155446,
      53.5818087293753,
      58.09017037947096,
      67.4806040238424,
      56.87970722602232,
      64.92817186831857,
      49.00831054093073,
      67.82419167819657,
      61.09912774435155,
      61.237330821298556,
      60.60919844801889,
      60.560522137014715,
      67.82419167819657,
      39.123123629033756,
      67.82419167819657,
      43.143425002037745,
      56.86089966204736,
      62.091808670153995,
      67.82419167819657,
      62.115639977001166,
      67.82419167819657,
      54.13076960980199,
      30.075137730244393,
      38.39215392124899,
      57.11001651805016,
      36.03561307976767,
      67.82419167819657,
      67.82419167819657,
      63.050213285033834,
      45.93210339821654,
      62.236568981780124,
      52.51459804999894,
      27.668804448619213,
      67.82419167819657,
      58.59749474322079,
      67.82419167819657,
      63.93781610981439,
      35.15298278004349,
      67.82419167819657,
      63.99274467539267,
      61.196164961754434,
      67.82419167819657,
      51.74880523901527,
      67.82419167819657,
      26.36381362956831,
      61.463456831842635,
      52.674381274916314
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 5,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- alpha: r = 0.243\n- beta: r = 0.211\n- trial_type_offset_equal: r = -0.080\n- trial_type_offset_opponent_more: r = -0.093\n- trial_type_offset_self_more: r = -0.078",
  "previous_models": [
    "Specification: FairShare = (combined_earning * token_self / (token_self + token_opp)) + (trial_type == 1) * trial_type_offset_equal + (trial_type == 2) * trial_type_offset_opponent_more + (trial_type == 3) * trial_type_offset_self_more\nFairness = FairShare - split_self\nU = beta * (split_self / (split_self + alpha * abs(Fairness)))\nSummary: A utility model predicting acceptance of offers based on a hyperbolic aversion to unfairness. The model calculates a 'FairShare' influenced by token contributions and trial type-specific offsets. The utility is determined by the amount offered (split_self), fairness sensitivity (alpha), amount sensitivity (beta), and the degree of fairness. The model includes learnable parameters for fairness sensitivity (alpha), amount sensitivity (beta), and trial type-specific offsets, allowing it to capture context-dependent fairness perceptions.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 51.78823615280974\nOverall Accuracy: 0.6697\n\nParameter Recovery:\n- alpha: r = 0.243\n- beta: r = 0.211\n- trial_type_offset_equal: r = -0.080\n- trial_type_offset_opponent_more: r = -0.093\n- trial_type_offset_self_more: r = -0.078"
  ]
}