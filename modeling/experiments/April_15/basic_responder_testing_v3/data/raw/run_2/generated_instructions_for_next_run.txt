<think>
Reviewing the run results: Current parameter recovery for bias is strong, but for beta_gain, beta_inequity, and especially gamma, it is moderate to low. BIC and accuracy are decent but not exceptional. Given the instructions, the LLM already considers nonlinearity and penalizes only deviations below a contribution-based fairness norm, with a nonlinear exponent. 

Parameter recovery issues for beta_inequity and gamma suggest that including both a fairness sensitivity and a nonlinearity exponent creates collinearity or overfitting. Additionally, gain and fairness terms may be correlated if the variables are not normalized. The variable mapping may still allow redundancy.

To improve, the instructions should urge explicit normalization of variables (e.g., working in percents of pot rather than absolute values), and/or divisive or interaction forms that can better separate psychological drivers and reduce parameter collinearity. The role of a fairness norm could be operationalized in ratio or difference space, or a relative–not just absolute–utility. Moreover, the possibility of using “softmax” or “ratio-based” forms (e.g., offered/deserved, or log(offered/deserved)), or piecewise relationships, should be specifically highlighted—not just general nonlinearity.

Additionally, there may be too many parameters for the data, so the instructions should emphasize bias towards minimizing unnecessary parameters, selecting the most behaviorally-identifiable ones (e.g., choose either nonlinearity OR fairness strength, but not both unless clearly distinct).

Finally, the modeler should explicitly simulate and reason about parameter recovery: which parameters can be recovered, and why. They should be told to assess/remedy collinearity and to compare alternative forms for possible parsimony and recovery enhancement.

Encourage less obvious modeling strategies—for example, “softmin” rather than “max”, or self/other differences; allow asymmetrical punishment for unfairness; or even “categorical” or “threshold” regimes that are hybrid between continuous and step models. Suggest considering whether a “reference-dependent” utility (evaluating relative to norm) or even a piecewise-linear/step utility might outperform additive approaches.

Additionally, nudge the LLM to avoid using both split_self and norm_self as separate inputs if they could yield the same information, and to explore modeling with derived/composite variables—such as ratio, percent deviation, or an explicit “relative unfairness” metric.

Make sure all terms in the instructions are precise. Encourage modelers to provide a short statement indicating why their model should yield improved parameter recovery AND prediction, not just post hoc description.

Summarize and clean up these changes in new instructions.
</think>

---
**Instructions for Next Computational Modeling Run**

Before preparing your model, think systematically through each of the following steps:

1. **Clarify Psychological Mechanisms**  
   - Explicitly identify the cognitive drivers influencing responder acceptance/rejection in this context (e.g., self-interest, inequity aversion, contribution-to-reward matching, "reference points" or norms, threshold effects).
   - Consider at least one non-standard mechanism, such as categorical regime change, attention to ratios, or “reference-dependent” utility—do not default to only additive linear or threshold forms.

2. **Consider Alternative Variable Mappings and Normalization**  
   - Reflect critically on whether using absolute values (e.g., £) or normalized values (e.g., percent of combined_earning, offered/deserved ratio) would improve parameter independence and interpretability.
   - Explore composite variables that condense information (e.g., offered/proportional norm, percent deviation from norm) to reduce redundancy and multicollinearity among predictors.

3. **Explore Varied Mathematical Formulations**  
   - Explicitly consider functional forms beyond strictly additive or monotonic (e.g., softmin, ratio, log-ratio, piecewise, or hybrid step-continuous).
   - If using nonlinearity (e.g., exponents, sigmoid penalties), justify its necessity and consider whether it can be parameterized so as not to be collinear with other parameters. If adding a nonlinearity parameter, consider omitting or fixing the corresponding slope so each parameter is interpretable and separately recoverable.
   - Where possible, choose between magnitude-based and direction-based fairness penalties (e.g., only penalize under-offers, or penalize both over- and under-offers differently).

4. **Apply Special Attention to Parameter Recovery and Parsimony**  
   - Before finalizing your model, reason about which parameters can be successfully identified and separated when fit to behavioral data. Prefer models with parameters that are not mathematically or conceptually redundant, to maximize recovery.
   - Where possible, simulate or reason about the collinearity between parameters, and bias toward forms that give clearer, less correlated parameter interpretations.
   - If two parameters show highly overlapping behavioral patterns, simplify: consider fixing one or removing it.

5. **Be Thoughtful and Justified in Model Construction**
   - Clearly justify the inclusion (or exclusion) of each model term and parameter, referencing psychological theory and the potential for behavioral identification.
   - Minimize number of learnable parameters, but do not ignore important mechanisms; if a standard mechanism does not improve recovery, consider alternatives such as stepwise or regime-change models, or interaction terms.
   - Consider offering at least one form that “breaks the mold” of recent models for this dataset (for instance, using a ratio, a piecewise or asymmetrical penalty, or log transformation).

6. **Explicitly Reflect and Predict Improved Performance**
   - In your reasoning, clearly state why your model form should yield improved parameter recovery AND predictive fit, not just descriptive plausibility.
   - Reflect on how your modeling choices specifically address previous limitations of collinearity, overfitting, or poor parameter identifiability.

**Formatting and Output Requirements**

- Use the provided tag format:  
  - Present your model’s formula using explicit mathematical notation between <MODEL>...</MODEL> tags.  
  - Detail all variables (including their source, learnability, range, and a clear description) in JSON format between <VARIABLES>...</VARIABLES> tags.  
  - Specify the target variable your model predicts (should be “accept”) within <target_variable> tags.  
  - Summarize your model, focusing only on its theoretical structure and innovations, within <SUMMARY> tags.

**General Advice**  
- Favor models that increase interpretability and parameter identifiability, potentially by using normalized or composite variables and reducing redundant terms.
- Directly address possible weak spots in earlier approaches—such as parameter correlation or indistinguishable effects.
- Encourage careful, creative departures from past models, ideally proposing structures that would provide more robust and recoverable insights.

Be rigorous, concise, and specific in your modeling choices and justifications.