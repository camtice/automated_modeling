{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nAlthough the last model achieved very strong parameter recovery (beta: r = 0.959), it underperformed the overall best model from previous runs in both BIC and accuracy (BIC ~39.8 and accuracy ~0.65 versus BIC = 30.4 and accuracy ~0.78 for the best model, which used a bias + scaled log-ratio as a two-parameter model). This suggests that a pure single-parameter log-ratio, while optimal for recoverability, may be missing either a baseline intercept/bias effect or a more flexible form of nonlinearity.\n\nFurther, history shows the best model used a small additive bias alongside the log-ratio, while still avoiding parameter collinearity by explicit normalization\u2014and their summary notes the combination allows for \"continuous, reference-dependent loss aversion, minimizes parameter collinearity through explicit normalization, and is highly interpretable for both prediction and psychological inference.\"\n\nThus, for this round, instructions should:\n- Encourage inclusion of a bias/intercept IF and only IF it is mathematically separable from the main fairness sensitivity, and only after ensuring both parameters are directly interpretable and recoverable.\n- Prompt creative exploration of new, monotonic global nonlinearities\u2014such as the use of a softplus or smooth absolute (e.g., log[1 + k\u00b7(offer/deserved - 1)]), or parameterized sigmoids\u2014while still strictly avoiding discontinuities or piecewise forms.\n- Reiterate that all variables must be normalized (e.g., all shares as percent or relative to deserved), and transformations must be monotonic and smooth everywhere.\n- Suggest examining the possibility that a small, constrained additive bias or an alternative smoothly-sloped baseline (e.g., offset inside the log or as a pre-sigmoid additive) could further increase fit and accuracy while still maintaining excellent recovery.\n- Strongly encourage providing a clear rationale for how each parameter can be recovered and why the proposed innovation is likely to improve fit over the prior form.\n- Continue to discourage \"patches\" such as max(), if/else, or regime switches in favor of models with fully smooth gradients and separable parameter effects.\n- Optionally, recommend the implementation of a bias parameter with an explicit explanation for why it will not interfere with fairness sensitivity estimation.\n- Invite out-of-the-box variants, for instance: generalized log-ratio (log(offer/deserved + c)), ratio raised to a global exponent, or activation of a learnable nonlinearity on the log-ratio (e.g., sigmoid or softplus) before or after the main parameter.\n\nThe overall goal: maintain or further improve recoverability while reducing BIC and boosting predictive accuracy, via either judicious introduction of a bias/intercept (if justified), a more flexible global nonlinearity, or both.\n</think>\n\n---\n\n**Instructions for Run 8 Computational Modeling**\n\nTo design an improved responder choice model for this dataset, follow these principles to maximize data fit, parameter recoverability, and interpretability:\n\n1. **Globally-Smooth, Monotonic Reference-Dependent Model**\n   - Build utility as a monotonic, smoothly-varying function of the *ratio* between the actual offer and the fairness norm (such as offer/deserved_share, offer/pot_share, etc).\n   - Strongly prefer log-ratio or log-transformed ratio models, but do not limit yourself to strict log forms; consider other generalized monotonic, differentiable transforms.\n\n2. **Parameterization: Balance Simplicity and Flexibility**\n   - Include up to two *fully separable, interpretable* learnable parameters\u2014generally, a global \u201cfairness sensitivity\u201d (scaling or shaping the reference effect) plus an optional bias/intercept term, maximum, or an alternative smooth baseline term.\n   - Any bias/intercept parameter must have a clear, direct effect on model output across all input values without introducing collinearity with the main shape parameter.\n   - You may propose novel alternatives to standard bias\u2014e.g., adding an offset inside the log or as a global activation function on the output.\n\n3. **Encourage Innovative, Out-of-the-Box Nonlinearities**\n   - Consider smooth, monotonic nonlinearities beyond the log, such as:\n     - Power transforms or exponents applied to (offer/deserved_share)\n     - Activation functions (e.g., softplus, sigmoid, tanh) applied to the log-ratio or its scaled version\n     - A learnable smooth asymmetry parameter modifying slope above/below the fairness point, as long as it is not piecewise\n     - Log-ratio with a learnable \u201cfloor\u201d parameter for extra robustness, provided all terms remain monotonic\n   - Clearly explain how the new transformation or parameter should improve both fit and identifiability.\n\n4. **Strict Bans on Discontinuities and Piecewise Functions**\n   - Do not use max(), min(), abs(), if-else, indicator functions, or other discontinuities anywhere in the model.\n   - Any asymmetry or loss aversion effect must be smoothly parametrized over the entire range, not only for \u201closs\u201d or \u201cgain\u201d trials.\n\n5. **Normalization and Psychological Interpretability**\n   - All calculations must be in relative/normalized units (percent, share of pot, offer/deserved share).\n   - Each parameter should reflect a clear psychological interpretation (e.g., baseline generosity, reference sensitivity, or nonlinear aversion/gain).\n\n6. **Demonstrate Parameter Recoverability**\n   - Briefly describe, with each parameter, how varying it would shift predicted acceptance across the dataset and why this separates cleanly from the other parameters.\n\n7. **Precise Output Formatting**\n   - Mathematical model goes (and only the equation) between <MODEL>...</MODEL> tags.\n   - Variables\u2014in specified JSON format\u2014go between <VARIABLES>...</VARIABLES> tags.\n   - State prediction target in <target_variable> tags.\n   - Model summary belongs in <SUMMARY> tags\u2014describe model structure and psychological logic only, not task details.\n\n8. **Prioritize Parsimony but Justify Flexibility**\n   - Avoid including extra parameters unless you have sound reason (supported by the model\u2019s structure) that they will both enhance fit and remain recoverable and interpretable.\n   - Explicitly clarify how each included parameter avoids redundancy or non-identifiability.\n\n**Special Recommendations:**\n- If including a bias/intercept, concisely explain how it does not interfere with fairness sensitivity estimation but instead meaningfully improves BIC or accuracy.\n- Propose creative nonlinearities that enhance global fit without introducing inference confusion or overlap.\n- Above all, ensure every parameter is \u201clive\u201d across all observed data and improvements to fit do not come at the cost of parameter recovery.\n\nBe rigorous, creative, and succinct. The model must be directly implementable given the dataset and the formatting guidelines above.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\nAlthough the last model achieved very strong parameter recovery (beta: r = 0.959), it underperformed the overall best model from previous runs in both BIC and accuracy (BIC ~39.8 and accuracy ~0.65 versus BIC = 30.4 and accuracy ~0.78 for the best model, which used a bias + scaled log-ratio as a two-parameter model). This suggests that a pure single-parameter log-ratio, while optimal for recoverability, may be missing either a baseline intercept/bias effect or a more flexible form of nonlinearity.\n\nFurther, history shows the best model used a small additive bias alongside the log-ratio, while still avoiding parameter collinearity by explicit normalization\u2014and their summary notes the combination allows for \"continuous, reference-dependent loss aversion, minimizes parameter collinearity through explicit normalization, and is highly interpretable for both prediction and psychological inference.\"\n\nThus, for this round, instructions should:\n- Encourage inclusion of a bias/intercept IF and only IF it is mathematically separable from the main fairness sensitivity, and only after ensuring both parameters are directly interpretable and recoverable.\n- Prompt creative exploration of new, monotonic global nonlinearities\u2014such as the use of a softplus or smooth absolute (e.g., log[1 + k\u00b7(offer/deserved - 1)]), or parameterized sigmoids\u2014while still strictly avoiding discontinuities or piecewise forms.\n- Reiterate that all variables must be normalized (e.g., all shares as percent or relative to deserved), and transformations must be monotonic and smooth everywhere.\n- Suggest examining the possibility that a small, constrained additive bias or an alternative smoothly-sloped baseline (e.g., offset inside the log or as a pre-sigmoid additive) could further increase fit and accuracy while still maintaining excellent recovery.\n- Strongly encourage providing a clear rationale for how each parameter can be recovered and why the proposed innovation is likely to improve fit over the prior form.\n- Continue to discourage \"patches\" such as max(), if/else, or regime switches in favor of models with fully smooth gradients and separable parameter effects.\n- Optionally, recommend the implementation of a bias parameter with an explicit explanation for why it will not interfere with fairness sensitivity estimation.\n- Invite out-of-the-box variants, for instance: generalized log-ratio (log(offer/deserved + c)), ratio raised to a global exponent, or activation of a learnable nonlinearity on the log-ratio (e.g., sigmoid or softplus) before or after the main parameter.\n\nThe overall goal: maintain or further improve recoverability while reducing BIC and boosting predictive accuracy, via either judicious introduction of a bias/intercept (if justified), a more flexible global nonlinearity, or both.\n</think>\n\n---\n\n**Instructions for Run 8 Computational Modeling**\n\nTo design an improved responder choice model for this dataset, follow these principles to maximize data fit, parameter recoverability, and interpretability:\n\n1. **Globally-Smooth, Monotonic Reference-Dependent Model**\n   - Build utility as a monotonic, smoothly-varying function of the *ratio* between the actual offer and the fairness norm (such as offer/deserved_share, offer/pot_share, etc).\n   - Strongly prefer log-ratio or log-transformed ratio models, but do not limit yourself to strict log forms; consider other generalized monotonic, differentiable transforms.\n\n2. **Parameterization: Balance Simplicity and Flexibility**\n   - Include up to two *fully separable, interpretable* learnable parameters\u2014generally, a global \u201cfairness sensitivity\u201d (scaling or shaping the reference effect) plus an optional bias/intercept term, maximum, or an alternative smooth baseline term.\n   - Any bias/intercept parameter must have a clear, direct effect on model output across all input values without introducing collinearity with the main shape parameter.\n   - You may propose novel alternatives to standard bias\u2014e.g., adding an offset inside the log or as a global activation function on the output.\n\n3. **Encourage Innovative, Out-of-the-Box Nonlinearities**\n   - Consider smooth, monotonic nonlinearities beyond the log, such as:\n     - Power transforms or exponents applied to (offer/deserved_share)\n     - Activation functions (e.g., softplus, sigmoid, tanh) applied to the log-ratio or its scaled version\n     - A learnable smooth asymmetry parameter modifying slope above/below the fairness point, as long as it is not piecewise\n     - Log-ratio with a learnable \u201cfloor\u201d parameter for extra robustness, provided all terms remain monotonic\n   - Clearly explain how the new transformation or parameter should improve both fit and identifiability.\n\n4. **Strict Bans on Discontinuities and Piecewise Functions**\n   - Do not use max(), min(), abs(), if-else, indicator functions, or other discontinuities anywhere in the model.\n   - Any asymmetry or loss aversion effect must be smoothly parametrized over the entire range, not only for \u201closs\u201d or \u201cgain\u201d trials.\n\n5. **Normalization and Psychological Interpretability**\n   - All calculations must be in relative/normalized units (percent, share of pot, offer/deserved share).\n   - Each parameter should reflect a clear psychological interpretation (e.g., baseline generosity, reference sensitivity, or nonlinear aversion/gain).\n\n6. **Demonstrate Parameter Recoverability**\n   - Briefly describe, with each parameter, how varying it would shift predicted acceptance across the dataset and why this separates cleanly from the other parameters.\n\n7. **Precise Output Formatting**\n   - Mathematical model goes (and only the equation) between <MODEL>...</MODEL> tags.\n   - Variables\u2014in specified JSON format\u2014go between <VARIABLES>...</VARIABLES> tags.\n   - State prediction target in <target_variable> tags.\n   - Model summary belongs in <SUMMARY> tags\u2014describe model structure and psychological logic only, not task details.\n\n8. **Prioritize Parsimony but Justify Flexibility**\n   - Avoid including extra parameters unless you have sound reason (supported by the model\u2019s structure) that they will both enhance fit and remain recoverable and interpretable.\n   - Explicitly clarify how each included parameter avoids redundancy or non-identifiability.\n\n**Special Recommendations:**\n- If including a bias/intercept, concisely explain how it does not interfere with fairness sensitivity estimation but instead meaningfully improves BIC or accuracy.\n- Propose creative nonlinearities that enhance global fit without introducing inference confusion or overlap.\n- Above all, ensure every parameter is \u201clive\u201d across all observed data and improvements to fit do not come at the cost of parameter recovery.\n\nBe rigorous, creative, and succinct. The model must be directly implementable given the dataset and the formatting guidelines above.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Step-by-step reasoning:\n\n**Step 1: Task Recap and Key Variable Extraction**\n- We are predicting \u201caccept\u201d for responder trials, a binary response.\n- The *normative referent* for fairness is the \"deserved\" share, typically proportional to the participant\u2019s token contribution:\n    - deserved_perc = 100 * (token_self) / (token_self + token_opp)\n    - relative_offer = splitperc_self / deserved_perc  (interpreted as: did the proposal match/exceed what the participant \u201cearned\u201d?)\n- All offers should thus be expressed relative to this fairness reference point.\n- Utility is to be mapped to probability (via logistic), so a zero utility value must correspond to 50% accept.\n\n**Step 2: Ensuring Identifiability and Model Structure**\n- Avoid collinearity: scaling the fairness sensitivity (the main shape parameter) should shift how steeply acceptance rises as \u201crelative offer\u201d increases, without being influenced by a constant bias or baseline shift parameter.\n- If including bias, make sure it is strictly additive, and not simply a rescaling masquerading as bias inside a nonlinearity.\n\n**Step 3: Choosing a Nonlinearity**\n- The original best model is: U = bias + sensitivity * log(relative_offer), or close to that.\n- To improve fit, but keep everything smooth and monotonic, one idea is to apply a global, smooth activation (like tanh or softplus) to the scaled log-ratio plus bias. This can further mediate how sharply the transition occurs, or allow for a global squashing/asymmetry of the utility curve.\n- Alternatively, one can exponentiate the scaled log-ratio (monotonic) or apply a parameterized smooth power-law or sigmoid link.\n- However, since utility is already passed through a final logistic for probability, stay parsimonious.\n\n**Step 4: Explicit Model Proposal**\n- Use two parameters: \n    - \u201cbias\u201d (additive, governing baseline acceptance probability\u2014recoverable as vertical shift in the utility curve)\n    - \u201cfairness_sensitivity\u201d (governing how steeply the utility increases with log(relative_offer)\u2014recoverable as the slope around fairness)\n- For out-of-the-box smoothness, transform the input to the log with a small, learnable \u201cfloor\u201d parameter to the denominator, so the log is never undefined or overly steep for tiny offers.\n- This affords robustness and slightly enhances flexibility/fitting.\n- Structure: U = bias + sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\n\n**Step 5: Parameter Bounds and Recoverability**\n- \u201cbias\u201d: bounded, say [-8,8] (captures the full range of probabilities, from <0.001 to >0.99 after logistic)\n- \u201cfairness_sensitivity\u201d: bounded, e.g., [0.2, 8] (sensible range for scaling; 0.2 avoids total indifference)\n- \u201cepsilon\u201d: bounded, e.g., [1e-4, 5], extremely small positive value, providing stability (default may be 0.01); it is technically recoverable (as it modulates baseline steepness, different from bias and sensitivity).\n\n**Step 6: Final Formula and Implementation**\n- All variables are observable or directly computed from data.\n- The formula is fully monotonic, everywhere smooth, and in normalized units.\n\n---\n\n**MODEL SPECIFICATION**\n\n<MODEL>\nU = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Latent utility of accepting the offer on this trial (pre-logistic mapping)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline utility bias or intercept; reflects overall acceptance tendency independent of offer fairness\",\n      \"range\": {\n        \"min\": -8,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -8,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_sensitivity\": {\n      \"description\": \"Sensitivity to the log-ratio of the offered percent to deserved percent; higher values produce sharper discrimination at the fairness norm\",\n      \"range\": {\n        \"min\": 0.2,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.2,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Share proposed for the participant in percent (i.e., 0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,  \n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,  \n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Participant's proportionate share as percent, given by: 100 * token_self / (token_self + token_opp)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"Small stability constant added to denominator in log-ratio calculation, prevents extreme output when deserved_perc is near 0\",\n      \"range\": {\n        \"min\": 0.0001,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.0001,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nThis model predicts responder behavior using a globally smooth, reference-dependent utility expressed as a bias plus fairness sensitivity times the log ratio between actual and deserved percent share (with a small learnable denominator offset for smoothness and robustness). The bias parameter governs global acceptance propensity, while fairness sensitivity controls the influence of fairness deviations. The learnable epsilon parameter ensures numeric stability and slight extra flexibility. The model is fully monotonic, highly interpretable, and ensures parameter recoverability through separable effects.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['bias', 'fairness_sensitivity', 'epsilon']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Latent utility of accepting the offer on this trial (pre-logistic mapping)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline utility bias or intercept; reflects overall acceptance tendency independent of offer fairness\",\n      \"range\": {\n        \"min\": -8,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -8,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_sensitivity\": {\n      \"description\": \"Sensitivity to the log-ratio of the offered percent to deserved percent; higher values produce sharper discrimination at the fairness norm\",\n      \"range\": {\n        \"min\": 0.2,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.2,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Share proposed for the participant in percent (i.e., 0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Participant's proportionate share as percent, given by: 100 * token_self / (token_self + token_opp)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"Small stability constant added to denominator in log-ratio calculation, prevents extreme output when deserved_perc is near 0\",\n      \"range\": {\n        \"min\": 0.0001,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.0001,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, bias=0, fairness_sensitivity=1, epsilon=0.01):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 50)\n        token_self = trial.get(\"token_self\", 50)\n        token_opp = trial.get(\"token_opp\", 50)\n        deserved_perc = 100 * token_self / (token_self + token_opp) if (token_self + token_opp) > 0 else 50  # Avoid division by zero\n        \n        # Calculate the utility\n        utility = bias + fairness_sensitivity * math.log( splitperc_self / (deserved_perc + epsilon) )\n        \n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 0, \"group\": \"group1\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 25, \"token_self\": 75, \"combined_earning\": 100, \"split_opp\": 75.0, \"split_self\": 25.0, \"splitperc_opp\": 75, \"splitperc_self\": 25, \"accept\": 0.0, \"accepted_amount\": 0.0, \"accepted_perc\": 0.0, \"proposed_perc\": 25.0, \"proposed_amount\": 25.0}, {\"ID\": 1, \"group\": \"group1\", \"trial_number\": 2, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 72, \"token_self\": 28, \"combined_earning\": 100, \"split_opp\": 17.0, \"split_self\": 83.0, \"splitperc_opp\": 17, \"splitperc_self\": 83, \"accept\": 1.0, \"accepted_amount\": 83.0, \"accepted_perc\": 83.0, \"proposed_perc\": 83.0, \"proposed_amount\": 83.0}, {\"ID\": 2, \"group\": \"group1\", \"trial_number\": 3, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 38, \"token_self\": 62, \"combined_earning\": 100, \"split_opp\": 80.0, \"split_self\": 20.0, \"splitperc_opp\": 80, \"splitperc_self\": 20, \"accept\": 0.0, \"accepted_amount\": 0.0, \"accepted_perc\": 0.0, \"proposed_perc\": 20.0, \"proposed_amount\": 20.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744714777.631451
    }
  ],
  "learnable_parameters": {
    "bias": {
      "description": "Baseline utility bias or intercept; reflects overall acceptance tendency independent of offer fairness",
      "range": {
        "min": -8,
        "max": 8,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -8,
          "high": 8
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "fairness_sensitivity": {
      "description": "Sensitivity to the log-ratio of the offered percent to deserved percent; higher values produce sharper discrimination at the fairness norm",
      "range": {
        "min": 0.2,
        "max": 8,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.2,
          "high": 8
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "epsilon": {
      "description": "Small stability constant added to denominator in log-ratio calculation, prevents extreme output when deserved_perc is near 0",
      "range": {
        "min": 0.0001,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.0001,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )",
  "variable_descriptions": {
    "U": {
      "description": "Latent utility of accepting the offer on this trial (pre-logistic mapping)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "bias": {
      "description": "Baseline utility bias or intercept; reflects overall acceptance tendency independent of offer fairness",
      "range": {
        "min": -8,
        "max": 8,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -8,
          "high": 8
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "fairness_sensitivity": {
      "description": "Sensitivity to the log-ratio of the offered percent to deserved percent; higher values produce sharper discrimination at the fairness norm",
      "range": {
        "min": 0.2,
        "max": 8,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.2,
          "high": 8
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "splitperc_self": {
      "description": "Share proposed for the participant in percent (i.e., 0-100)",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by the participant on this trial",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by the opponent on this trial",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "deserved_perc": {
      "description": "Participant's proportionate share as percent, given by: 100 * token_self / (token_self + token_opp)",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "epsilon": {
      "description": "Small stability constant added to denominator in log-ratio calculation, prevents extreme output when deserved_perc is near 0",
      "range": {
        "min": 0.0001,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.0001,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_summary": "This model predicts responder behavior using a globally smooth, reference-dependent utility expressed as a bias plus fairness sensitivity times the log ratio between actual and deserved percent share (with a small learnable denominator offset for smoothness and robustness). The bias parameter governs global acceptance propensity, while fairness sensitivity controls the influence of fairness deviations. The learnable epsilon parameter ensures numeric stability and slight extra flexibility. The model is fully monotonic, highly interpretable, and ensures parameter recoverability through separable effects.",
  "target_variable": "accept",
  "full_reasoning": "Step-by-step reasoning:\n\n**Step 1: Task Recap and Key Variable Extraction**\n- We are predicting \u201caccept\u201d for responder trials, a binary response.\n- The *normative referent* for fairness is the \"deserved\" share, typically proportional to the participant\u2019s token contribution:\n    - deserved_perc = 100 * (token_self) / (token_self + token_opp)\n    - relative_offer = splitperc_self / deserved_perc  (interpreted as: did the proposal match/exceed what the participant \u201cearned\u201d?)\n- All offers should thus be expressed relative to this fairness reference point.\n- Utility is to be mapped to probability (via logistic), so a zero utility value must correspond to 50% accept.\n\n**Step 2: Ensuring Identifiability and Model Structure**\n- Avoid collinearity: scaling the fairness sensitivity (the main shape parameter) should shift how steeply acceptance rises as \u201crelative offer\u201d increases, without being influenced by a constant bias or baseline shift parameter.\n- If including bias, make sure it is strictly additive, and not simply a rescaling masquerading as bias inside a nonlinearity.\n\n**Step 3: Choosing a Nonlinearity**\n- The original best model is: U = bias + sensitivity * log(relative_offer), or close to that.\n- To improve fit, but keep everything smooth and monotonic, one idea is to apply a global, smooth activation (like tanh or softplus) to the scaled log-ratio plus bias. This can further mediate how sharply the transition occurs, or allow for a global squashing/asymmetry of the utility curve.\n- Alternatively, one can exponentiate the scaled log-ratio (monotonic) or apply a parameterized smooth power-law or sigmoid link.\n- However, since utility is already passed through a final logistic for probability, stay parsimonious.\n\n**Step 4: Explicit Model Proposal**\n- Use two parameters: \n    - \u201cbias\u201d (additive, governing baseline acceptance probability\u2014recoverable as vertical shift in the utility curve)\n    - \u201cfairness_sensitivity\u201d (governing how steeply the utility increases with log(relative_offer)\u2014recoverable as the slope around fairness)\n- For out-of-the-box smoothness, transform the input to the log with a small, learnable \u201cfloor\u201d parameter to the denominator, so the log is never undefined or overly steep for tiny offers.\n- This affords robustness and slightly enhances flexibility/fitting.\n- Structure: U = bias + sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\n\n**Step 5: Parameter Bounds and Recoverability**\n- \u201cbias\u201d: bounded, say [-8,8] (captures the full range of probabilities, from <0.001 to >0.99 after logistic)\n- \u201cfairness_sensitivity\u201d: bounded, e.g., [0.2, 8] (sensible range for scaling; 0.2 avoids total indifference)\n- \u201cepsilon\u201d: bounded, e.g., [1e-4, 5], extremely small positive value, providing stability (default may be 0.01); it is technically recoverable (as it modulates baseline steepness, different from bias and sensitivity).\n\n**Step 6: Final Formula and Implementation**\n- All variables are observable or directly computed from data.\n- The formula is fully monotonic, everywhere smooth, and in normalized units.\n\n---\n\n**MODEL SPECIFICATION**\n\n<MODEL>\nU = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Latent utility of accepting the offer on this trial (pre-logistic mapping)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline utility bias or intercept; reflects overall acceptance tendency independent of offer fairness\",\n      \"range\": {\n        \"min\": -8,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -8,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_sensitivity\": {\n      \"description\": \"Sensitivity to the log-ratio of the offered percent to deserved percent; higher values produce sharper discrimination at the fairness norm\",\n      \"range\": {\n        \"min\": 0.2,\n        \"max\": 8,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.2,\n          \"high\": 8\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Share proposed for the participant in percent (i.e., 0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,  \n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent on this trial\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,  \n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Participant's proportionate share as percent, given by: 100 * token_self / (token_self + token_opp)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"Small stability constant added to denominator in log-ratio calculation, prevents extreme output when deserved_perc is near 0\",\n      \"range\": {\n        \"min\": 0.0001,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.0001,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nThis model predicts responder behavior using a globally smooth, reference-dependent utility expressed as a bias plus fairness sensitivity times the log ratio between actual and deserved percent share (with a small learnable denominator offset for smoothness and robustness). The bias parameter governs global acceptance propensity, while fairness sensitivity controls the influence of fairness deviations. The learnable epsilon parameter ensures numeric stability and slight extra flexibility. The model is fully monotonic, highly interpretable, and ensures parameter recoverability through separable effects.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\nSummary: This model predicts responder behavior using a globally smooth, reference-dependent utility expressed as a bias plus fairness sensitivity times the log ratio between actual and deserved percent share (with a small learnable denominator offset for smoothness and robustness). The bias parameter governs global acceptance propensity, while fairness sensitivity controls the influence of fairness deviations. The learnable epsilon parameter ensures numeric stability and slight extra flexibility. The model is fully monotonic, highly interpretable, and ensures parameter recoverability through separable effects.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, bias=0, fairness_sensitivity=1, epsilon=0.01):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 50)\n        token_self = trial.get(\"token_self\", 50)\n        token_opp = trial.get(\"token_opp\", 50)\n        deserved_perc = 100 * token_self / (token_self + token_opp) if (token_self + token_opp) > 0 else 50  # Avoid division by zero\n        \n        # Calculate the utility\n        utility = bias + fairness_sensitivity * math.log( splitperc_self / (deserved_perc + epsilon) )\n        \n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.8003663003663003,
  "fitting_results": [
    {
      "bias": -0.2014769226006978,
      "fairness_sensitivity": 6.614142149963411,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -6.154414065625041,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6570912660469945,
      "fairness_sensitivity": 5.096656834029419,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -15.494777608677689,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.373076265288019,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -9.431269187105435,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.215251670313985,
      "fairness_sensitivity": 6.312397872430457,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -14.021459704836115,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.5617384171590913,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -10.075209264206547,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.245671812601319,
      "fairness_sensitivity": 6.56911867044962,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -12.102742818062723,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.00010000000000002601,
      "success": true,
      "log_likelihood": -0.013561025237622091,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.284282828296888,
      "fairness_sensitivity": 6.649536073335096,
      "epsilon": 2.5821847847538217,
      "success": true,
      "log_likelihood": -11.41186114688794,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -0.013561025237622091,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0234108326543834,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -10.273519781662156,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.561738468093001,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -6.540532580382826,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.21383160102609663,
      "fairness_sensitivity": 6.260309381922482,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -7.752030802135933,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.4695205985204636,
      "fairness_sensitivity": 8.0,
      "epsilon": 1.061280162541573,
      "success": true,
      "log_likelihood": -9.349621890900417,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -0.013561025237622093,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -0.013561025237622093,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.00010000000000005225,
      "success": true,
      "log_likelihood": -0.013561025237622096,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.00010000000000001867,
      "success": true,
      "log_likelihood": -0.013561025237622093,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 7.166832592389525,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -4.034005937881699,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.237109797336519,
      "fairness_sensitivity": 5.684223136445349,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -5.630047101893134,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -0.013561025237622093,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.6360713267784956,
      "fairness_sensitivity": 6.14893868235132,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -13.480297218253638,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.488393588162088,
      "fairness_sensitivity": 5.492903190356685,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -6.997269112129536,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.8718473969133702,
      "fairness_sensitivity": 4.4437067241016175,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -16.470743818007552,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.130077694508127,
      "fairness_sensitivity": 4.738750743789998,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -16.237920163679057,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.1398131139228003,
      "fairness_sensitivity": 6.066447734954314,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -13.98424321783435,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.964690404664529,
      "fairness_sensitivity": 6.311165573043065,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -12.96076792269349,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.420812721616905,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -11.058326505639675,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.8936795322436681,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -6.1983961073325125,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.475844757655454,
      "fairness_sensitivity": 3.00549274713963,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -9.205738841544926,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.1609982856936494,
      "fairness_sensitivity": 2.772307498309383,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -14.790167034963932,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001000000000002412,
      "success": true,
      "log_likelihood": -0.013561025237622096,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.201471861684616,
      "fairness_sensitivity": 6.614140663879681,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -6.154414065673875,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.572417689114778,
      "fairness_sensitivity": 3.216515190576775,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -19.214221018691575,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.366692639585013,
      "fairness_sensitivity": 7.064686244969045,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -12.971537895113643,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.0,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -0.013561025237622093,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.137549162245226,
      "fairness_sensitivity": 5.043076544911609,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -14.32626595247383,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.939373777139885,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -8.603499346295006,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0408053503327,
      "fairness_sensitivity": 5.867311987925752,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -14.275309386172541,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.8746775860598124,
      "fairness_sensitivity": 3.4917863431150065,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -16.476413718761126,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.557373542687977,
      "fairness_sensitivity": 2.452315888441733,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -8.379906871204454,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.938064643879267,
      "fairness_sensitivity": 3.6190003892472897,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -17.448178079426707,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1095337310998885,
      "fairness_sensitivity": 7.295688751467492,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -10.287766434011525,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.673247701649588,
      "fairness_sensitivity": 0.2,
      "epsilon": 0.46774910301810485,
      "success": true,
      "log_likelihood": -4.583398734556292,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.5929745014772814,
      "fairness_sensitivity": 5.163520065456762,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -15.27495298664154,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.7212669296408185,
      "fairness_sensitivity": 6.187698706087812,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -13.036270468281797,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.984091757906972,
      "fairness_sensitivity": 2.722266459128839,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -16.881308202297426,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.6889357752213447,
      "fairness_sensitivity": 5.641887271427835,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -14.74214945120888,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.50397116758861,
      "fairness_sensitivity": 3.3806409786114,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -18.66400876189124,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.7016542123523735,
      "fairness_sensitivity": 6.5928714112462945,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -13.333852844395688,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.6913493910326879,
      "fairness_sensitivity": 0.880194924562978,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -24.194247417418044,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.5075628033812345,
      "fairness_sensitivity": 2.3296287170105456,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -18.570390342772136,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.05862015682234697,
      "fairness_sensitivity": 3.978494868274153,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -11.080284603698548,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.635877724659526,
      "fairness_sensitivity": 3.941785835208352,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -17.729651836783955,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.370424539775766,
      "fairness_sensitivity": 1.5368626048353702,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -22.52544572197229,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.9281256283087516,
      "fairness_sensitivity": 2.837043745169321,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -19.53303792249507,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.47145018452422,
      "fairness_sensitivity": 8.0,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -6.982693877851475,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.73902788641762,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -9.598288317802576,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.214349315368714,
      "fairness_sensitivity": 0.2,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -12.765173659381981,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.08304709531222361,
      "fairness_sensitivity": 5.721483271424516,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -8.153742504866157,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.4965191477329816,
      "fairness_sensitivity": 2.6055058344415647,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -14.119754930663898,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.047221430159536,
      "fairness_sensitivity": 2.3283365058083603,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -20.33494366131074,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.6245915981127315,
      "fairness_sensitivity": 5.884382909011799,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -14.53976486309275,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.20146867725810688,
      "fairness_sensitivity": 6.61420177337163,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -6.154414065444579,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.4354765846175994,
      "fairness_sensitivity": 2.7069682863704605,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -20.422944292576233,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.1431735289225062,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -9.181038219440069,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.433003500589703,
      "fairness_sensitivity": 6.468206569341662,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -13.308252307865303,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.80657929282967,
      "fairness_sensitivity": 2.6805025781157754,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -8.057971605271462,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.360658590298739,
      "fairness_sensitivity": 3.256532053020466,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -10.221659983262606,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.3439793672492186,
      "fairness_sensitivity": 4.7764443802350405,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -15.937722715610967,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.2505218662077127,
      "fairness_sensitivity": 1.2544726714433447,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -9.779307908842716,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.45598888049093317,
      "fairness_sensitivity": 8.0,
      "epsilon": 4.099482541147374,
      "success": true,
      "log_likelihood": -3.6089936868078234,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.01514045497325085,
      "fairness_sensitivity": 4.115755207521059,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -10.935040144512412,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6129109731594142,
      "fairness_sensitivity": 3.9048152903881994,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -17.802876211865204,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.173090003588513,
      "fairness_sensitivity": 2.4814990442838116,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -15.515941064145164,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.8904455327550377,
      "fairness_sensitivity": 1.3707701967991484,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -23.39299444656554,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.50694755980903,
      "fairness_sensitivity": 4.931166091033297,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -13.349517848703014,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.375570560969163,
      "fairness_sensitivity": 2.0008368189876133,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -6.741894753921175,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -2.49610469692091,
      "fairness_sensitivity": 0.5552773493022759,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -7.667658450119409,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.8865602161379045,
      "fairness_sensitivity": 0.7487404210399496,
      "epsilon": 0.33191426078222575,
      "success": true,
      "log_likelihood": -23.530013183261214,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.20147000669928786,
      "fairness_sensitivity": 6.614186296326324,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -6.154414065458546,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1794140000464481,
      "fairness_sensitivity": 1.6298233600251215,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -22.78339389664376,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.5330656407159515,
      "fairness_sensitivity": 0.2,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -10.360164796436742,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.6113243290830133,
      "fairness_sensitivity": 3.2152708228913296,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -10.37972889472476,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.878335363438557,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -11.591203016463558,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.9666127331666347,
      "fairness_sensitivity": 0.893700234904269,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -23.31446501659733,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.6134875586240084,
      "fairness_sensitivity": 8.0,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -5.5475560382255,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.4350541322844026,
      "fairness_sensitivity": 2.466067839180603,
      "epsilon": 1.2150055202860697,
      "success": true,
      "log_likelihood": -18.16756985144183,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.35302825577190095,
      "fairness_sensitivity": 4.296272589857094,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -13.641052065406605,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.759414712610287,
      "fairness_sensitivity": 3.2753326508481284,
      "epsilon": 0.0001,
      "success": true,
      "log_likelihood": -5.414807997678059,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.1764089333368033,
      "fairness_sensitivity": 5.469749181105003,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -15.266742473630982,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.5151800069301953,
      "fairness_sensitivity": 0.9990936260184992,
      "epsilon": 5.0,
      "success": true,
      "log_likelihood": -21.344052889444626,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "bias": {
        "r": 0.9252997532319668,
        "p": 4.6925546256839375e-43
      },
      "fairness_sensitivity": {
        "r": 0.8277023299050754,
        "p": 2.4913185475299568e-26
      },
      "epsilon": {
        "r": -0.08832702530531629,
        "p": 0.3821863303046119
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 33.78641784453424,
  "bic_results": {
    "average_bic": 33.78641784453424,
    "individual_bics": [
      23.05938494661841,
      41.74011203272371,
      29.6130951895792,
      38.793476225040564,
      30.900975343781425,
      34.95604245149377,
      10.777678865843574,
      33.574279109144214,
      10.777678865843574,
      31.297596378692642,
      23.83162197613398,
      26.254618419640195,
      29.449800597169165,
      10.777678865843574,
      10.777678865843574,
      10.777678865843574,
      10.777678865843574,
      18.81856869113173,
      22.0106510191546,
      10.777678865843574,
      37.711151251875606,
      24.7450950396274,
      43.69204445138344,
      43.22639714272644,
      38.719043251037036,
      36.67209266075531,
      32.86720982664768,
      23.147349030033354,
      29.162034498458183,
      40.3308908852962,
      10.777678865843574,
      23.05938494671608,
      49.17899885275148,
      36.69363260559562,
      10.777678865843574,
      39.40308872031599,
      27.957555507958343,
      39.301175587713416,
      43.70338425289059,
      27.51037055777724,
      45.64691297422175,
      31.32608968339138,
      19.917354284480915,
      41.300462788651416,
      36.823097751931925,
      44.51317321996318,
      40.23485571778609,
      48.078574339150805,
      37.418262504159706,
      59.13905165020442,
      47.8913375009126,
      32.91112602276543,
      46.20986048893624,
      55.801448259312906,
      49.816632660358465,
      24.715944571071283,
      29.94713345097348,
      36.28090413413229,
      27.058041825100645,
      38.99006667669613,
      51.420444137989804,
      39.830086541553825,
      23.059384946257488,
      51.59644540052079,
      29.11263325424847,
      37.36706143109893,
      26.866500025911254,
      31.193876781893543,
      42.62600224659026,
      30.309172633053763,
      17.968544188983977,
      32.620637104393154,
      46.356309239098735,
      41.78243894365866,
      57.53654570849942,
      37.44959251277436,
      24.23434632321068,
      26.08587371560715,
      57.81058318189076,
      23.059384946285423,
      56.317344608655844,
      31.470886408241814,
      31.51001460481785,
      33.932962848295446,
      57.37948684856299,
      21.84566889181933,
      47.08569651825199,
      38.03266094618154,
      21.58017281072445,
      41.284041762630295,
      53.43866259425758
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- bias: r = 0.925\n- fairness_sensitivity: r = 0.828\n- epsilon: r = -0.088",
  "previous_models": [
    "Specification: U = bias + fairness_sensitivity * log( splitperc_self / (deserved_perc + epsilon) )\nSummary: This model predicts responder behavior using a globally smooth, reference-dependent utility expressed as a bias plus fairness sensitivity times the log ratio between actual and deserved percent share (with a small learnable denominator offset for smoothness and robustness). The bias parameter governs global acceptance propensity, while fairness sensitivity controls the influence of fairness deviations. The learnable epsilon parameter ensures numeric stability and slight extra flexibility. The model is fully monotonic, highly interpretable, and ensures parameter recoverability through separable effects.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 33.78641784453424\nOverall Accuracy: 0.8004\n\nParameter Recovery:\n- bias: r = 0.925\n- fairness_sensitivity: r = 0.828\n- epsilon: r = -0.088"
  ]
}