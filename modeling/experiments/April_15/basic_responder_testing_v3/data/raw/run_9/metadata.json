{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nThe previous model achieved a strong balance of fit (BIC, accuracy) and parameter recovery, with two highly recoverable parameters (bias and fairness_sensitivity). However, the learnable epsilon (the log denominator offset) was essentially unrecoverable (r \u2248 0), indicating it functions mainly as a technical stabilizer rather than a meaningful psychological parameter. The overall structure\u2014a bias plus scaled log-ratio of actual/deserved percent\u2014is highly effective, but further gains may require:\n\n1. Addressing the redundancy/non-informativeness of epsilon, either by reimagining its role (as a learnable slope/nonlinearity instead, or as a robust but fixed value), or reallocating complexity to a more globally-influential but still monotonic and separable parameter.\n2. Introducing an additional nonlinearity or smooth asymmetry parameter, so long as all components remain globally differentiable, monotonic, and interpretable. For example, a power/exponent shaping of the (splitperc_self / deserved_perc) ratio, or a smooth, learnable slope difference above/below norm\u2014implemented via a hyperbolic tangent or smooth exponential function, not via step/if/max.\n3. Ensuring all parameters have non-overlapping psychological interpretations, live gradients across all data, and produce separable effects observable in parameter recovery.\n\nOther possibilities include:\n- A model where the main effect is through a power-law (e.g., (offer/deserved)^rho or its log variant), providing flexible psychophysical scaling\u2014rho can control \u201ccompression/expansion\u201d around fairness.\n- Use of a soft, differentiable global nonlinearity such as tanh, sigmoid, or softplus applied to the bias/scaled log-ratio sum, or transformation of the ratio itself (e.g., log(1 + gamma*[x - 1])).\n- Introduction of a single smooth \"loss aversion\" or \"asymmetry\" parameter, but in a way that does not rely on piecewise/if/else logic (e.g., via tanh or a parametrized scalar multiplying log-ratio for negative values).\n\nIt is essential to avoid adding parameters unless they improve BIC/accuracy and are demonstrably and theoretically recoverable\u2014do not introduce technical terms whose estimation is neither robust nor interpretable. The goal is to surpass previous performance by increasing either fit or identifiability\u2014or, ideally, both\u2014using creative, smooth, nonlinear transforms or asymmetry, but never at the expense of modeling clarity or inference soundness.\n\nFinally, rigorous parameterization and careful explanation of how each parameter can be independently recovered is crucial. If bias is retained, make sure it is not redundant with any new nonlinearity or scaling term.\n\nEncourage out-of-the-box innovations such as generalized ratio exponents, soft nonlinear \"loss aversion,\" activation-based models, or flexible, reference-dependent sigmoids, always within the constraints of monotonicity, smoothness, and interpretability.\n</think>\n\n---\n\n**Instructions for Run 9 Computational Modeling**\n\nTo design the next-generation computational model for responder behavior in this task, adhere to the following principles to maximize predictive accuracy, model fit (BIC), and parameter interpretability/recovery:\n\n1. **Globally Smooth, Reference-Dependent Utility**\n   - Construct your model as a smooth, monotonic function of the *relative* offer\u2014the ratio of the participant's proposed share to their deserved share (e.g., splitperc_self / deserved_perc).\n   - All nonlinearities or transforms must be differentiable everywhere and globally monotonic; no discontinuities or regime changes.\n\n2. **Parameterization: Parsimony AND Power**\n   - Include up to two or three learnable parameters max, but only if all are demonstrably separable, have clear psychological interpretations, and impact the utility globally across all data.\n   - You MUST provide a succinct rationale for how each parameter affects predictions and for why their effects are strictly nonredundant.\n   - Strongly consider creative, globally-applied nonlinearity\u2014e.g., a learnable exponent, softplus, or other activation applied either to the ratio itself or to the output of log-ratio/linear sum.\n   - If a bias/intercept is included, make clear its unique role and show it does not overlap functionally with the main fairness/shape parameters.\n\n3. **Innovation: Flexible Nonlinearity or Smooth Asymmetry**\n   - Encourage use of non-standard but monotonic transforms, such as:\n     - Raising the (splitperc_self / deserved_perc) to a learnable exponent (U = bias + beta * ((splitperc_self / deserved_perc)^rho - 1)), to flexibly shape sensitivity above/below fairness.\n     - A smooth, differentiable asymmetry parameter controlling loss/gain sensitivity (e.g., U = bias + beta * asinh(alpha * [splitperc_self / deserved_perc - 1])).\n     - A global transform applied to the output (e.g., tanh, softplus, or sigmoid of a scaled log-ratio + bias).\n     - Explicitly avoid technical parameters that are unrecoverable; any offset/epsilon/floor-type parameter should be included only if empirically justified and recoverable.\n   - All proposed transforms must be strictly monotonic and smooth\u2014NO use of max, min, abs, or piecewise logic.\n\n4. **Normalization and Interpretability**\n   - All central calculations MUST be in normalized or percent units for offers/deserved shares.\n   - Specify, in the variable descriptions, the range, type, (learnable/status), and a brief note on interpretation.\n   - For each parameter, describe how varying it shifts the utility curve, and how its impact is kept independent from the others.\n\n5. **Parameter Recoverability**\n   - For every learnable parameter included, offer a brief justification for its expected identifiability given the model structure and observed data.\n\n6. **Formatting and Output**\n   - The model formula (and ONLY the formula) goes between <MODEL>...</MODEL> tags.\n   - Variables, including ranges, descriptions, learnable/data status, and (for learnable) prior distribution, must be formatted as specified in JSON between <VARIABLES>...</VARIABLES> tags.\n   - The predicted variable, one from the dataset, goes in <target_variable> tags.\n   - Concise model summary (structure, psychological logic, not task details) belongs in <SUMMARY>...</SUMMARY> tags.\n\n7. **Caution on Parameter Addition**\n   - Avoid technical or redundant parameters (e.g., a \"stabilization\" epsilon) unless it is empirically shown to improve model fit and is readily recoverable.\n   - Favor adding a global shape/nonlinearity parameter or asymmetry IF and ONLY IF you can explain and demonstrate how it increases both fit (expected BIC/accuracy) and parameter recovery.\n   - Do not introduce parameters that act only in pathological data regimes or can be compensated for by other parameters.\n\n8. **Creativity Encouraged**\n   - Go beyond the linear and log-ratio staples: propose a novel, smooth, monotonic, and interpretable global nonlinearity or asymmetry, ensuring compatibility with robust parameter recovery and fit.\n   - Examples (to inspire, not limit): learnable exponents, arctan/tanh-scaled log-ratio, softplus applied to normalized offer gaps, or gain/loss smoothness via sigmoid-multiplicative slopes.\n   - If you use a new nonlinearity, briefly explain its theoretical motivation and its practical advantage over standard log/linear specifications.\n\nBe concise, rigorous, and inventive. Your model must remain implementable with the given dataset and comply with the model and variable formatting standards above. Prioritize genuine improvements in BIC/accuracy or parameter recovery, and explain clearly how each parameter uniquely contributes.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\nThe previous model achieved a strong balance of fit (BIC, accuracy) and parameter recovery, with two highly recoverable parameters (bias and fairness_sensitivity). However, the learnable epsilon (the log denominator offset) was essentially unrecoverable (r \u2248 0), indicating it functions mainly as a technical stabilizer rather than a meaningful psychological parameter. The overall structure\u2014a bias plus scaled log-ratio of actual/deserved percent\u2014is highly effective, but further gains may require:\n\n1. Addressing the redundancy/non-informativeness of epsilon, either by reimagining its role (as a learnable slope/nonlinearity instead, or as a robust but fixed value), or reallocating complexity to a more globally-influential but still monotonic and separable parameter.\n2. Introducing an additional nonlinearity or smooth asymmetry parameter, so long as all components remain globally differentiable, monotonic, and interpretable. For example, a power/exponent shaping of the (splitperc_self / deserved_perc) ratio, or a smooth, learnable slope difference above/below norm\u2014implemented via a hyperbolic tangent or smooth exponential function, not via step/if/max.\n3. Ensuring all parameters have non-overlapping psychological interpretations, live gradients across all data, and produce separable effects observable in parameter recovery.\n\nOther possibilities include:\n- A model where the main effect is through a power-law (e.g., (offer/deserved)^rho or its log variant), providing flexible psychophysical scaling\u2014rho can control \u201ccompression/expansion\u201d around fairness.\n- Use of a soft, differentiable global nonlinearity such as tanh, sigmoid, or softplus applied to the bias/scaled log-ratio sum, or transformation of the ratio itself (e.g., log(1 + gamma*[x - 1])).\n- Introduction of a single smooth \"loss aversion\" or \"asymmetry\" parameter, but in a way that does not rely on piecewise/if/else logic (e.g., via tanh or a parametrized scalar multiplying log-ratio for negative values).\n\nIt is essential to avoid adding parameters unless they improve BIC/accuracy and are demonstrably and theoretically recoverable\u2014do not introduce technical terms whose estimation is neither robust nor interpretable. The goal is to surpass previous performance by increasing either fit or identifiability\u2014or, ideally, both\u2014using creative, smooth, nonlinear transforms or asymmetry, but never at the expense of modeling clarity or inference soundness.\n\nFinally, rigorous parameterization and careful explanation of how each parameter can be independently recovered is crucial. If bias is retained, make sure it is not redundant with any new nonlinearity or scaling term.\n\nEncourage out-of-the-box innovations such as generalized ratio exponents, soft nonlinear \"loss aversion,\" activation-based models, or flexible, reference-dependent sigmoids, always within the constraints of monotonicity, smoothness, and interpretability.\n</think>\n\n---\n\n**Instructions for Run 9 Computational Modeling**\n\nTo design the next-generation computational model for responder behavior in this task, adhere to the following principles to maximize predictive accuracy, model fit (BIC), and parameter interpretability/recovery:\n\n1. **Globally Smooth, Reference-Dependent Utility**\n   - Construct your model as a smooth, monotonic function of the *relative* offer\u2014the ratio of the participant's proposed share to their deserved share (e.g., splitperc_self / deserved_perc).\n   - All nonlinearities or transforms must be differentiable everywhere and globally monotonic; no discontinuities or regime changes.\n\n2. **Parameterization: Parsimony AND Power**\n   - Include up to two or three learnable parameters max, but only if all are demonstrably separable, have clear psychological interpretations, and impact the utility globally across all data.\n   - You MUST provide a succinct rationale for how each parameter affects predictions and for why their effects are strictly nonredundant.\n   - Strongly consider creative, globally-applied nonlinearity\u2014e.g., a learnable exponent, softplus, or other activation applied either to the ratio itself or to the output of log-ratio/linear sum.\n   - If a bias/intercept is included, make clear its unique role and show it does not overlap functionally with the main fairness/shape parameters.\n\n3. **Innovation: Flexible Nonlinearity or Smooth Asymmetry**\n   - Encourage use of non-standard but monotonic transforms, such as:\n     - Raising the (splitperc_self / deserved_perc) to a learnable exponent (U = bias + beta * ((splitperc_self / deserved_perc)^rho - 1)), to flexibly shape sensitivity above/below fairness.\n     - A smooth, differentiable asymmetry parameter controlling loss/gain sensitivity (e.g., U = bias + beta * asinh(alpha * [splitperc_self / deserved_perc - 1])).\n     - A global transform applied to the output (e.g., tanh, softplus, or sigmoid of a scaled log-ratio + bias).\n     - Explicitly avoid technical parameters that are unrecoverable; any offset/epsilon/floor-type parameter should be included only if empirically justified and recoverable.\n   - All proposed transforms must be strictly monotonic and smooth\u2014NO use of max, min, abs, or piecewise logic.\n\n4. **Normalization and Interpretability**\n   - All central calculations MUST be in normalized or percent units for offers/deserved shares.\n   - Specify, in the variable descriptions, the range, type, (learnable/status), and a brief note on interpretation.\n   - For each parameter, describe how varying it shifts the utility curve, and how its impact is kept independent from the others.\n\n5. **Parameter Recoverability**\n   - For every learnable parameter included, offer a brief justification for its expected identifiability given the model structure and observed data.\n\n6. **Formatting and Output**\n   - The model formula (and ONLY the formula) goes between <MODEL>...</MODEL> tags.\n   - Variables, including ranges, descriptions, learnable/data status, and (for learnable) prior distribution, must be formatted as specified in JSON between <VARIABLES>...</VARIABLES> tags.\n   - The predicted variable, one from the dataset, goes in <target_variable> tags.\n   - Concise model summary (structure, psychological logic, not task details) belongs in <SUMMARY>...</SUMMARY> tags.\n\n7. **Caution on Parameter Addition**\n   - Avoid technical or redundant parameters (e.g., a \"stabilization\" epsilon) unless it is empirically shown to improve model fit and is readily recoverable.\n   - Favor adding a global shape/nonlinearity parameter or asymmetry IF and ONLY IF you can explain and demonstrate how it increases both fit (expected BIC/accuracy) and parameter recovery.\n   - Do not introduce parameters that act only in pathological data regimes or can be compensated for by other parameters.\n\n8. **Creativity Encouraged**\n   - Go beyond the linear and log-ratio staples: propose a novel, smooth, monotonic, and interpretable global nonlinearity or asymmetry, ensuring compatibility with robust parameter recovery and fit.\n   - Examples (to inspire, not limit): learnable exponents, arctan/tanh-scaled log-ratio, softplus applied to normalized offer gaps, or gain/loss smoothness via sigmoid-multiplicative slopes.\n   - If you use a new nonlinearity, briefly explain its theoretical motivation and its practical advantage over standard log/linear specifications.\n\nBe concise, rigorous, and inventive. Your model must remain implementable with the given dataset and comply with the model and variable formatting standards above. Prioritize genuine improvements in BIC/accuracy or parameter recovery, and explain clearly how each parameter uniquely contributes.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Let\u2019s proceed step by step, closely following each directive:\n\n**Step 1. What is the key modeling target?**\n\n- Predict responder behavior (accept = 1/reject = 0), based on the share offered and \u201cdeserved\u201d (proportional) share, as well as possible nonlinearity/asymmetry in fairness sensitivity.\n- All central computations should use normalized (percent) share, i.e. splitperc_self and deserved_perc, the latter computed as deserved_perc = 100 \u00d7 (token_self) / (token_self + token_opp).\n\n**Step 2. Candidate nonlinear monotonic transforms**\n\nThe classic model is a log-ratio or difference, e.g. utility = bias + beta\u00b7log(splitperc_self / deserved_perc). But as per your prompt, let\u2019s innovate:\n\n- A *power-law* model, with learnable exponent \u03c1 (rho): U = bias + beta\u00b7((splitperc_self / deserved_perc)^rho \u2013 1), allows both compression/expansion and asymmetry of the fairness function.\n    - When \u03c1 = 1, standard proportionality.\n    - \u03c1 > 1: superlinear, greater sensitivity to high offers.\n    - \u03c1 < 1: sublinear, compresses differences.\n\n- To ensure global monotonicity and avoid pathological behavior, we define the ratio as R = splitperc_self / deserved_perc (in percent units, both positive).\n\n**Step 3. Learnable parameterization**\n\n- bias: baseline willingness to accept (identifiable from overall acceptance rate, when fair/neutral offers).\n- beta: positive or negative, scales how strongly (and in what direction) deviations from fairness affect utility; not redundant with bias.\n- rho: (exponent) controls global shape; nonredundant with beta and bias as it warps the response to fairness.\n  - All three are globally recoverable: bias affects mean utility, beta the slope/strength of fairness, and rho the *shape* of the fairness curve (compression vs. expansion).\n\n**Step 4. Explicit model formula**\n\n- Normalize by computing deserved_perc (not provided directly, but calculable):\n    - deserved_perc = 100\u00b7(token_self) / (token_self + token_opp)\n    - ratio = splitperc_self / deserved_perc\n- Power-law nonlinear utility: U = bias + beta * (ratio^rho - 1)\n- Probability: P(accept) = logistic(U), but that is outside the model; you only need to return U\n\n**Step 5. Variables and bounds**\n\n- bias: (learnable) [-10, 10], covers all meaningful ranges for logit-scale utility; wide but finite.\n- beta: (learnable) [-10, 10], allows reversed/strong influence; wide but avoids identifiability issues at extreme values.\n- rho (fairness_exponent): (learnable) [0.1, 5.0]; 0.1 avoids division by zero (no values 0), 5 allows sharply nonlinear but still monotonic behavior.\n- splitperc_self: [0, 100], data input.\n- token_self, token_opp: (>=0), data input.\n- deserved_perc: [0, 100], derived as above.\n\n**Step 6. Model summary and rationale**\n\n- Rho manipulates the shape (\u201cpsychophysical fairness sensitivity\u201d): allows asymmetric or symmetric stretch\u2014separately identifiable from bias and beta.\n- Bias determines global acceptance (e.g. more/less likely at all offers); beta gives the directional slope; all are globally identifiable.\n- All input variables are available in dataset, or computed directly.\n\n---\n\n## Final Output\n\n<MODEL>\nU = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Responder utility for the proposed offer (higher = more likely to accept). Used as input to the decision probability logistic.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Bias/intercept parameter: overall willingness or reluctance to accept, regardless of fairness. Shifts the curve vertically.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Fairness scaling parameter: sensitivity to deviations from deserved share. Positive = more likely to accept generous offers, negative = stricter/reverse sensitivity.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_exponent\": {\n      \"description\": \"Global nonlinearity parameter: shapes psychophysical response to fairness. Controls compression/expansion of utility curve for offers above/below deserved. >1: accentuates differences above deserved, <1: compresses.\",\n      \"range\": {\n        \"min\": 0.1,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.1,\n          \"high\": 5.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed percent share for participant (offer to responder), from data.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Deserved percent share, calculated as 100*(token_self)/(token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by responder participant, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA globally monotonic, power-law fairness model for responder choice: utility depends on bias, fairness scaling, and a learnable exponent shaping nonlinear sensitivity to the ratio of received/deserved percent shares. The exponent allows asymmetric, compression- or expansion-based deviations from proportional fairness, providing greater flexibility and separable recoverability for all parameters compared to standard log- or linear-ratio models. All variables are percent-normalized, and the model is strictly smooth, differentiable, and monotonic for all parameter settings.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['bias', 'beta', 'fairness_exponent']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Responder utility for the proposed offer (higher = more likely to accept). Used as input to the decision probability logistic.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Bias/intercept parameter: overall willingness or reluctance to accept, regardless of fairness. Shifts the curve vertically.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Fairness scaling parameter: sensitivity to deviations from deserved share. Positive = more likely to accept generous offers, negative = stricter/reverse sensitivity.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_exponent\": {\n      \"description\": \"Global nonlinearity parameter: shapes psychophysical response to fairness. Controls compression/expansion of utility curve for offers above/below deserved. >1: accentuates differences above deserved, <1: compresses.\",\n      \"range\": {\n        \"min\": 0.1,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.1,\n          \"high\": 5.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed percent share for participant (offer to responder), from data.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Deserved percent share, calculated as 100*(token_self)/(token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by responder participant, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, bias=0.0, beta=1.0, fairness_exponent=1.0):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n\n        # Calculate deserved_perc\n        total_tokens = token_self + token_opp\n        if total_tokens == 0:\n            deserved_perc = 50.0  # avoid division by zero, set to 50 as default\n        else:\n            deserved_perc = 100.0 * (token_self / total_tokens)\n\n        # Calculate ratio\n        if deserved_perc == 0:\n            ratio = 0.0 # avoid division by zero\n        else:\n            ratio = splitperc_self / deserved_perc\n\n        # Calculate utility\n        utility = bias + beta * ((ratio ** fairness_exponent) - 1)\n        model_predictions.append(utility)\n\n    return model_predictions\n```",
      "timestamp": 1744714849.777948
    }
  ],
  "learnable_parameters": {
    "bias": {
      "description": "Bias/intercept parameter: overall willingness or reluctance to accept, regardless of fairness. Shifts the curve vertically.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10.0,
          "high": 10.0
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Fairness scaling parameter: sensitivity to deviations from deserved share. Positive = more likely to accept generous offers, negative = stricter/reverse sensitivity.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10.0,
          "high": 10.0
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "fairness_exponent": {
      "description": "Global nonlinearity parameter: shapes psychophysical response to fairness. Controls compression/expansion of utility curve for offers above/below deserved. >1: accentuates differences above deserved, <1: compresses.",
      "range": {
        "min": 0.1,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.1,
          "high": 5.0
        }
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)",
  "variable_descriptions": {
    "U": {
      "description": "Responder utility for the proposed offer (higher = more likely to accept). Used as input to the decision probability logistic.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "bias": {
      "description": "Bias/intercept parameter: overall willingness or reluctance to accept, regardless of fairness. Shifts the curve vertically.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10.0,
          "high": 10.0
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Fairness scaling parameter: sensitivity to deviations from deserved share. Positive = more likely to accept generous offers, negative = stricter/reverse sensitivity.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10.0,
          "high": 10.0
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "fairness_exponent": {
      "description": "Global nonlinearity parameter: shapes psychophysical response to fairness. Controls compression/expansion of utility curve for offers above/below deserved. >1: accentuates differences above deserved, <1: compresses.",
      "range": {
        "min": 0.1,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0.1,
          "high": 5.0
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "splitperc_self": {
      "description": "Proposed percent share for participant (offer to responder), from data.",
      "range": {
        "min": 0.0,
        "max": 100.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "deserved_perc": {
      "description": "Deserved percent share, calculated as 100*(token_self)/(token_self + token_opp).",
      "range": {
        "min": 0.0,
        "max": 100.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "token_self": {
      "description": "Number of tokens found by responder participant, used to compute deserved percent.",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by opponent, used to compute deserved percent.",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A globally monotonic, power-law fairness model for responder choice: utility depends on bias, fairness scaling, and a learnable exponent shaping nonlinear sensitivity to the ratio of received/deserved percent shares. The exponent allows asymmetric, compression- or expansion-based deviations from proportional fairness, providing greater flexibility and separable recoverability for all parameters compared to standard log- or linear-ratio models. All variables are percent-normalized, and the model is strictly smooth, differentiable, and monotonic for all parameter settings.",
  "target_variable": "accept",
  "full_reasoning": "Let\u2019s proceed step by step, closely following each directive:\n\n**Step 1. What is the key modeling target?**\n\n- Predict responder behavior (accept = 1/reject = 0), based on the share offered and \u201cdeserved\u201d (proportional) share, as well as possible nonlinearity/asymmetry in fairness sensitivity.\n- All central computations should use normalized (percent) share, i.e. splitperc_self and deserved_perc, the latter computed as deserved_perc = 100 \u00d7 (token_self) / (token_self + token_opp).\n\n**Step 2. Candidate nonlinear monotonic transforms**\n\nThe classic model is a log-ratio or difference, e.g. utility = bias + beta\u00b7log(splitperc_self / deserved_perc). But as per your prompt, let\u2019s innovate:\n\n- A *power-law* model, with learnable exponent \u03c1 (rho): U = bias + beta\u00b7((splitperc_self / deserved_perc)^rho \u2013 1), allows both compression/expansion and asymmetry of the fairness function.\n    - When \u03c1 = 1, standard proportionality.\n    - \u03c1 > 1: superlinear, greater sensitivity to high offers.\n    - \u03c1 < 1: sublinear, compresses differences.\n\n- To ensure global monotonicity and avoid pathological behavior, we define the ratio as R = splitperc_self / deserved_perc (in percent units, both positive).\n\n**Step 3. Learnable parameterization**\n\n- bias: baseline willingness to accept (identifiable from overall acceptance rate, when fair/neutral offers).\n- beta: positive or negative, scales how strongly (and in what direction) deviations from fairness affect utility; not redundant with bias.\n- rho: (exponent) controls global shape; nonredundant with beta and bias as it warps the response to fairness.\n  - All three are globally recoverable: bias affects mean utility, beta the slope/strength of fairness, and rho the *shape* of the fairness curve (compression vs. expansion).\n\n**Step 4. Explicit model formula**\n\n- Normalize by computing deserved_perc (not provided directly, but calculable):\n    - deserved_perc = 100\u00b7(token_self) / (token_self + token_opp)\n    - ratio = splitperc_self / deserved_perc\n- Power-law nonlinear utility: U = bias + beta * (ratio^rho - 1)\n- Probability: P(accept) = logistic(U), but that is outside the model; you only need to return U\n\n**Step 5. Variables and bounds**\n\n- bias: (learnable) [-10, 10], covers all meaningful ranges for logit-scale utility; wide but finite.\n- beta: (learnable) [-10, 10], allows reversed/strong influence; wide but avoids identifiability issues at extreme values.\n- rho (fairness_exponent): (learnable) [0.1, 5.0]; 0.1 avoids division by zero (no values 0), 5 allows sharply nonlinear but still monotonic behavior.\n- splitperc_self: [0, 100], data input.\n- token_self, token_opp: (>=0), data input.\n- deserved_perc: [0, 100], derived as above.\n\n**Step 6. Model summary and rationale**\n\n- Rho manipulates the shape (\u201cpsychophysical fairness sensitivity\u201d): allows asymmetric or symmetric stretch\u2014separately identifiable from bias and beta.\n- Bias determines global acceptance (e.g. more/less likely at all offers); beta gives the directional slope; all are globally identifiable.\n- All input variables are available in dataset, or computed directly.\n\n---\n\n## Final Output\n\n<MODEL>\nU = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Responder utility for the proposed offer (higher = more likely to accept). Used as input to the decision probability logistic.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Bias/intercept parameter: overall willingness or reluctance to accept, regardless of fairness. Shifts the curve vertically.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Fairness scaling parameter: sensitivity to deviations from deserved share. Positive = more likely to accept generous offers, negative = stricter/reverse sensitivity.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10.0,\n          \"high\": 10.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fairness_exponent\": {\n      \"description\": \"Global nonlinearity parameter: shapes psychophysical response to fairness. Controls compression/expansion of utility curve for offers above/below deserved. >1: accentuates differences above deserved, <1: compresses.\",\n      \"range\": {\n        \"min\": 0.1,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.1,\n          \"high\": 5.0\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed percent share for participant (offer to responder), from data.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"Deserved percent share, calculated as 100*(token_self)/(token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by responder participant, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent, used to compute deserved percent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA globally monotonic, power-law fairness model for responder choice: utility depends on bias, fairness scaling, and a learnable exponent shaping nonlinear sensitivity to the ratio of received/deserved percent shares. The exponent allows asymmetric, compression- or expansion-based deviations from proportional fairness, providing greater flexibility and separable recoverability for all parameters compared to standard log- or linear-ratio models. All variables are percent-normalized, and the model is strictly smooth, differentiable, and monotonic for all parameter settings.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)\nSummary: A globally monotonic, power-law fairness model for responder choice: utility depends on bias, fairness scaling, and a learnable exponent shaping nonlinear sensitivity to the ratio of received/deserved percent shares. The exponent allows asymmetric, compression- or expansion-based deviations from proportional fairness, providing greater flexibility and separable recoverability for all parameters compared to standard log- or linear-ratio models. All variables are percent-normalized, and the model is strictly smooth, differentiable, and monotonic for all parameter settings.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, bias=0.0, beta=1.0, fairness_exponent=1.0):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n\n        # Calculate deserved_perc\n        total_tokens = token_self + token_opp\n        if total_tokens == 0:\n            deserved_perc = 50.0  # avoid division by zero, set to 50 as default\n        else:\n            deserved_perc = 100.0 * (token_self / total_tokens)\n\n        # Calculate ratio\n        if deserved_perc == 0:\n            ratio = 0.0 # avoid division by zero\n        else:\n            ratio = splitperc_self / deserved_perc\n\n        # Calculate utility\n        utility = bias + beta * ((ratio ** fairness_exponent) - 1)\n        model_predictions.append(utility)\n\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.7826617826617828,
  "fitting_results": [
    {
      "bias": -1.1527387159523703,
      "beta": 10.0,
      "fairness_exponent": 0.5945975933318197,
      "success": true,
      "log_likelihood": -6.555959190116022,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.970969204097032,
      "beta": 10.0,
      "fairness_exponent": 3.7393577025446274,
      "success": true,
      "log_likelihood": -14.100609230627247,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.8526232130836675,
      "beta": 10.0,
      "fairness_exponent": 1.7215043966295835,
      "success": true,
      "log_likelihood": -9.899692109863532,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6258933862928955,
      "beta": 10.0,
      "fairness_exponent": 0.7901666106714497,
      "success": true,
      "log_likelihood": -14.453502638262249,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.9168680080476435,
      "beta": 10.0,
      "fairness_exponent": 2.198627832861157,
      "success": true,
      "log_likelihood": -9.790175685002303,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.751796471563827,
      "beta": 10.0,
      "fairness_exponent": 1.6984532171123472,
      "success": true,
      "log_likelihood": -12.049929829412786,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.3311234173554164,
      "success": true,
      "log_likelihood": -0.0007261577212364715,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.188553719731077,
      "beta": 10.0,
      "fairness_exponent": 1.3424082688396617,
      "success": true,
      "log_likelihood": -11.567428451549,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.33114254077063776,
      "success": true,
      "log_likelihood": -0.000726157720057533,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.583469044285979,
      "beta": 10.0,
      "fairness_exponent": 1.742437660255153,
      "success": true,
      "log_likelihood": -10.286520496279309,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.763161230153148,
      "beta": 10.0,
      "fairness_exponent": 2.099875373872487,
      "success": true,
      "log_likelihood": -6.549885764553768,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.7075665439922044,
      "beta": 10.0,
      "fairness_exponent": 0.5661235462985813,
      "success": true,
      "log_likelihood": -8.218468493737388,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.282695357413325,
      "beta": 10.0,
      "fairness_exponent": 2.6736142591897147,
      "success": true,
      "log_likelihood": -8.193314086170624,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.3311273893017461,
      "success": true,
      "log_likelihood": -0.0007261577207023476,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.331202141833825,
      "success": true,
      "log_likelihood": -0.0007261577388159298,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.33111790895567356,
      "success": true,
      "log_likelihood": -0.0007261577222230591,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.3311414525097791,
      "success": true,
      "log_likelihood": -0.0007261577200315233,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.132252041828078,
      "beta": 10.0,
      "fairness_exponent": 1.0051779223964088,
      "success": true,
      "log_likelihood": -5.761136340598079,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.4290676942645,
      "beta": 10.0,
      "fairness_exponent": 0.9809079898505569,
      "success": true,
      "log_likelihood": -6.127101918197539,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.3310830011558318,
      "success": true,
      "log_likelihood": -0.0007261577352272549,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.1245951103821294,
      "beta": 10.0,
      "fairness_exponent": 2.3526268506303945,
      "success": true,
      "log_likelihood": -12.426084671719918,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.078586456443085,
      "beta": 10.0,
      "fairness_exponent": 0.9895709440747936,
      "success": true,
      "log_likelihood": -7.427750907123597,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1885721364925366,
      "beta": 10.0,
      "fairness_exponent": 0.44030110024905966,
      "success": true,
      "log_likelihood": -17.361150279452247,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.079258767560482,
      "beta": 8.536254862594228,
      "fairness_exponent": 0.8406373134231248,
      "success": true,
      "log_likelihood": -16.407627628867463,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.350667956624604,
      "beta": 10.0,
      "fairness_exponent": 2.951901943159829,
      "success": true,
      "log_likelihood": -12.93003952883112,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.848010951368031,
      "beta": 10.0,
      "fairness_exponent": 2.0103107367544792,
      "success": true,
      "log_likelihood": -12.231247451070887,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.412012357684159,
      "beta": 10.0,
      "fairness_exponent": 1.8921871155963506,
      "success": true,
      "log_likelihood": -11.565603856255654,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.11886975075454,
      "beta": 10.0,
      "fairness_exponent": 3.211122900402918,
      "success": true,
      "log_likelihood": -4.541064655706654,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.807155118107698,
      "beta": 10.0,
      "fairness_exponent": 2.138068141806362,
      "success": true,
      "log_likelihood": -8.43660351956001,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.648321125684657,
      "beta": 10.0,
      "fairness_exponent": 3.268602539191947,
      "success": true,
      "log_likelihood": -13.453645788805407,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.33103520891904076,
      "success": true,
      "log_likelihood": -0.0007261577719256918,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -1.1527350736894275,
      "beta": 10.0,
      "fairness_exponent": 0.594595643312108,
      "success": true,
      "log_likelihood": -6.55595919009198,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1234517608873014,
      "beta": 10.0,
      "fairness_exponent": 0.32882275958222434,
      "success": true,
      "log_likelihood": -19.78857376350521,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6632925081634524,
      "beta": 10.0,
      "fairness_exponent": 0.8815042611147159,
      "success": true,
      "log_likelihood": -13.541958498431983,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": -10.0,
      "fairness_exponent": 0.33110927959392394,
      "success": true,
      "log_likelihood": -0.0007261577243537424,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.7546198136142594,
      "beta": 10.0,
      "fairness_exponent": 0.6581012785731637,
      "success": true,
      "log_likelihood": -15.074929787544425,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.3921983912843094,
      "beta": 10.0,
      "fairness_exponent": 1.3277903559439819,
      "success": true,
      "log_likelihood": -9.701248368595113,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.408304979807746,
      "beta": 10.0,
      "fairness_exponent": 3.011951598299255,
      "success": true,
      "log_likelihood": -13.39748854515311,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.239724014126804,
      "beta": 10.0,
      "fairness_exponent": 3.990226949098418,
      "success": true,
      "log_likelihood": -16.207917004120553,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": 9.613700294167963,
      "fairness_exponent": 2.2859868080652603,
      "success": true,
      "log_likelihood": -7.588135449075943,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.121952787279493,
      "beta": 10.0,
      "fairness_exponent": 4.587305198745407,
      "success": true,
      "log_likelihood": -16.12537329172346,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0473071147822797,
      "beta": 6.3780005780858655,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -9.598014559418637,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.320184747192645,
      "beta": 3.215892086303942,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -4.372646781312419,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0936384233922705,
      "beta": 10.0,
      "fairness_exponent": 0.6359180245026042,
      "success": true,
      "log_likelihood": -16.05173614055416,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.994355184772917,
      "beta": 10.0,
      "fairness_exponent": 1.079137587610088,
      "success": true,
      "log_likelihood": -13.342189557339534,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.7549291814973786,
      "beta": 10.0,
      "fairness_exponent": 0.3186325349567189,
      "success": true,
      "log_likelihood": -17.134478838254612,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.075524510504444,
      "beta": 7.983376295458614,
      "fairness_exponent": 2.037111052001162,
      "success": true,
      "log_likelihood": -14.901609609519063,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0791598119682906,
      "beta": 4.74402982610744,
      "fairness_exponent": 4.318162723626503,
      "success": true,
      "log_likelihood": -17.518922096760885,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.073278461671413,
      "beta": 9.229751957773498,
      "fairness_exponent": 2.994547528966339,
      "success": true,
      "log_likelihood": -12.41695647194395,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.746978463333659,
      "beta": 1.4313520657077925,
      "fairness_exponent": 1.344480558324457,
      "success": true,
      "log_likelihood": -24.010955029378486,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.9630975746232546,
      "beta": 4.37348543537711,
      "fairness_exponent": 1.239236622796452,
      "success": true,
      "log_likelihood": -18.41568824126433,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.6396657254914424,
      "beta": 10.0,
      "fairness_exponent": 0.37675911812852697,
      "success": true,
      "log_likelihood": -11.460317526998816,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.2112214503022916,
      "beta": 10.0,
      "fairness_exponent": 0.45141090574813025,
      "success": true,
      "log_likelihood": -18.26989709710244,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1219180897661396,
      "beta": 10.0,
      "fairness_exponent": 0.14623294549077714,
      "success": true,
      "log_likelihood": -22.811770007340062,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.0707291197234214,
      "beta": 4.560272743662583,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -18.0100025399951,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.112532190922187,
      "beta": 10.0,
      "fairness_exponent": 2.500530493193086,
      "success": true,
      "log_likelihood": -6.204883606584867,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.2029322195576646,
      "beta": 10.0,
      "fairness_exponent": 1.1292889108011537,
      "success": true,
      "log_likelihood": -10.269870274141645,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.4638956456154129,
      "beta": -10.0,
      "fairness_exponent": 0.14530644660958597,
      "success": true,
      "log_likelihood": -11.907622544835517,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.7671089913341053,
      "beta": 10.0,
      "fairness_exponent": 0.514845312286515,
      "success": true,
      "log_likelihood": -8.65786187386633,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.993124896950134,
      "beta": 10.0,
      "fairness_exponent": 3.510032619070194,
      "success": true,
      "log_likelihood": -13.418709740893236,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.2487253971775965,
      "beta": 4.26898973777949,
      "fairness_exponent": 2.3061936778138556,
      "success": true,
      "log_likelihood": -19.432925282474105,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.547514674291267,
      "beta": 10.0,
      "fairness_exponent": 3.166253836662057,
      "success": true,
      "log_likelihood": -12.191105717889421,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -1.1527361552277968,
      "beta": 10.0,
      "fairness_exponent": 0.5945968166457712,
      "success": true,
      "log_likelihood": -6.555959190094763,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.1456847788102287,
      "beta": 10.0,
      "fairness_exponent": 0.2967240272071653,
      "success": true,
      "log_likelihood": -20.633571784900802,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.3325831451293488,
      "beta": 10.0,
      "fairness_exponent": 0.9905063490822642,
      "success": true,
      "log_likelihood": -9.94128739998466,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 7.435757753328403,
      "beta": 10.0,
      "fairness_exponent": 2.60392197906517,
      "success": true,
      "log_likelihood": -12.37689085720564,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": 9.969566341118089,
      "fairness_exponent": 2.013334772027734,
      "success": true,
      "log_likelihood": -6.933013406624756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 5.472571941852025,
      "beta": 8.95422751018841,
      "fairness_exponent": 0.7126342354850353,
      "success": true,
      "log_likelihood": -10.144064150552218,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.8513762866997796,
      "beta": 10.0,
      "fairness_exponent": 0.5716347266346417,
      "success": true,
      "log_likelihood": -16.63222703864031,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 8.458214102892557,
      "beta": 6.755552218546237,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -9.28670321180097,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.760308220379515,
      "beta": 10.0,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -0.6211334581954298,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.6261012494056456,
      "beta": 10.0,
      "fairness_exponent": 0.3841685853080198,
      "success": true,
      "log_likelihood": -11.372545281235617,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.7647259396066657,
      "beta": 6.258547258026663,
      "fairness_exponent": 1.8687676326232714,
      "success": true,
      "log_likelihood": -16.8973829013084,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.2596048586748405,
      "beta": 7.085188793992882,
      "fairness_exponent": 0.5221442102220736,
      "success": true,
      "log_likelihood": -15.526596141185522,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.8349411127041391,
      "beta": 3.361297290466462,
      "fairness_exponent": 0.5721921206571544,
      "success": true,
      "log_likelihood": -23.316614774137573,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 4.292900339593232,
      "beta": 10.0,
      "fairness_exponent": 0.6889283851770757,
      "success": true,
      "log_likelihood": -13.913816549357227,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "beta": 8.913340194984812,
      "fairness_exponent": 2.453594166781183,
      "success": true,
      "log_likelihood": -5.883543673142306,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -2.560792486006102,
      "beta": 0.749458872041252,
      "fairness_exponent": 1.1479407276107028,
      "success": true,
      "log_likelihood": -7.668942979013394,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.9464331048056023,
      "beta": 4.215020797014828,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -20.475380782833692,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -1.152698438921983,
      "beta": 10.0,
      "fairness_exponent": 0.5945835740829973,
      "success": true,
      "log_likelihood": -6.555959192854653,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 1.6271693699815173,
      "beta": 1.9884040025402583,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -22.616576242926477,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6202147300359115,
      "beta": 0.32533358252803374,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -10.242950833399723,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -1.1456731315391886,
      "beta": 10.0,
      "fairness_exponent": 0.2692099104437957,
      "success": true,
      "log_likelihood": -10.785432231598266,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 3.5763792806624157,
      "beta": 10.0,
      "fairness_exponent": 0.8983609339635265,
      "success": true,
      "log_likelihood": -13.327954660435926,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.563591805784683,
      "beta": 2.6424216984127784,
      "fairness_exponent": 5.0,
      "success": true,
      "log_likelihood": -21.664798181137087,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": -0.2403325442650142,
      "beta": 5.4491542766698915,
      "fairness_exponent": 2.4785713547030572,
      "success": true,
      "log_likelihood": -5.719759822236902,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 9.69573902469525,
      "beta": 10.0,
      "fairness_exponent": 4.794299107077931,
      "success": true,
      "log_likelihood": -16.582281374009973,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 0.17977888267611192,
      "beta": 10.0,
      "fairness_exponent": 0.41564557958665777,
      "success": true,
      "log_likelihood": -14.101965701103408,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 6.536275395028402,
      "beta": 10.0,
      "fairness_exponent": 0.5562235258724793,
      "success": true,
      "log_likelihood": -5.474615572068374,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.301494847968321,
      "beta": 10.0,
      "fairness_exponent": 0.5668117393146851,
      "success": true,
      "log_likelihood": -16.526864541336526,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "bias": 2.6883449881324655,
      "beta": 2.562511855995283,
      "fairness_exponent": 3.2491917527543452,
      "success": true,
      "log_likelihood": -20.14083569914415,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "bias": {
        "r": 0.8488097808769006,
        "p": 7.065126218681647e-29
      },
      "beta": {
        "r": 0.7588244845659232,
        "p": 5.917854880538949e-20
      },
      "fairness_exponent": {
        "r": 0.41970119605457845,
        "p": 1.3818891227600836e-05
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 33.40199622217957,
  "bic_results": {
    "average_bic": 33.40199622217957,
    "individual_bics": [
      23.862475195600375,
      38.951775276622826,
      30.549941035095394,
      39.65756209189283,
      30.330908185372937,
      34.850416474193906,
      10.752009130810803,
      33.88541371846633,
      10.752009130808446,
      31.323597807926948,
      23.850328344475866,
      27.187493802843107,
      27.137184987709578,
      10.752009130809736,
      10.752009130845963,
      10.752009130812777,
      10.752009130808394,
      22.27282949656449,
      23.00476065176341,
      10.752009130838784,
      35.60272615880817,
      25.606058629615525,
      45.47285737427282,
      43.56581207310326,
      36.610635873030574,
      35.213051717510105,
      33.88176452787964,
      19.83268612678164,
      27.623763854488352,
      37.65784839297915,
      10.752009130912182,
      23.862475195552292,
      50.32770434237875,
      37.8344738122323,
      10.752009130817038,
      40.90041639045718,
      30.153053552558557,
      37.545533905674546,
      43.16639082360943,
      25.92682771352022,
      43.00130339881525,
      29.946585934205604,
      19.495850377993168,
      42.85402909647665,
      37.4349359300474,
      45.01951449187756,
      40.553776034406454,
      45.788401008890105,
      35.58446975925623,
      58.7724668741253,
      47.581933297896995,
      33.67119186936596,
      47.290351009573214,
      56.37409683004846,
      46.770561895358526,
      23.160324028538064,
      31.29029736365162,
      34.565801905039365,
      28.066280563100992,
      37.5879762971548,
      49.616407380316545,
      35.13276825114717,
      23.862475195557856,
      52.01770038516993,
      30.63313161533765,
      35.50433852977961,
      24.616583628617843,
      31.038685116472767,
      44.015010892648945,
      29.323963238970272,
      11.99282373175919,
      33.49564737783956,
      44.545322617985136,
      41.80374909773937,
      57.38378636364348,
      38.578189914082785,
      22.517644161652942,
      26.08844277339512,
      51.70131838103572,
      23.862475201077636,
      55.98370930122128,
      31.236458482167777,
      32.32142127856486,
      37.406466136240184,
      54.0801531776425,
      22.190076459842135,
      43.915119563388274,
      38.95448821757515,
      21.69978795950508,
      43.804285898041385,
      51.03222821365664
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- bias: r = 0.849\n- beta: r = 0.759\n- fairness_exponent: r = 0.420",
  "previous_models": [
    "Specification: U = bias + beta * ((splitperc_self / deserved_perc)^fairness_exponent - 1)\nSummary: A globally monotonic, power-law fairness model for responder choice: utility depends on bias, fairness scaling, and a learnable exponent shaping nonlinear sensitivity to the ratio of received/deserved percent shares. The exponent allows asymmetric, compression- or expansion-based deviations from proportional fairness, providing greater flexibility and separable recoverability for all parameters compared to standard log- or linear-ratio models. All variables are percent-normalized, and the model is strictly smooth, differentiable, and monotonic for all parameter settings.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 33.40199622217957\nOverall Accuracy: 0.7827\n\nParameter Recovery:\n- bias: r = 0.849\n- beta: r = 0.759\n- fairness_exponent: r = 0.420"
  ]
}