run_number,average_bic,bic_control,bic_cocaine,overall_accuracy,model_specification,model_summary,version,instructions_used,bias_recovery,beta_self_recovery,beta_ineq_recovery,beta_contrib_recovery,beta_fairness_recovery,inequity_weight_recovery,intercept_recovery,w_offered_recovery,w_fairness_recovery,fairness_weight_recovery,beta1_recovery,beta2_recovery,gamma_recovery,alpha_recovery,beta_recovery,inequity_aversion_recovery,baseline_recovery,offer_weight_recovery,w_self_recovery,w_fair_recovery,alpha_fairness_recovery,beta_fair_recovery,kappa_self_recovery,kappa_disadv_recovery,theta_recovery,weight_self_recovery,weight_DI_recovery,weight_AI_recovery,penalty_ineq_recovery,delta_recovery
20,32.598141021526224,28.051983435687685,36.670740525506574,0.8113553113553112,"utility = intercept + (weight_self * split_self) + (penalty_ineq * max(merit_share - split_self, 0))
merit_share = combined_earning * token_self / (token_self + token_opp)","This model predicts a responder's decision to accept or reject a proposed division of money based on three mechanisms: the absolute amount offered to self (self-interest), the deviation below a merit-based fair share (inequity aversion), and a baseline bias to accept. The perceived fair share is computed from the responder's relative token contribution. The utility for each trial is the sum of these influences and is transformed to acceptance probability by the logistic function.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,0.8756294287947155,,,,,,,,,,,,,,,,,,,0.6482504859870498,,,0.7315750898917976,
4,32.74967484750011,28.351555100764983,36.689657120617,0.7832722832722832,U = intercept + w_offered * (split_self / combined_earning) + w_fairness * ((split_self / combined_earning) - (token_self / (token_self + token_opp))),"A proportional fairness model for responder behavior in a group resource division task. Utility is a weighted sum of the share offered to self (relative to total), the deviation from proportional fairness (what is offered minus what is deserved, based on actual contributions), and a baseline bias. Three learnable parameters (intercept, offered weight, fairness weight) are constrained to [-10, 10]. The model provides strong parameter recoverability and interpretable effects, balancing parsimony and explanatory power.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,0.8815255783011746,0.4536147740647156,0.5629443244323822,,,,,,,,,,,,,,,,,,,,,
10,32.822216241151246,27.580564943790034,37.51786219503733,0.7704517704517705,U = baseline + fairness_weight * (split_self - (combined_earning * token_self / (token_self + token_opp))),This model computes responder utility as the sum of a base bias and a fairness sensitivity term. The fairness term is the difference between the money offered to the responder and what they would have received based on their relative contribution to the pot. Utility is transformed via a logistic function to predict probability of acceptance. The model has two learnable parameters: a fairness weight (allowing asymmetric valuation of unfair offers) and a baseline bias.,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,0.8161900410778208,,,,,,,0.8677133542180278,,,,,,,,,,,,,
3,32.843901319225544,27.580985000148853,37.558597188398416,0.764041514041514,U = bias + inequity_weight * (split_self - (combined_earning * (token_self / (token_self + token_opp)))),"A contribution-based inequity aversion model for predicting binary responder behavior: acceptance utility is the sum of an individual baseline bias and a weighted difference between the proposed share and the responder's contribution-proportional fair share of the available money. Logistic choice rule (temperature 1) is used to link utility to the observed accept/reject response. Two learnable parameters: one for acceptance bias, and one for sensitivity to disadvantageous inequity relative to contribution.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.644160254663821,,,,,0.7357462280268308,,,,,,,,,,,,,,,,,,,,,,,,
9,33.16416074763337,27.935745416122217,37.847949482112114,0.7576312576312576,"subjective_fair = combined_earning × token_self / (token_self + token_opp)
U = bias – inequity_aversion × max(subjective_fair – split_self, 0)","A two-parameter computational model of responder choice. The utility of an offer is computed as a linear function of bias minus the product of an inequity aversion strength and the shortfall of the offer from the responder's contribution-weighted fair share. This utility is mapped probabilistically to acceptance using a logistic function. Only deviations below the fair share penalize utility, and parameters are bounded for recoverability.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.8476737130002227,,,,,,,,,,,,,,,0.805787187413321,,,,,,,,,,,,,,
18,34.22156945251409,26.268269731653984,41.34640045245126,0.7994505494505495,"utility = split_self - theta * max(0, ((token_self / (token_self + token_opp)) * combined_earning - split_self))","This model predicts responder behavior by combining the absolute monetary gain from accepting an offer and a penalty for being offered less than a contribution-based entitlement. The penalty is only applied if the offer is less than entitled. The model has one learnable parameter, theta, reflecting sensitivity to disadvantageous entitlement violations, and is designed to enable clear parameter recovery and interpretability.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,,,,,,,,,0.9287938917775006,,,,,
13,35.72178971538055,31.05767068301422,39.900063015208715,0.7213064713064713,"U = beta_self * split_self - alpha_fairness * max(0, (token_self / (token_self + token_opp) - split_self / combined_earning))","A two-parameter utility model for responder behavior that combines the value of the offered amount (split_self) and a penalty for receiving less than one's deserved share (proportional to one's own contribution). The model predicts acceptance using a weighted sum of the offer and fairness penalty, with parameters for monetary reward weighting and fairness aversion, both bounded between 0 and 5.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,0.8324750752472463,,,,,,,,,,,,,,,,,,,0.23553023748520902,,,,,,,,,
21,36.386212915509596,32.2553762463303,40.08675409831604,0.7442002442002442,U = gamma * (split_self / combined_earning) - theta * abs((split_self / combined_earning) - (token_self / (token_self + token_opp))) + delta,"A three-parameter responder model predicting the probability of acceptance by combining sensitivity to absolute share (own payoff as a proportion), sensitivity to fairness (distance from deserved share based on relative contributions), and an idiosyncratic bias. The model can flexibly capture payoff maximization, fairness preference, or entitlement-driven strategies, using only variables directly specified in the dataset and is robust to parameter identifiability concerns.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,0.32778866267855516,,,,,,,,,,,,0.3133353549749973,,,,,0.8879865685718551
12,37.339228149464056,34.7942094223579,39.61914075916332,0.81990231990232,"contrib_fair_share = combined_earning * (token_self / (token_self + token_opp))
fairness_deviation = split_self - contrib_fair_share
utility = w_self * split_self + w_fair * fairness_deviation + bias","This is a linear utility model for responder choice that combines sensitivity to one's own monetary payoff and to deviations from the fair share based on individual contribution. The model predicts acceptance if the weighted sum of personal gain, fairness deviation, and an overall bias exceeds zero (after logistic transformation). There are three learnable parameters: weight on self-interest, weight on fairness deviation, and a bias term.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.710482643267311,,,,,,,,,,,,,,,,,,0.6776478002990607,0.8380839996005356,,,,,,,,,,
19,37.99949216897891,31.54012449711001,43.7860090416948,0.8015873015873015,"fair_share = combined_earning * (token_self / (token_self + token_opp))
DI = max(fair_share - split_self, 0)
AI = max(split_self - fair_share, 0)
U = bias + weight_self * split_self - weight_DI * DI - weight_AI * AI","A parsimonious inequity aversion model for responder acceptance, combining absolute self-gain, disadvantageous inequity aversion, and advantageous inequity aversion. The model flexibly calibrates each participant’s sensitivity to monetary self-gain, unfair disadvantage, and (to a lesser extent) unfair advantage, with a bias term capturing individual baseline tendencies.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.7988670973897465,,,,,,,,,,,,,,,,,,,,,,,,,0.6718562094967278,0.7035934333111553,0.47604541470285916,,
11,40.22569941656723,37.44501553804742,42.7167287244079,0.72008547008547,"deserved_perc = token_self / (token_self + token_opp)
delta = (splitperc_self / 100) - deserved_perc
U = bias + offer_weight * split_self + alpha * min(0, delta)","A minimal disadvantageous inequity aversion model for responder behavior, where utility is a weighted sum of the monetary offer (£) and a penalty for receiving a less-than-deserved share (relative to personal contribution), plus a baseline bias. The model uses three learnable parameters: an absolute offer weight, a bias, and an inequity aversion parameter penalizing negative deviations from deserved share. Utility is mapped to choice probability via the logistic function.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.8232580777931583,,,,,,,,,,,,,0.3095457688490111,,,,0.5490073862648491,,,,,,,,,,,,
16,40.340246823735676,37.69834228353815,42.70695297432929,0.6941391941391941,"utility = alpha * (split_self / combined_earning) 
        - beta * max((fair_share_perc - split_self / combined_earning), 0)
        - gamma * max((split_self / combined_earning - fair_share_perc), 0)","A three-parameter utility model for responder choices that linearly combines the self-interest of monetary gain with aversion to both disadvantageous and advantageous inequity, the latter two computed relative to the participant’s proportional contribution. The model predicts acceptance probability as a sigmoid of utility, balancing earnings and fairness-based considerations.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,0.15135145445880638,0.9011293625966366,0.6872734598462296,,,,,,,,,,,,,,,
5,46.60296069929388,43.13760812709247,49.70733904522431,0.6684981684981686,"U = intercept + fairness_weight * min(split_self - deserved_share, 0)","A merit-weighted inequity aversion model predicting responder acceptance based on the discrepancy between the offer and the participant's deserved share according to individual contributions. Utility penalizes only when offers are less than deserved, scaled by a negative fairness sensitivity parameter. Only two learnable parameters: a bias/intercept and a fairness-weight capturing sensitivity to unfairness, ensuring parsimony and identifiability.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,0.806541647633544,,,0.317972186120489,,,,,,,,,,,,,,,,,,,,
6,48.379804996094215,47.72509387637416,48.96631704084343,0.8040293040293041,"fair_share = (token_self / (token_self + token_opp)) * combined_earning
U = bias + beta1 * split_self + beta2 * (split_self - fair_share)","A linear utility model predicting responder acceptance of offers based on the absolute amount offered and the deviation from proportional (fair) splits, with a bias term capturing general acceptance propensity. The model uses three learnable parameters: a baseline bias, sensitivity to amount offered (beta1), and sensitivity to fairness deviation (beta2). Parameters are generously but finitely bounded for robust parameter recovery. The model is compact, interpretable, and tailored for the experimental structure described.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.778936824901335,,,,,,,,,,0.8004764622654977,0.8477711511098525,,,,,,,,,,,,,,,,,,
17,49.036378088548716,43.88018379162745,53.65546881287402,0.7967032967032966,"fair_share = (token_self) / (token_self + token_opp) * 100
disadv_gap = max(fair_share - splitperc_self, 0)
U = kappa_self * splitperc_self - kappa_disadv * disadv_gap","A two-parameter utility model for responder behavior combining sensitivity to own gain and aversion to being offered less than a proportional (contribution-based) fair share. The utility integrates both self-interest and fairness considerations, predicting acceptance probability using a logistic function applied to the trialwise utility.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,,,,,,,0.7412592199791901,0.811624282191038,,,,,,
2,50.51143555728199,46.70881974486263,53.91794555590767,0.78998778998779,"fairness_perc = 100 * token_self / (token_self + token_opp)
inequity = abs(splitperc_self - fairness_perc)
U = beta_self * split_self + beta_fairness * inequity + bias","A utility-based model for responder choices, combining linear sensitivity to monetary self-gain and absolute deviation from a contribution-based fair share. The model has three learnable parameters: one for self-gain, one for fairness aversion, and a general acceptance bias. The offer's utility is converted to an acceptance probability via a sigmoid, targeting binary accept/reject decisions.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.7486821403146444,0.5459632309411973,,,0.8836942169684964,,,,,,,,,,,,,,,,,,,,,,,,,
25,98.13582341928667,75.38596094276873,118.51590855450064,0.7713675213675214,utility = fairness_weight * (splitperc_self - deserved_perc) + bias,"This model predicts acceptance of offers based on how the proposed share for the responder (in percent) deviates from the share deserved according to their relative contribution of tokens. Acceptance utility is a linear function of this difference, scaled by a fairness sensitivity and intercept term. The model contains two learnable parameters: the fairness sensitivity and a response bias. The deserved percentage is computed as tokens found by self divided by the total tokens found, times 100.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.5731745116236705,,,,,,,,,0.9044234805304349,,,,,,,,,,,,,,,,,,,,
15,99.07287572974909,68.55135032710241,126.41507556962006,0.8147130647130647,U = bias + beta_self * split_perc_self + beta_fair * (split_perc_self - 100 * token_self / (token_self + token_opp)),"A linear utility model predicting the likelihood of responder acceptance based on a weighted combination of baseline acceptance tendency, the percentage of the total pot the participant receives, and the deviation from a fair division proportional to each player's contribution. The model allows for individual differences in sensitivity to both self-interest and fairness using only three learnable parameters, supporting robust parameter recovery and interpretability.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.13538701846663595,0.8701195186944061,,,,,,,,,,,,,,,,,,,,0.8526078919822623,,,,,,,,
7,222.12066303786148,191.3120823803502,249.72001654354867,0.7069597069597069,"deserved_share = combined_earning * (token_self / (token_self + token_opp))

U = gamma + alpha * min(0, split_self - deserved_share) + beta * split_self","A three-parameter model predicting responder acceptance by combining (1) aversion to being offered less than a fair share based on contributions, (2) sensitivity to the absolute size of the offer, and (3) baseline acceptance tendency. The model computes the difference between the actual offer and the responder’s deserved share, penalizes negative deviations, and combines these effects linearly. The utility is then mapped to acceptance probability via a logistic function.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,0.07066440148534156,-0.0004818530143452151,0.02407597678168695,,,,,,,,,,,,,,,
14,429.83124465205753,414.26515439486695,443.7758671741241,0.6593406593406593,"deserved_share = combined_earning * (token_self / (token_self + token_opp))
U = alpha_fairness * (split_self - deserved_share) + beta_self * split_self + bias","A utility-based model predicting responder acceptance by combining sensitivity to proportional fairness (difference between actual and deserved share), own monetary gain, and a constant bias. The model uses three learnable parameters with generous, finite bounds: fairness sensitivity (alpha_fairness), self-interest (beta_self), and bias. Utility is mapped to choice probability via a logistic function.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.25901524791622743,0.3138679689235997,,,,,,,,,,,,,,,,,,,0.26241055470742436,,,,,,,,,
1,470.5713695320011,503.962417784214,440.6585554727271,0.6648351648351648,"utility = bias + beta_self * split_self - beta_ineq * max(0, splitperc_opp - splitperc_self) - beta_contrib * abs((split_self / combined_earning) - (token_self / (token_self + token_opp)))","A not-overspecified inequity aversion and norm-based model predicting responder acceptance. Utility is determined by own monetary payoff, aversion to disadvantageous inequality, and punishment of deviations from the individual's contribution norm. Four parameters (three learnable psychological weights plus a bias term) map trial variables to acceptance utility, balancing self-interest and fairness concerns as a function of the offer and each player's contribution.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.12033606753600497,0.7766892459094891,0.02210355174697628,-0.04362456817716285,,,,,,,,,,,,,,,,,,,,,,,,,,
8,,,,,No metadata,,v0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22,,,,,"deserved_share_self = combined_earning * (token_self / (token_self + token_opp))
fairness_gap = split_self - deserved_share_self
U = theta * split_self + phi * fairness_gap + bias","This is a simple linear utility model for responder behavior accounting for sensitivity to own monetary gain, fairness relative to contribution (the difference between received offer and deserved share), and a baseline acceptance bias. It uses three learnable parameters: own-gain sensitivity, fairness-gap sensitivity, and an intercept. Utility is mapped via a logistic function to binary accept/reject predictions.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23,,,,,U = w_self * split_self + w_fair * (splitperc_self / 100 - token_self / (token_self + token_opp)) + intercept,"A linear utility model for responder choices that combines (1) the absolute offered amount, (2) the deviation of the offer from the participant's proportional contribution (contribution-weighted fairness), and (3) a participant-specific response bias. The model has only three learnable parameters per participant to ensure identifiability and efficient parameter recovery.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24,,,,,"proportional_share_self = (token_self / (token_self + token_opp)) * combined_earning

U = w_self * log(split_self + 1) - w_ineq * max(0, proportional_share_self - split_self) + bias","This is a fairness-based utility model for responder decisions, combining sensitivity to own monetary gain and a penalty for receiving less than a proportional share based on contributions. The model uses three learnable parameters: sensitivity to gain, proportional fairness aversion, and an acceptance bias. The computed utility is mapped to choice probability via a logistic function.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
