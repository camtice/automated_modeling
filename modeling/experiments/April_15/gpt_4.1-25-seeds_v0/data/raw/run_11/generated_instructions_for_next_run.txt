

---

**INSTRUCTIONS – RUN 12**

Your task is to design an advanced computational model of responder (accept/reject) decisions for the provided dataset. Your primary targets are:

- **(1) Maximize parameter recoverability:** Each learnable parameter must independently and robustly affect model predictions, such that it can be confidently recovered from realistic simulated data.
- **(2) Optimize fit (low BIC, high accuracy):** Select nonlinearities and mechanisms that allow your model to fit the real data distribution as well as, or better than, previous best approaches.
- **(3) Guarantee psychological interpretability:** Every parameter and computation must correspond to a clear psychological construct: fairness, unfairness aversion, generosity/reward, or context-based modulation.

**Updated Guidelines and Requirements:**

1. **Maximal Parameter Separability & Influence:**  
   - Only up to three learnable parameters, each *exclusively* governing one model region (threshold, below-threshold penalty, above-threshold bonus).
   - *No parameter overlap*: A given parameter must appear in one, and only one, mathematical region.
   - The loss and gain (unfair/fair) regions must be governed by strictly distinct, explicitly parameterized mechanisms.
   - Ensure your penalty and bonus region functions are *powerfully* influential throughout the real trial range. Demonstrate that varied parameter settings *clearly and predictably* affect acceptance patterns, not just in a narrow band.
   - Whenever possible, *normalize* penalty or bonus (e.g., by context variable, such as combined_earning, or by a percent/relative measure), so parameter effects generalize across different pot sizes and proposal types.

2. **Strong, Recoverable Nonlinearities (Avoid Overly Smooth or Flat Functions):**  
   - Move beyond simple powered penalties or softplus bonuses.
     - For unfair penalty: Try exponential (e.g., -A * (exp(B * abs(delta/scale)) - 1)), nonlinear polynomials, or custom piecewise functions. Consider normalizing "delta" by fairness_threshold or combined_earning for stability.
     - For generosity bonus: Use steep polynomials, exponential, or context-scaled sigmoid; or a combination (e.g., context-sensitive power for supra-threshold, or a sharper nonlinearity than softplus).
   - Explicitly exclude functions that saturate quickly unless steepness is directly and robustly tunable (with a learnable parameter).
   - *Creativity is strongly encouraged*: hybrid/conditional functions, context-weighted polynomials, or even "hinged" mixtures.

3. **Contextual Sensitivity:**
   - If you incorporate "context" (e.g., combined_earning), you must introduce it via its *own, strictly bounded and learnable* parameter that appears only in a single region.
   - You may alternatively use percent/relative delta (e.g., (split_self − threshold) / threshold), or a hybrid, to help with identifiability.
   - Avoid fixed multipliers: if context matters, make its impact parameterizable and localized.

4. **Expanded Simulation-based Justification:**
   - You must provide, before the model specification, simulation reasoning where you:
     - For *each* parameter, explicitly lay out—using at least two realistic example scenarios (for both small and large stakes)—how changing only that parameter affects model output, keeping the rest constant.
     - Highlight how the penalty/bonus shape changes are robust and recoverable, and not redundant with threshold shifts.

5. **Parameter Bounds and Documentation:**
   - List all learnable parameters in the <VARIABLES> section with generous but finite bounds, using Python-safe names.
   - Use clear, unambiguous mathematical notation in <MODEL>.
   - Every variable and parameter must be described in the JSON, indicating learnable/calculated/data; default inclusive bounds unless otherwise stated.

6. **Format and Output:**
   - Begin with simulation-based parameter reasoning as outlined above.
   - Give model equations only between <MODEL> and </MODEL>, strictly mathematical expressions.
   - Give variable and parameter descriptions (with bounds) as JSON in <VARIABLES>.
   - Specify the model’s prediction target using <target_variable>.
   - Insert a concise, mechanism-focused model description between <SUMMARY> tags.

**MANDATORY CREATIVE CHALLENGE:**  
_For this run, you are required to:_
- (A) Use a *parameterized exponential or "exponential-minus-one" nonlinearity* for the unfair (sub-threshold) penalty, with a learnable shape/steepness parameter acting only in the penalty region; consider context normalization.
- (B) Use a *parameterized power, exponential, or sharply nonlinear function* for the generosity (above-threshold) bonus, with explicit context or proportionality if possible.
- (C) Ensure, via simulation reasoning, that both penalty and bonus parameters create sharply distinct acceptance curve changes—especially in heavy-tailed, large context, and edge-case scenarios.

Push for creative, hybrid, and sharply separated model mechanisms. The best models will empower strong recovery, low BIC, and high accuracy by ensuring *every parameter is both interpretable and easily “visible” to the data during fitting*.

---