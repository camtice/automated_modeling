

---

**INSTRUCTIONS – RUN 7**

Your task is to design a computational model of responder (accept/reject) choice using the dataset described. Your principal goals are: (1) maximize recoverability of all learnable parameters, (2) ensure strong overall fit (e.g., BIC/accuracy), and (3) capture psychologically plausible, nonlinear, context- and fairness-sensitive mechanisms that go beyond simple additive models.

Please rigorously adhere to the following expanded process:

1. **Nonlinear and Contextual Mechanisms:**
   - Identify points in the offer/entitlement space where sharp, nonlinear, or stepwise changes in choice likelihood are expected.
   - Explicitly map and justify, for each model region (e.g., offer < threshold, offer ≥ threshold), what type of penalty/reward is applied and why.
   - Use at least one of: a saturating penalty/bonus (e.g., log or hyperbolic), loss/gain asymmetry (distinct treatment for unfair vs generous), or an explicit indicator/step/sigmoid function. Avoid simple power-law penalty exponents unless you can demonstrate that this term is strictly uncorrelated with penalty sensitivity.
   - Strongly consider a model structure where the psychological fairness threshold itself is a learnable but bounded parameter (not always a literal proportional entitlement).

2. **Parameter Separation, Recovery, and Identifiability:**
   - Your three learnable parameters must have clearly defined, *non-overlapping functional zones*: for example, one for placement of threshold, one for penalty strength below threshold, one for bonus magnitude above.
   - Do **not** allow any two parameters to both affect the same region (e.g., avoid penalty sensitivity *and* penalty exponent acting together).
   - In your **reasoning** step, perform a simulated “toy recovery” thought experiment: suppose each parameter is changed in isolation (holding others fixed at mid-range)—how does the accept/reject curve over split_self vs entitlement change? Are these changes visually separable and uniquely attributable?
   - Clearly predict, in your reasoning, how the model would distinguish a fairness-stickler from a greedy-acceptor or generous thresholder (give at least two parameter profiles and expected patterns).

3. **Move Beyond Additive Sweeps:**
   - At least one core interaction, ratio, or piecewise region must be used. *Mandatory*: Avoid purely additive linear models unless you can robustly defend recoverability.
   - If you use soft-threshold or sigmoid-like logic, be explicit: “Threshold placement parameter T controls where the S-curve bends; penalty/bonus steepness parameter S affects how rapidly acceptance moves around threshold.”

4. **Exploit Absolute and Proportional Context:**
   - Combine both absolute offer amount (split_self) and contextual fairness (e.g., proportional entitlement, combined_earning, token_self/token_opp).
   - When modeling threshold, *do not assume participants' threshold is always at their objective entitlement*; let this be inferred (learnable), ideally as a proportion.

5. **Parameterization, Bounds, and Interpretability:**
   - Strict maximum of three learnable parameters, all with wide, explicit, inclusive numerical bounds.
   - For each, state in reasoning which region it governs and how it affects choices and fits.
   - Document variables/parameters with python-safe names and ranges in the required JSON schema.
   - All variables in the model formula must be listed in the JSON spec.
   - Always specify which dataset variable is the prediction target.

6. **Model Output Requirements and Format:**
   - Think step by step (show all reasoning before formalizing the model).
   - Output the full mathematical model strictly between <MODEL> and </MODEL> tags (math only).
   - Output all variable and parameter documentation between <VARIABLES> and </VARIABLES> tags.
   - Output the prediction target within <target_variable> tags.
   - Output a purely descriptive <SUMMARY> (do not mention the task name).
   - Use only Python-safe parameter names.

**MANDATORY CREATIVE CHALLENGE:**  
Attempt at least one of the following:
- (A) Implement a smooth or soft threshold via sigmoidal or logistic or hyperbolic tangent function, with learnable threshold location and slope.
- (B) Introduce an explicit, parameterized "fairness threshold" scaling (e.g., tau_fairness: threshold = tau_fairness × entitlement), learnable from data.
- (C) Model an interaction term such that effect of unfairness is larger for bigger pots (or another contextual variable).
- (D) Any highly interpretable, innovative structure that breaks linear or exponent-only trade-off and uniquely partitions parameter impacts.
*State which you choose and why in your reasoning step.*

Think boldly and ground every parameter in a clear, testable psychological hypothesis.

---