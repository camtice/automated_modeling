{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "\n\n---\n\n**INSTRUCTIONS \u2013 RUN 7**\n\nYour task is to design a computational model of responder (accept/reject) choice using the dataset described. Your principal goals are: (1) maximize recoverability of all learnable parameters, (2) ensure strong overall fit (e.g., BIC/accuracy), and (3) capture psychologically plausible, nonlinear, context- and fairness-sensitive mechanisms that go beyond simple additive models.\n\nPlease rigorously adhere to the following expanded process:\n\n1. **Nonlinear and Contextual Mechanisms:**\n   - Identify points in the offer/entitlement space where sharp, nonlinear, or stepwise changes in choice likelihood are expected.\n   - Explicitly map and justify, for each model region (e.g., offer < threshold, offer \u2265 threshold), what type of penalty/reward is applied and why.\n   - Use at least one of: a saturating penalty/bonus (e.g., log or hyperbolic), loss/gain asymmetry (distinct treatment for unfair vs generous), or an explicit indicator/step/sigmoid function. Avoid simple power-law penalty exponents unless you can demonstrate that this term is strictly uncorrelated with penalty sensitivity.\n   - Strongly consider a model structure where the psychological fairness threshold itself is a learnable but bounded parameter (not always a literal proportional entitlement).\n\n2. **Parameter Separation, Recovery, and Identifiability:**\n   - Your three learnable parameters must have clearly defined, *non-overlapping functional zones*: for example, one for placement of threshold, one for penalty strength below threshold, one for bonus magnitude above.\n   - Do **not** allow any two parameters to both affect the same region (e.g., avoid penalty sensitivity *and* penalty exponent acting together).\n   - In your **reasoning** step, perform a simulated \u201ctoy recovery\u201d thought experiment: suppose each parameter is changed in isolation (holding others fixed at mid-range)\u2014how does the accept/reject curve over split_self vs entitlement change? Are these changes visually separable and uniquely attributable?\n   - Clearly predict, in your reasoning, how the model would distinguish a fairness-stickler from a greedy-acceptor or generous thresholder (give at least two parameter profiles and expected patterns).\n\n3. **Move Beyond Additive Sweeps:**\n   - At least one core interaction, ratio, or piecewise region must be used. *Mandatory*: Avoid purely additive linear models unless you can robustly defend recoverability.\n   - If you use soft-threshold or sigmoid-like logic, be explicit: \u201cThreshold placement parameter T controls where the S-curve bends; penalty/bonus steepness parameter S affects how rapidly acceptance moves around threshold.\u201d\n\n4. **Exploit Absolute and Proportional Context:**\n   - Combine both absolute offer amount (split_self) and contextual fairness (e.g., proportional entitlement, combined_earning, token_self/token_opp).\n   - When modeling threshold, *do not assume participants' threshold is always at their objective entitlement*; let this be inferred (learnable), ideally as a proportion.\n\n5. **Parameterization, Bounds, and Interpretability:**\n   - Strict maximum of three learnable parameters, all with wide, explicit, inclusive numerical bounds.\n   - For each, state in reasoning which region it governs and how it affects choices and fits.\n   - Document variables/parameters with python-safe names and ranges in the required JSON schema.\n   - All variables in the model formula must be listed in the JSON spec.\n   - Always specify which dataset variable is the prediction target.\n\n6. **Model Output Requirements and Format:**\n   - Think step by step (show all reasoning before formalizing the model).\n   - Output the full mathematical model strictly between <MODEL> and </MODEL> tags (math only).\n   - Output all variable and parameter documentation between <VARIABLES> and </VARIABLES> tags.\n   - Output the prediction target within <target_variable> tags.\n   - Output a purely descriptive <SUMMARY> (do not mention the task name).\n   - Use only Python-safe parameter names.\n\n**MANDATORY CREATIVE CHALLENGE:**  \nAttempt at least one of the following:\n- (A) Implement a smooth or soft threshold via sigmoidal or logistic or hyperbolic tangent function, with learnable threshold location and slope.\n- (B) Introduce an explicit, parameterized \"fairness threshold\" scaling (e.g., tau_fairness: threshold = tau_fairness \u00d7 entitlement), learnable from data.\n- (C) Model an interaction term such that effect of unfairness is larger for bigger pots (or another contextual variable).\n- (D) Any highly interpretable, innovative structure that breaks linear or exponent-only trade-off and uniquely partitions parameter impacts.\n*State which you choose and why in your reasoning step.*\n\nThink boldly and ground every parameter in a clear, testable psychological hypothesis.\n\n---",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: \n\n---\n\n**INSTRUCTIONS \u2013 RUN 7**\n\nYour task is to design a computational model of responder (accept/reject) choice using the dataset described. Your principal goals are: (1) maximize recoverability of all learnable parameters, (2) ensure strong overall fit (e.g., BIC/accuracy), and (3) capture psychologically plausible, nonlinear, context- and fairness-sensitive mechanisms that go beyond simple additive models.\n\nPlease rigorously adhere to the following expanded process:\n\n1. **Nonlinear and Contextual Mechanisms:**\n   - Identify points in the offer/entitlement space where sharp, nonlinear, or stepwise changes in choice likelihood are expected.\n   - Explicitly map and justify, for each model region (e.g., offer < threshold, offer \u2265 threshold), what type of penalty/reward is applied and why.\n   - Use at least one of: a saturating penalty/bonus (e.g., log or hyperbolic), loss/gain asymmetry (distinct treatment for unfair vs generous), or an explicit indicator/step/sigmoid function. Avoid simple power-law penalty exponents unless you can demonstrate that this term is strictly uncorrelated with penalty sensitivity.\n   - Strongly consider a model structure where the psychological fairness threshold itself is a learnable but bounded parameter (not always a literal proportional entitlement).\n\n2. **Parameter Separation, Recovery, and Identifiability:**\n   - Your three learnable parameters must have clearly defined, *non-overlapping functional zones*: for example, one for placement of threshold, one for penalty strength below threshold, one for bonus magnitude above.\n   - Do **not** allow any two parameters to both affect the same region (e.g., avoid penalty sensitivity *and* penalty exponent acting together).\n   - In your **reasoning** step, perform a simulated \u201ctoy recovery\u201d thought experiment: suppose each parameter is changed in isolation (holding others fixed at mid-range)\u2014how does the accept/reject curve over split_self vs entitlement change? Are these changes visually separable and uniquely attributable?\n   - Clearly predict, in your reasoning, how the model would distinguish a fairness-stickler from a greedy-acceptor or generous thresholder (give at least two parameter profiles and expected patterns).\n\n3. **Move Beyond Additive Sweeps:**\n   - At least one core interaction, ratio, or piecewise region must be used. *Mandatory*: Avoid purely additive linear models unless you can robustly defend recoverability.\n   - If you use soft-threshold or sigmoid-like logic, be explicit: \u201cThreshold placement parameter T controls where the S-curve bends; penalty/bonus steepness parameter S affects how rapidly acceptance moves around threshold.\u201d\n\n4. **Exploit Absolute and Proportional Context:**\n   - Combine both absolute offer amount (split_self) and contextual fairness (e.g., proportional entitlement, combined_earning, token_self/token_opp).\n   - When modeling threshold, *do not assume participants' threshold is always at their objective entitlement*; let this be inferred (learnable), ideally as a proportion.\n\n5. **Parameterization, Bounds, and Interpretability:**\n   - Strict maximum of three learnable parameters, all with wide, explicit, inclusive numerical bounds.\n   - For each, state in reasoning which region it governs and how it affects choices and fits.\n   - Document variables/parameters with python-safe names and ranges in the required JSON schema.\n   - All variables in the model formula must be listed in the JSON spec.\n   - Always specify which dataset variable is the prediction target.\n\n6. **Model Output Requirements and Format:**\n   - Think step by step (show all reasoning before formalizing the model).\n   - Output the full mathematical model strictly between <MODEL> and </MODEL> tags (math only).\n   - Output all variable and parameter documentation between <VARIABLES> and </VARIABLES> tags.\n   - Output the prediction target within <target_variable> tags.\n   - Output a purely descriptive <SUMMARY> (do not mention the task name).\n   - Use only Python-safe parameter names.\n\n**MANDATORY CREATIVE CHALLENGE:**  \nAttempt at least one of the following:\n- (A) Implement a smooth or soft threshold via sigmoidal or logistic or hyperbolic tangent function, with learnable threshold location and slope.\n- (B) Introduce an explicit, parameterized \"fairness threshold\" scaling (e.g., tau_fairness: threshold = tau_fairness \u00d7 entitlement), learnable from data.\n- (C) Model an interaction term such that effect of unfairness is larger for bigger pots (or another contextual variable).\n- (D) Any highly interpretable, innovative structure that breaks linear or exponent-only trade-off and uniquely partitions parameter impacts.\n*State which you choose and why in your reasoning step.*\n\nThink boldly and ground every parameter in a clear, testable psychological hypothesis.\n\n---\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Let\u2019s proceed step by step, as required, with detailed reasoning and compliance with all constraints.\n\n---\n\n### Step 1: BUILDING BLOCKS, OFFER SPACE, NONLINEARITY, FAIRNESS, CONTEXT\n\nResponder choice in such bargaining is sharply nonlinear near a fairness threshold: people strongly shift from likely-reject to likely-accept as offers move past their subjective minimum, and this threshold is *not* always their literal entitlement. There\u2019s also loss/gain asymmetry\u2014people are very sensitive to unfairness below this threshold, while becoming less sensitive or even indifferent to \u201cover-generous\u201d offers above.\n\nAdditionally, context matters: people may demand a higher share in large pots, or adjust their threshold proportional to what they contributed (number of tokens found), but with individual variation.\n\nLet\u2019s structure a model where:\n- Acceptance probability follows a *sigmoidal (logistic)* function of the distance between expected \u201centitlement\u201d and offered share.\n- Fairness threshold location (as a proportion of entitlement) is a *learnable parameter* (MANDATORY CREATIVE CHALLENGE B: parameterized fairness threshold scaling).\n- Punishment for sub-threshold offers is *steep* and separately parameterized via a *penalty steepness* (CREATIVE CHALLENGE A: soft-threshold with sigmoidal slope).\n- Additionally, magnitude of penalty for sub-threshold unfairness *scales with total pot size* (CREATIVE CHALLENGE C) so that violations in big pots \u201csting more.\u201d\n\n---\n\n### Step 2: PARAMETER FUNCTIONS AND RECOVERY, SEPARABILITY\n\n**Parameter 1:** `tau_fairness` (Threshold scaling)\u2014controls where the threshold is, as a *proportion* of entitlement:\n- If tau_fairness = 1, threshold is participant\u2019s literal entitlement.\n- If tau_fairness < 1, threshold is more tolerant (will accept less than earned).\n- If tau_fairness > 1, threshold is demanding (wants more than earned).\n\n**Parameter 2:** `slopesig` (Soft threshold slope)\u2014affects how *sharp* the acceptance curve is near threshold:\n- Large positive slopesig: almost stepwise change at threshold (\"all-or-nothing\").\n- Small slopesig: gradual acceptance increase around threshold.\n\n**Parameter 3:** `penalty_scaling` (Scaling unfairness penalty by pot size)\u2014modulates importance of total pot in the penalty for unfairness:\n- Higher penalty_scaling: in bigger pots, participants more intolerant of unfair offers.\n\n**Parameter recovery/identifiability simulations:**\n1. Increasing tau_fairness (other params held fixed): moves the acceptance \"S-curve\" to the right, so that only larger offers are accepted, but slope and context sensitivity *unchanged*.\n2. Increasing slopesig (holding others): makes the transition steeper; same threshold, but boundary between reject/accept sharpens.\n3. Increasing penalty_scaling: rejection risk for unfair offers increases more dramatically in large pots, but not for above-threshold offers.\n\n- No two parameters overlap in function: threshold placement, threshold *steepness*, and *context* scaling are separate.\n\n**Distinguishing participant types:**\n- \u201cFairness-stickler\u201d: high tau_fairness, high slopesig, high penalty_scaling\u2014demands at least full entitlement, sharply rejects less, especially in big pots.\n- \u201cGreedy-acceptor\u201d: low tau_fairness (~0.5), low slopesig\u2014accepts even low offers, gradual change, doesn't really \"care\" about pot size (low penalty_scaling).\n- \u201cGenerous thresholder\u201d: high tau_fairness (>1), lower slopesig\u2014they require MORE than their entitlement, but are more gradual/reasonable about acceptance.\n\n---\n\n### Step 3: FORMAL MODEL STRUCTURE\n\nLet:\n- *Entitlement* (per trial) = combined_earning \u00d7 (token_self / (token_self + token_opp))\n    - NOTE: We always use the share based on actual contributions.\n- *Threshold* = tau_fairness \u00d7 Entitlement (learnable scaling!)\n- *Normalized Offer Distance* = (split_self \u2212 Threshold) / combined_earning\n    - This normalization accommodates scaling by pot size.\n\n**Utility Function:**\n- U = slopesig \u00d7 [ (split_self \u2212 Threshold) / (combined_earning \u00d7 exp(penalty_scaling \u00d7 indicator_below)) ]\n    - where indicator_below = 1 if split_self < Threshold, 0 else.\n      - So, when the offer is below threshold, the denominator increases and U drops\u2014this interacts with penalty_scaling and total pot size.\n\n- More generally (for interpretable/identifiable form):\n    - If split_self \u2265 Threshold:      U = slopesig \u00d7 (split_self \u2212 Threshold)/combined_earning \u00a0  \n    - Else:                          U = slopesig \u00d7 (split_self \u2212 Threshold)/(combined_earning \u00d7 exp(penalty_scaling))\n    - Equivalent to a \u201csofter\u201d, context-scaled sigmoid penalty for sub-threshold offers.\n\n**Choice Rule:**\n- P(accept) = logistic(U), temperature fixed at 1.\n\n---\n\n### Step 4: MANDATORY CREATIVE CHALLENGE SELECTION\n\n- **(A) Smooth threshold (sigmoid via slopesig\u2014done)**\n- **(B) Parameterized threshold scaling (tau_fairness\u2014done)**\n- **(C) Context-dynamic penalty scaling (penalty_scaling\u2014done)**\n- This model covers all three challenges via its explicit partitioning and interaction.\n\n---\n\n### Step 5: MODEL EQUATION FORMULATION\n\nLet\u2019s write the actual model. All variables used explicitly. For space, we\u2019ll use python-safe names.\n\n---\n\n<MODEL>\nentitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom\n</MODEL>\n\n---\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"entitlement\": {\n      \"description\": \"Participant's earned share based on token contribution (in \u00a3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total value of the pot in this trial (in \u00a3)\",\n      \"range\": {\n        \"min\": 6,\n        \"max\": 90,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed amount to participant (in \u00a3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"tau_fairness\": {\n      \"description\": \"Scaling factor for psychological fairness threshold (multiplies entitlement); 1.0 = objective share, <1 = tolerant, >1 = demanding\",\n      \"range\": {\n        \"min\": 0.5,\n        \"max\": 1.5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.5,\n          \"high\": 1.5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"threshold\": {\n      \"description\": \"Offer amount required for 50% acceptance probability (in \u00a3), calculated as tau_fairness \u00d7 entitlement\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\"*1.5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"indicator_below\": {\n      \"description\": \"Indicator: 1 if split_self < threshold, else 0\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"penalty_scaling\": {\n      \"description\": \"Controls how strongly unfairness penalty increases with total pot for sub-threshold offers (bigger = harsher penalty for unfairness as pot grows)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"denom\": {\n      \"description\": \"Normalization denominator for slopesig (accounts for pot size, penalized if below threshold)\",\n      \"range\": {\n        \"min\": \"combined_earning\",\n        \"max\": \"combined_earning * exp(5)\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"slopesig\": {\n      \"description\": \"Slope parameter controlling steepness of acceptance probability as offer approaches threshold (higher = more step-like); can be positive or negative, but positive values produce standard responder shape\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 30,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 1,\n          \"high\": 30\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"U\": {\n      \"description\": \"Utility of acceptance (unbounded, transformed to probability by logistic)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA nonlinear fairness-threshold model for responder decisions. The model computes utility as a sigmoidal function of the distance between the proposed share and a learnable psychological fairness threshold (parameterized as a multiple of the participant's earned entitlement). Sub-threshold offers are penalized with strength that increases with total pot size, controlled by a penalty scaling parameter. The transition from rejection to acceptance is governed by an explicit slope parameter, allowing recoverable separation of threshold location, steepness of decision, and contextual sensitivity to offer size.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: []\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                entitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom\n\n                Variable Descriptions:\n                {\n  \"variables\": {}\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, tau_fairness=1.0, slopesig=1.0, penalty_scaling=1.0):\n    model_predictions = []\n    for trial in trial_data:\n        token_opp = trial.get(\"token_opp\", 1)\n        token_self = trial.get(\"token_self\", 1)\n        combined_earning = trial.get(\"combined_earning\", 1)\n        split_self = trial.get(\"split_self\", 0)\n        \n        entitlement = combined_earning * (token_self / (token_self + token_opp))\n        threshold = tau_fairness * entitlement\n        indicator_below = 1 if split_self < threshold else 0\n        denom = combined_earning * math.exp(penalty_scaling * indicator_below)\n        U = slopesig * (split_self - threshold) / denom\n        \n        model_predictions.append(U)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 1, \"group\": \"group1\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 60, \"split_opp\": 30.0, \"split_self\": 30.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 30.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 30.0}, {\"ID\": 2, \"group\": \"group1\", \"trial_number\": 2, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 60, \"split_opp\": 30.0, \"split_self\": 30.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 30.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 30.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n```",
      "timestamp": 1744725982.476584
    }
  ],
  "parsing_error": "Failed to parse variable descriptions JSON",
  "model_specification": "entitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom",
  "variable_descriptions": {},
  "model_summary": "A nonlinear fairness-threshold model for responder decisions. The model computes utility as a sigmoidal function of the distance between the proposed share and a learnable psychological fairness threshold (parameterized as a multiple of the participant's earned entitlement). Sub-threshold offers are penalized with strength that increases with total pot size, controlled by a penalty scaling parameter. The transition from rejection to acceptance is governed by an explicit slope parameter, allowing recoverable separation of threshold location, steepness of decision, and contextual sensitivity to offer size.",
  "target_variable": "accept",
  "full_reasoning": "Let\u2019s proceed step by step, as required, with detailed reasoning and compliance with all constraints.\n\n---\n\n### Step 1: BUILDING BLOCKS, OFFER SPACE, NONLINEARITY, FAIRNESS, CONTEXT\n\nResponder choice in such bargaining is sharply nonlinear near a fairness threshold: people strongly shift from likely-reject to likely-accept as offers move past their subjective minimum, and this threshold is *not* always their literal entitlement. There\u2019s also loss/gain asymmetry\u2014people are very sensitive to unfairness below this threshold, while becoming less sensitive or even indifferent to \u201cover-generous\u201d offers above.\n\nAdditionally, context matters: people may demand a higher share in large pots, or adjust their threshold proportional to what they contributed (number of tokens found), but with individual variation.\n\nLet\u2019s structure a model where:\n- Acceptance probability follows a *sigmoidal (logistic)* function of the distance between expected \u201centitlement\u201d and offered share.\n- Fairness threshold location (as a proportion of entitlement) is a *learnable parameter* (MANDATORY CREATIVE CHALLENGE B: parameterized fairness threshold scaling).\n- Punishment for sub-threshold offers is *steep* and separately parameterized via a *penalty steepness* (CREATIVE CHALLENGE A: soft-threshold with sigmoidal slope).\n- Additionally, magnitude of penalty for sub-threshold unfairness *scales with total pot size* (CREATIVE CHALLENGE C) so that violations in big pots \u201csting more.\u201d\n\n---\n\n### Step 2: PARAMETER FUNCTIONS AND RECOVERY, SEPARABILITY\n\n**Parameter 1:** `tau_fairness` (Threshold scaling)\u2014controls where the threshold is, as a *proportion* of entitlement:\n- If tau_fairness = 1, threshold is participant\u2019s literal entitlement.\n- If tau_fairness < 1, threshold is more tolerant (will accept less than earned).\n- If tau_fairness > 1, threshold is demanding (wants more than earned).\n\n**Parameter 2:** `slopesig` (Soft threshold slope)\u2014affects how *sharp* the acceptance curve is near threshold:\n- Large positive slopesig: almost stepwise change at threshold (\"all-or-nothing\").\n- Small slopesig: gradual acceptance increase around threshold.\n\n**Parameter 3:** `penalty_scaling` (Scaling unfairness penalty by pot size)\u2014modulates importance of total pot in the penalty for unfairness:\n- Higher penalty_scaling: in bigger pots, participants more intolerant of unfair offers.\n\n**Parameter recovery/identifiability simulations:**\n1. Increasing tau_fairness (other params held fixed): moves the acceptance \"S-curve\" to the right, so that only larger offers are accepted, but slope and context sensitivity *unchanged*.\n2. Increasing slopesig (holding others): makes the transition steeper; same threshold, but boundary between reject/accept sharpens.\n3. Increasing penalty_scaling: rejection risk for unfair offers increases more dramatically in large pots, but not for above-threshold offers.\n\n- No two parameters overlap in function: threshold placement, threshold *steepness*, and *context* scaling are separate.\n\n**Distinguishing participant types:**\n- \u201cFairness-stickler\u201d: high tau_fairness, high slopesig, high penalty_scaling\u2014demands at least full entitlement, sharply rejects less, especially in big pots.\n- \u201cGreedy-acceptor\u201d: low tau_fairness (~0.5), low slopesig\u2014accepts even low offers, gradual change, doesn't really \"care\" about pot size (low penalty_scaling).\n- \u201cGenerous thresholder\u201d: high tau_fairness (>1), lower slopesig\u2014they require MORE than their entitlement, but are more gradual/reasonable about acceptance.\n\n---\n\n### Step 3: FORMAL MODEL STRUCTURE\n\nLet:\n- *Entitlement* (per trial) = combined_earning \u00d7 (token_self / (token_self + token_opp))\n    - NOTE: We always use the share based on actual contributions.\n- *Threshold* = tau_fairness \u00d7 Entitlement (learnable scaling!)\n- *Normalized Offer Distance* = (split_self \u2212 Threshold) / combined_earning\n    - This normalization accommodates scaling by pot size.\n\n**Utility Function:**\n- U = slopesig \u00d7 [ (split_self \u2212 Threshold) / (combined_earning \u00d7 exp(penalty_scaling \u00d7 indicator_below)) ]\n    - where indicator_below = 1 if split_self < Threshold, 0 else.\n      - So, when the offer is below threshold, the denominator increases and U drops\u2014this interacts with penalty_scaling and total pot size.\n\n- More generally (for interpretable/identifiable form):\n    - If split_self \u2265 Threshold:      U = slopesig \u00d7 (split_self \u2212 Threshold)/combined_earning \u00a0  \n    - Else:                          U = slopesig \u00d7 (split_self \u2212 Threshold)/(combined_earning \u00d7 exp(penalty_scaling))\n    - Equivalent to a \u201csofter\u201d, context-scaled sigmoid penalty for sub-threshold offers.\n\n**Choice Rule:**\n- P(accept) = logistic(U), temperature fixed at 1.\n\n---\n\n### Step 4: MANDATORY CREATIVE CHALLENGE SELECTION\n\n- **(A) Smooth threshold (sigmoid via slopesig\u2014done)**\n- **(B) Parameterized threshold scaling (tau_fairness\u2014done)**\n- **(C) Context-dynamic penalty scaling (penalty_scaling\u2014done)**\n- This model covers all three challenges via its explicit partitioning and interaction.\n\n---\n\n### Step 5: MODEL EQUATION FORMULATION\n\nLet\u2019s write the actual model. All variables used explicitly. For space, we\u2019ll use python-safe names.\n\n---\n\n<MODEL>\nentitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom\n</MODEL>\n\n---\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"entitlement\": {\n      \"description\": \"Participant's earned share based on token contribution (in \u00a3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total value of the pot in this trial (in \u00a3)\",\n      \"range\": {\n        \"min\": 6,\n        \"max\": 90,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed amount to participant (in \u00a3)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"tau_fairness\": {\n      \"description\": \"Scaling factor for psychological fairness threshold (multiplies entitlement); 1.0 = objective share, <1 = tolerant, >1 = demanding\",\n      \"range\": {\n        \"min\": 0.5,\n        \"max\": 1.5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0.5,\n          \"high\": 1.5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"threshold\": {\n      \"description\": \"Offer amount required for 50% acceptance probability (in \u00a3), calculated as tau_fairness \u00d7 entitlement\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"combined_earning\"*1.5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"indicator_below\": {\n      \"description\": \"Indicator: 1 if split_self < threshold, else 0\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"penalty_scaling\": {\n      \"description\": \"Controls how strongly unfairness penalty increases with total pot for sub-threshold offers (bigger = harsher penalty for unfairness as pot grows)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"denom\": {\n      \"description\": \"Normalization denominator for slopesig (accounts for pot size, penalized if below threshold)\",\n      \"range\": {\n        \"min\": \"combined_earning\",\n        \"max\": \"combined_earning * exp(5)\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"slopesig\": {\n      \"description\": \"Slope parameter controlling steepness of acceptance probability as offer approaches threshold (higher = more step-like); can be positive or negative, but positive values produce standard responder shape\",\n      \"range\": {\n        \"min\": 1,\n        \"max\": 30,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 1,\n          \"high\": 30\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"U\": {\n      \"description\": \"Utility of acceptance (unbounded, transformed to probability by logistic)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA nonlinear fairness-threshold model for responder decisions. The model computes utility as a sigmoidal function of the distance between the proposed share and a learnable psychological fairness threshold (parameterized as a multiple of the participant's earned entitlement). Sub-threshold offers are penalized with strength that increases with total pot size, controlled by a penalty scaling parameter. The transition from rejection to acceptance is governed by an explicit slope parameter, allowing recoverable separation of threshold location, steepness of decision, and contextual sensitivity to offer size.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: entitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom\nSummary: A nonlinear fairness-threshold model for responder decisions. The model computes utility as a sigmoidal function of the distance between the proposed share and a learnable psychological fairness threshold (parameterized as a multiple of the participant's earned entitlement). Sub-threshold offers are penalized with strength that increases with total pot size, controlled by a penalty scaling parameter. The transition from rejection to acceptance is governed by an explicit slope parameter, allowing recoverable separation of threshold location, steepness of decision, and contextual sensitivity to offer size.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, tau_fairness=1.0, slopesig=1.0, penalty_scaling=1.0):\n    model_predictions = []\n    for trial in trial_data:\n        token_opp = trial.get(\"token_opp\", 1)\n        token_self = trial.get(\"token_self\", 1)\n        combined_earning = trial.get(\"combined_earning\", 1)\n        split_self = trial.get(\"split_self\", 0)\n        \n        entitlement = combined_earning * (token_self / (token_self + token_opp))\n        threshold = tau_fairness * entitlement\n        indicator_below = 1 if split_self < threshold else 0\n        denom = combined_earning * math.exp(penalty_scaling * indicator_below)\n        U = slopesig * (split_self - threshold) / denom\n        \n        model_predictions.append(U)\n    return model_predictions",
  "total_retries": 0,
  "fitting_warnings": [
    "Error fitting participant 1001: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1002: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1003: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1004: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1005: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1006: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1007: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1008: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1009: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1010: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1011: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1012: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1013: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1015: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1016: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1017: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1018: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1019: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1020: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1021: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1022: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1023: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1024: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1025: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1026: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1027: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1028: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1029: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1030: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1031: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1032: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1033: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1034: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1035: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1036: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1037: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1038: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1039: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1040: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1041: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1042: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1043: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 1044: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2001: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2002: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2003: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2004: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2005: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2006: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2007: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2008: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2009: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2010: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2011: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2012: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2013: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2014: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2015: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2016: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2017: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2018: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2019: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2020: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2021: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2022: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2023: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2024: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2025: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2026: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2027: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2028: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2029: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2030: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2031: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2032: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2033: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2034: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2035: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2036: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2037: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2038: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2039: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2040: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2041: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2042: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2043: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2044: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2045: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2046: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2047: Error in parameter fitting: No valid parameter bounds found in learnable_params",
    "Error fitting participant 2048: Error in parameter fitting: No valid parameter bounds found in learnable_params"
  ],
  "skipped_participants": [
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: No valid parameter bounds found in learnable_params"
    }
  ],
  "num_skipped_participants": 91,
  "fitting_error": "No successful parameter fits obtained",
  "recovery_error": "No fitting results found",
  "previous_models": [
    "Specification: entitlement = combined_earning * (token_self / (token_self + token_opp))\nthreshold = tau_fairness * entitlement\nindicator_below = 1 if split_self < threshold else 0\ndenom = combined_earning * exp(penalty_scaling * indicator_below)\nU = slopesig * (split_self - threshold) / denom\nSummary: A nonlinear fairness-threshold model for responder decisions. The model computes utility as a sigmoidal function of the distance between the proposed share and a learnable psychological fairness threshold (parameterized as a multiple of the participant's earned entitlement). Sub-threshold offers are penalized with strength that increases with total pot size, controlled by a penalty scaling parameter. The transition from rejection to acceptance is governed by an explicit slope parameter, allowing recoverable separation of threshold location, steepness of decision, and contextual sensitivity to offer size.\nTarget Variable: accept\nPrediction Type: utility"
  ]
}