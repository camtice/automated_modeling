{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\n- The previous instructions (and likely subsequent models) emphasize balancing parameter parsimony and psychological realism, but parameter recovery for \"alpha_self\" and \"bias\" is notably weaker than for \"alpha_fair\".\n- Multicollinearity between self-interest and fairness parameters probably impairs recovery; the two terms as constructed both depend on split_self, possibly causing redundancy.\n- There are additional sources of \u201cfairness\u201d signals in the dataset (e.g., splitperc_self, splitperc_opp) that might clarify fairness deviations, or a non-linear treatment of fairness deviations might reduce redundancy.\n- The model is not explicitly utilizing opponent-centric fairness (\u201cdisadvantageous\u201d vs. \u201cadvantageous\u201d inequality), nor does it model possible threshold or \"rejection zone\" effects. Alternative forms (e.g., using absolute deviations, or piecewise penalties) might yield better identifiability.\n- There is room for improving parameter recovery by:\n    - Encouraging the isolation of collinear terms (e.g., use deviation score only, or construct terms orthogonally).\n    - Suggesting non-linear transforms (e.g., using |split_self \u2212 fair_share| or indicator functions for \u201cunfair\u201d offers).\n    - Considering alternative measures of fairness, possibly capturing aversion to both being under-offered and over-offered, as in Fehr-Schmidt\u2013style models.\n    - Suggesting or allowing constraint for some parameters (e.g., weighting fairness aversion parameter to be \u22650).\n    - Pointing out that high bias for lower parameter count should not overshadow testability or psychological theorizing.\n\n- Modelers should be encouraged to:\n    - Explore models that go beyond linear combinations of monetary/fairness motives, especially non-linear effects or piecewise penalties.\n    - Think about including or manipulating \"inequality aversion\" to distinguish between different fairness violations, not just deviations from fair share.\n    - Reflect on including \"rejection thresholds\" (i.e., utility becomes sharply negative under certain conditions).\n    - Consider utilizing all available data (possibly testing constructs such as percent splits) where they might uniquely identify a psychological mechanism.\n</think>\n\n**Updated Instructions for Run 2:**\n\nBe strategically critical of parameter redundancy and high covariance, aiming for strong parameter recovery as well as interpretability and fit. \n\nFirst, before formalizing a model, reason step by step about:\n* What distinct psychological processes (self-interest, fairness aversion, social reference, etc.) may drive responder behavior in this context.\n* Whether these motives interact linearly or non-linearly, and whether threshold, piecewise, or asymmetric (e.g., disadvantageous vs. advantageous inequality) effects may be present.\n* How to mathematically structure the model to minimize redundancy: for example, can fairness/inequity be represented via a single orthogonal term rather than overlapping with monetary terms? Should you use deviation, percent difference, or an indicator function?\n* Whether non-linear penalties for unfairness (e.g., absolute value, squared difference, step/indicator, or asymmetric treatment of unfair splits) could disentangle parameters and improve recovery.\n* How best to set parameter constraints (e.g., non-negativity for aversion parameters) to further decrease redundancy and ensure interpretable roles.\n\nWhen developing your model:\n- Explicitly address the risk of collinearity between parameters. If using fairness and self-interest, justify how their effects can be uniquely identified, or merge them into a single interpretable metric.\n- Consider employing alternative fairness constructs (e.g., Fehr-Schmidt: punish only disadvantageous/advantageous inequality, or piecewise loss-function for unfair offers).\n- Allow for out-of-the-box modeling approaches including non-linear, piecewise, or \u201cthreshold\u201d/stepwise mechanisms, especially if these could differentiate between hypotheses or improve parameter recovery.\n- Think about whether utilizing percentage-based splits or other available variables could introduce new, orthogonal information to the model.\n- Prioritize models that can be robustly recovered from data with minimal mutual dependence between learnable parameters, even if this results in changes from strictly linear models.\n\nOnce you have reasoned about these steps, then and only then provide your model specification and variable descriptions.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\n- The previous instructions (and likely subsequent models) emphasize balancing parameter parsimony and psychological realism, but parameter recovery for \"alpha_self\" and \"bias\" is notably weaker than for \"alpha_fair\".\n- Multicollinearity between self-interest and fairness parameters probably impairs recovery; the two terms as constructed both depend on split_self, possibly causing redundancy.\n- There are additional sources of \u201cfairness\u201d signals in the dataset (e.g., splitperc_self, splitperc_opp) that might clarify fairness deviations, or a non-linear treatment of fairness deviations might reduce redundancy.\n- The model is not explicitly utilizing opponent-centric fairness (\u201cdisadvantageous\u201d vs. \u201cadvantageous\u201d inequality), nor does it model possible threshold or \"rejection zone\" effects. Alternative forms (e.g., using absolute deviations, or piecewise penalties) might yield better identifiability.\n- There is room for improving parameter recovery by:\n    - Encouraging the isolation of collinear terms (e.g., use deviation score only, or construct terms orthogonally).\n    - Suggesting non-linear transforms (e.g., using |split_self \u2212 fair_share| or indicator functions for \u201cunfair\u201d offers).\n    - Considering alternative measures of fairness, possibly capturing aversion to both being under-offered and over-offered, as in Fehr-Schmidt\u2013style models.\n    - Suggesting or allowing constraint for some parameters (e.g., weighting fairness aversion parameter to be \u22650).\n    - Pointing out that high bias for lower parameter count should not overshadow testability or psychological theorizing.\n\n- Modelers should be encouraged to:\n    - Explore models that go beyond linear combinations of monetary/fairness motives, especially non-linear effects or piecewise penalties.\n    - Think about including or manipulating \"inequality aversion\" to distinguish between different fairness violations, not just deviations from fair share.\n    - Reflect on including \"rejection thresholds\" (i.e., utility becomes sharply negative under certain conditions).\n    - Consider utilizing all available data (possibly testing constructs such as percent splits) where they might uniquely identify a psychological mechanism.\n</think>\n\n**Updated Instructions for Run 2:**\n\nBe strategically critical of parameter redundancy and high covariance, aiming for strong parameter recovery as well as interpretability and fit. \n\nFirst, before formalizing a model, reason step by step about:\n* What distinct psychological processes (self-interest, fairness aversion, social reference, etc.) may drive responder behavior in this context.\n* Whether these motives interact linearly or non-linearly, and whether threshold, piecewise, or asymmetric (e.g., disadvantageous vs. advantageous inequality) effects may be present.\n* How to mathematically structure the model to minimize redundancy: for example, can fairness/inequity be represented via a single orthogonal term rather than overlapping with monetary terms? Should you use deviation, percent difference, or an indicator function?\n* Whether non-linear penalties for unfairness (e.g., absolute value, squared difference, step/indicator, or asymmetric treatment of unfair splits) could disentangle parameters and improve recovery.\n* How best to set parameter constraints (e.g., non-negativity for aversion parameters) to further decrease redundancy and ensure interpretable roles.\n\nWhen developing your model:\n- Explicitly address the risk of collinearity between parameters. If using fairness and self-interest, justify how their effects can be uniquely identified, or merge them into a single interpretable metric.\n- Consider employing alternative fairness constructs (e.g., Fehr-Schmidt: punish only disadvantageous/advantageous inequality, or piecewise loss-function for unfair offers).\n- Allow for out-of-the-box modeling approaches including non-linear, piecewise, or \u201cthreshold\u201d/stepwise mechanisms, especially if these could differentiate between hypotheses or improve parameter recovery.\n- Think about whether utilizing percentage-based splits or other available variables could introduce new, orthogonal information to the model.\n- Prioritize models that can be robustly recovered from data with minimal mutual dependence between learnable parameters, even if this results in changes from strictly linear models.\n\nOnce you have reasoned about these steps, then and only then provide your model specification and variable descriptions.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Let me proceed step by step as requested:\n\n---\n\n### 1. What distinct psychological processes may drive responder behavior in this context?\n\n**a. Self-interest (Monetary Value):**  \nResponders are motivated by their personal gain (\u201csplit_self\u201d). They will naturally prefer proposals where their own share is higher.\n\n**b. Fairness/Inequity Aversion:**  \nResponders might also care about how fair the split is with respect to some reference point\u2014for example:\n- **Equity reference:** \u201cFair share\u201d defined as:  \n  \\( \\text{Fair share} = \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\times \\text{combined_earning} \\)\n- **Percentages as fairness reference:** Instead of absolute values, the percent of the total received could be compared to \u201cearned percentage.\u201d\n\nFairness aversion can be expressed in several ways:\n- **Disadvantageous inequality aversion:** The \u201churt\u201d of getting less than a fair share.\n- **Advantageous inequality aversion** (less common, sometimes ignored): Discomfort from getting more than deserved.\n- **General deviation from fairness:** Aversion to any deviation from the equitable share, no matter in which direction.\n\n**c. Reference dependence/social context:**  \nPeople may be especially averse if they get less than they \u201cearned,\u201d and only mildly bothered if they get more.\n\n---\n\n### 2. Interactions: linear vs non-linear?\n\n- **Linear** models (weighted sum of self-interest and fairness) often show high collinearity (as \u201csplit_self\u201d and \u201cfair_share\u201d are mathematically related for the same pot).\n- **Non-linear**: Using the **absolute deviation** (or squared deviation), or indicator functions for whether the responder is under-offered, can allow more distinct parameter roles.\n- **Piecewise/Threshold**: Strong effect if split falls below a \u201crejection threshold\u201d (e.g., a minimum acceptable offer).\n- **Asymmetrical effects**: Fehr-Schmidt style (distinct weights for disadvantageous/advantageous unfairness, potentially with disadvantageous being much stronger).\n\n---\n\n### 3. Minimizing redundancy & improving identifiability\n\nTo disentangle self-interest from fairness aversion:\n- Recasting the model in **percentages** is helpful (using splitperc_self vs. earned proportion), as it normalizes proposals across trials with varying pots.\n- Ideally, make sure any \u201cself-interest\u201d and \u201cfairness\u201d term do not both rely on the same source of variance (\u201csplit_self\u201d, which may introduce redundancy).\n- **Fairness aversion** could be encoded as\n  - **Deviation from fair share in %:**  \n    \\( d = \\text{splitperc_self} - 100 \\times \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\)  \n    This is naturally trial-by-trial orthogonalized.\n  - **Threshold:** Utility drops sharply below a minimum percent.\n  - **Absolute or squared deviation:** Non-linear cost to larger unfairness.\n\n**On parameter constraints**:  \n- For aversion parameters (\\(\\alpha\\)), set lower bound at zero (no negative penalization for fairness aversion).\n- Bias/intercept may be unbounded.\n\n---\n\n### 4. Alternative constructs & potential improvements\n\n- **Fehr-Schmidt (Inequity Aversion) approach:**  \n  Utility penalizes both being under-offered (**disadvantageous**) and over-offered (**advantageous**) with different weights:\n    \\( U = \\beta_0 + \\beta_1 \\cdot \\text{splitperc_self} - \\alpha_{\\text{dis}} \\cdot \\max\\{d, 0\\} - \\alpha_{\\text{adv}} \\cdot \\max\\{-d, 0\\} \\)\n    where \\( d \\) is defined as above.\n- **Threshold/floor effect:** If \u201csplitperc_self\u201d is below a dynamic (or fixed) threshold, set utility very low (e.g., step function).\n- **Drop additive self-interest:** If fairness term is already encoded as \u201chow much less (or more) I receive than expected,\u201d explicit self-interest term adds only redundancy.\n\n---\n\n### 5. Choice of model\n\n**Best practice\u2014Fehr-Schmidt\u2013style, with percent-based fairness handled piecewise, and explicit self-interest omitted (since any deviation from fair share captures both self-gain and social reference).**\n\n- This addresses multicollinearity: \u201cDeviation from earned proportion\u201d is (almost) orthogonal to absolute gain; one can only get higher \u201csplitperc_self\u201d by having an unfair split.\n- By separating disadvantageous and advantageous cases (asymmetrically penalized), parameter recovery improves.\n- No explicit self-interest parameter: \u201csplitperc_self\u201d only matters through the fairness lens (i.e., is *relatively* high or low).\n\n**Model equation:**\n- Let\n    - \\( d = \\text{splitperc_self} - 100 \\times \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\)\n      (positive: got more than earned, negative: less than earned)\n- Utility is:\n    \\( U = \\text{intercept} - \\alpha_{\\text{dis}} \\cdot \\max(-d, 0) - \\alpha_{\\text{adv}} \\cdot \\max(d, 0) \\)\n    - All parameters except intercept are constrained to [0, 20] (ample for sensitivity, not unbounded).\n- Probability of accept: sigmoid with temperature 1.\n\n---\n\n### 6. Variable bounds and details\n\n- \\(\\text{intercept}\\): [-10, 10] (bias toward/against acceptance).\n- \\(\\alpha_{\\text{dis}}\\) and \\(\\alpha_{\\text{adv}}\\): [0, 20].\n- All split percent and fair share percent variables are in [0, 100] by construction.\n\n---\n\n## Final Specification\n\n<MODEL>\nd = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"d\": {\n      \"description\": \"Deviation of participant's proposed share (percentage) from their earned share (percentage). Positive means a better-than-earned offer, negative means worse-than-earned.\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant, in percent of total.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"intercept\": {\n      \"description\": \"Model bias parameter reflecting overall willingness to accept offers.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_disadvantageous\": {\n      \"description\": \"Aversion to disadvantageous inequity (getting less than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_advantageous\": {\n      \"description\": \"Aversion to advantageous inequity (getting more than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal (to be converted to a probability via the logistic function).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA non-linear inequity aversion model (Fehr-Schmidt type) for responder decisions. Utility depends on the deviation between the proposed share (percent) and the participant's \u201cearned share\u201d (percent from pretask), penalized by separate weights for disadvantageous (receiving less than earned) and advantageous (receiving more than earned) inequity. No explicit self-interest parameter is used, eliminating collinearity and improving parameter recovery. Acceptance probability is the logistic transform of utility.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['intercept', 'alpha_disadvantageous', 'alpha_advantageous']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                d = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"d\": {\n      \"description\": \"Deviation of participant's proposed share (percentage) from their earned share (percentage). Positive means a better-than-earned offer, negative means worse-than-earned.\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant, in percent of total.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"intercept\": {\n      \"description\": \"Model bias parameter reflecting overall willingness to accept offers.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_disadvantageous\": {\n      \"description\": \"Aversion to disadvantageous inequity (getting less than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_advantageous\": {\n      \"description\": \"Aversion to advantageous inequity (getting more than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal (to be converted to a probability via the logistic function).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, intercept=0, alpha_disadvantageous=0, alpha_advantageous=0):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Calculate d: Deviation from earned share (in percentage)\n        if (token_self + token_opp) == 0:\n          d = 0 #Avoid dividing by zero\n        else:\n          d = splitperc_self - (100 * token_self / (token_self + token_opp))\n\n        # Calculate Utility\n        utility = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\n\n        model_predictions.append(utility)\n    return model_predictions\n```",
      "timestamp": 1744723638.3187141
    }
  ],
  "learnable_parameters": {
    "intercept": {
      "description": "Model bias parameter reflecting overall willingness to accept offers.",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_disadvantageous": {
      "description": "Aversion to disadvantageous inequity (getting less than earned). Non-negative.",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_advantageous": {
      "description": "Aversion to advantageous inequity (getting more than earned). Non-negative.",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "d = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)",
  "variable_descriptions": {
    "d": {
      "description": "Deviation of participant's proposed share (percentage) from their earned share (percentage). Positive means a better-than-earned offer, negative means worse-than-earned.",
      "range": {
        "min": -100,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "splitperc_self": {
      "description": "Proposed share for participant, in percent of total.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by participant in pretask.",
      "range": {
        "min": 0,
        "max": 1000,
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by opponent in pretask.",
      "range": {
        "min": 0,
        "max": 1000,
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "intercept": {
      "description": "Model bias parameter reflecting overall willingness to accept offers.",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_disadvantageous": {
      "description": "Aversion to disadvantageous inequity (getting less than earned). Non-negative.",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_advantageous": {
      "description": "Aversion to advantageous inequity (getting more than earned). Non-negative.",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "U": {
      "description": "Utility of accepting the proposal (to be converted to a probability via the logistic function).",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    }
  },
  "model_summary": "A non-linear inequity aversion model (Fehr-Schmidt type) for responder decisions. Utility depends on the deviation between the proposed share (percent) and the participant's \u201cearned share\u201d (percent from pretask), penalized by separate weights for disadvantageous (receiving less than earned) and advantageous (receiving more than earned) inequity. No explicit self-interest parameter is used, eliminating collinearity and improving parameter recovery. Acceptance probability is the logistic transform of utility.",
  "target_variable": "accept",
  "full_reasoning": "Let me proceed step by step as requested:\n\n---\n\n### 1. What distinct psychological processes may drive responder behavior in this context?\n\n**a. Self-interest (Monetary Value):**  \nResponders are motivated by their personal gain (\u201csplit_self\u201d). They will naturally prefer proposals where their own share is higher.\n\n**b. Fairness/Inequity Aversion:**  \nResponders might also care about how fair the split is with respect to some reference point\u2014for example:\n- **Equity reference:** \u201cFair share\u201d defined as:  \n  \\( \\text{Fair share} = \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\times \\text{combined_earning} \\)\n- **Percentages as fairness reference:** Instead of absolute values, the percent of the total received could be compared to \u201cearned percentage.\u201d\n\nFairness aversion can be expressed in several ways:\n- **Disadvantageous inequality aversion:** The \u201churt\u201d of getting less than a fair share.\n- **Advantageous inequality aversion** (less common, sometimes ignored): Discomfort from getting more than deserved.\n- **General deviation from fairness:** Aversion to any deviation from the equitable share, no matter in which direction.\n\n**c. Reference dependence/social context:**  \nPeople may be especially averse if they get less than they \u201cearned,\u201d and only mildly bothered if they get more.\n\n---\n\n### 2. Interactions: linear vs non-linear?\n\n- **Linear** models (weighted sum of self-interest and fairness) often show high collinearity (as \u201csplit_self\u201d and \u201cfair_share\u201d are mathematically related for the same pot).\n- **Non-linear**: Using the **absolute deviation** (or squared deviation), or indicator functions for whether the responder is under-offered, can allow more distinct parameter roles.\n- **Piecewise/Threshold**: Strong effect if split falls below a \u201crejection threshold\u201d (e.g., a minimum acceptable offer).\n- **Asymmetrical effects**: Fehr-Schmidt style (distinct weights for disadvantageous/advantageous unfairness, potentially with disadvantageous being much stronger).\n\n---\n\n### 3. Minimizing redundancy & improving identifiability\n\nTo disentangle self-interest from fairness aversion:\n- Recasting the model in **percentages** is helpful (using splitperc_self vs. earned proportion), as it normalizes proposals across trials with varying pots.\n- Ideally, make sure any \u201cself-interest\u201d and \u201cfairness\u201d term do not both rely on the same source of variance (\u201csplit_self\u201d, which may introduce redundancy).\n- **Fairness aversion** could be encoded as\n  - **Deviation from fair share in %:**  \n    \\( d = \\text{splitperc_self} - 100 \\times \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\)  \n    This is naturally trial-by-trial orthogonalized.\n  - **Threshold:** Utility drops sharply below a minimum percent.\n  - **Absolute or squared deviation:** Non-linear cost to larger unfairness.\n\n**On parameter constraints**:  \n- For aversion parameters (\\(\\alpha\\)), set lower bound at zero (no negative penalization for fairness aversion).\n- Bias/intercept may be unbounded.\n\n---\n\n### 4. Alternative constructs & potential improvements\n\n- **Fehr-Schmidt (Inequity Aversion) approach:**  \n  Utility penalizes both being under-offered (**disadvantageous**) and over-offered (**advantageous**) with different weights:\n    \\( U = \\beta_0 + \\beta_1 \\cdot \\text{splitperc_self} - \\alpha_{\\text{dis}} \\cdot \\max\\{d, 0\\} - \\alpha_{\\text{adv}} \\cdot \\max\\{-d, 0\\} \\)\n    where \\( d \\) is defined as above.\n- **Threshold/floor effect:** If \u201csplitperc_self\u201d is below a dynamic (or fixed) threshold, set utility very low (e.g., step function).\n- **Drop additive self-interest:** If fairness term is already encoded as \u201chow much less (or more) I receive than expected,\u201d explicit self-interest term adds only redundancy.\n\n---\n\n### 5. Choice of model\n\n**Best practice\u2014Fehr-Schmidt\u2013style, with percent-based fairness handled piecewise, and explicit self-interest omitted (since any deviation from fair share captures both self-gain and social reference).**\n\n- This addresses multicollinearity: \u201cDeviation from earned proportion\u201d is (almost) orthogonal to absolute gain; one can only get higher \u201csplitperc_self\u201d by having an unfair split.\n- By separating disadvantageous and advantageous cases (asymmetrically penalized), parameter recovery improves.\n- No explicit self-interest parameter: \u201csplitperc_self\u201d only matters through the fairness lens (i.e., is *relatively* high or low).\n\n**Model equation:**\n- Let\n    - \\( d = \\text{splitperc_self} - 100 \\times \\frac{\\text{token_self}}{\\text{token_self} + \\text{token_opp}} \\)\n      (positive: got more than earned, negative: less than earned)\n- Utility is:\n    \\( U = \\text{intercept} - \\alpha_{\\text{dis}} \\cdot \\max(-d, 0) - \\alpha_{\\text{adv}} \\cdot \\max(d, 0) \\)\n    - All parameters except intercept are constrained to [0, 20] (ample for sensitivity, not unbounded).\n- Probability of accept: sigmoid with temperature 1.\n\n---\n\n### 6. Variable bounds and details\n\n- \\(\\text{intercept}\\): [-10, 10] (bias toward/against acceptance).\n- \\(\\alpha_{\\text{dis}}\\) and \\(\\alpha_{\\text{adv}}\\): [0, 20].\n- All split percent and fair share percent variables are in [0, 100] by construction.\n\n---\n\n## Final Specification\n\n<MODEL>\nd = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"d\": {\n      \"description\": \"Deviation of participant's proposed share (percentage) from their earned share (percentage). Positive means a better-than-earned offer, negative means worse-than-earned.\",\n      \"range\": {\n        \"min\": -100,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant, in percent of total.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent in pretask.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1000,\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"intercept\": {\n      \"description\": \"Model bias parameter reflecting overall willingness to accept offers.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_disadvantageous\": {\n      \"description\": \"Aversion to disadvantageous inequity (getting less than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_advantageous\": {\n      \"description\": \"Aversion to advantageous inequity (getting more than earned). Non-negative.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal (to be converted to a probability via the logistic function).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA non-linear inequity aversion model (Fehr-Schmidt type) for responder decisions. Utility depends on the deviation between the proposed share (percent) and the participant's \u201cearned share\u201d (percent from pretask), penalized by separate weights for disadvantageous (receiving less than earned) and advantageous (receiving more than earned) inequity. No explicit self-interest parameter is used, eliminating collinearity and improving parameter recovery. Acceptance probability is the logistic transform of utility.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: d = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\nSummary: A non-linear inequity aversion model (Fehr-Schmidt type) for responder decisions. Utility depends on the deviation between the proposed share (percent) and the participant's \u201cearned share\u201d (percent from pretask), penalized by separate weights for disadvantageous (receiving less than earned) and advantageous (receiving more than earned) inequity. No explicit self-interest parameter is used, eliminating collinearity and improving parameter recovery. Acceptance probability is the logistic transform of utility.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, intercept=0, alpha_disadvantageous=0, alpha_advantageous=0):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Calculate d: Deviation from earned share (in percentage)\n        if (token_self + token_opp) == 0:\n          d = 0 #Avoid dividing by zero\n        else:\n          d = splitperc_self - (100 * token_self / (token_self + token_opp))\n\n        # Calculate Utility\n        utility = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\n\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.7576312576312576,
  "group_accuracies": {
    "Control": 0.7945736434108527,
    "Cocaine": 0.7245370370370371
  },
  "group_parameter_averages": {
    "Control": {
      "intercept": 5.259653713779907,
      "alpha_disadvantageous": 1.6031046024468456,
      "alpha_advantageous": 5.73830551266149
    },
    "Cocaine": {
      "intercept": 2.7275290453127963,
      "alpha_disadvantageous": 2.1810186116788,
      "alpha_advantageous": 7.400900531898177
    }
  },
  "fitting_results": [
    {
      "intercept": -5.702642521679481e-07,
      "alpha_disadvantageous": 10.95166547907769,
      "alpha_advantageous": 13.182236667016209,
      "success": true,
      "log_likelihood": -47.43799621740089,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 2.4656574778111224,
      "alpha_disadvantageous": 0.12165025280595483,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -17.24934516075144,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 9.933042505300797,
      "alpha_disadvantageous": 13.96321269457185,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -345.38795559968986,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 1.9957813727728073,
      "alpha_disadvantageous": 0.12787880795998516,
      "alpha_advantageous": 5.326945507309635,
      "success": true,
      "log_likelihood": -61.90934693831885,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 9.834597502815996,
      "alpha_disadvantageous": 0.5532406386691237,
      "alpha_advantageous": 0.1296050448571941,
      "success": true,
      "log_likelihood": -5.010317308012645,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.817333258972648,
      "alpha_disadvantageous": 0.1394860817112605,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -14.95730637865,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 4.301336647520132,
      "alpha_disadvantageous": 0.15023416058861463,
      "alpha_advantageous": 12.76632785896141,
      "success": true,
      "log_likelihood": -59.81752447547923,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 13.76031100996469,
      "success": true,
      "log_likelihood": -46.05324541905409,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.4554070136794643,
      "alpha_disadvantageous": 0.22891876460620994,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -10.970723675523294,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 8.450440240161065,
      "alpha_disadvantageous": 0.4754053368996635,
      "alpha_advantageous": 15.754076548620475,
      "success": true,
      "log_likelihood": -51.9205303814386,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": -0.43239824585935094,
      "alpha_disadvantageous": 0.13800665120252678,
      "alpha_advantageous": 9.487831766485414,
      "success": true,
      "log_likelihood": -30.7621878941783,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.4558235702596627,
      "alpha_disadvantageous": 0.21262253924556376,
      "alpha_advantageous": 13.601933289845663,
      "success": true,
      "log_likelihood": -57.54712973880124,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 6.231934711817223e-16,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 8.90804156522064,
      "success": true,
      "log_likelihood": -46.053245419050505,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 1.6143110779075928e-16,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 6.969722887749215,
      "alpha_disadvantageous": 0.17189646867864505,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -8.454678761521887,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.24282942384201373,
      "alpha_advantageous": 14.62320021711702,
      "success": true,
      "log_likelihood": -51.16979123702859,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.8805040637008297,
      "alpha_disadvantageous": 0.17051193691757632,
      "alpha_advantageous": 8.88801537152352,
      "success": true,
      "log_likelihood": -59.66864296313606,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 6.149385778708154,
      "alpha_disadvantageous": 0.14844963662719673,
      "alpha_advantageous": 10.674512636256814,
      "success": true,
      "log_likelihood": -55.30190933490219,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 0.8605279961675815,
      "alpha_disadvantageous": 0.07720701442758833,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -19.859188718585862,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 1.9749761673438644,
      "alpha_disadvantageous": 0.09132183727528313,
      "alpha_advantageous": 8.792246182869656,
      "success": true,
      "log_likelihood": -64.93630726837152,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 4.017762501571389,
      "alpha_disadvantageous": 0.20003348440686936,
      "alpha_advantageous": 9.884326760463754,
      "success": true,
      "log_likelihood": -58.33827530620122,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 4.00491594278156,
      "alpha_disadvantageous": 0.1655316605932341,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -13.912086065261612,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 2.7648638908275305,
      "alpha_disadvantageous": 0.11899044978550137,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -17.23118210317901,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.645626697235351,
      "alpha_disadvantageous": 0.36488343890114344,
      "alpha_advantageous": 10.868633549578945,
      "success": true,
      "log_likelihood": -52.34856113331482,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 6.58075852353616,
      "alpha_disadvantageous": 0.14998593021301226,
      "alpha_advantageous": 5.437893672406039,
      "success": true,
      "log_likelihood": -54.163376044831196,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.902167913662094,
      "alpha_disadvantageous": 0.10411504392919632,
      "alpha_advantageous": 14.428194562738131,
      "success": true,
      "log_likelihood": -60.22300706395422,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 4.582516916688475e-16,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": -1.1376794813670948e-07,
      "alpha_disadvantageous": 14.70871381957232,
      "alpha_advantageous": 12.815694349750954,
      "success": true,
      "log_likelihood": -47.43799621740081,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 1.7990316108711536e-05,
      "alpha_disadvantageous": 10.801707960138934,
      "alpha_advantageous": 5.332342214845112,
      "success": true,
      "log_likelihood": -323.7482014299503,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 1.6187215722196564,
      "alpha_disadvantageous": 0.11704189244592278,
      "alpha_advantageous": 12.336547887162407,
      "success": true,
      "log_likelihood": -62.285506876544545,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 4.5761308256485915e-16,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -0.0016343567716418062,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 2.46324695136369,
      "alpha_disadvantageous": 0.08505643948166267,
      "alpha_advantageous": 13.365066800335622,
      "success": true,
      "log_likelihood": -64.57653904026672,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 5.591802795002212,
      "alpha_disadvantageous": 0.18897532546597057,
      "alpha_advantageous": 8.449371447213798,
      "success": true,
      "log_likelihood": -57.44652988495529,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 9.957085580843058,
      "alpha_disadvantageous": 13.524038390224794,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -322.3620914248121,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 2.88491394997616,
      "alpha_disadvantageous": 0.09528623504455641,
      "alpha_advantageous": 17.93378213390097,
      "success": true,
      "log_likelihood": -63.40912908060014,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 4.545848789250991,
      "alpha_disadvantageous": 0.07972640632187569,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -8.84241875809582,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 2.3778421128893332,
      "alpha_disadvantageous": 0.08703260881186337,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -19.251302044674077,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 1.1420477771534572,
      "alpha_disadvantageous": 0.1778410947707565,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -11.47036469034429,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 3.555349150835483,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -4.569499625091052,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "intercept": 7.085097888734176,
      "alpha_disadvantageous": 0.3773102075287643,
      "alpha_advantageous": 0.17572992257618966,
      "success": true,
      "log_likelihood": -38.85944862967371,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 3.3261851671464973,
      "alpha_disadvantageous": 0.1280376736715709,
      "alpha_advantageous": 14.47076508195246,
      "success": true,
      "log_likelihood": -61.84703342345484,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.204248103056901,
      "alpha_disadvantageous": 0.05580038885869064,
      "alpha_advantageous": 15.425450134796945,
      "success": true,
      "log_likelihood": -64.820687461194,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 9.029551532336143,
      "alpha_disadvantageous": 0.3638336612371407,
      "alpha_advantageous": 0.5344410267092525,
      "success": true,
      "log_likelihood": -35.233164428742874,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.8328056171365323,
      "alpha_disadvantageous": 0.0721452813494997,
      "alpha_advantageous": 19.707678393265432,
      "success": true,
      "log_likelihood": -65.22140881529445,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 3.8730882839032046,
      "alpha_disadvantageous": 0.2364330717400128,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -10.798490736485132,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.8490406671043259,
      "alpha_disadvantageous": 0.0332448657732803,
      "alpha_advantageous": 4.467622918991136,
      "success": true,
      "log_likelihood": -45.71347595978832,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.1583806456519863,
      "alpha_disadvantageous": 0.05888212789976546,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -19.826117868131767,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -5.685772321967262e-08,
      "alpha_disadvantageous": 8.146822621668242,
      "alpha_advantageous": 9.55867050560683,
      "success": true,
      "log_likelihood": -93.48969807748492,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.4106352471214774,
      "alpha_disadvantageous": 0.06494180084206018,
      "alpha_advantageous": 15.510107409970262,
      "success": true,
      "log_likelihood": -66.8735905466248,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.9658722558753882,
      "alpha_disadvantageous": 0.029743019822177596,
      "alpha_advantageous": 0.003581736545790545,
      "success": true,
      "log_likelihood": -23.717605228975206,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 9.864909532510376,
      "alpha_disadvantageous": 18.544341759105723,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -230.25871715776591,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 4.952863425325303,
      "alpha_disadvantageous": 0.3861113907203915,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -6.499143162029194,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.5053126620515518,
      "alpha_disadvantageous": 0.17135471570665642,
      "alpha_advantageous": 11.808605146938723,
      "success": true,
      "log_likelihood": -57.600448373626826,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.0149365211420993,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 13.15215398147576,
      "success": true,
      "log_likelihood": -58.366860797666575,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -0.6977066857146094,
      "alpha_disadvantageous": 0.10896135585282243,
      "alpha_advantageous": 16.18992172684513,
      "success": true,
      "log_likelihood": -31.375845052391348,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.6542809137580794,
      "alpha_disadvantageous": 0.0530058237952229,
      "alpha_advantageous": 15.69375211477507,
      "success": true,
      "log_likelihood": -62.00112348082592,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.8422028464498166,
      "alpha_disadvantageous": 0.06371370007104513,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -21.12302176002162,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.634301861128758,
      "alpha_disadvantageous": 0.13137843976887176,
      "alpha_advantageous": 12.640933786973832,
      "success": true,
      "log_likelihood": -62.097453267643466,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -3.304815478324653e-07,
      "alpha_disadvantageous": 11.928770106259435,
      "alpha_advantageous": 10.625030165255806,
      "success": true,
      "log_likelihood": -47.43799621740088,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.8654206360487593,
      "alpha_disadvantageous": 0.05859223948160898,
      "alpha_advantageous": 18.19360937858813,
      "success": true,
      "log_likelihood": -66.88503012153052,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.9537074021187606,
      "alpha_disadvantageous": 0.15802897408416272,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -12.308337384228722,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.6554729014625686,
      "alpha_disadvantageous": 0.11395212610981355,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -17.619331477642948,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 4.335139921821732,
      "alpha_disadvantageous": 0.07347522813281536,
      "alpha_advantageous": 15.506513430296012,
      "success": true,
      "log_likelihood": -54.998168301074614,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 5.220941859071445,
      "alpha_disadvantageous": 0.12106987908346589,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -10.373279433943477,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.9201834668259072,
      "alpha_disadvantageous": 0.08170616116031666,
      "alpha_advantageous": 5.902961544725243,
      "success": true,
      "log_likelihood": -65.58146255528511,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 4.061237243970335,
      "alpha_disadvantageous": 0.06478224442960173,
      "alpha_advantageous": 18.143515727314583,
      "success": true,
      "log_likelihood": -55.22813180990441,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 10.0,
      "alpha_disadvantageous": 18.131949340104047,
      "alpha_advantageous": 7.810378548530639,
      "success": true,
      "log_likelihood": -46.051792648914194,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -3.7378015215282965e-07,
      "alpha_disadvantageous": 12.38914926645436,
      "alpha_advantageous": 7.6299733499909195,
      "success": true,
      "log_likelihood": -93.48969807748175,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.4453834594761186,
      "alpha_disadvantageous": 0.11213623214223674,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -17.90829518804836,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.761831247756468,
      "alpha_disadvantageous": 0.0639513202013122,
      "alpha_advantageous": 7.78282724740315,
      "success": true,
      "log_likelihood": -62.56392405244092,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.0447424733863306,
      "alpha_disadvantageous": 0.047972838095291154,
      "alpha_advantageous": 11.606193340300164,
      "success": true,
      "log_likelihood": -44.97251981036368,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 3.0705705276784805,
      "alpha_disadvantageous": 0.09500237125940848,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -17.174990115049447,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 7.618699267349875,
      "alpha_disadvantageous": 0.1506238131668667,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -5.271633895764899,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -9.94608899370719e-08,
      "alpha_disadvantageous": 7.608301651459026,
      "alpha_advantageous": 15.562043471478608,
      "success": true,
      "log_likelihood": -24.41214528737975,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.1251293771523752,
      "alpha_disadvantageous": 0.03160907629467326,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -23.236698240354073,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -8.495531294297173e-08,
      "alpha_disadvantageous": 13.169160786535308,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -25.798439648280247,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.5210554277458441,
      "alpha_disadvantageous": 0.023859606674057045,
      "alpha_advantageous": 17.545446252585524,
      "success": true,
      "log_likelihood": -69.18523355040827,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.3979322240043968,
      "alpha_disadvantageous": 0.0,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -10.326095384699055,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": -0.09710761442200745,
      "alpha_disadvantageous": 0.13198180735831475,
      "alpha_advantageous": 14.673586559239046,
      "success": true,
      "log_likelihood": -9.342605860857482,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.567951366084659,
      "alpha_disadvantageous": 0.12809866675889792,
      "alpha_advantageous": 6.426542937215421,
      "success": true,
      "log_likelihood": -62.31366207804111,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 0.9112115191181788,
      "alpha_disadvantageous": 0.024921913349967496,
      "alpha_advantageous": 19.524853202717868,
      "success": true,
      "log_likelihood": -68.62606847719013,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.098685096031497,
      "alpha_disadvantageous": 10.282015239988622,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -25.275191506503514,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 2.672539336371211,
      "alpha_disadvantageous": 0.07948719930737765,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -18.33511507457816,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.4144864228653526,
      "alpha_disadvantageous": 0.1888297497112184,
      "alpha_advantageous": 16.23859398484139,
      "success": true,
      "log_likelihood": -33.34143312562226,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 9.999997286845806,
      "alpha_disadvantageous": 0.20961978980766843,
      "alpha_advantageous": 0.0,
      "success": true,
      "log_likelihood": -4.390213448052906,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 1.5922743593715865,
      "alpha_disadvantageous": 0.08787962429311907,
      "alpha_advantageous": 12.613614723544549,
      "success": true,
      "log_likelihood": -65.06674038185584,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "intercept": 3.2579034276961596,
      "alpha_disadvantageous": 0.10590420346746239,
      "alpha_advantageous": 0.1181277796626543,
      "success": true,
      "log_likelihood": -24.553841183304414,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "intercept": {
        "r": 0.46809525259043383,
        "p": 9.06538370240189e-07
      },
      "alpha_disadvantageous": {
        "r": 0.38194616349779736,
        "p": 8.811351210297262e-05
      },
      "alpha_advantageous": {
        "r": -0.13088200077090512,
        "p": 0.19430244368894237
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 108.19860711736384,
  "bic_Control": 117.54566752126479,
  "bic_Cocaine": 99.82519883886924,
  "bic_results": {
    "average_bic": 108.19860711736384,
    "individual_bics": [
      105.6265492501701,
      45.249247136871205,
      701.526468014748,
      134.56925069200602,
      20.77119143139362,
      40.66516957266833,
      10.753825528911614,
      130.3856057663268,
      102.85704765347651,
      32.69200416641492,
      114.59161757824553,
      72.27493260372493,
      125.8448162929708,
      10.753825528911614,
      102.85704765346934,
      10.753825528911614,
      10.753825528911614,
      27.659914338412104,
      113.09013928942551,
      10.753825528911614,
      130.08784274164046,
      121.35437548517271,
      50.46893425254005,
      140.62317135211137,
      127.42710742777076,
      38.57472894589155,
      45.212921021726345,
      115.44767908199796,
      119.07730890503072,
      131.19657094327678,
      10.753825528911614,
      105.62654925016994,
      658.246959675269,
      135.32157056845742,
      10.753825528911614,
      139.90363489590177,
      125.6436165852789,
      655.4747396649925,
      137.5688149765686,
      28.43539433155997,
      49.25316090471648,
      33.69128619605691,
      19.889556065550437,
      88.46945407471574,
      134.44462366227802,
      140.39193173775632,
      81.21688567285408,
      141.19337444595723,
      32.3475382883386,
      102.17750873494496,
      50.40279255163186,
      197.72995297033816,
      144.49773790861792,
      58.185767273318746,
      471.26799113090016,
      23.748843139426718,
      125.95145356262198,
      127.48427841070148,
      73.50224692015102,
      134.75280377702018,
      52.99660033541157,
      134.94546335065527,
      105.62654925017009,
      144.52061705842937,
      35.36723158382577,
      45.98921977065423,
      120.74689341751755,
      31.497115683255284,
      141.91348192593856,
      121.20682043517715,
      102.85414211319672,
      197.72995297033182,
      46.567147191465054,
      135.87840492025018,
      100.69559643609568,
      45.10053704546722,
      21.293824606898127,
      59.57484739012783,
      57.22395329607647,
      62.34743611192883,
      149.12102391618487,
      31.40274758476644,
      29.435768537083295,
      135.37788097145057,
      148.0026937697486,
      61.30093982837536,
      47.42078696452465,
      77.43342306661285,
      19.530983711474143,
      140.88403757908,
      59.858239181977154
    ],
    "group_enabled": true,
    "group_bics": {
      "Control": [
        105.6265492501701,
        45.249247136871205,
        701.526468014748,
        134.56925069200602,
        20.77119143139362,
        40.66516957266833,
        10.753825528911614,
        130.3856057663268,
        102.85704765347651,
        32.69200416641492,
        114.59161757824553,
        72.27493260372493,
        125.8448162929708,
        10.753825528911614,
        102.85704765346934,
        10.753825528911614,
        10.753825528911614,
        27.659914338412104,
        113.09013928942551,
        10.753825528911614,
        130.08784274164046,
        121.35437548517271,
        50.46893425254005,
        140.62317135211137,
        127.42710742777076,
        38.57472894589155,
        45.212921021726345,
        115.44767908199796,
        119.07730890503072,
        131.19657094327678,
        10.753825528911614,
        105.62654925016994,
        658.246959675269,
        135.32157056845742,
        10.753825528911614,
        139.90363489590177,
        125.6436165852789,
        655.4747396649925,
        137.5688149765686,
        28.43539433155997,
        49.25316090471648,
        33.69128619605691,
        19.889556065550437
      ],
      "Cocaine": [
        88.46945407471574,
        134.44462366227802,
        140.39193173775632,
        81.21688567285408,
        141.19337444595723,
        32.3475382883386,
        102.17750873494496,
        50.40279255163186,
        197.72995297033816,
        144.49773790861792,
        58.185767273318746,
        471.26799113090016,
        23.748843139426718,
        125.95145356262198,
        127.48427841070148,
        73.50224692015102,
        134.75280377702018,
        52.99660033541157,
        134.94546335065527,
        105.62654925017009,
        144.52061705842937,
        35.36723158382577,
        45.98921977065423,
        120.74689341751755,
        31.497115683255284,
        141.91348192593856,
        121.20682043517715,
        102.85414211319672,
        197.72995297033182,
        46.567147191465054,
        135.87840492025018,
        100.69559643609568,
        45.10053704546722,
        21.293824606898127,
        59.57484739012783,
        57.22395329607647,
        62.34743611192883,
        149.12102391618487,
        31.40274758476644,
        29.435768537083295,
        135.37788097145057,
        148.0026937697486,
        61.30093982837536,
        47.42078696452465,
        77.43342306661285,
        19.530983711474143,
        140.88403757908,
        59.858239181977154
      ]
    },
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- intercept: r = 0.468\n- alpha_disadvantageous: r = 0.382\n- alpha_advantageous: r = -0.131",
  "previous_models": [
    "Specification: d = splitperc_self - (100 * token_self / (token_self + token_opp))\nU = intercept - alpha_disadvantageous * max(-d, 0) - alpha_advantageous * max(d, 0)\nSummary: A non-linear inequity aversion model (Fehr-Schmidt type) for responder decisions. Utility depends on the deviation between the proposed share (percent) and the participant's \u201cearned share\u201d (percent from pretask), penalized by separate weights for disadvantageous (receiving less than earned) and advantageous (receiving more than earned) inequity. No explicit self-interest parameter is used, eliminating collinearity and improving parameter recovery. Acceptance probability is the logistic transform of utility.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 108.19860711736384\nOverall Accuracy: 0.7576\nGroup Accuracies:\n- Control: 0.7946\n- Cocaine: 0.7245\n\nParameter Recovery:\n- intercept: r = 0.468\n- alpha_disadvantageous: r = 0.382\n- alpha_advantageous: r = -0.131"
  ]
}