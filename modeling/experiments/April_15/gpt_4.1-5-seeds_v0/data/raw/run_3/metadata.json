{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nThe previous instructions encouraged moving away from linear combinations of self-interest and fairness\u2014especially to avoid collinearity\u2014and explored Fehr-Schmidt\u2013style models, piecewise penalties, and threshold mechanisms using percent-based deviations. However, model performance (accuracy, BIC, parameter recovery) was still suboptimal, especially in parameter recovery (notably negative or weak recovery for some parameters).\n\nTo improve, new instructions should:\n\n- Push the modeler to test *distinct* non-linear or non-continuous features:\n    - For example, explicit \u201cacceptance thresholds\u201d (stepwise/indicator functions), or using quantiles/ranks rather than continuous differences, to model strong rejections below a certain fairness standard.\n    - Explore non-monotonic utility shapes (e.g., U- or S-shaped fairness sensitivity).\n    - Use softmax/soft-threshold approaches to balance interpretable steep effects and gradient-based fitting.\n    - Consider stochasticity or lapse rates if noise or unmodeled variability could explain parameter recovery issues.\n- Suggest hybrid models:\n    - For example, combine a threshold/floor effect (utility very low below a threshold percent) with a smooth penalty for additional unfairness, or multiply fairness and self-interest in a non-linear way (instead of adding).\n    - Use multiplicative interactions between fairness and self-interest.\n    - Try \u201cminimum acceptable offer\u201d as a learnable parameter (with or without additional fairness weighting).\n    - Trial-specific \u201canchoring\u201d (e.g., reward difference to a social standard), or \u201creference-dependent\u201d models where the response is based on distance to the closest categorical standard (e.g., equality vs. contribution-based fairness).\n- Explicitly ask the modeler to consider parameter recoverability during the design phase:\n    - Propose/contrast 1-parameter (threshold or step) vs. multi-parameter (penalty gradient) models.\n    - Emphasize transparent orthogonality among model terms: parameters should ideally respond to distinguishable behavioral patterns, not the same source of variance.\n- Push for the use of all relevant variables, or at least investigator justification when simplifying.\n- Remind to bound parameters meaningfully (e.g., min threshold within possible percent ranges, fairness weights strictly non-negative unless theory demands otherwise).\n\nExplicitly encourage proposals that are:\n- Non-additive (multiplicative or max/min schemes).\n- Based on indicator or \u201churdle\u201d mechanics, not solely continuous penalties.\n- Actively evaluated for the ease of parameter separation by simulated recovery checks.\n\nInvite the modeler to sketch several plausible variants before formalizing, including at least one unconventional utility formulation.\n\n</think>\n\n**Updated Instructions for Run 3:**\n\nContinue to prioritize both psychological interpretability and mathematical identifiability of your models. Model proposals should critically address parameter recovery and avoid hidden redundancy.\n\n**Before formalizing a model, complete this stepwise reasoning:**\n1. Describe the likely distinct psychological processes driving responder behavior (e.g., self-interest, aversion to unfairness, satisficing, thresholding, \u201cminimum acceptable offer\u201d, lapse/noise).\n2. Assess whether these motives are best captured with linear, non-linear, piecewise, threshold/indicator, or multiplicative/interaction effects\u2014and what behavioral patterns each form is hypothesized to generate (e.g., abrupt rejection below fairness standard, smooth gradients, insensitivity above threshold).\n3. For each candidate model, explain how its parameters are expected to relate to *unique* behavioral patterns in the data (i.e., that parameter recovery will be robust and low in inter-parameter correlation).\n4. Explicitly consider models with the following features:\n    - Step or \u201churdle\u201d effects (e.g., utility drops sharply when split_self falls below a learnable threshold).\n    - Non-additive or multiplicative terms (e.g., interaction between fairness and self-interest, or fairness penalty scaled by self-interest).\n    - Minimum acceptable offer as a direct, learnable parameter.\n    - Non-monotonic or \u201creference-dependent\u201d models (e.g., utility highest at either equality or earned share, and falls with distance in either direction).\n    - Explicitly modeled lapse or stochastic noise (additive random term, or probability lapse).\n5. Use all relevant variables (splitperc_self, token_self, token_opp, combined_earning, etc.) and justify the selection.\n6. Set meaningful, theory-consistent bounds for all parameters (e.g., thresholds within the [0,100] percent range, fairness aversion \u22650, bias/intercept as needed).\n\n**When developing your model:**\n- Compare at least two structurally distinct approaches\u2014at least one should use a threshold, indicator, or piecewise function, and at least one should use an interaction (multiplicative or otherwise non-additive).\n- Comment on the expected ease of parameter recovery for each.\n- Avoid direct linear-additive combinations unless you can argue their parameters are reliably separable.\n- Prioritize models likely to yield robust, high-accuracy predictions *and* strong parameter recovery even in the presence of noisy data.\n- Present your final mathematical model and variable specifications as clearly structured.\n\n**Encouragement:**\nDo not hesitate to propose unconventional or hybrid models (e.g., max/min, softmax thresholding, indicator-triggered penalties, or combinations of self-interest and fairness in multiplicative or non-standard ways). Short-list and then select/justify the most promising based on the above reasoning\u2014don\u2019t default to the expected solution.\n\nAfter this rigorous reasoning, provide your single formal model specification and variable descriptions as instructed.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\nThe previous instructions encouraged moving away from linear combinations of self-interest and fairness\u2014especially to avoid collinearity\u2014and explored Fehr-Schmidt\u2013style models, piecewise penalties, and threshold mechanisms using percent-based deviations. However, model performance (accuracy, BIC, parameter recovery) was still suboptimal, especially in parameter recovery (notably negative or weak recovery for some parameters).\n\nTo improve, new instructions should:\n\n- Push the modeler to test *distinct* non-linear or non-continuous features:\n    - For example, explicit \u201cacceptance thresholds\u201d (stepwise/indicator functions), or using quantiles/ranks rather than continuous differences, to model strong rejections below a certain fairness standard.\n    - Explore non-monotonic utility shapes (e.g., U- or S-shaped fairness sensitivity).\n    - Use softmax/soft-threshold approaches to balance interpretable steep effects and gradient-based fitting.\n    - Consider stochasticity or lapse rates if noise or unmodeled variability could explain parameter recovery issues.\n- Suggest hybrid models:\n    - For example, combine a threshold/floor effect (utility very low below a threshold percent) with a smooth penalty for additional unfairness, or multiply fairness and self-interest in a non-linear way (instead of adding).\n    - Use multiplicative interactions between fairness and self-interest.\n    - Try \u201cminimum acceptable offer\u201d as a learnable parameter (with or without additional fairness weighting).\n    - Trial-specific \u201canchoring\u201d (e.g., reward difference to a social standard), or \u201creference-dependent\u201d models where the response is based on distance to the closest categorical standard (e.g., equality vs. contribution-based fairness).\n- Explicitly ask the modeler to consider parameter recoverability during the design phase:\n    - Propose/contrast 1-parameter (threshold or step) vs. multi-parameter (penalty gradient) models.\n    - Emphasize transparent orthogonality among model terms: parameters should ideally respond to distinguishable behavioral patterns, not the same source of variance.\n- Push for the use of all relevant variables, or at least investigator justification when simplifying.\n- Remind to bound parameters meaningfully (e.g., min threshold within possible percent ranges, fairness weights strictly non-negative unless theory demands otherwise).\n\nExplicitly encourage proposals that are:\n- Non-additive (multiplicative or max/min schemes).\n- Based on indicator or \u201churdle\u201d mechanics, not solely continuous penalties.\n- Actively evaluated for the ease of parameter separation by simulated recovery checks.\n\nInvite the modeler to sketch several plausible variants before formalizing, including at least one unconventional utility formulation.\n\n</think>\n\n**Updated Instructions for Run 3:**\n\nContinue to prioritize both psychological interpretability and mathematical identifiability of your models. Model proposals should critically address parameter recovery and avoid hidden redundancy.\n\n**Before formalizing a model, complete this stepwise reasoning:**\n1. Describe the likely distinct psychological processes driving responder behavior (e.g., self-interest, aversion to unfairness, satisficing, thresholding, \u201cminimum acceptable offer\u201d, lapse/noise).\n2. Assess whether these motives are best captured with linear, non-linear, piecewise, threshold/indicator, or multiplicative/interaction effects\u2014and what behavioral patterns each form is hypothesized to generate (e.g., abrupt rejection below fairness standard, smooth gradients, insensitivity above threshold).\n3. For each candidate model, explain how its parameters are expected to relate to *unique* behavioral patterns in the data (i.e., that parameter recovery will be robust and low in inter-parameter correlation).\n4. Explicitly consider models with the following features:\n    - Step or \u201churdle\u201d effects (e.g., utility drops sharply when split_self falls below a learnable threshold).\n    - Non-additive or multiplicative terms (e.g., interaction between fairness and self-interest, or fairness penalty scaled by self-interest).\n    - Minimum acceptable offer as a direct, learnable parameter.\n    - Non-monotonic or \u201creference-dependent\u201d models (e.g., utility highest at either equality or earned share, and falls with distance in either direction).\n    - Explicitly modeled lapse or stochastic noise (additive random term, or probability lapse).\n5. Use all relevant variables (splitperc_self, token_self, token_opp, combined_earning, etc.) and justify the selection.\n6. Set meaningful, theory-consistent bounds for all parameters (e.g., thresholds within the [0,100] percent range, fairness aversion \u22650, bias/intercept as needed).\n\n**When developing your model:**\n- Compare at least two structurally distinct approaches\u2014at least one should use a threshold, indicator, or piecewise function, and at least one should use an interaction (multiplicative or otherwise non-additive).\n- Comment on the expected ease of parameter recovery for each.\n- Avoid direct linear-additive combinations unless you can argue their parameters are reliably separable.\n- Prioritize models likely to yield robust, high-accuracy predictions *and* strong parameter recovery even in the presence of noisy data.\n- Present your final mathematical model and variable specifications as clearly structured.\n\n**Encouragement:**\nDo not hesitate to propose unconventional or hybrid models (e.g., max/min, softmax thresholding, indicator-triggered penalties, or combinations of self-interest and fairness in multiplicative or non-standard ways). Short-list and then select/justify the most promising based on the above reasoning\u2014don\u2019t default to the expected solution.\n\nAfter this rigorous reasoning, provide your single formal model specification and variable descriptions as instructed.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Let's carefully proceed stepwise as instructed.\n\n---\n\n### **Step 1: Distinct Psychological Processes in Responder Behavior**\n\nBased on the task, responder choices are likely driven by several plausible motives:\n\n1. **Self-Interest**: Preferring to maximize one\u2019s own monetary gain (*split_self*).\n2. **Fairness Concerns**: Aversion to receiving less than what\u2019s \u201cfair\u201d. \u201cFair\u201d can be:\n    - *Equality*: Each gets 50%.\n    - *Merit-based*: Each gets a share proportional to their contribution (i.e., based on *token_self/(token_self + token_opp)*).\n3. **Threshold/Satisficing**: Some responders may not consider offers below a subjective minimum acceptable share, regardless of other details\u2014a \"hurdle effect\".\n4. **Lapse/Stochasticity**: Some proportion of random response, regardless of utility.\n5. **Reference Dependence/Non-monotonicity**: Disliking both disadvantageous *and* advantageous deviations from a fairness reference (e.g., preferring offers \"close to fair\" to either side).\n\n---\n\n### **Step 2: Modeling Alternatives & Behavioral Predictions**\n\n**Candidate Model Classes:**\n\nA. **Stepwise/Indicator \u201cMinimum Acceptable Offer\u201d**\n- Utility is high above a critical threshold (*threshold_perc*, e.g., 22% or \u201cmy fair share\u201d); drops abruptly below.\n- **Behavior**: Clear kink in acceptance probability at personal threshold. Easy to identify parameter (threshold) as a unique behavioral pattern.\n\nB. **Multiplicative Model**\n- Utility is the product (not sum) of self-interest and fairness:\n    - U = self_gain \u00d7 fairness_penalty.\n- **Behavior**: Acceptance depends on both high own payoff *and* alignment with fairness. Penalizes \u201cselfish but unfair\u201d and \u201cfair but poor\u201d splits.\n\nC. **Reference-Dependent, U-shaped Fairness (Non-monotonic)**\n- Utility highest at reference point (equality or merit-based share); falls as offer deviates (in either direction).\n- **Prediction**: Dislike for \u201ctoo unfair\u201d (even in own favor for some). Captures idiosyncratic fairness norms.\n\nD. **Hybrid: Soft threshold + smooth penalty**\n- Utility drops sharply (but smoothly) below a threshold, then receives additional (possibly linear or quadratic) penalty for further deviations.\n- **Prediction**: Threshold-like response, with granularity in degree of unfairness.\n\nE. **Lapse/Noise**\n- Supplement any model above with a \u201cprobability of random choice,\u201d needed for fully realistic predictions and parameter recovery.\n\n---\n\n### **Step 3: Parameter Identifiability & Recovery**\n\n- **Threshold-based**: Clear utility \u201churdle\u201d\u2014threshold will recover well as the acceptance point in the data.\n- **Multiplicative**: Parameters correspond to distinct patterns; e.g., a \u201cfairness weight\u201d directly controls the depth of utility penalty as fairness decreases, distinguishable from shift in threshold.\n- **Non-linear/reference-dependent**: Tuning for standard (e.g., fairness preference) and \u201ctolerance\u201d (width of acceptance)\u2014potential for collinearity but distinguishable if spread of behaviors.\n- **Lapse rate**: Recovers as proportion of unmodeled (random) responses.\n\n*Additive \u201cself-interest + fairness penalty\u201d models struggle with low parameter recovery under collinearity\u2014thus, for the main model specification below I will avoid or hybridize with other forms to aid interpretability and recoverability.*\n\n---\n\n### **Step 4: Concrete Model Proposals**\n\nLet\u2019s draft two models, then choose the more robust for formal presentation.\n\n---\n\n**A. Soft-Threshold Model (with Minimum Acceptable Offer Reference)**\n- A \u201cminimum acceptable offer\u201d in percent; below, utility quickly becomes negative. Add a penalty for deviation from reference fairness standard. Logistic transformation for accept probability.\n- Utility = smooth (soft) threshold on *split_perc_self* at *min_acceptable_perc*, plus penalty for deviation from a fairness reference.\n\n**B. Multiplicative Interaction Model**\n- Utility = (amount gained) \u00d7 (fairness penalty), e.g.:\n    - U = split_self \u00d7 exp(-alpha \u00d7 |splitperc_self - fairness_reference|), where *fairness_reference* could be 50% (equal split) or proportional to contribution.\n\n---\n\n### **Step 5: Variable Selection & Theoretical Justification**\n\n- *splitperc_self* (percent offered to self): main driver, subject to threshold/fairness effect.\n- *token_self, token_opp*: allow calculation of merit-based fairness standard.\n- *combined_earning*: scaling monetary amounts, for alternative model variants.\n- *trial_type*: reflects contribution roles, but included in calculation.\n- *split_self* (amount), *splitperc_self* (percent): both can be used for flexibility, but percent is more interpretable for step/threshold.\n- *Lapse rate*: to model random responding.\n\n---\n\n### **Step 6: Setting Bounds**\n\n- *min_acceptable_perc*: [0, 100] (%).\n- *penalty_strength*: \u2265 0 (no upper bound necessary, e.g. [0, 20]).\n- *fairness_reference*: [0, 100], but set via observation (either 50% or calculated from *token_self*).\n- *lapse_rate*: [0, 0.2] (allow up to 20% lapse).\n- *utility*: unbounded.\n\n---\n\n### **Comparison and Selection**\n\n**Soft-threshold model**: Highly interpretable (\u201churdle\u201d effect easily parameterized and recovered). Empirically, parameter is recoverable as clear behavioral step function.\n\n**Multiplicative model**: Distinct mechanisms: any acceptance requires both reasonable payoff *and* fairness. Risk of collinearity reduced by multiplying terms (rather than adding). Parameters recoverable, especially if not too many are included.\n\n**Hybrid (best of both)**: Utility is a product of a softened step function (smooth approximation of \u201cabove threshold\u201d) and an increasing penalty for deviance from fairness standard:\n\n    U = soft_step(splitperc_self - min_acceptable_perc, k) \u00d7 exp(-alpha \u00d7 |splitperc_self - fairness_reference|)\n\n**This is both interpretable and supports robust parameter recovery.**\n\n---\n\n## **Final Model Specification**\n\n### **Mathematical Formulation:**\n\nLet's formalize:\n\nLet:\n- Let *fairness_reference* = 100 \u00d7 (token_self) / (token_self + token_opp) (i.e., the percent in line with contribution-based fairness)\n- The soft-threshold is implemented as a logistic sigmoid: 1 / (1 + exp(-k \u00d7 (splitperc_self - min_acceptable_perc)))\n- *alpha* = fairness penalty sensitivity (\u22650, up to 10)\n\nSo:\n\n<MODEL>\nutility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5\n</MODEL>\n\n*Where logistic(x) = 1/(1 + exp(-x)), utility is unbounded, accept_prob_raw is between [0,1].*\n\n---\n\n### **Variable Descriptions:**\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility for accepting the proposed offer; predicts probability of accepting.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"accept_prob_raw\": {\n      \"description\": \"Predicted probability of acceptance after lapse correction.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Percentage of the shared pot allocated to the participant (self) in the proposal.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"min_acceptable_perc\": {\n      \"description\": \"Minimum acceptable % for self before the participant reliably considers accepting (soft threshold location).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sigmoid_steepness\": {\n      \"description\": \"Steepness parameter for the soft threshold (larger = closer to hard threshold, must be positive).\",\n      \"range\": {\n        \"min\": 0.01,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant (proxy for merit-based 'fair' share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent (proxy for merit-based fair share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_reference\": {\n      \"description\": \"Percent fair share for participant as defined by merit (tokens); computed as 100 * token_self / (token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"fairness_penalty_strength\": {\n      \"description\": \"Sensitivity to deviation from merit-based fairness (penalty for offers deviating from merit reference); controls weight of fairness consideration.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"lapse_rate\": {\n      \"description\": \"Fraction of trials the participant responds randomly (lapse/attention failure) regardless of offer; 0 means no lapses.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 0.2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n\n---\n\n<target_variable>accept</target_variable>\n\n---\n\n<SUMMARY>\nA hybrid threshold-plus-fairness model: The responder\u2019s utility combines a soft minimum-acceptable-offer threshold with a continuous penalty for deviation from their merit-based fair share. The threshold is implemented by a sigmoid on self-offer percentage, whose location and steepness are both learnable. An additional smooth penalty for deviation from merit-based fairness is applied multiplicatively. A lapse rate parameter models noisy or random responses. This structure supports interpretable, well-separated, and robustly recoverable parameters while capturing both satisficing and fairness-sensitive responding.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['min_acceptable_perc', 'sigmoid_steepness', 'fairness_penalty_strength', 'lapse_rate']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                utility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility for accepting the proposed offer; predicts probability of accepting.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"accept_prob_raw\": {\n      \"description\": \"Predicted probability of acceptance after lapse correction.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Percentage of the shared pot allocated to the participant (self) in the proposal.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"min_acceptable_perc\": {\n      \"description\": \"Minimum acceptable % for self before the participant reliably considers accepting (soft threshold location).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sigmoid_steepness\": {\n      \"description\": \"Steepness parameter for the soft threshold (larger = closer to hard threshold, must be positive).\",\n      \"range\": {\n        \"min\": 0.01,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant (proxy for merit-based 'fair' share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent (proxy for merit-based fair share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_reference\": {\n      \"description\": \"Percent fair share for participant as defined by merit (tokens); computed as 100 * token_self / (token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"fairness_penalty_strength\": {\n      \"description\": \"Sensitivity to deviation from merit-based fairness (penalty for offers deviating from merit reference); controls weight of fairness consideration.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"lapse_rate\": {\n      \"description\": \"Fraction of trials the participant responds randomly (lapse/attention failure) regardless of offer; 0 means no lapses.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 0.2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n---\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, min_acceptable_perc, sigmoid_steepness, fairness_penalty_strength, lapse_rate):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Calculate fairness reference\n        if (token_self + token_opp) == 0:\n            fairness_reference = 50  # Default to 50 if no tokens\n        else:\n            fairness_reference = 100 * token_self / (token_self + token_opp)\n\n        # Calculate utility\n        utility = sigmoid_steepness / (1 + math.exp(-sigmoid_steepness * (splitperc_self - min_acceptable_perc))) * math.exp(-fairness_penalty_strength * abs(splitperc_self - fairness_reference))\n\n        # Logistic function\n        def logistic(x):\n            return 1 / (1 + math.exp(-x))\n\n        # Calculate acceptance probability\n        accept_prob_raw = (1 - lapse_rate) * logistic(utility) + lapse_rate * 0.5\n\n        model_predictions.append(accept_prob_raw)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 1, \"group\": \"control\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 0, \"token_opp\": 14, \"token_self\": 16, \"combined_earning\": 44, \"split_opp\": 22.0, \"split_self\": 22.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 22.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 22.0}, {\"ID\": 2, \"group\": \"control\", \"trial_number\": 2, \"trial_type\": 1, \"trial_role\": 0, \"token_opp\": 17, \"token_self\": 17, \"combined_earning\": 28, \"split_opp\": 14.0, \"split_self\": 14.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 14.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 14.0}]'\ndata = json.loads(data_json)\n\n# Example usage: Replace with your actual data and parameter values\n# Assuming you load your data into a variable called 'data'\n# And you have some parameter estimates:\nmin_acceptable_perc_est = 30.0\nsigmoid_steepness_est = 1.0\nfairness_penalty_strength_est = 0.5\nlapse_rate_est = 0.05\n\n# Get results for the data\nresults = simulate_model(data, min_acceptable_perc_est, sigmoid_steepness_est, fairness_penalty_strength_est, lapse_rate_est)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744723713.365603
    }
  ],
  "learnable_parameters": {
    "min_acceptable_perc": {
      "description": "Minimum acceptable % for self before the participant reliably considers accepting (soft threshold location).",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sigmoid_steepness": {
      "description": "Steepness parameter for the soft threshold (larger = closer to hard threshold, must be positive).",
      "range": {
        "min": 0.01,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "fairness_penalty_strength": {
      "description": "Sensitivity to deviation from merit-based fairness (penalty for offers deviating from merit reference); controls weight of fairness consideration.",
      "range": {
        "min": 0.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "lapse_rate": {
      "description": "Fraction of trials the participant responds randomly (lapse/attention failure) regardless of offer; 0 means no lapses.",
      "range": {
        "min": 0.0,
        "max": 0.2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "utility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5",
  "variable_descriptions": {
    "utility": {
      "description": "Latent utility for accepting the proposed offer; predicts probability of accepting.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "accept_prob_raw": {
      "description": "Predicted probability of acceptance after lapse correction.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "splitperc_self": {
      "description": "Percentage of the shared pot allocated to the participant (self) in the proposal.",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "min_acceptable_perc": {
      "description": "Minimum acceptable % for self before the participant reliably considers accepting (soft threshold location).",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sigmoid_steepness": {
      "description": "Steepness parameter for the soft threshold (larger = closer to hard threshold, must be positive).",
      "range": {
        "min": 0.01,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "token_self": {
      "description": "Number of tokens found by participant (proxy for merit-based 'fair' share calculation).",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by opponent (proxy for merit-based fair share calculation).",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "fairness_reference": {
      "description": "Percent fair share for participant as defined by merit (tokens); computed as 100 * token_self / (token_self + token_opp).",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "fairness_penalty_strength": {
      "description": "Sensitivity to deviation from merit-based fairness (penalty for offers deviating from merit reference); controls weight of fairness consideration.",
      "range": {
        "min": 0.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "lapse_rate": {
      "description": "Fraction of trials the participant responds randomly (lapse/attention failure) regardless of offer; 0 means no lapses.",
      "range": {
        "min": 0.0,
        "max": 0.2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_summary": "A hybrid threshold-plus-fairness model: The responder\u2019s utility combines a soft minimum-acceptable-offer threshold with a continuous penalty for deviation from their merit-based fair share. The threshold is implemented by a sigmoid on self-offer percentage, whose location and steepness are both learnable. An additional smooth penalty for deviation from merit-based fairness is applied multiplicatively. A lapse rate parameter models noisy or random responses. This structure supports interpretable, well-separated, and robustly recoverable parameters while capturing both satisficing and fairness-sensitive responding.",
  "target_variable": "accept",
  "full_reasoning": "Let's carefully proceed stepwise as instructed.\n\n---\n\n### **Step 1: Distinct Psychological Processes in Responder Behavior**\n\nBased on the task, responder choices are likely driven by several plausible motives:\n\n1. **Self-Interest**: Preferring to maximize one\u2019s own monetary gain (*split_self*).\n2. **Fairness Concerns**: Aversion to receiving less than what\u2019s \u201cfair\u201d. \u201cFair\u201d can be:\n    - *Equality*: Each gets 50%.\n    - *Merit-based*: Each gets a share proportional to their contribution (i.e., based on *token_self/(token_self + token_opp)*).\n3. **Threshold/Satisficing**: Some responders may not consider offers below a subjective minimum acceptable share, regardless of other details\u2014a \"hurdle effect\".\n4. **Lapse/Stochasticity**: Some proportion of random response, regardless of utility.\n5. **Reference Dependence/Non-monotonicity**: Disliking both disadvantageous *and* advantageous deviations from a fairness reference (e.g., preferring offers \"close to fair\" to either side).\n\n---\n\n### **Step 2: Modeling Alternatives & Behavioral Predictions**\n\n**Candidate Model Classes:**\n\nA. **Stepwise/Indicator \u201cMinimum Acceptable Offer\u201d**\n- Utility is high above a critical threshold (*threshold_perc*, e.g., 22% or \u201cmy fair share\u201d); drops abruptly below.\n- **Behavior**: Clear kink in acceptance probability at personal threshold. Easy to identify parameter (threshold) as a unique behavioral pattern.\n\nB. **Multiplicative Model**\n- Utility is the product (not sum) of self-interest and fairness:\n    - U = self_gain \u00d7 fairness_penalty.\n- **Behavior**: Acceptance depends on both high own payoff *and* alignment with fairness. Penalizes \u201cselfish but unfair\u201d and \u201cfair but poor\u201d splits.\n\nC. **Reference-Dependent, U-shaped Fairness (Non-monotonic)**\n- Utility highest at reference point (equality or merit-based share); falls as offer deviates (in either direction).\n- **Prediction**: Dislike for \u201ctoo unfair\u201d (even in own favor for some). Captures idiosyncratic fairness norms.\n\nD. **Hybrid: Soft threshold + smooth penalty**\n- Utility drops sharply (but smoothly) below a threshold, then receives additional (possibly linear or quadratic) penalty for further deviations.\n- **Prediction**: Threshold-like response, with granularity in degree of unfairness.\n\nE. **Lapse/Noise**\n- Supplement any model above with a \u201cprobability of random choice,\u201d needed for fully realistic predictions and parameter recovery.\n\n---\n\n### **Step 3: Parameter Identifiability & Recovery**\n\n- **Threshold-based**: Clear utility \u201churdle\u201d\u2014threshold will recover well as the acceptance point in the data.\n- **Multiplicative**: Parameters correspond to distinct patterns; e.g., a \u201cfairness weight\u201d directly controls the depth of utility penalty as fairness decreases, distinguishable from shift in threshold.\n- **Non-linear/reference-dependent**: Tuning for standard (e.g., fairness preference) and \u201ctolerance\u201d (width of acceptance)\u2014potential for collinearity but distinguishable if spread of behaviors.\n- **Lapse rate**: Recovers as proportion of unmodeled (random) responses.\n\n*Additive \u201cself-interest + fairness penalty\u201d models struggle with low parameter recovery under collinearity\u2014thus, for the main model specification below I will avoid or hybridize with other forms to aid interpretability and recoverability.*\n\n---\n\n### **Step 4: Concrete Model Proposals**\n\nLet\u2019s draft two models, then choose the more robust for formal presentation.\n\n---\n\n**A. Soft-Threshold Model (with Minimum Acceptable Offer Reference)**\n- A \u201cminimum acceptable offer\u201d in percent; below, utility quickly becomes negative. Add a penalty for deviation from reference fairness standard. Logistic transformation for accept probability.\n- Utility = smooth (soft) threshold on *split_perc_self* at *min_acceptable_perc*, plus penalty for deviation from a fairness reference.\n\n**B. Multiplicative Interaction Model**\n- Utility = (amount gained) \u00d7 (fairness penalty), e.g.:\n    - U = split_self \u00d7 exp(-alpha \u00d7 |splitperc_self - fairness_reference|), where *fairness_reference* could be 50% (equal split) or proportional to contribution.\n\n---\n\n### **Step 5: Variable Selection & Theoretical Justification**\n\n- *splitperc_self* (percent offered to self): main driver, subject to threshold/fairness effect.\n- *token_self, token_opp*: allow calculation of merit-based fairness standard.\n- *combined_earning*: scaling monetary amounts, for alternative model variants.\n- *trial_type*: reflects contribution roles, but included in calculation.\n- *split_self* (amount), *splitperc_self* (percent): both can be used for flexibility, but percent is more interpretable for step/threshold.\n- *Lapse rate*: to model random responding.\n\n---\n\n### **Step 6: Setting Bounds**\n\n- *min_acceptable_perc*: [0, 100] (%).\n- *penalty_strength*: \u2265 0 (no upper bound necessary, e.g. [0, 20]).\n- *fairness_reference*: [0, 100], but set via observation (either 50% or calculated from *token_self*).\n- *lapse_rate*: [0, 0.2] (allow up to 20% lapse).\n- *utility*: unbounded.\n\n---\n\n### **Comparison and Selection**\n\n**Soft-threshold model**: Highly interpretable (\u201churdle\u201d effect easily parameterized and recovered). Empirically, parameter is recoverable as clear behavioral step function.\n\n**Multiplicative model**: Distinct mechanisms: any acceptance requires both reasonable payoff *and* fairness. Risk of collinearity reduced by multiplying terms (rather than adding). Parameters recoverable, especially if not too many are included.\n\n**Hybrid (best of both)**: Utility is a product of a softened step function (smooth approximation of \u201cabove threshold\u201d) and an increasing penalty for deviance from fairness standard:\n\n    U = soft_step(splitperc_self - min_acceptable_perc, k) \u00d7 exp(-alpha \u00d7 |splitperc_self - fairness_reference|)\n\n**This is both interpretable and supports robust parameter recovery.**\n\n---\n\n## **Final Model Specification**\n\n### **Mathematical Formulation:**\n\nLet's formalize:\n\nLet:\n- Let *fairness_reference* = 100 \u00d7 (token_self) / (token_self + token_opp) (i.e., the percent in line with contribution-based fairness)\n- The soft-threshold is implemented as a logistic sigmoid: 1 / (1 + exp(-k \u00d7 (splitperc_self - min_acceptable_perc)))\n- *alpha* = fairness penalty sensitivity (\u22650, up to 10)\n\nSo:\n\n<MODEL>\nutility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5\n</MODEL>\n\n*Where logistic(x) = 1/(1 + exp(-x)), utility is unbounded, accept_prob_raw is between [0,1].*\n\n---\n\n### **Variable Descriptions:**\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility for accepting the proposed offer; predicts probability of accepting.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"accept_prob_raw\": {\n      \"description\": \"Predicted probability of acceptance after lapse correction.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Percentage of the shared pot allocated to the participant (self) in the proposal.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"min_acceptable_perc\": {\n      \"description\": \"Minimum acceptable % for self before the participant reliably considers accepting (soft threshold location).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sigmoid_steepness\": {\n      \"description\": \"Steepness parameter for the soft threshold (larger = closer to hard threshold, must be positive).\",\n      \"range\": {\n        \"min\": 0.01,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by participant (proxy for merit-based 'fair' share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by opponent (proxy for merit-based fair share calculation).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_reference\": {\n      \"description\": \"Percent fair share for participant as defined by merit (tokens); computed as 100 * token_self / (token_self + token_opp).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"fairness_penalty_strength\": {\n      \"description\": \"Sensitivity to deviation from merit-based fairness (penalty for offers deviating from merit reference); controls weight of fairness consideration.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"lapse_rate\": {\n      \"description\": \"Fraction of trials the participant responds randomly (lapse/attention failure) regardless of offer; 0 means no lapses.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 0.2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    }\n  }\n}\n</VARIABLES>\n\n---\n\n<target_variable>accept</target_variable>\n\n---\n\n<SUMMARY>\nA hybrid threshold-plus-fairness model: The responder\u2019s utility combines a soft minimum-acceptable-offer threshold with a continuous penalty for deviation from their merit-based fair share. The threshold is implemented by a sigmoid on self-offer percentage, whose location and steepness are both learnable. An additional smooth penalty for deviation from merit-based fairness is applied multiplicatively. A lapse rate parameter models noisy or random responses. This structure supports interpretable, well-separated, and robustly recoverable parameters while capturing both satisficing and fairness-sensitive responding.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: utility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5\nSummary: A hybrid threshold-plus-fairness model: The responder\u2019s utility combines a soft minimum-acceptable-offer threshold with a continuous penalty for deviation from their merit-based fair share. The threshold is implemented by a sigmoid on self-offer percentage, whose location and steepness are both learnable. An additional smooth penalty for deviation from merit-based fairness is applied multiplicatively. A lapse rate parameter models noisy or random responses. This structure supports interpretable, well-separated, and robustly recoverable parameters while capturing both satisficing and fairness-sensitive responding.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, min_acceptable_perc, sigmoid_steepness, fairness_penalty_strength, lapse_rate):\n    model_predictions = []\n    for trial in trial_data:\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Calculate fairness reference\n        if (token_self + token_opp) == 0:\n            fairness_reference = 50  # Default to 50 if no tokens\n        else:\n            fairness_reference = 100 * token_self / (token_self + token_opp)\n\n        # Calculate utility\n        utility = sigmoid_steepness / (1 + math.exp(-sigmoid_steepness * (splitperc_self - min_acceptable_perc))) * math.exp(-fairness_penalty_strength * abs(splitperc_self - fairness_reference))\n\n        # Logistic function\n        def logistic(x):\n            return 1 / (1 + math.exp(-x))\n\n        # Calculate acceptance probability\n        accept_prob_raw = (1 - lapse_rate) * logistic(utility) + lapse_rate * 0.5\n\n        model_predictions.append(accept_prob_raw)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.5286935286935287,
  "group_accuracies": {
    "Control": 0.5432816537467701,
    "Cocaine": 0.515625
  },
  "group_parameter_averages": {
    "Control": {
      "min_acceptable_perc": 30.23880481346786,
      "sigmoid_steepness": 8.006615308805273,
      "fairness_penalty_strength": 4.276975994240626,
      "lapse_rate": 0.03446853991893114
    },
    "Cocaine": {
      "min_acceptable_perc": 37.30196940895055,
      "sigmoid_steepness": 8.41549277128117,
      "fairness_penalty_strength": 4.075062376006167,
      "lapse_rate": 0.027235697398601016
    }
  },
  "fitting_results": [
    {
      "min_acceptable_perc": 35.09506494320808,
      "sigmoid_steepness": 0.01000000000000003,
      "fairness_penalty_strength": 6.315010765093,
      "lapse_rate": 0.2,
      "success": true,
      "log_likelihood": -33.56700377688035,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 53.726846981465606,
      "sigmoid_steepness": 6.246073650686364,
      "fairness_penalty_strength": 3.5385947283268138,
      "lapse_rate": 0.1897785073897635,
      "success": true,
      "log_likelihood": -26.066771422787276,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 12.07559495921437,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.14945140892781147,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.858763641192944,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 37.64250906327537,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.4258258089485016,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.245165248261795,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 4.776423887598424,
      "sigmoid_steepness": 9.381744134415182,
      "fairness_penalty_strength": 9.575669487313522,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -26.745186142543684,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 21.018348744802367,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.09550526377281009,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -21.59226925472556,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 33.13911543455137,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 8.206241880791099,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.745165250564163,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 9.121071816119159,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.1195959901277945,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -21.082890238639912,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 21.539918940504812,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 4.475918291192963,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.74516462448639,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 7.456171281296142,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 7.997325104328224,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.745165248266368,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 52.85616991499547,
      "sigmoid_steepness": 2.6712697249764807,
      "fairness_penalty_strength": 6.871466645219172,
      "lapse_rate": 0.07791451138014903,
      "success": true,
      "log_likelihood": -27.066658534566635,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 12.26440779595137,
      "sigmoid_steepness": 0.01,
      "fairness_penalty_strength": 9.177341168666754,
      "lapse_rate": 0.2,
      "success": true,
      "log_likelihood": -33.06703202899401,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 2.5931725804507533,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.2223532794933327,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -26.342318503165306,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 2.8111051252129315,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.028780246233888,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.74516524702908,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 67.98734394516069,
      "sigmoid_steepness": 3.397439084377797,
      "fairness_penalty_strength": 7.292714447597173,
      "lapse_rate": 0.019115483325841634,
      "success": true,
      "log_likelihood": -17.066771424700317,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 2.656932077891938,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -11.277860290249533,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 46.01470200511367,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.584362163496085,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 69.97993438540433,
      "sigmoid_steepness": 0.2319658804394127,
      "fairness_penalty_strength": 5.001472413123978,
      "lapse_rate": 0.19605509922086137,
      "success": true,
      "log_likelihood": -19.566585405314935,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 24.374147310896177,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 7.706598176870063,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.74516525013412,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 4.098344845108127,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 2.525676622652852e-16,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -11.277860290249533,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 28.19598584484644,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.11469327155327498,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.360291096154995,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 26.36618480630668,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 8.310997577052108,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -19.245165250041318,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 3.7537495693261924,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 7.6566472299439745,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -28.245165248192787,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 25.182903383003087,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 8.289593500120047,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.245165248793068,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 10.827229823823071,
      "sigmoid_steepness": 8.355761867910193,
      "fairness_penalty_strength": 7.714579621184734,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.745267233782624,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 33.95960006693629,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 4.318687811977984,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -24.2451652482099,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 14.699255391133082,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.19074291676190627,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.76044034370634,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 47.072815442624226,
      "sigmoid_steepness": 9.56171779081459,
      "fairness_penalty_strength": 1.754775852003958,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -29.905975050402073,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 37.0751007800717,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 5.275991534218597,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.74516525014729,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 38.32629201008415,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.453644184496633,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -20.74516524964246,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 29.87807875851125,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 8.368378924459037,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.745165250563044,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 19.68775632722346,
      "sigmoid_steepness": 0.01,
      "fairness_penalty_strength": 9.59912731781504,
      "lapse_rate": 0.2,
      "success": true,
      "log_likelihood": -33.567022852244286,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 71.74185343328381,
      "sigmoid_steepness": 0.20681416880734999,
      "fairness_penalty_strength": 1.3736820040210607,
      "lapse_rate": 0.06959009896086636,
      "success": true,
      "log_likelihood": -27.566613391601916,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 27.200914528281373,
      "sigmoid_steepness": 8.729738127014693,
      "fairness_penalty_strength": 0.36793386000263684,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.51573368193414,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 21.513946529430317,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.218818535183428,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -16.745165248687936,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 60.312277194241496,
      "sigmoid_steepness": 0.8294342804617186,
      "fairness_penalty_strength": 1.7578890184583784,
      "lapse_rate": 0.13676724894506753,
      "success": true,
      "log_likelihood": -23.566758386925226,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 26.893454599630445,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -19.68986120811267,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 83.62833041317512,
      "sigmoid_steepness": 4.642499568722939,
      "fairness_penalty_strength": 7.278993617411307,
      "lapse_rate": 0.19292626729148948,
      "success": true,
      "log_likelihood": -26.06677142282439,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 31.449417138641998,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.9264484755431575,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -22.74516524368722,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 20.207934836992013,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.788638418670844,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.245165249970725,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 45.856164951900446,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.584362162037035,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 27.082286560827093,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.7148341957108862,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -30.675375271583075,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 48.12974855060303,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 4.235004779731036,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -17.405968337528943,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 34.35185597943441,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 2.6963505712441753,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -24.745162602581935,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 56.928599867396876,
      "sigmoid_steepness": 3.667359553196537,
      "fairness_penalty_strength": 1.4342296436860325,
      "lapse_rate": 0.02645863520751368,
      "success": true,
      "log_likelihood": -24.066771423238155,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 4.000511674888541,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 9.132400059876746,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -21.745165249521868,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 33.25206846449963,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.65467971892671,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 18.84297818388838,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.811720584732559,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.745167095811826,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 45.30507169103589,
      "sigmoid_steepness": 9.873825761747868,
      "fairness_penalty_strength": 2.552929360032341,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.40596997733078,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 22.63631508310994,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 4.627730742409533,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.245165371206145,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 28.89824633303418,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -20.18981581114825,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 59.225179559897434,
      "sigmoid_steepness": 2.1058849126380164,
      "fairness_penalty_strength": 9.195779940041902,
      "lapse_rate": 0.15150900289951674,
      "success": true,
      "log_likelihood": -32.56677142085314,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 47.84979642589533,
      "sigmoid_steepness": 9.786917434594201,
      "fairness_penalty_strength": 1.458592381424767,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.405971235318066,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 33.71447619281008,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.654588923845168,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 18.097174944910932,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.4110104964122542,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -27.514155539894492,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 38.74724929583511,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.159660984936797,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -28.745165248505586,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 61.08337541353607,
      "sigmoid_steepness": 7.818619487412319,
      "fairness_penalty_strength": 2.993746359945242,
      "lapse_rate": 0.0744152409860228,
      "success": true,
      "log_likelihood": -30.066771421990648,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.2777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 14.618555539565426,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 5.11442305483939,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.745165175670653,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 48.87053426728829,
      "sigmoid_steepness": 9.278463613629562,
      "fairness_penalty_strength": 5.2598555643996905,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -32.90598125282626,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 14.044252886126419,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -17.760042560726685,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 46.596709533860064,
      "sigmoid_steepness": 9.732539003342769,
      "fairness_penalty_strength": 6.28449060869404,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.90597208000735,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 0.03236131509011253,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.707465869572621,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.745165248320202,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 43.40400176035865,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 1.9344771171483155,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -33.40596833419301,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 62.882402807724766,
      "sigmoid_steepness": 9.641256727368209,
      "fairness_penalty_strength": 7.537160646755725,
      "lapse_rate": 0.017003641267599234,
      "success": true,
      "log_likelihood": -27.066771422615957,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 72.89813456696754,
      "sigmoid_steepness": 2.027313706640108,
      "fairness_penalty_strength": 0.031094337817323403,
      "lapse_rate": 0.1994741530828413,
      "success": true,
      "log_likelihood": -31.06677142178221,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 15.79877709731045,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.19134212868161993,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.761509049959066,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 38.73278217524012,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 8.961793926802208,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.24516525063454,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 8.133891874653564,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 7.7723440263895585,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -19.245165250032496,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 2.308673158830621,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.947919542217226,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -24.745165248950233,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 22.918085822494483,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.4347953668825095,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.245165249338193,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 64.2168539471172,
      "sigmoid_steepness": 0.0851294290216594,
      "fairness_penalty_strength": 0.6363583694971118,
      "lapse_rate": 0.07418530555892161,
      "success": true,
      "log_likelihood": -33.0644510714474,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3611111111111111,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 74.57095407824252,
      "sigmoid_steepness": 9.017375635903765,
      "fairness_penalty_strength": 2.178547322393433,
      "lapse_rate": 0.15574025940413816,
      "success": true,
      "log_likelihood": -32.566771421469554,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3611111111111111,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 2.463635120095542,
      "sigmoid_steepness": 9.36215907369212,
      "fairness_penalty_strength": 4.045804743408921,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.245187833078997,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 11.642589377423462,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.096174526014226,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -20.7451652506462,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 23.10983876311219,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.8875660534839525,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.745166684423815,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 98.14710844532273,
      "sigmoid_steepness": 4.288626110603239,
      "fairness_penalty_strength": 6.320781395952442,
      "lapse_rate": 0.15838840227181505,
      "success": true,
      "log_likelihood": -22.566771423553924,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 18.52291744075407,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -13.760178755353483,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 41.97808941069779,
      "sigmoid_steepness": 9.1798503068302,
      "fairness_penalty_strength": 7.029759544714445,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -33.90598386804678,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 79.17740945060046,
      "sigmoid_steepness": 7.1402183110518855,
      "fairness_penalty_strength": 2.5094186723285272,
      "lapse_rate": 0.13262172200552472,
      "success": true,
      "log_likelihood": -24.066771423241264,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 95.34359091105644,
      "sigmoid_steepness": 2.166816157009032,
      "fairness_penalty_strength": 1.686125524461325,
      "lapse_rate": 0.00114795303736841,
      "success": true,
      "log_likelihood": -33.566771421261116,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 28.33050835695886,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.905833716104014,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.245166608155284,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 27.176736833609382,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 3.8328278412083967,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -18.24516697259208,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 95.76849402970554,
      "sigmoid_steepness": 2.1771927120507137,
      "fairness_penalty_strength": 4.293940737864191,
      "lapse_rate": 0.11636915941158708,
      "success": true,
      "log_likelihood": -33.06677142136533,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 24.18977643960313,
      "sigmoid_steepness": 8.489341132536728,
      "fairness_penalty_strength": 6.494914632673718,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -25.745251430235978,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 24.152937966842448,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 5.7120545605246225,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -23.74516523894549,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 32.82328998364169,
      "sigmoid_steepness": 0.01,
      "fairness_penalty_strength": 3.3822442988969073,
      "lapse_rate": 0.2,
      "success": true,
      "log_likelihood": -33.067006601211126,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 28.183603481064125,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 7.6596192137816885,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -22.24516524940237,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 49.53568454941369,
      "sigmoid_steepness": 8.22550870873556,
      "fairness_penalty_strength": 3.578021207501163,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -30.90604202374242,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 19.26843914120247,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 0.0,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -13.26022464174729,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 13.885047668226392,
      "sigmoid_steepness": 10.0,
      "fairness_penalty_strength": 6.542858488748724,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -26.245165249634333,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "min_acceptable_perc": 43.834964319252926,
      "sigmoid_steepness": 9.869255243491637,
      "fairness_penalty_strength": 8.158829883795605,
      "lapse_rate": 0.0,
      "success": true,
      "log_likelihood": -22.405970041824116,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "min_acceptable_perc": {
        "r": 0.07594341246957691,
        "p": 0.4526697559623729
      },
      "sigmoid_steepness": {
        "r": 0.061488881887158384,
        "p": 0.5433641608501113
      },
      "fairness_penalty_strength": {
        "r": -0.07585849955148546,
        "p": 0.4531767210754749
      },
      "lapse_rate": {
        "r": -0.04663212289125878,
        "p": 0.6450072684617371
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 62.674758394036076,
  "bic_Control": 60.03153700559288,
  "bic_Cocaine": 65.04264422118311,
  "bic_results": {
    "average_bic": 62.674758394036076,
    "individual_bics": [
      81.46808330758513,
      66.46761859939899,
      62.051603036210324,
      68.82440625034803,
      67.82444803891181,
      57.518614263275566,
      47.82440625495276,
      56.49985623110426,
      47.82440500279722,
      69.82440625035717,
      68.4673928229577,
      80.46813981181245,
      67.01871276015505,
      47.82440624788261,
      48.46761860322508,
      36.889796334323506,
      47.50280008081661,
      53.467246564454314,
      51.82440625409268,
      36.889796334323506,
      61.05465794613443,
      52.82440625390707,
      70.82440625021002,
      64.82440625141058,
      65.82461022138969,
      62.82440625024424,
      61.85495644123712,
      74.14602585462859,
      51.824406254119026,
      55.82440625310936,
      47.82440625495053,
      81.46812145831301,
      69.46730253702827,
      69.36554311769272,
      47.824406251200315,
      61.467592527674896,
      53.713798170049785,
      66.46761859947323,
      59.824406241198886,
      50.824406253765886,
      61.50280007789851,
      75.6848262969906,
      49.14601242888233,
      63.824400958988306,
      62.46761860030075,
      57.82440625286817,
      61.64343519167787,
      69.8244099454481,
      69.146015708486,
      64.82440649623673,
      54.71370737612094,
      79.46761859553071,
      65.14601822446058,
      61.64325360151477,
      69.36238683361343,
      71.82440625083561,
      74.46761859780574,
      51.82440610516575,
      80.14603825947695,
      49.85416087527781,
      62.14601991383914,
      65.82440625046485,
      81.14601242221046,
      68.46761859905635,
      76.46761859738886,
      61.85709385374257,
      50.82440625509352,
      52.824406253889435,
      63.82440625172491,
      50.82440625250082,
      80.46297789671924,
      79.46761859676354,
      64.82445141998244,
      55.82440625511684,
      65.82440912267207,
      59.46761860093228,
      41.85443326453141,
      82.146043489918,
      62.46761860030696,
      81.46761859634667,
      64.82440897013501,
      50.8244096990086,
      80.4676185965551,
      65.8245786142964,
      61.824406231715415,
      80.46808895624669,
      58.824406252629174,
      76.14615980130928,
      40.85452503731902,
      66.8244062530931,
      59.146015837472675
    ],
    "group_enabled": true,
    "group_bics": {
      "Control": [
        81.46808330758513,
        66.46761859939899,
        62.051603036210324,
        68.82440625034803,
        67.82444803891181,
        57.518614263275566,
        47.82440625495276,
        56.49985623110426,
        47.82440500279722,
        69.82440625035717,
        68.4673928229577,
        80.46813981181245,
        67.01871276015505,
        47.82440624788261,
        48.46761860322508,
        36.889796334323506,
        47.50280008081661,
        53.467246564454314,
        51.82440625409268,
        36.889796334323506,
        61.05465794613443,
        52.82440625390707,
        70.82440625021002,
        64.82440625141058,
        65.82461022138969,
        62.82440625024424,
        61.85495644123712,
        74.14602585462859,
        51.824406254119026,
        55.82440625310936,
        47.82440625495053,
        81.46812145831301,
        69.46730253702827,
        69.36554311769272,
        47.824406251200315,
        61.467592527674896,
        53.713798170049785,
        66.46761859947323,
        59.824406241198886,
        50.824406253765886,
        61.50280007789851,
        75.6848262969906,
        49.14601242888233
      ],
      "Cocaine": [
        63.824400958988306,
        62.46761860030075,
        57.82440625286817,
        61.64343519167787,
        69.8244099454481,
        69.146015708486,
        64.82440649623673,
        54.71370737612094,
        79.46761859553071,
        65.14601822446058,
        61.64325360151477,
        69.36238683361343,
        71.82440625083561,
        74.46761859780574,
        51.82440610516575,
        80.14603825947695,
        49.85416087527781,
        62.14601991383914,
        65.82440625046485,
        81.14601242221046,
        68.46761859905635,
        76.46761859738886,
        61.85709385374257,
        50.82440625509352,
        52.824406253889435,
        63.82440625172491,
        50.82440625250082,
        80.46297789671924,
        79.46761859676354,
        64.82445141998244,
        55.82440625511684,
        65.82440912267207,
        59.46761860093228,
        41.85443326453141,
        82.146043489918,
        62.46761860030696,
        81.46761859634667,
        64.82440897013501,
        50.8244096990086,
        80.4676185965551,
        65.8245786142964,
        61.824406231715415,
        80.46808895624669,
        58.824406252629174,
        76.14615980130928,
        40.85452503731902,
        66.8244062530931,
        59.146015837472675
      ]
    },
    "num_parameters": 4,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- min_acceptable_perc: r = 0.076\n- sigmoid_steepness: r = 0.061\n- fairness_penalty_strength: r = -0.076\n- lapse_rate: r = -0.047",
  "previous_models": [
    "Specification: utility = sigmoid_steepness / (1 + exp(-sigmoid_steepness \u00d7 (splitperc_self - min_acceptable_perc))) \u00d7 exp(-fairness_penalty_strength \u00d7 abs(splitperc_self - fairness_reference))\naccept_prob_raw = (1 - lapse_rate) \u00d7 logistic(utility) + lapse_rate \u00d7 0.5\nSummary: A hybrid threshold-plus-fairness model: The responder\u2019s utility combines a soft minimum-acceptable-offer threshold with a continuous penalty for deviation from their merit-based fair share. The threshold is implemented by a sigmoid on self-offer percentage, whose location and steepness are both learnable. An additional smooth penalty for deviation from merit-based fairness is applied multiplicatively. A lapse rate parameter models noisy or random responses. This structure supports interpretable, well-separated, and robustly recoverable parameters while capturing both satisficing and fairness-sensitive responding.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 62.674758394036076\nOverall Accuracy: 0.5287\nGroup Accuracies:\n- Control: 0.5433\n- Cocaine: 0.5156\n\nParameter Recovery:\n- min_acceptable_perc: r = 0.076\n- sigmoid_steepness: r = 0.061\n- fairness_penalty_strength: r = -0.076\n- lapse_rate: r = -0.047"
  ]
}