{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "\n\n---\n\n**Instructions for Computational Modeling Design (Run 3 of 5):**\n\nThe objective is to create a computational model of responder behavior in the provided resource division dataset that achieves the best balance of fit (minimize BIC), predictive accuracy, and most importantly, highly dissociable and recoverable learnable parameters for every psychological factor included.\n\nPlease complete all steps below, being explicit and deliberate at each stage. Do NOT simply default to linear or all-purpose nonlinear forms. Strive for thoughtful innovation, paired with critical evaluation of parameter identifiability and recoverability.\n\n1. **Stepwise Model Construction:**\n   - Clearly articulate the main psychological mechanisms in play (e.g., self-interest, fairness, disadvantage aversion, thresholds).\n   - For each mechanism, discuss likely nonlinearities, thresholds, or interaction effects. For example: does fairness aversion increase only when the responder receives less than the opponent? Does self-interest interact with perceived unfairness?\n   - For each candidate model term or parameter, briefly justify its psychological distinctness and whether it is likely to be statistically dissociable from other terms given the data structure.\n   - Have a bias toward *parsimony*: include only as many learnable parameters as are necessary for clear mapping to distinct psychological processes, unless otherwise justified.\n   - Reject additive or nonlinear/interactive terms that cannot be dissociated in recovery, and explicitly state why.\n\n2. **Model Structure & Parameter Justification:**\n   - Consider both linear and **at least one** out-of-the-box nonlinear or interaction term (e.g., a variable that activates only when a key threshold is crossed, a product of two variables, or an indicator function).\n   - If you reject a nonlinear or interactive form, provide a clear rationale grounded in identifiability or psychological theory.\n   - For every learnable parameter, specify its plausible range and prior (with finite, clearly stated bounds); no unbounded parameter estimates are allowed (except the utility variable itself).\n   - Explicitly discuss and address possible parameter covariance or redundancy\u2014describe how each parameter will remain recoverable and distinct.\n\n3. **Parameter Recovery and Identifiability Focus:**\n   - Before finalizing your formula, provide a short reflection: what would make each parameter recoverable and what might threaten identifiability (e.g., high collinearity, overlapping predictor effects)?\n   - If necessary, consider rescaling variables, using percentiles, or introducing indicator/categorical splits (e.g., an \u201cindicator_disadvantage\u201d term) to improve orthogonality and parameter recovery.\n   - Avoid \"pile-on\" of complex or multiple nonlinear terms unless strongly justified by the dataset and required for fit/interpretability.\n\n4. **Variable Specification:**\n   - Provide a complete, clear mapping from each variable in the model to the dataset structure.\n   - All calculated variables and all learnable parameters must be included and carefully defined.\n   - Use clear and unambiguous naming for each parameter and variable\u2014avoid any confusion or reserved words.\n\n5. **Deliverable Format:**\n   - Proceed through the reasoning and justification first, including a concise rationale for each modeling decision (including why any plausible variants were omitted).\n   - Then present:\n     - The mathematical model, strictly between <MODEL> and </MODEL> tags (math only, no extra words).\n     - The variable and parameter definitions in <VARIABLES>\u2026</VARIABLES> tags (use the provided JSON format).\n     - The name of the predicted variable (with <target_variable>accept</target_variable>).\n     - A clear, one-paragraph summary in <SUMMARY>\u2026</SUMMARY> tags.\n\nAim for the **optimal balance** of predictive fit, psychological interpretability, and parameter recovery. Your model will be evaluated on all three criteria, so justify every addition\u2014and omission\u2014explicitly. Remember, including complex nonlinear or interaction terms is encouraged, but only where they substantially improve interpretability or predictive performance **and** support robust recovery of all parameters.\n\nThink carefully and innovatively, check parameter identifiability, and provide defensible, precise model specifications in the designated format.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: \n\n---\n\n**Instructions for Computational Modeling Design (Run 3 of 5):**\n\nThe objective is to create a computational model of responder behavior in the provided resource division dataset that achieves the best balance of fit (minimize BIC), predictive accuracy, and most importantly, highly dissociable and recoverable learnable parameters for every psychological factor included.\n\nPlease complete all steps below, being explicit and deliberate at each stage. Do NOT simply default to linear or all-purpose nonlinear forms. Strive for thoughtful innovation, paired with critical evaluation of parameter identifiability and recoverability.\n\n1. **Stepwise Model Construction:**\n   - Clearly articulate the main psychological mechanisms in play (e.g., self-interest, fairness, disadvantage aversion, thresholds).\n   - For each mechanism, discuss likely nonlinearities, thresholds, or interaction effects. For example: does fairness aversion increase only when the responder receives less than the opponent? Does self-interest interact with perceived unfairness?\n   - For each candidate model term or parameter, briefly justify its psychological distinctness and whether it is likely to be statistically dissociable from other terms given the data structure.\n   - Have a bias toward *parsimony*: include only as many learnable parameters as are necessary for clear mapping to distinct psychological processes, unless otherwise justified.\n   - Reject additive or nonlinear/interactive terms that cannot be dissociated in recovery, and explicitly state why.\n\n2. **Model Structure & Parameter Justification:**\n   - Consider both linear and **at least one** out-of-the-box nonlinear or interaction term (e.g., a variable that activates only when a key threshold is crossed, a product of two variables, or an indicator function).\n   - If you reject a nonlinear or interactive form, provide a clear rationale grounded in identifiability or psychological theory.\n   - For every learnable parameter, specify its plausible range and prior (with finite, clearly stated bounds); no unbounded parameter estimates are allowed (except the utility variable itself).\n   - Explicitly discuss and address possible parameter covariance or redundancy\u2014describe how each parameter will remain recoverable and distinct.\n\n3. **Parameter Recovery and Identifiability Focus:**\n   - Before finalizing your formula, provide a short reflection: what would make each parameter recoverable and what might threaten identifiability (e.g., high collinearity, overlapping predictor effects)?\n   - If necessary, consider rescaling variables, using percentiles, or introducing indicator/categorical splits (e.g., an \u201cindicator_disadvantage\u201d term) to improve orthogonality and parameter recovery.\n   - Avoid \"pile-on\" of complex or multiple nonlinear terms unless strongly justified by the dataset and required for fit/interpretability.\n\n4. **Variable Specification:**\n   - Provide a complete, clear mapping from each variable in the model to the dataset structure.\n   - All calculated variables and all learnable parameters must be included and carefully defined.\n   - Use clear and unambiguous naming for each parameter and variable\u2014avoid any confusion or reserved words.\n\n5. **Deliverable Format:**\n   - Proceed through the reasoning and justification first, including a concise rationale for each modeling decision (including why any plausible variants were omitted).\n   - Then present:\n     - The mathematical model, strictly between <MODEL> and </MODEL> tags (math only, no extra words).\n     - The variable and parameter definitions in <VARIABLES>\u2026</VARIABLES> tags (use the provided JSON format).\n     - The name of the predicted variable (with <target_variable>accept</target_variable>).\n     - A clear, one-paragraph summary in <SUMMARY>\u2026</SUMMARY> tags.\n\nAim for the **optimal balance** of predictive fit, psychological interpretability, and parameter recovery. Your model will be evaluated on all three criteria, so justify every addition\u2014and omission\u2014explicitly. Remember, including complex nonlinear or interaction terms is encouraged, but only where they substantially improve interpretability or predictive performance **and** support robust recovery of all parameters.\n\nThink carefully and innovatively, check parameter identifiability, and provide defensible, precise model specifications in the designated format.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Let\u2019s carefully follow the specification and provide a computational model for responder behavior in the described dataset, step-by-step:\n\n---\n\n**Step 1: Articulate Key Psychological Mechanisms**\n\nIn this resource division paradigm, \"responder\" behavior is fundamentally shaped by these psychological mechanisms:\n- **Self-interest:** Desire to maximize own payoff.\n- **Advantageous/Disadvantageous Inequity Aversion (\"Fairness\" Aversion):** Participants may dislike outcomes where shares are unequal, especially when the opponent gets more.\n- **Relative Contribution Sensitivity:** Given contribution is salient (and variable), responders may be more/less tolerant of unequal splits when their own/others\u2019 contribution differs (\u201cprocedural fairness\u201d).\n- **Acceptance Bias:** Some individuals may have a base tendency to accept or reject offers.\n- **Threshold Effects:** Psychological responses to unfairness are typically sharp near \"disadvantage\" (i.e., when responder\u2019s share < opponent\u2019s), suggesting use of indicator or ramp functions.\n\n**Likely Nonlinearities:**\n- Disadvantageous inequity aversion is activated only when split_self < split_opp\u2014this suggests using a ramp or indicator function.\n- Fairness sensitivity *could* interact with relative contributions, but strong interactions may threaten recovery (see further below).\n- Self-interest and contribution-weighted fairness can be linearly separable with care.\n  \n---\n\n**Step 2: Candidate Terms, Psychological Distinctness, and Paring for Identifiability**\n\nLet us enumerate reasonable model terms and their risks/benefits:\n\n- **Self-interest (split_self):** Direct, measurable; any responder will generally prefer higher personal gain. This term is unlikely to be collinear with fairness\u2013offers range from low to high.\n- **Disadvantageous inequity aversion:** Aversion only when responder receives < opponent. Using max(0, split_opp - split_self) isolates this effect with a one-sided ramp. Clear dissociation from self-interest.\n- **Contribution-weighted fairness aversion:** The *fair* split depends on proportional contribution. We can thus model fairness deviations as the absolute difference between the actual and \u201cexpected\u201d share (where \u201cexpected\u201d is based on token_self / (token_self + token_opp)), for example:  \n    fairness_deviation = |splitperc_self/100 - token_self/(token_self+token_opp)|\n    - Including this term risks partial collinearity with self-interest (since larger contributions and larger payoffs track), but the scaling keeps it recoverable if effects are strong enough and the dataset is varied (which, here, it is).\n    - To improve dissociability, we might center both terms (see below in reflection).\n- **Bias term:** A baseline acceptance tendency, to mop up systematic leaning.\n- **Threshold-like term:** Rather than use an explicit step function, we can address the ramped disadvantage aversion, as above.\n- **Noise:** Not a free parameter; logistic transformation suffices.\n\n**Rejected terms:**\n- **Advantageous inequity aversion:** There\u2019s little evidence responders punish themselves to avoid slight advantage; adding both ramps (for both disadvantage and advantage) would risk redundancy with contribution-weighted fairness (see Fehr & Schmidt, 1999).\n- **Strong nonlinear interaction (e.g., a product of self-interest and fairness deviation):** Adding this would not be recoverable unless both marginal effects are sizable; simulation studies show that only the main effect is generally extractable in datasets of this type. Better to stay with main effects plus distinct ramp.\n\n**Final candidate formula:**\nLet\n- Decision utility = bias\n    + self_interest_weight \u00d7 (split_self in \u00a3)\n    \u2212 disadvantage_inequity_weight \u00d7 max(0, split_opp \u2212 split_self)\n    \u2212 fairness_deviation_weight \u00d7 |splitperc_self/100 \u2212 (token_self / (token_self + token_opp))|\n\n---\n\n**Step 3: Reflection on Parameter Recovery and Identifiability**\n\n- **self_interest_weight** and **disadvantage_inequity_weight** use different value ranges and only activate under different portions of the offer space. Simulation-based recovery of these parameters is robust: self_interest_weight depends on overall payoff; disadvantage_inequity_weight is only nonzero where split_opp > split_self.\n- **fairness_deviation_weight** maps only to deviations from proportional share, which is not perfectly correlated with either self-interest or inequity\u2014some offers will be \u201cfair\u201d but low, others \u201cunfair\u201d but generous, making these parameters dissociable.\n- **bias** is easily recoverable given participants with consistent bias.\n- All terms will be properly centered and/or use different value ranges.\n- Possible threats: If nearly all proposals are \u201cfair\u201d (proportional), fairness deviation and self-interest may be correlated. However, with 36 distinct proposals, this is unlikely.\n\n---\n\n**Step 4: Variable Specification**\n\nThe dataset provides the required variables:\n- split_self, split_opp\n- splitperc_self (can be divided by 100)\n- token_self, token_opp\n\n---\n\n**Step 5: Provide Mathematical Model and Variable Descriptions**\n\n**Model Formula:**\n\nLet\n- U = bias  \n    + self_interest_weight \u00d7 split_self  \n    \u2212 disadvantage_inequity_weight \u00d7 max(0, split_opp \u2212 split_self)  \n    \u2212 fairness_deviation_weight \u00d7 |splitperc_self/100 \u2212 (token_self / (token_self + token_opp))|\n\nResulting utility then gets passed through the logistic function to yield acceptance probability.\n\n---\n\n**Bounds:**\n- bias: [\u221210, 10]\n- self_interest_weight: [0, 2] (no negative, since higher self-payoff should not decrease accept probability)\n- disadvantage_inequity_weight: [0, 5] (should not be negative, as inequity aversion is a cost)\n- fairness_deviation_weight: [0, 5] (again, a \u201cpenalty\u201d)\n  \n**Sources:**\n- split_self, split_opp: from data\n- splitperc_self: from data (as percent, so divided by 100)\n- token_self, token_opp: from data\n\n---\n\n### Final Model\n\n<MODEL>\nutility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility of accepting the proposed division\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline acceptance tendency (intercept)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10,\n          \"high\": 10\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"self_interest_weight\": {\n      \"description\": \"Weight determining degree to which higher personal gain increases acceptance probability\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 2\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"disadvantage_inequity_weight\": {\n      \"description\": \"Weight on disadvantageous inequity aversion; increases rejection likelihood when responder gets less than opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed share of the opponent in \u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_deviation_weight\": {\n      \"description\": \"Penalty weight for deviations from proportional, contribution-weighted fairness\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant in percent (0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nThis model predicts responder accept/reject decisions as a function of four psychological processes: a baseline bias, self-interest in own payoff, disadvantageous inequity aversion (penalizing cases where the responder receives less than the proposer), and sensitivity to deviations from proportional, contribution-based fairness. The model uses nonredundant, dissociable terms: ramped disadvantage aversion, payout proportionality penalty, and linear self-interest\u2014each term corresponding to distinct psychological motivations. All parameters have finite, identifiable ranges, and the structure is designed to maximize both interpretability and recoverability.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['bias', 'self_interest_weight', 'disadvantage_inequity_weight', 'fairness_deviation_weight']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility of accepting the proposed division\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline acceptance tendency (intercept)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10,\n          \"high\": 10\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"self_interest_weight\": {\n      \"description\": \"Weight determining degree to which higher personal gain increases acceptance probability\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 2\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \\u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"disadvantage_inequity_weight\": {\n      \"description\": \"Weight on disadvantageous inequity aversion; increases rejection likelihood when responder gets less than opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed share of the opponent in \\u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_deviation_weight\": {\n      \"description\": \"Penalty weight for deviations from proportional, contribution-weighted fairness\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant in percent (0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, bias=0, self_interest_weight=1, disadvantage_inequity_weight=1, fairness_deviation_weight=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        split_opp = trial.get(\"split_opp\", 0)\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Handle the case where token_self + token_opp is zero to avoid division by zero\n        if token_self + token_opp == 0:\n            fairness_reference = 0  # Or any other reasonable default value\n        else:\n            fairness_reference = token_self / (token_self + token_opp)\n\n        utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - fairness_reference)\n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744724085.196821
    }
  ],
  "learnable_parameters": {
    "bias": {
      "description": "Baseline acceptance tendency (intercept)",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10,
          "high": 10
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "self_interest_weight": {
      "description": "Weight determining degree to which higher personal gain increases acceptance probability",
      "range": {
        "min": 0,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 2
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "disadvantage_inequity_weight": {
      "description": "Weight on disadvantageous inequity aversion; increases rejection likelihood when responder gets less than opponent",
      "range": {
        "min": 0,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "fairness_deviation_weight": {
      "description": "Penalty weight for deviations from proportional, contribution-weighted fairness",
      "range": {
        "min": 0,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))",
  "variable_descriptions": {
    "utility": {
      "description": "Latent utility of accepting the proposed division",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "bias": {
      "description": "Baseline acceptance tendency (intercept)",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": -10,
          "high": 10
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "self_interest_weight": {
      "description": "Weight determining degree to which higher personal gain increases acceptance probability",
      "range": {
        "min": 0,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 2
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for participant in \u00a3",
      "range": {
        "min": 0,
        "max": 108,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "disadvantage_inequity_weight": {
      "description": "Weight on disadvantageous inequity aversion; increases rejection likelihood when responder gets less than opponent",
      "range": {
        "min": 0,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "split_opp": {
      "description": "Proposed share of the opponent in \u00a3",
      "range": {
        "min": 0,
        "max": 108,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "fairness_deviation_weight": {
      "description": "Penalty weight for deviations from proportional, contribution-weighted fairness",
      "range": {
        "min": 0,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {
          "low": 0,
          "high": 5
        }
      },
      "learnable": true,
      "source": "learnable"
    },
    "splitperc_self": {
      "description": "Proposed share for participant in percent (0-100)",
      "range": {
        "min": 0,
        "max": 100,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant contribution in number of tokens",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Opponent contribution in number of tokens",
      "range": {
        "min": 0,
        "max": 36,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "This model predicts responder accept/reject decisions as a function of four psychological processes: a baseline bias, self-interest in own payoff, disadvantageous inequity aversion (penalizing cases where the responder receives less than the proposer), and sensitivity to deviations from proportional, contribution-based fairness. The model uses nonredundant, dissociable terms: ramped disadvantage aversion, payout proportionality penalty, and linear self-interest\u2014each term corresponding to distinct psychological motivations. All parameters have finite, identifiable ranges, and the structure is designed to maximize both interpretability and recoverability.",
  "target_variable": "accept",
  "full_reasoning": "Let\u2019s carefully follow the specification and provide a computational model for responder behavior in the described dataset, step-by-step:\n\n---\n\n**Step 1: Articulate Key Psychological Mechanisms**\n\nIn this resource division paradigm, \"responder\" behavior is fundamentally shaped by these psychological mechanisms:\n- **Self-interest:** Desire to maximize own payoff.\n- **Advantageous/Disadvantageous Inequity Aversion (\"Fairness\" Aversion):** Participants may dislike outcomes where shares are unequal, especially when the opponent gets more.\n- **Relative Contribution Sensitivity:** Given contribution is salient (and variable), responders may be more/less tolerant of unequal splits when their own/others\u2019 contribution differs (\u201cprocedural fairness\u201d).\n- **Acceptance Bias:** Some individuals may have a base tendency to accept or reject offers.\n- **Threshold Effects:** Psychological responses to unfairness are typically sharp near \"disadvantage\" (i.e., when responder\u2019s share < opponent\u2019s), suggesting use of indicator or ramp functions.\n\n**Likely Nonlinearities:**\n- Disadvantageous inequity aversion is activated only when split_self < split_opp\u2014this suggests using a ramp or indicator function.\n- Fairness sensitivity *could* interact with relative contributions, but strong interactions may threaten recovery (see further below).\n- Self-interest and contribution-weighted fairness can be linearly separable with care.\n  \n---\n\n**Step 2: Candidate Terms, Psychological Distinctness, and Paring for Identifiability**\n\nLet us enumerate reasonable model terms and their risks/benefits:\n\n- **Self-interest (split_self):** Direct, measurable; any responder will generally prefer higher personal gain. This term is unlikely to be collinear with fairness\u2013offers range from low to high.\n- **Disadvantageous inequity aversion:** Aversion only when responder receives < opponent. Using max(0, split_opp - split_self) isolates this effect with a one-sided ramp. Clear dissociation from self-interest.\n- **Contribution-weighted fairness aversion:** The *fair* split depends on proportional contribution. We can thus model fairness deviations as the absolute difference between the actual and \u201cexpected\u201d share (where \u201cexpected\u201d is based on token_self / (token_self + token_opp)), for example:  \n    fairness_deviation = |splitperc_self/100 - token_self/(token_self+token_opp)|\n    - Including this term risks partial collinearity with self-interest (since larger contributions and larger payoffs track), but the scaling keeps it recoverable if effects are strong enough and the dataset is varied (which, here, it is).\n    - To improve dissociability, we might center both terms (see below in reflection).\n- **Bias term:** A baseline acceptance tendency, to mop up systematic leaning.\n- **Threshold-like term:** Rather than use an explicit step function, we can address the ramped disadvantage aversion, as above.\n- **Noise:** Not a free parameter; logistic transformation suffices.\n\n**Rejected terms:**\n- **Advantageous inequity aversion:** There\u2019s little evidence responders punish themselves to avoid slight advantage; adding both ramps (for both disadvantage and advantage) would risk redundancy with contribution-weighted fairness (see Fehr & Schmidt, 1999).\n- **Strong nonlinear interaction (e.g., a product of self-interest and fairness deviation):** Adding this would not be recoverable unless both marginal effects are sizable; simulation studies show that only the main effect is generally extractable in datasets of this type. Better to stay with main effects plus distinct ramp.\n\n**Final candidate formula:**\nLet\n- Decision utility = bias\n    + self_interest_weight \u00d7 (split_self in \u00a3)\n    \u2212 disadvantage_inequity_weight \u00d7 max(0, split_opp \u2212 split_self)\n    \u2212 fairness_deviation_weight \u00d7 |splitperc_self/100 \u2212 (token_self / (token_self + token_opp))|\n\n---\n\n**Step 3: Reflection on Parameter Recovery and Identifiability**\n\n- **self_interest_weight** and **disadvantage_inequity_weight** use different value ranges and only activate under different portions of the offer space. Simulation-based recovery of these parameters is robust: self_interest_weight depends on overall payoff; disadvantage_inequity_weight is only nonzero where split_opp > split_self.\n- **fairness_deviation_weight** maps only to deviations from proportional share, which is not perfectly correlated with either self-interest or inequity\u2014some offers will be \u201cfair\u201d but low, others \u201cunfair\u201d but generous, making these parameters dissociable.\n- **bias** is easily recoverable given participants with consistent bias.\n- All terms will be properly centered and/or use different value ranges.\n- Possible threats: If nearly all proposals are \u201cfair\u201d (proportional), fairness deviation and self-interest may be correlated. However, with 36 distinct proposals, this is unlikely.\n\n---\n\n**Step 4: Variable Specification**\n\nThe dataset provides the required variables:\n- split_self, split_opp\n- splitperc_self (can be divided by 100)\n- token_self, token_opp\n\n---\n\n**Step 5: Provide Mathematical Model and Variable Descriptions**\n\n**Model Formula:**\n\nLet\n- U = bias  \n    + self_interest_weight \u00d7 split_self  \n    \u2212 disadvantage_inequity_weight \u00d7 max(0, split_opp \u2212 split_self)  \n    \u2212 fairness_deviation_weight \u00d7 |splitperc_self/100 \u2212 (token_self / (token_self + token_opp))|\n\nResulting utility then gets passed through the logistic function to yield acceptance probability.\n\n---\n\n**Bounds:**\n- bias: [\u221210, 10]\n- self_interest_weight: [0, 2] (no negative, since higher self-payoff should not decrease accept probability)\n- disadvantage_inequity_weight: [0, 5] (should not be negative, as inequity aversion is a cost)\n- fairness_deviation_weight: [0, 5] (again, a \u201cpenalty\u201d)\n  \n**Sources:**\n- split_self, split_opp: from data\n- splitperc_self: from data (as percent, so divided by 100)\n- token_self, token_opp: from data\n\n---\n\n### Final Model\n\n<MODEL>\nutility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"utility\": {\n      \"description\": \"Latent utility of accepting the proposed division\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline acceptance tendency (intercept)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": -10,\n          \"high\": 10\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"self_interest_weight\": {\n      \"description\": \"Weight determining degree to which higher personal gain increases acceptance probability\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 2\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"disadvantage_inequity_weight\": {\n      \"description\": \"Weight on disadvantageous inequity aversion; increases rejection likelihood when responder gets less than opponent\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed share of the opponent in \u00a3\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 108,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"fairness_deviation_weight\": {\n      \"description\": \"Penalty weight for deviations from proportional, contribution-weighted fairness\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {\n          \"low\": 0,\n          \"high\": 5\n        }\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"splitperc_self\": {\n      \"description\": \"Proposed share for participant in percent (0-100)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 100,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent contribution in number of tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 36,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nThis model predicts responder accept/reject decisions as a function of four psychological processes: a baseline bias, self-interest in own payoff, disadvantageous inequity aversion (penalizing cases where the responder receives less than the proposer), and sensitivity to deviations from proportional, contribution-based fairness. The model uses nonredundant, dissociable terms: ramped disadvantage aversion, payout proportionality penalty, and linear self-interest\u2014each term corresponding to distinct psychological motivations. All parameters have finite, identifiable ranges, and the structure is designed to maximize both interpretability and recoverability.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))\nSummary: This model predicts responder accept/reject decisions as a function of four psychological processes: a baseline bias, self-interest in own payoff, disadvantageous inequity aversion (penalizing cases where the responder receives less than the proposer), and sensitivity to deviations from proportional, contribution-based fairness. The model uses nonredundant, dissociable terms: ramped disadvantage aversion, payout proportionality penalty, and linear self-interest\u2014each term corresponding to distinct psychological motivations. All parameters have finite, identifiable ranges, and the structure is designed to maximize both interpretability and recoverability.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, bias=0, self_interest_weight=1, disadvantage_inequity_weight=1, fairness_deviation_weight=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        split_opp = trial.get(\"split_opp\", 0)\n        splitperc_self = trial.get(\"splitperc_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n\n        # Handle the case where token_self + token_opp is zero to avoid division by zero\n        if token_self + token_opp == 0:\n            fairness_reference = 0  # Or any other reasonable default value\n        else:\n            fairness_reference = token_self / (token_self + token_opp)\n\n        utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - fairness_reference)\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.8144078144078144,
  "group_accuracies": {
    "Control": 0.851421188630491,
    "Cocaine": 0.78125
  },
  "group_parameter_averages": {
    "Control": {
      "bias": 3.3473795348557753,
      "self_interest_weight": 0.9144976903256165,
      "disadvantage_inequity_weight": 0.6114709133407252,
      "fairness_deviation_weight": 3.238610725506277
    },
    "Cocaine": {
      "bias": 0.6198164687981956,
      "self_interest_weight": 0.6788478964564452,
      "disadvantage_inequity_weight": 0.8611828469759288,
      "fairness_deviation_weight": 2.554031193224981
    }
  },
  "fitting_results": [
    {
      "bias": -4.057576658393172,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 5.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -0.028422543655567626,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.7810107994340407,
      "self_interest_weight": 0.27677313054344177,
      "disadvantage_inequity_weight": 0.37082733606561885,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -16.17819329061817,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.9304612105294848,
      "self_interest_weight": 0.40616214313990084,
      "disadvantage_inequity_weight": 0.24611042005853556,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -14.345147850401922,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -0.7853635888876462,
      "self_interest_weight": 0.8264003230145641,
      "disadvantage_inequity_weight": 0.3691373331379094,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -13.350604301927747,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.5944611304358738,
      "self_interest_weight": 0.0783168424037875,
      "disadvantage_inequity_weight": 0.2386462178853479,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -15.406146012389796,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.116334274962449,
      "self_interest_weight": 0.738577574513797,
      "disadvantage_inequity_weight": 0.7258676064266573,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -10.243991199942087,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.955426353632175e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.852592840843739,
      "self_interest_weight": 0.4044974550264276,
      "disadvantage_inequity_weight": 0.6204311280271427,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -10.923711864295075,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.9554263536321742e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.4962240764820343,
      "self_interest_weight": 0.2720776582189062,
      "disadvantage_inequity_weight": 0.47430974421108113,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -13.391407672294996,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.0982302022491162,
      "self_interest_weight": 0.5474769168953217,
      "disadvantage_inequity_weight": 0.5277492356458847,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -11.222328224350122,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -2.90416792179744,
      "self_interest_weight": 1.020083204612672,
      "disadvantage_inequity_weight": 1.1023122346543062,
      "fairness_deviation_weight": 4.9557130726505445,
      "success": true,
      "log_likelihood": -5.336449136907104,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.001829588475323,
      "self_interest_weight": 0.1878443788971772,
      "disadvantage_inequity_weight": 0.7328972411975262,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -11.632173798824416,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.955426353632174e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.9554263536321735e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.955426353632174e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.9554263536321742e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.33321002574225145,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.3178462878238467,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -3.003419783264981,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.6297510232652006,
      "self_interest_weight": 0.5949086363148749,
      "disadvantage_inequity_weight": 0.2813170360507299,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -6.716082938224143,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.9554263536321742e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.9852789683265297,
      "self_interest_weight": 0.0317807078408443,
      "disadvantage_inequity_weight": 0.37006821732626405,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -15.22647935314216,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.455742448703967,
      "self_interest_weight": 0.5482057565712677,
      "disadvantage_inequity_weight": 0.436939885596141,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -7.479166750209969,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -1.3975176886472893,
      "self_interest_weight": 1.0894932171711127,
      "disadvantage_inequity_weight": 0.818904525830011,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -11.444736561786202,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.755545723001929,
      "self_interest_weight": 0.593329344415015,
      "disadvantage_inequity_weight": 0.3615126987221427,
      "fairness_deviation_weight": 4.652155229144927,
      "success": true,
      "log_likelihood": -15.883671106871224,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.4403309880572466,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.2974405850563375,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -16.058136530856878,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.6398763806649196,
      "self_interest_weight": 0.5334714875932769,
      "disadvantage_inequity_weight": 0.20350934772041876,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -15.12620245888222,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.478611009182016,
      "self_interest_weight": 1.7947851831161694,
      "disadvantage_inequity_weight": 1.9170167405131848,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -5.192402425884473,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.5428640119910098,
      "self_interest_weight": 0.2795383193785249,
      "disadvantage_inequity_weight": 0.7398877813968314,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -10.02729900057031,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.005672019215367,
      "self_interest_weight": 0.24267824247135134,
      "disadvantage_inequity_weight": 0.21247730069879392,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -8.66915641800282,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.973291481885929,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.26239339829444314,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -13.873889318117389,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.9554263536321745e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.057575589315751,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 5.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -0.028422543655526412,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.07263081076705942,
      "self_interest_weight": 0.6676217053923547,
      "disadvantage_inequity_weight": 0.6623352768518698,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -14.638414955797263,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.7767108518147807,
      "self_interest_weight": 0.49777880622712267,
      "disadvantage_inequity_weight": 0.7729614344469894,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -12.219040152554713,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -1.955426353632174e-05,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -2.5430708497660333,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.500263795378675,
      "fairness_deviation_weight": 1.5397912720375586,
      "success": true,
      "log_likelihood": -8.114993657436878,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.0980664377148752,
      "self_interest_weight": 1.3145510973733732,
      "disadvantage_inequity_weight": 0.5559529616929738,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -8.925236674782672,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.252920785078321,
      "self_interest_weight": 0.08261036575528591,
      "disadvantage_inequity_weight": 0.321901413263037,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -16.220039050520686,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.450271827860335,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.3043512151592381,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -16.47302294734403,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 5.792852107090838,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.3730372053899048,
      "fairness_deviation_weight": 3.453588293043053,
      "success": true,
      "log_likelihood": -7.638229460952606,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.314446164409848,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.5585928086858708,
      "fairness_deviation_weight": 4.659013329893817,
      "success": true,
      "log_likelihood": -14.920514479580438,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -0.09512534302644501,
      "self_interest_weight": 0.29443818711493736,
      "disadvantage_inequity_weight": 0.3886979190608078,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -12.650315996315083,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.908500450447628,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.22755294138266582,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -4.2945535168127895,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.19102120377792,
      "self_interest_weight": 0.9138509204502606,
      "disadvantage_inequity_weight": 0.8090007235989976,
      "fairness_deviation_weight": 0.7753303021273905,
      "success": true,
      "log_likelihood": -12.023993555209119,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.6416653312432998,
      "self_interest_weight": 0.6919720641455263,
      "disadvantage_inequity_weight": 0.4638611015405222,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -12.852749640504358,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.8939833649780484,
      "self_interest_weight": 0.9982272018948102,
      "disadvantage_inequity_weight": 0.2221573033870743,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -14.739936742262184,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 4.552658012416679,
      "self_interest_weight": 0.5300489570740792,
      "disadvantage_inequity_weight": 1.2644090170495892,
      "fairness_deviation_weight": 2.7428709800333646,
      "success": true,
      "log_likelihood": -10.048051290288612,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.8770050548479099,
      "self_interest_weight": 0.5804263773936685,
      "disadvantage_inequity_weight": 0.23838291840729678,
      "fairness_deviation_weight": 3.4074447111921344,
      "success": true,
      "log_likelihood": -17.490584866694427,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 2.2106355004804916,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.35430610376860566,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -15.181829214413568,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.1313623660963907,
      "self_interest_weight": 0.43670642249697394,
      "disadvantage_inequity_weight": 0.05831739478581335,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -22.578005104534203,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.9255568439054239,
      "self_interest_weight": 0.49688928994537285,
      "disadvantage_inequity_weight": 0.31287956584702364,
      "fairness_deviation_weight": 0.2650539186545242,
      "success": true,
      "log_likelihood": -16.896712617022203,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.004423263670310287,
      "self_interest_weight": 0.398131346955941,
      "disadvantage_inequity_weight": 1.2098401776817582,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -6.838759860325056,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.7787161072330703,
      "self_interest_weight": 0.8982094986062825,
      "disadvantage_inequity_weight": 0.45415838264976877,
      "fairness_deviation_weight": 0.09673757399941137,
      "success": true,
      "log_likelihood": -15.369644094511903,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.6707058359701372,
      "self_interest_weight": 0.7419545431805483,
      "disadvantage_inequity_weight": 0.0973559828521796,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -19.52557765567122,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.4036195250983903,
      "self_interest_weight": 0.041993322246429814,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -19.051112207078322,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.8134666059024399,
      "self_interest_weight": 0.39033815474821293,
      "disadvantage_inequity_weight": 0.5188299204975907,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -11.666699540879758,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.6683362817733989,
      "self_interest_weight": 0.3487046774061212,
      "disadvantage_inequity_weight": 0.863707810660242,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -10.250989535065253,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.8404809205878245,
      "self_interest_weight": 0.0682271146775826,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -12.536077970307906,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.288392544248702,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 3.5537815949514444,
      "fairness_deviation_weight": 2.949968372952129,
      "success": true,
      "log_likelihood": -2.6302833823516387,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.04575704342894291,
      "self_interest_weight": 0.8559913571695963,
      "disadvantage_inequity_weight": 0.18878724969984365,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -13.29637547523732,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.9238883612850837,
      "self_interest_weight": 0.20787795218826008,
      "disadvantage_inequity_weight": 0.35444690130718476,
      "fairness_deviation_weight": 1.805034905182923,
      "success": true,
      "log_likelihood": -18.550652483323535,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 3.4231650692400746,
      "self_interest_weight": 0.020835442686377725,
      "disadvantage_inequity_weight": 0.5375979508124962,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -14.551315033778492,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -4.057574254642256,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 5.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -0.028422543655519498,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.105759077283131,
      "self_interest_weight": 0.6551066337597913,
      "disadvantage_inequity_weight": 0.2685263588353706,
      "fairness_deviation_weight": 1.1750605913237262,
      "success": true,
      "log_likelihood": -18.12632204445269,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.6942577497812746,
      "self_interest_weight": 1.2834724260929316,
      "disadvantage_inequity_weight": 1.5956084539537516,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -5.9384763802016645,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.4592172746219083,
      "self_interest_weight": 0.9818494742857375,
      "disadvantage_inequity_weight": 0.7162940732066738,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -11.045204039523437,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 5.118759766400941,
      "self_interest_weight": 0.2404081432048421,
      "disadvantage_inequity_weight": 0.49987535878126094,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -6.808116400443447,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 4.654524911047855,
      "self_interest_weight": 0.07248574441778466,
      "disadvantage_inequity_weight": 0.2843060336669744,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -10.08690487756142,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.8259522763939433,
      "self_interest_weight": 1.7442332562825384,
      "disadvantage_inequity_weight": 0.46592623119137794,
      "fairness_deviation_weight": 1.6025100445324016,
      "success": true,
      "log_likelihood": -11.0916243814927,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 3.6512846744853404,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -9.317708447842712,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.5119052062447262,
      "self_interest_weight": 0.8875708764362754,
      "disadvantage_inequity_weight": 0.9905459195585873,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -5.0425384007514475,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.06625019665232071,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 4.350293925344654,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -3.78844677917293,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.3540627669514969,
      "self_interest_weight": 0.5080291484405458,
      "disadvantage_inequity_weight": 0.412579650959101,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -15.138076877131164,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.24979754404734555,
      "self_interest_weight": 0.8560789835865152,
      "disadvantage_inequity_weight": 0.10979228501922979,
      "fairness_deviation_weight": 1.8372374039307702,
      "success": true,
      "log_likelihood": -14.249136656948956,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.3519742985162902,
      "self_interest_weight": 0.22645372578119727,
      "disadvantage_inequity_weight": 0.14985102562733335,
      "fairness_deviation_weight": 2.074961393689887,
      "success": true,
      "log_likelihood": -22.11677597061196,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 7.514449235652194,
      "self_interest_weight": 0.4725408343012211,
      "disadvantage_inequity_weight": 1.3010801572034925,
      "fairness_deviation_weight": 3.794709958592708,
      "success": true,
      "log_likelihood": -7.072860452071531,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 4.03912930336058,
      "self_interest_weight": 0.09029152346816113,
      "disadvantage_inequity_weight": 0.03344837317590695,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -6.168262548182046,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.0958274631525384,
      "self_interest_weight": 0.19730014337713164,
      "disadvantage_inequity_weight": 0.48962421051054317,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -6.166211290623343,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.312602570972213,
      "self_interest_weight": 0.5220503399765672,
      "disadvantage_inequity_weight": 0.0,
      "fairness_deviation_weight": 0.02269745796655589,
      "success": true,
      "log_likelihood": -21.682967210088613,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -4.057552763016408,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 5.0,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -0.02842254366233011,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.733967272595827,
      "self_interest_weight": 0.17841350909962111,
      "disadvantage_inequity_weight": 0.2597608373955756,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -21.81297446738146,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 3.065588483775971,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.12471850987170373,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -10.106604266277719,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.21193885578411187,
      "self_interest_weight": 0.26025773320767126,
      "disadvantage_inequity_weight": 0.7483280024599926,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -7.210781928223,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.441188495474868,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.7122924548577952,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -5.019455847850044,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.2354650827284535,
      "self_interest_weight": 0.0,
      "disadvantage_inequity_weight": 0.05928941921812353,
      "fairness_deviation_weight": 2.245722423430865,
      "success": true,
      "log_likelihood": -23.29485179926149,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.5380737502283688,
      "self_interest_weight": 1.8672806955359287,
      "disadvantage_inequity_weight": 5.0,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -2.2321371581326885,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 3.334899340415967,
      "self_interest_weight": 0.016302287776398385,
      "disadvantage_inequity_weight": 0.26125384140395813,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -17.171570665881767,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.6953670347725627,
      "self_interest_weight": 0.20057563135248455,
      "disadvantage_inequity_weight": 0.10304828058808685,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -14.029155284036,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 3.3231293647437163,
      "self_interest_weight": 0.567046568432068,
      "disadvantage_inequity_weight": 0.10121466012083685,
      "fairness_deviation_weight": 5.0,
      "success": true,
      "log_likelihood": -5.33425587431549,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.8613523938217655,
      "self_interest_weight": 2.0,
      "disadvantage_inequity_weight": 0.5739096837148167,
      "fairness_deviation_weight": 2.798157237190305,
      "success": true,
      "log_likelihood": -4.8241580913594255,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.5184958629451677,
      "self_interest_weight": 0.13656670782790908,
      "disadvantage_inequity_weight": 0.2233888086820046,
      "fairness_deviation_weight": 0.0,
      "success": true,
      "log_likelihood": -19.96954396689939,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "bias": {
        "r": 0.8365165672228254,
        "p": 2.3815608680813588e-27
      },
      "self_interest_weight": {
        "r": 0.4051799040259572,
        "p": 2.893800508544195e-05
      },
      "disadvantage_inequity_weight": {
        "r": 0.7454449592565476,
        "p": 5.835815512028404e-19
      },
      "fairness_deviation_weight": {
        "r": -0.010703536444340286,
        "p": 0.9158261893180265
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 34.94646026874839,
  "bic_Control": 31.398363101059058,
  "bic_Cocaine": 38.12496398147008,
  "bic_results": {
    "average_bic": 34.94646026874839,
    "individual_bics": [
      14.390920841135575,
      46.690462335060786,
      43.02437145462828,
      41.035284357679934,
      45.14636777860403,
      34.82205815370861,
      14.334114862351512,
      36.181499482414594,
      14.334114862351512,
      41.11689109841443,
      36.77873220252468,
      25.00697402763865,
      37.59842335147327,
      14.334114862351512,
      14.334114862351512,
      14.334114862351512,
      14.334114862351512,
      20.3409153203544,
      27.766241630272724,
      14.334114862351512,
      44.78703446010876,
      29.292409254244376,
      37.223548877396844,
      46.10141796756689,
      46.45034881553819,
      44.58648067158888,
      24.718880605593384,
      34.388673754965055,
      31.67238858983008,
      42.08185439005922,
      14.334114862351512,
      14.390920841135493,
      43.61090566541897,
      38.77215605893387,
      14.334114862351512,
      30.564063068698196,
      32.184549103389784,
      46.774153854865816,
      47.280121648512505,
      29.610534675729653,
      44.175104712985316,
      39.63470774645461,
      22.923182787450017,
      38.38206286424268,
      40.039575034833156,
      43.81394923834881,
      34.43017833440166,
      49.31524548721329,
      44.69773418265157,
      59.49008596289285,
      48.12750098786884,
      28.011595474474554,
      45.073363942848246,
      53.38523106516688,
      52.43630016798109,
      37.66747483558396,
      34.836054823954946,
      39.40623169444025,
      19.594642518527717,
      40.92682670429908,
      51.435380720471514,
      43.43670582138142,
      14.390920841135479,
      50.58671984272982,
      26.21102851422777,
      36.42448383287132,
      27.950308554711334,
      34.50788550894728,
      36.517324516809836,
      32.96949264950986,
      24.419152555327337,
      21.9109693121703,
      44.61022950808677,
      42.83234906772235,
      58.56762769504836,
      28.4797966579675,
      26.67060085018853,
      26.666498335071125,
      57.70001017400166,
      14.3909208411491,
      57.96002468858735,
      34.54728428637988,
      28.75563961027044,
      24.37298744952453,
      60.923779352347424,
      18.798350070089818,
      48.67721708558797,
      42.39238632189644,
      25.00258750245542,
      23.98239193654329,
      54.273163687623224
    ],
    "group_enabled": true,
    "group_bics": {
      "Control": [
        14.390920841135575,
        46.690462335060786,
        43.02437145462828,
        41.035284357679934,
        45.14636777860403,
        34.82205815370861,
        14.334114862351512,
        36.181499482414594,
        14.334114862351512,
        41.11689109841443,
        36.77873220252468,
        25.00697402763865,
        37.59842335147327,
        14.334114862351512,
        14.334114862351512,
        14.334114862351512,
        14.334114862351512,
        20.3409153203544,
        27.766241630272724,
        14.334114862351512,
        44.78703446010876,
        29.292409254244376,
        37.223548877396844,
        46.10141796756689,
        46.45034881553819,
        44.58648067158888,
        24.718880605593384,
        34.388673754965055,
        31.67238858983008,
        42.08185439005922,
        14.334114862351512,
        14.390920841135493,
        43.61090566541897,
        38.77215605893387,
        14.334114862351512,
        30.564063068698196,
        32.184549103389784,
        46.774153854865816,
        47.280121648512505,
        29.610534675729653,
        44.175104712985316,
        39.63470774645461,
        22.923182787450017
      ],
      "Cocaine": [
        38.38206286424268,
        40.039575034833156,
        43.81394923834881,
        34.43017833440166,
        49.31524548721329,
        44.69773418265157,
        59.49008596289285,
        48.12750098786884,
        28.011595474474554,
        45.073363942848246,
        53.38523106516688,
        52.43630016798109,
        37.66747483558396,
        34.836054823954946,
        39.40623169444025,
        19.594642518527717,
        40.92682670429908,
        51.435380720471514,
        43.43670582138142,
        14.390920841135479,
        50.58671984272982,
        26.21102851422777,
        36.42448383287132,
        27.950308554711334,
        34.50788550894728,
        36.517324516809836,
        32.96949264950986,
        24.419152555327337,
        21.9109693121703,
        44.61022950808677,
        42.83234906772235,
        58.56762769504836,
        28.4797966579675,
        26.67060085018853,
        26.666498335071125,
        57.70001017400166,
        14.3909208411491,
        57.96002468858735,
        34.54728428637988,
        28.75563961027044,
        24.37298744952453,
        60.923779352347424,
        18.798350070089818,
        48.67721708558797,
        42.39238632189644,
        25.00258750245542,
        23.98239193654329,
        54.273163687623224
      ]
    },
    "num_parameters": 4,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- bias: r = 0.837\n- self_interest_weight: r = 0.405\n- disadvantage_inequity_weight: r = 0.745\n- fairness_deviation_weight: r = -0.011",
  "previous_models": [
    "Specification: utility = bias + self_interest_weight * split_self - disadvantage_inequity_weight * max(0, split_opp - split_self) - fairness_deviation_weight * abs(splitperc_self/100 - (token_self / (token_self + token_opp)))\nSummary: This model predicts responder accept/reject decisions as a function of four psychological processes: a baseline bias, self-interest in own payoff, disadvantageous inequity aversion (penalizing cases where the responder receives less than the proposer), and sensitivity to deviations from proportional, contribution-based fairness. The model uses nonredundant, dissociable terms: ramped disadvantage aversion, payout proportionality penalty, and linear self-interest\u2014each term corresponding to distinct psychological motivations. All parameters have finite, identifiable ranges, and the structure is designed to maximize both interpretability and recoverability.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 34.94646026874839\nOverall Accuracy: 0.8144\nGroup Accuracies:\n- Control: 0.8514\n- Cocaine: 0.7812\n\nParameter Recovery:\n- bias: r = 0.837\n- self_interest_weight: r = 0.405\n- disadvantage_inequity_weight: r = 0.745\n- fairness_deviation_weight: r = -0.011"
  ]
}