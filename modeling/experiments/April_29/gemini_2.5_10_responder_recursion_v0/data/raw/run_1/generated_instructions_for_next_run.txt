Based on previous attempts, models incorporating simple linear terms for self-interest (based on `split_perc_self`) and disadvantageous inequity (based on the difference between `split_perc_self` and a contribution-based `deserved_perc_self`) have struggled with parameter recovery, particularly in disentangling these two effects.

Your primary goal for this run is to design a model that significantly improves **parameter recovery** (aiming for correlations > 0.7 for *all* learnable parameters) while also maintaining or improving BIC and accuracy compared to a baseline BIC of ~44 and accuracy of ~0.69.

To achieve this, consider the following:

1.  **Rethink Functional Form:** Move beyond simple linear additions. Explore alternative mathematical structures:
    *   Could fairness be better represented by a **ratio** (e.g., `split_perc_self / deserved_perc_self`) instead of a difference? How would you handle division by zero if `deserved_perc_self` is 0?
    *   Are there **non-linear** effects? (e.g., sensitivity to unfairness might increase sharply below a certain threshold, or sensitivity to the offered amount might diminish at higher levels).
    *   Could there be **interaction terms** between the offered amount and the perceived fairness level? Perhaps the weight given to fairness depends on the stakes?
    *   Consider incorporating **absolute amounts** (`split_self`, `combined_earning`) perhaps alongside or instead of percentages, as perceived utility might not scale linearly with percentages alone, especially when `combined_earning` varies significantly.
    *   Explore established decision-making models like **Fehr-Schmidt utility** (which includes terms for *both* disadvantageous and advantageous inequity), but adapt them to use the contribution-based fairness norm (`deserved_perc_self`). Does getting *more* than deserved affect utility?

2.  **Parameter Identifiability:** Focus explicitly on designing a model where the learnable parameters capture distinct psychological processes (e.g., baseline acceptance, pure self-interest, sensitivity to unfairness) in a way that is statistically identifiable, minimizing potential covariance between parameter estimates. Justify *why* your proposed formulation might lead to better disentanglement than previous attempts.

3.  **Alternative Mechanisms:** Think creatively and propose potentially less obvious mechanisms.
    *   Could the 'deserved' amount act as a **reference point** in a prospect theory-like value function, where losses (offers below deserved) loom larger than gains (offers above deserved)?
    *   Could the *relative* contribution (`token_self / token_opp`) directly modulate the sensitivity to the offer, rather than just setting a fairness point?

4.  **Parsimony vs. Performance:** While parsimony (fewer parameters) is generally preferred to avoid overfitting and aid interpretation, prioritize finding a model structure that demonstrably improves parameter recovery for this task. If adding a parameter or complexity *specifically addresses* the identifiability issue and is well-justified psychologically, it may be worthwhile. Aim for a model with 2-4 well-motivated parameters.

Please provide your reasoning step-by-step, focusing on how your proposed model addresses the challenge of parameter disentanglement and aims for better overall performance metrics (lower BIC, higher accuracy, better recovery). Then, provide the model specification following the required format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>).