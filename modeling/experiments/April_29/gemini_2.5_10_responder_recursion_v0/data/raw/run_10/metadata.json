{
  "task_description": "In this ultimatum game experiment, the participant acts as both a proposer and a responsder. They are the proposer 14 times and the responsder 36 times. Each is designated by a trial number in the data set. This gives 50 instances for the learnable parameters to be trained (although really it may rather be 36 or 14 depending on how the computational model should be created). There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent. The rounds are a mixed, with the participant doing a handful of turns as a responder, then a handful as a proposer, and then a handful as a responder, and so on.\n\nAgain, the participant gets to act as both a proposer and responder - this is reflected in the data. If you are guessing the proposed amount, you should only be making this guess when trial_role == 2, since this is when the data within the proposed_perc and proposed_amount columns are relevent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\n2. You will have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n3. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "Okay, here are the instructions for the next run (Run 10):\n\n<instructions>\n**Analysis of Previous Attempt (Run 9):**\nThe prior model attempted to improve parameter recovery by using proportional gain (`split_perc`) combined with a non-linear (logarithmic) transformation of proportional inequity (`log(inequity_perc + epsilon)`). The model specification was: `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`.\n\n*   **Results:**\n    *   BIC: 31.20 (Slightly worse than the previous linear proportional model's 31.01).\n    *   Accuracy: 0.821 (Met the target > 0.82).\n    *   Parameter Recovery: Failed significantly. `bias` recovery was acceptable (r=0.760), but `sensitivity_prop` recovery collapsed (r=0.118) and `alpha_log_ineq_prop` recovery remained poor (r=0.488).\n\n*   **Conclusion:** Introducing logarithmic non-linearity to the *proportional* inequity term did not resolve, and in fact worsened, the parameter identifiability issues, particularly between gain sensitivity and inequity aversion. While accuracy was good, the model is unreliable due to poor parameter recovery.\n\n**Your Goal for Run 10 (Final Run):**\nDevelop a model that achieves **excellent parameter recovery (r > 0.75 for ALL learnable parameters)** as the primary goal. Secondary goals are to maintain **good accuracy (Accuracy > 0.82)** and achieve a **reasonable BIC score (aim for BIC < 33)**. Given the persistent recovery challenges, a slight increase in BIC might be acceptable if recovery targets are met.\n\n**New Direction: Revisit Absolute Values with Interaction**\n\nPrevious attempts with proportional values consistently struggled with recovery for sensitivity and inequity parameters. An earlier model (Run 4) using **absolute values** (`Utility = bias + sensitivity * split_self - alpha_log_ineq * log(inequity_abs + 1)`) showed more promising recovery (`sensitivity`: r=0.787, `alpha_log_ineq`: r=0.670), although it still fell short for the inequity parameter.\n\nThe persistent difficulty in separating gain and inequity effects suggests they might not exert independent influences on utility. Their impact could be **interdependent**. For this final run, let's explicitly model this potential interaction. We will revert to using **absolute monetary values** (which showed better sensitivity recovery previously) and add an **interaction term**. This will result in a 4-parameter model.\n\n**Proposed Model Structure (Primary Focus):**\n\nBuild upon the structure of the promising Run 4 model (absolute gain, log-transformed absolute inequity) by adding an interaction term between the gain (`split_self`) and the log-inequity (`inequity_log`).\n\n1.  **Calculate Intermediate Absolute Terms:**\n    *   `total_tokens = token_self + token_opp`\n    *   `contribution_ratio = (token_self / total_tokens) if total_tokens > 0 else 0.5`\n    *   `deserved_split = contribution_ratio * combined_earning`\n    *   `inequity_abs = max(0, deserved_split - split_self)`\n    *   `inequity_log = log(inequity_abs + 1)` *(Note: using `log(x+1)` avoids issues with log(0))*\n\n2.  **Calculate Utility with Interaction:**\n    *   `Utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log`\n\nThis model uses 4 learnable parameters:\n*   `bias`: Baseline acceptance tendency.\n*   `sensitivity`: Sensitivity to the *absolute amount* offered (`split_self`).\n*   `alpha_log_ineq`: Sensitivity (aversion) to the *logarithm* of absolute disadvantageous inequity (`inequity_log`).\n*   `delta_interaction`: Parameter capturing how the effect of log-inequity is modulated by the absolute amount offered (or vice-versa).\n\n**Emphasis:**\n*   Implement the **4-parameter absolute value model with the specified interaction term** (`delta_interaction * split_self * inequity_log`).\n*   **Parameter recovery (r > 0.75 for ALL parameters)** is the most critical goal for this run.\n*   Justify this approach by referencing the partial success of absolute value models (like Run 4) in terms of recovery compared to proportional models, and the hypothesis that an interaction term is needed to disentangle gain and inequity effects.\n*   Ensure your model uses exactly 4 learnable parameters (`bias`, `sensitivity`, `alpha_log_ineq`, `delta_interaction`).\n*   Define appropriate, generous but finite numerical bounds for all parameters. Note that the `delta_interaction` term could potentially be positive or negative, so its bounds should reflect that (e.g., -10 to 10). Consider the scale of `split_self` and `inequity_log` when setting bounds.\n*   Think outside the box: While the interaction model is the primary focus, if you have a strong alternative rationale for a different 3 or 4-parameter model structure (perhaps using a different transformation or interaction) that you believe is more likely to achieve the recovery goals based on all previous run information, feel free to propose and justify it clearly. However, the proposed interaction model directly addresses the core observed problem.\n\nPlease provide your reasoning step-by-step, justify your chosen model structure by explaining how it addresses the limitations of previous models and aims to meet all performance goals (especially Recovery), and detail the model specification in the required format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>).\n</instructions>",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In this ultimatum game experiment, the participant acts as both a proposer and a responsder. They are the proposer 14 times and the responsder 36 times. Each is designated by a trial number in the data set. This gives 50 instances for the learnable parameters to be trained (although really it may rather be 36 or 14 depending on how the computational model should be created). There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent. The rounds are a mixed, with the participant doing a handful of turns as a responder, then a handful as a proposer, and then a handful as a responder, and so on.\n\nAgain, the participant gets to act as both a proposer and responder - this is reflected in the data. If you are guessing the proposed amount, you should only be making this guess when trial_role == 2, since this is when the data within the proposed_perc and proposed_amount columns are relevent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\n2. You will have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n3. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: Okay, here are the instructions for the next run (Run 10):\n\n<instructions>\n**Analysis of Previous Attempt (Run 9):**\nThe prior model attempted to improve parameter recovery by using proportional gain (`split_perc`) combined with a non-linear (logarithmic) transformation of proportional inequity (`log(inequity_perc + epsilon)`). The model specification was: `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`.\n\n*   **Results:**\n    *   BIC: 31.20 (Slightly worse than the previous linear proportional model's 31.01).\n    *   Accuracy: 0.821 (Met the target > 0.82).\n    *   Parameter Recovery: Failed significantly. `bias` recovery was acceptable (r=0.760), but `sensitivity_prop` recovery collapsed (r=0.118) and `alpha_log_ineq_prop` recovery remained poor (r=0.488).\n\n*   **Conclusion:** Introducing logarithmic non-linearity to the *proportional* inequity term did not resolve, and in fact worsened, the parameter identifiability issues, particularly between gain sensitivity and inequity aversion. While accuracy was good, the model is unreliable due to poor parameter recovery.\n\n**Your Goal for Run 10 (Final Run):**\nDevelop a model that achieves **excellent parameter recovery (r > 0.75 for ALL learnable parameters)** as the primary goal. Secondary goals are to maintain **good accuracy (Accuracy > 0.82)** and achieve a **reasonable BIC score (aim for BIC < 33)**. Given the persistent recovery challenges, a slight increase in BIC might be acceptable if recovery targets are met.\n\n**New Direction: Revisit Absolute Values with Interaction**\n\nPrevious attempts with proportional values consistently struggled with recovery for sensitivity and inequity parameters. An earlier model (Run 4) using **absolute values** (`Utility = bias + sensitivity * split_self - alpha_log_ineq * log(inequity_abs + 1)`) showed more promising recovery (`sensitivity`: r=0.787, `alpha_log_ineq`: r=0.670), although it still fell short for the inequity parameter.\n\nThe persistent difficulty in separating gain and inequity effects suggests they might not exert independent influences on utility. Their impact could be **interdependent**. For this final run, let's explicitly model this potential interaction. We will revert to using **absolute monetary values** (which showed better sensitivity recovery previously) and add an **interaction term**. This will result in a 4-parameter model.\n\n**Proposed Model Structure (Primary Focus):**\n\nBuild upon the structure of the promising Run 4 model (absolute gain, log-transformed absolute inequity) by adding an interaction term between the gain (`split_self`) and the log-inequity (`inequity_log`).\n\n1.  **Calculate Intermediate Absolute Terms:**\n    *   `total_tokens = token_self + token_opp`\n    *   `contribution_ratio = (token_self / total_tokens) if total_tokens > 0 else 0.5`\n    *   `deserved_split = contribution_ratio * combined_earning`\n    *   `inequity_abs = max(0, deserved_split - split_self)`\n    *   `inequity_log = log(inequity_abs + 1)` *(Note: using `log(x+1)` avoids issues with log(0))*\n\n2.  **Calculate Utility with Interaction:**\n    *   `Utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log`\n\nThis model uses 4 learnable parameters:\n*   `bias`: Baseline acceptance tendency.\n*   `sensitivity`: Sensitivity to the *absolute amount* offered (`split_self`).\n*   `alpha_log_ineq`: Sensitivity (aversion) to the *logarithm* of absolute disadvantageous inequity (`inequity_log`).\n*   `delta_interaction`: Parameter capturing how the effect of log-inequity is modulated by the absolute amount offered (or vice-versa).\n\n**Emphasis:**\n*   Implement the **4-parameter absolute value model with the specified interaction term** (`delta_interaction * split_self * inequity_log`).\n*   **Parameter recovery (r > 0.75 for ALL parameters)** is the most critical goal for this run.\n*   Justify this approach by referencing the partial success of absolute value models (like Run 4) in terms of recovery compared to proportional models, and the hypothesis that an interaction term is needed to disentangle gain and inequity effects.\n*   Ensure your model uses exactly 4 learnable parameters (`bias`, `sensitivity`, `alpha_log_ineq`, `delta_interaction`).\n*   Define appropriate, generous but finite numerical bounds for all parameters. Note that the `delta_interaction` term could potentially be positive or negative, so its bounds should reflect that (e.g., -10 to 10). Consider the scale of `split_self` and `inequity_log` when setting bounds.\n*   Think outside the box: While the interaction model is the primary focus, if you have a strong alternative rationale for a different 3 or 4-parameter model structure (perhaps using a different transformation or interaction) that you believe is more likely to achieve the recovery goals based on all previous run information, feel free to propose and justify it clearly. However, the proposed interaction model directly addresses the core observed problem.\n\nPlease provide your reasoning step-by-step, justify your chosen model structure by explaining how it addresses the limitations of previous models and aims to meet all performance goals (especially Recovery), and detail the model specification in the required format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>).\n</instructions>\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Okay, let's formulate the model step-by-step.\n\n**1. Reasoning and Justification:**\n\n*   **Goal:** Develop a model predicting responder acceptance (`accept`) in an Ultimatum Game variant, prioritizing parameter recovery (all r > 0.75), while maintaining accuracy (> 0.82) and reasonable BIC (< 33).\n*   **Problem:** Previous models, especially those using proportional values, suffered from poor parameter recovery, specifically in distinguishing the effects of gain sensitivity and inequity aversion.\n*   **Learning from Past Runs:**\n    *   Proportional models (e.g., Run 9) had poor recovery.\n    *   An absolute value model with log-transformed inequity (Run 4: `Utility = bias + sensitivity * split_self - alpha_log_ineq * log(inequity_abs + 1)`) showed better, but still imperfect, recovery (`sensitivity` r=0.787, `alpha_log_ineq` r=0.670). This suggests absolute values might be more identifiable.\n    *   The persistent difficulty points towards interdependence between gain and inequity effects. They might not influence utility additively and independently.\n*   **Proposed Solution (Run 10):**\n    1.  **Revert to Absolute Values:** Use `split_self` (absolute gain) and `inequity_abs` (absolute disadvantageous inequity) based on the partial success of Run 4. Use the `log(inequity_abs + 1)` transformation for inequity as in Run 4 to handle non-linearity and zero values.\n    2.  **Introduce Interaction Term:** Add a term `delta_interaction * split_self * inequity_log`. This explicitly models the hypothesis that the perceived utility/disutility of inequity (`inequity_log`) might depend on the magnitude of the offer (`split_self`), or conversely, that the utility of the gain (`split_self`) is modulated by the level of perceived unfairness (`inequity_log`). Adding this interaction term might allow the model fitting process to better disentangle the main effects of gain (`sensitivity`) and inequity aversion (`alpha_log_ineq`), hopefully leading to improved recovery for all parameters.\n*   **Model Structure:** `Utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log`. This uses 4 learnable parameters (`bias`, `sensitivity`, `alpha_log_ineq`, `delta_interaction`).\n*   **Parameter Bounds:** Set generous but finite bounds, ensuring parameters like `sensitivity` and `alpha_log_ineq` are non-negative (reflecting gain seeking and inequity aversion), while `bias` and `delta_interaction` can be positive or negative.\n\n**2. Model Specification:**\n\n<MODEL>\ntotal_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"The calculated utility of accepting the offer.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency to accept the offer, independent of offer characteristics.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity\": {\n      \"description\": \"Sensitivity to the absolute monetary amount offered to the participant ('split_self'). Higher values indicate greater utility gain per unit of money offered.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of absolute disadvantageous inequity ('inequity_log'). Higher values indicate stronger aversion to receiving less than the deserved amount.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"delta_interaction\": {\n        \"description\": \"Parameter capturing the interaction effect between the absolute offer ('split_self') and the log-transformed absolute inequity ('inequity_log'). Modulates how the effect of inequity changes with the offer size (or vice-versa).\",\n        \"range\": {\n            \"min\": -5.0,\n            \"max\": 5.0,\n            \"inclusive_min\": true,\n            \"inclusive_max\": true\n        },\n        \"learnable\": true,\n        \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \u00a3).\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial (in \u00a3).\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n      \"description\": \"Sum of tokens found by participant and opponent.\",\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n      \"description\": \"Participant's share of total tokens contributed.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"deserved_split\": {\n      \"description\": \"The split amount the participant 'deserves' based purely on their contribution ratio.\",\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_abs\": {\n      \"description\": \"Absolute amount of disadvantageous inequity (how much less the participant received than their deserved split). Capped at 0.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_log\": {\n      \"description\": \"Logarithm of (absolute disadvantageous inequity + 1). Used to capture non-linear aversion to inequity and handle zero inequity.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model predicting responder acceptance based on absolute monetary values. Utility is determined by a baseline acceptance tendency (`bias`), sensitivity to the absolute amount offered (`sensitivity`), aversion to the logarithm of absolute disadvantageous inequity (`alpha_log_ineq`), and an interaction term (`delta_interaction`) capturing the interdependence between the offered amount and the log-inequity. It includes 4 learnable parameters. The model uses absolute values and an interaction term specifically to address parameter recovery issues observed in previous models.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['bias', 'sensitivity', 'alpha_log_ineq', 'delta_interaction']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"The calculated utility of accepting the offer.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency to accept the offer, independent of offer characteristics.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity\": {\n      \"description\": \"Sensitivity to the absolute monetary amount offered to the participant ('split_self'). Higher values indicate greater utility gain per unit of money offered.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of absolute disadvantageous inequity ('inequity_log'). Higher values indicate stronger aversion to receiving less than the deserved amount.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"delta_interaction\": {\n      \"description\": \"Parameter capturing the interaction effect between the absolute offer ('split_self') and the log-transformed absolute inequity ('inequity_log'). Modulates how the effect of inequity changes with the offer size (or vice-versa).\",\n      \"range\": {\n        \"min\": -5.0,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \\u00a3).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial (in \\u00a3).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n      \"description\": \"Sum of tokens found by participant and opponent.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n      \"description\": \"Participant's share of total tokens contributed.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"deserved_split\": {\n      \"description\": \"The split amount the participant 'deserves' based purely on their contribution ratio.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_abs\": {\n      \"description\": \"Absolute amount of disadvantageous inequity (how much less the participant received than their deserved split). Capped at 0.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_log\": {\n      \"description\": \"Logarithm of (absolute disadvantageous inequity + 1). Used to capture non-linear aversion to inequity and handle zero inequity.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, bias=0, sensitivity=1, alpha_log_ineq=1, delta_interaction=0):\n    \"\"\"\n    Simulates the utility model for each trial in the provided dataset.\n\n    Args:\n        trial_data (list of dict): A list of dictionaries, where each dictionary\n            represents a trial and contains the necessary data (token_self,\n            token_opp, combined_earning, split_self).\n        bias (float): Baseline tendency to accept the offer.\n        sensitivity (float): Sensitivity to the absolute monetary amount offered.\n        alpha_log_ineq (float): Sensitivity to the logarithm of absolute disadvantageous inequity.\n        delta_interaction (float): Interaction effect between the offer and the log-transformed inequity.\n\n    Returns:\n        list of float: A list of utility predictions for each trial.\n    \"\"\"\n\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n\n        total_tokens = token_self + token_opp\n        contribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\n        deserved_split = contribution_ratio * combined_earning\n        inequity_abs = max(0, deserved_split - split_self)\n        inequity_log = math.log(inequity_abs + 1)\n        utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\n\n        model_predictions.append(utility)\n\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n",
      "timestamp": 1745950288.6413949
    }
  ],
  "learnable_parameters": {
    "bias": {
      "description": "Baseline tendency to accept the offer, independent of offer characteristics.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sensitivity": {
      "description": "Sensitivity to the absolute monetary amount offered to the participant ('split_self'). Higher values indicate greater utility gain per unit of money offered.",
      "range": {
        "min": 0.0,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_log_ineq": {
      "description": "Sensitivity (aversion) to the logarithm of absolute disadvantageous inequity ('inequity_log'). Higher values indicate stronger aversion to receiving less than the deserved amount.",
      "range": {
        "min": 0.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "delta_interaction": {
      "description": "Parameter capturing the interaction effect between the absolute offer ('split_self') and the log-transformed absolute inequity ('inequity_log'). Modulates how the effect of inequity changes with the offer size (or vice-versa).",
      "range": {
        "min": -5.0,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log",
  "variable_descriptions": {
    "Utility": {
      "description": "The calculated utility of accepting the offer.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": false,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "bias": {
      "description": "Baseline tendency to accept the offer, independent of offer characteristics.",
      "range": {
        "min": -10.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sensitivity": {
      "description": "Sensitivity to the absolute monetary amount offered to the participant ('split_self'). Higher values indicate greater utility gain per unit of money offered.",
      "range": {
        "min": 0.0,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_log_ineq": {
      "description": "Sensitivity (aversion) to the logarithm of absolute disadvantageous inequity ('inequity_log'). Higher values indicate stronger aversion to receiving less than the deserved amount.",
      "range": {
        "min": 0.0,
        "max": 10.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "delta_interaction": {
      "description": "Parameter capturing the interaction effect between the absolute offer ('split_self') and the log-transformed absolute inequity ('inequity_log'). Modulates how the effect of inequity changes with the offer size (or vice-versa).",
      "range": {
        "min": -5.0,
        "max": 5.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "The proposed share for the participant (in \u00a3).",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by the participant.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by the opponent.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "Amount of money earned in total for the trial (in \u00a3).",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "total_tokens": {
      "description": "Sum of tokens found by participant and opponent.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "contribution_ratio": {
      "description": "Participant's share of total tokens contributed.",
      "range": {
        "min": 0.0,
        "max": 1.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "deserved_split": {
      "description": "The split amount the participant 'deserves' based purely on their contribution ratio.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "inequity_abs": {
      "description": "Absolute amount of disadvantageous inequity (how much less the participant received than their deserved split). Capped at 0.",
      "range": {
        "min": 0.0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "inequity_log": {
      "description": "Logarithm of (absolute disadvantageous inequity + 1). Used to capture non-linear aversion to inequity and handle zero inequity.",
      "range": {
        "min": 0.0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    }
  },
  "model_summary": "A utility model predicting responder acceptance based on absolute monetary values. Utility is determined by a baseline acceptance tendency (`bias`), sensitivity to the absolute amount offered (`sensitivity`), aversion to the logarithm of absolute disadvantageous inequity (`alpha_log_ineq`), and an interaction term (`delta_interaction`) capturing the interdependence between the offered amount and the log-inequity. It includes 4 learnable parameters. The model uses absolute values and an interaction term specifically to address parameter recovery issues observed in previous models.",
  "target_variable": "accept",
  "full_reasoning": "Okay, let's formulate the model step-by-step.\n\n**1. Reasoning and Justification:**\n\n*   **Goal:** Develop a model predicting responder acceptance (`accept`) in an Ultimatum Game variant, prioritizing parameter recovery (all r > 0.75), while maintaining accuracy (> 0.82) and reasonable BIC (< 33).\n*   **Problem:** Previous models, especially those using proportional values, suffered from poor parameter recovery, specifically in distinguishing the effects of gain sensitivity and inequity aversion.\n*   **Learning from Past Runs:**\n    *   Proportional models (e.g., Run 9) had poor recovery.\n    *   An absolute value model with log-transformed inequity (Run 4: `Utility = bias + sensitivity * split_self - alpha_log_ineq * log(inequity_abs + 1)`) showed better, but still imperfect, recovery (`sensitivity` r=0.787, `alpha_log_ineq` r=0.670). This suggests absolute values might be more identifiable.\n    *   The persistent difficulty points towards interdependence between gain and inequity effects. They might not influence utility additively and independently.\n*   **Proposed Solution (Run 10):**\n    1.  **Revert to Absolute Values:** Use `split_self` (absolute gain) and `inequity_abs` (absolute disadvantageous inequity) based on the partial success of Run 4. Use the `log(inequity_abs + 1)` transformation for inequity as in Run 4 to handle non-linearity and zero values.\n    2.  **Introduce Interaction Term:** Add a term `delta_interaction * split_self * inequity_log`. This explicitly models the hypothesis that the perceived utility/disutility of inequity (`inequity_log`) might depend on the magnitude of the offer (`split_self`), or conversely, that the utility of the gain (`split_self`) is modulated by the level of perceived unfairness (`inequity_log`). Adding this interaction term might allow the model fitting process to better disentangle the main effects of gain (`sensitivity`) and inequity aversion (`alpha_log_ineq`), hopefully leading to improved recovery for all parameters.\n*   **Model Structure:** `Utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log`. This uses 4 learnable parameters (`bias`, `sensitivity`, `alpha_log_ineq`, `delta_interaction`).\n*   **Parameter Bounds:** Set generous but finite bounds, ensuring parameters like `sensitivity` and `alpha_log_ineq` are non-negative (reflecting gain seeking and inequity aversion), while `bias` and `delta_interaction` can be positive or negative.\n\n**2. Model Specification:**\n\n<MODEL>\ntotal_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"The calculated utility of accepting the offer.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency to accept the offer, independent of offer characteristics.\",\n      \"range\": {\n        \"min\": -10.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity\": {\n      \"description\": \"Sensitivity to the absolute monetary amount offered to the participant ('split_self'). Higher values indicate greater utility gain per unit of money offered.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of absolute disadvantageous inequity ('inequity_log'). Higher values indicate stronger aversion to receiving less than the deserved amount.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"delta_interaction\": {\n        \"description\": \"Parameter capturing the interaction effect between the absolute offer ('split_self') and the log-transformed absolute inequity ('inequity_log'). Modulates how the effect of inequity changes with the offer size (or vice-versa).\",\n        \"range\": {\n            \"min\": -5.0,\n            \"max\": 5.0,\n            \"inclusive_min\": true,\n            \"inclusive_max\": true\n        },\n        \"learnable\": true,\n        \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \u00a3).\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial (in \u00a3).\",\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n      \"description\": \"Sum of tokens found by participant and opponent.\",\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n      \"description\": \"Participant's share of total tokens contributed.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"deserved_split\": {\n      \"description\": \"The split amount the participant 'deserves' based purely on their contribution ratio.\",\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_abs\": {\n      \"description\": \"Absolute amount of disadvantageous inequity (how much less the participant received than their deserved split). Capped at 0.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_log\": {\n      \"description\": \"Logarithm of (absolute disadvantageous inequity + 1). Used to capture non-linear aversion to inequity and handle zero inequity.\",\n      \"range\": {\n        \"min\": 0.0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model predicting responder acceptance based on absolute monetary values. Utility is determined by a baseline acceptance tendency (`bias`), sensitivity to the absolute amount offered (`sensitivity`), aversion to the logarithm of absolute disadvantageous inequity (`alpha_log_ineq`), and an interaction term (`delta_interaction`) capturing the interdependence between the offered amount and the log-inequity. It includes 4 learnable parameters. The model uses absolute values and an interaction term specifically to address parameter recovery issues observed in previous models.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\nSummary: A utility model predicting responder acceptance based on absolute monetary values. Utility is determined by a baseline acceptance tendency (`bias`), sensitivity to the absolute amount offered (`sensitivity`), aversion to the logarithm of absolute disadvantageous inequity (`alpha_log_ineq`), and an interaction term (`delta_interaction`) capturing the interdependence between the offered amount and the log-inequity. It includes 4 learnable parameters. The model uses absolute values and an interaction term specifically to address parameter recovery issues observed in previous models.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, bias=0, sensitivity=1, alpha_log_ineq=1, delta_interaction=0):\n    \"\"\"\n    Simulates the utility model for each trial in the provided dataset.\n\n    Args:\n        trial_data (list of dict): A list of dictionaries, where each dictionary\n            represents a trial and contains the necessary data (token_self,\n            token_opp, combined_earning, split_self).\n        bias (float): Baseline tendency to accept the offer.\n        sensitivity (float): Sensitivity to the absolute monetary amount offered.\n        alpha_log_ineq (float): Sensitivity to the logarithm of absolute disadvantageous inequity.\n        delta_interaction (float): Interaction effect between the offer and the log-transformed inequity.\n\n    Returns:\n        list of float: A list of utility predictions for each trial.\n    \"\"\"\n\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n\n        total_tokens = token_self + token_opp\n        contribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\n        deserved_split = contribution_ratio * combined_earning\n        inequity_abs = max(0, deserved_split - split_self)\n        inequity_log = math.log(inequity_abs + 1)\n        utility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\n\n        model_predictions.append(utility)\n\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.8192918192918193,
  "group_accuracies": {
    "Control": 0.8727390180878553,
    "Cocaine": 0.771412037037037
  },
  "group_parameter_averages": {
    "Control": {
      "bias": 2.6466987182778743,
      "sensitivity": 2.475063359803363,
      "alpha_log_ineq": 2.8409955974402297,
      "delta_interaction": 0.8243625407964669
    },
    "Cocaine": {
      "bias": -0.8857656896080551,
      "sensitivity": 1.2344912340961602,
      "alpha_log_ineq": 1.9681196991991152,
      "delta_interaction": -0.25475291788903187
    }
  },
  "fitting_results": [
    {
      "bias": -3.9419219635529643,
      "sensitivity": 0.6754351181648773,
      "alpha_log_ineq": 1.988386218683816,
      "delta_interaction": 0.0016722731160572469,
      "success": true,
      "log_likelihood": -6.1869148310743745,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.0653503956717056,
      "sensitivity": 0.4390502692597871,
      "alpha_log_ineq": 3.639377152808173,
      "delta_interaction": 0.1216335310605545,
      "success": true,
      "log_likelihood": -14.950267147736804,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.6613459495863009,
      "sensitivity": 2.115962140206454,
      "alpha_log_ineq": 3.8035194829874426,
      "delta_interaction": -0.7798309147173246,
      "success": true,
      "log_likelihood": -9.55719878961176,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -5.175642794407415,
      "sensitivity": 2.4423409538860996,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.9842299699369346,
      "success": true,
      "log_likelihood": -12.07557224439467,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -1.7717894084748045,
      "sensitivity": 3.0130617186016724,
      "alpha_log_ineq": 0.4280980927406918,
      "delta_interaction": -2.1392957704946984,
      "success": true,
      "log_likelihood": -7.878259047527197,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.0621282564695735,
      "sensitivity": 1.0786938062106985,
      "alpha_log_ineq": 4.631658147842745,
      "delta_interaction": -0.04067125001583837,
      "success": true,
      "log_likelihood": -10.961185319418055,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.3477747239230056e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -2.6337705846006605,
      "sensitivity": 4.369265867669374,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -2.4192648290569903,
      "success": true,
      "log_likelihood": -9.844234797266889,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 6.074368251620683,
      "sensitivity": 5.0,
      "alpha_log_ineq": 1.060397280340037,
      "delta_interaction": 3.5481107917067254,
      "success": true,
      "log_likelihood": -2.4047505868771406e-07,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 5.316591834012594,
      "sensitivity": 0.0,
      "alpha_log_ineq": 10.0,
      "delta_interaction": 1.0890726447991461,
      "success": true,
      "log_likelihood": -8.57279790714984,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -0.5132186230703766,
      "sensitivity": 5.0,
      "alpha_log_ineq": 10.0,
      "delta_interaction": -1.5642693727879737,
      "success": true,
      "log_likelihood": -1.994529387999864,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -3.7997837393366627,
      "sensitivity": 0.7554345092875547,
      "alpha_log_ineq": 2.808391112474152,
      "delta_interaction": 0.18071821725665707,
      "success": true,
      "log_likelihood": -7.3620245758622955,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.325900360366972,
      "sensitivity": 4.033821372514687,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -2.5856308368062555,
      "success": true,
      "log_likelihood": -6.374898028271766,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 9.952646227723495,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.3355433968592218e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.347774723923005e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.3477747239230056e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.3477747239230056e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -1.5382726921431065,
      "sensitivity": 5.0,
      "alpha_log_ineq": 10.0,
      "delta_interaction": 2.399645898159468,
      "success": true,
      "log_likelihood": -0.39841225718208684,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 6.664463695346224,
      "sensitivity": 3.3941689754032955,
      "alpha_log_ineq": 4.824454791640807,
      "delta_interaction": -1.4272769124380658,
      "success": true,
      "log_likelihood": -5.02965139361047,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.347774723923005e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.382751368249078,
      "sensitivity": 1.1842756113004986,
      "alpha_log_ineq": 2.9626289363719867,
      "delta_interaction": -0.6161302168771279,
      "success": true,
      "log_likelihood": -12.313937800641257,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 0.137311708883881,
      "alpha_log_ineq": 7.100509368605637,
      "delta_interaction": 0.48684014375654633,
      "success": true,
      "log_likelihood": -6.797844291974275,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -0.9715569244881561,
      "sensitivity": 0.4728866529406521,
      "alpha_log_ineq": 3.6068618051862917,
      "delta_interaction": 0.582760195562499,
      "success": true,
      "log_likelihood": -15.184289853703191,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -3.0776574436812147,
      "sensitivity": 1.8889112880986971,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.8080507320754148,
      "success": true,
      "log_likelihood": -15.468658736640911,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.8423389246766841,
      "sensitivity": 1.825136604091299,
      "alpha_log_ineq": 1.5992788607170836,
      "delta_interaction": -1.5527640894358625,
      "success": true,
      "log_likelihood": -9.436545495222584,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.742910388951342,
      "sensitivity": 1.164124149661539,
      "alpha_log_ineq": 2.8932240101352615,
      "delta_interaction": -0.20643402573737124,
      "success": true,
      "log_likelihood": -13.406820504521434,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.699973572846592,
      "sensitivity": 3.4882401087402086,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.6085171538585281,
      "success": true,
      "log_likelihood": -10.511387288910083,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.9044088749889865,
      "sensitivity": 1.5041514082396599,
      "alpha_log_ineq": 10.0,
      "delta_interaction": -0.16186566809509495,
      "success": true,
      "log_likelihood": -3.7178259363697563,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 5.757260648365423,
      "sensitivity": 1.1993783159144034,
      "alpha_log_ineq": 3.428801576659987,
      "delta_interaction": -0.48230748001162693,
      "success": true,
      "log_likelihood": -7.740483599049602,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.6213637483396335,
      "sensitivity": 0.3968123724928048,
      "alpha_log_ineq": 2.9876146149593117,
      "delta_interaction": -0.14299091804831995,
      "success": true,
      "log_likelihood": -13.3072147814209,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.3477747239230056e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -3.9417257914063772,
      "sensitivity": 0.6753857249595062,
      "alpha_log_ineq": 1.9891662711942513,
      "delta_interaction": 0.0018413208875877021,
      "success": true,
      "log_likelihood": -6.186914851972191,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 0.324855419260386,
      "sensitivity": 0.09926617890354632,
      "alpha_log_ineq": 3.49651598446492,
      "delta_interaction": 0.7027349410592538,
      "success": true,
      "log_likelihood": -18.22808993462277,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.9793347797192533,
      "sensitivity": 0.0,
      "alpha_log_ineq": 7.734467180902209,
      "delta_interaction": 1.0991361633875172,
      "success": true,
      "log_likelihood": -12.125004945786293,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": 3.347774723923006e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.754234813869871,
      "sensitivity": 2.564030545272694,
      "alpha_log_ineq": 1.948524207919809,
      "delta_interaction": -0.006704022190759378,
      "success": true,
      "log_likelihood": -9.24934077028127,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.623321414138393,
      "sensitivity": 1.6957277286824304,
      "alpha_log_ineq": 6.573918512190109,
      "delta_interaction": 0.17358049067895756,
      "success": true,
      "log_likelihood": -7.400757893718761,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -0.0992590633727594,
      "sensitivity": 1.6097735610506336,
      "alpha_log_ineq": 1.3410815100697369,
      "delta_interaction": -0.9581396063779055,
      "success": true,
      "log_likelihood": -12.84386931103683,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 2.4425910573891563,
      "sensitivity": 0.7326070809776789,
      "alpha_log_ineq": 2.0370618918867383,
      "delta_interaction": -0.38248863504605163,
      "success": true,
      "log_likelihood": -15.617587986507552,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.0336626212666193,
      "sensitivity": 2.489538582231052,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.3943220721678748,
      "success": true,
      "log_likelihood": -7.588092306429914,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.8169906090281094,
      "sensitivity": 0.9829321178989352,
      "alpha_log_ineq": 1.630023851435012,
      "delta_interaction": -0.6357725041080805,
      "success": true,
      "log_likelihood": -15.23810177384895,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.7840681967628953,
      "sensitivity": 0.0,
      "alpha_log_ineq": 7.648849827713665,
      "delta_interaction": 0.9567996231012027,
      "success": true,
      "log_likelihood": -10.082076779600456,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 5.0,
      "success": true,
      "log_likelihood": -23.025850926692705,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 1.3270290695490525,
      "sensitivity": 0.4113015856072703,
      "alpha_log_ineq": 3.5864584686886882,
      "delta_interaction": 0.4000411604455156,
      "success": true,
      "log_likelihood": -15.541419295703351,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.77352843647026,
      "sensitivity": 0.7983953374067859,
      "alpha_log_ineq": 3.7608162285025433,
      "delta_interaction": 0.14043206846047085,
      "success": true,
      "log_likelihood": -13.11758879864978,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.3616704631754444,
      "sensitivity": 1.4990241659205468,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.33785103655886417,
      "success": true,
      "log_likelihood": -15.075432834456402,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.59248052622799,
      "sensitivity": 2.1329227461003324,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.113614204530799,
      "success": true,
      "log_likelihood": -14.364190786782045,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.0447346624390745,
      "sensitivity": 0.6568526382064775,
      "alpha_log_ineq": 2.0838372022573046,
      "delta_interaction": 0.08854818587576178,
      "success": true,
      "log_likelihood": -16.736889217935378,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 6.156532592762138,
      "sensitivity": 0.04891821676047139,
      "alpha_log_ineq": 5.6911714558743896,
      "delta_interaction": -0.19951246105134363,
      "success": true,
      "log_likelihood": -8.400524573302755,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.4385115678102027,
      "sensitivity": 0.568731430361769,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.1180556339951591,
      "success": true,
      "log_likelihood": -22.436073200751704,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.2089074857164704,
      "sensitivity": 0.7414730308958831,
      "alpha_log_ineq": 1.096466650628355,
      "delta_interaction": -0.12048349749431023,
      "success": true,
      "log_likelihood": -17.466920288271222,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.8671988421420693,
      "sensitivity": 0.3075863434493178,
      "alpha_log_ineq": 2.9431289215363345,
      "delta_interaction": 0.3827316192894352,
      "success": true,
      "log_likelihood": -11.195508505171196,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.5544167202016215,
      "sensitivity": 0.0,
      "alpha_log_ineq": 4.878018491777972,
      "delta_interaction": 1.0449185791439584,
      "success": true,
      "log_likelihood": -15.804668413052433,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.008326164990979,
      "sensitivity": 0.6699358561993561,
      "alpha_log_ineq": 0.3267124284092344,
      "delta_interaction": 0.1307352529011473,
      "success": true,
      "log_likelihood": -19.729085346603462,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.1871760611323772,
      "sensitivity": 0.19094309963427644,
      "alpha_log_ineq": 1.5795710739293392,
      "delta_interaction": -0.20070095168733643,
      "success": true,
      "log_likelihood": -17.93627457170548,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.710833015332525,
      "sensitivity": 5.0,
      "alpha_log_ineq": 0.5324143416619178,
      "delta_interaction": -2.9781215100413343,
      "success": true,
      "log_likelihood": -3.869178352300745,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.4131387444847009,
      "sensitivity": 0.7538750839433834,
      "alpha_log_ineq": 3.2569271490257066,
      "delta_interaction": -0.13662333256211723,
      "success": true,
      "log_likelihood": -10.588874805122677,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.318814485424956,
      "sensitivity": 0.023802668769452123,
      "alpha_log_ineq": 0.0,
      "delta_interaction": 0.2249479826680946,
      "success": true,
      "log_likelihood": -12.10183732360836,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.619043406545674,
      "sensitivity": 0.6720193042777368,
      "alpha_log_ineq": 2.158712866762331,
      "delta_interaction": 0.11374426830899914,
      "success": true,
      "log_likelihood": -8.123180327137197,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.4626876400210929,
      "sensitivity": 1.6083583666065235,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.4941522991569476,
      "success": true,
      "log_likelihood": -13.088116269859745,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.038014566593431,
      "sensitivity": 1.2108291072418353,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.644335392537273,
      "success": true,
      "log_likelihood": -18.522488261109164,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.7959550429241788,
      "sensitivity": 2.3926597944853873,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.566401726457415,
      "success": true,
      "log_likelihood": -11.95749170913855,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.9427074749219253,
      "sensitivity": 0.6756194809837719,
      "alpha_log_ineq": 1.9878426074157496,
      "delta_interaction": 0.0015662888526380158,
      "success": true,
      "log_likelihood": -6.186914899276374,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.08316801241588799,
      "sensitivity": 0.15832783567729744,
      "alpha_log_ineq": 3.180230637488035,
      "delta_interaction": 0.6687315969367679,
      "success": true,
      "log_likelihood": -18.376339364257205,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.10713004039941673,
      "sensitivity": 0.4907252666601402,
      "alpha_log_ineq": 8.857250733290892,
      "delta_interaction": 1.1465095428798437,
      "success": true,
      "log_likelihood": -8.526693161066909,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -4.202240585414263,
      "sensitivity": 2.812351714815355,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.2100151560094556,
      "success": true,
      "log_likelihood": -12.220276691011398,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.2900857330711586,
      "sensitivity": 3.3786624382142394,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -1.7494140120274564,
      "success": true,
      "log_likelihood": -6.753849650069598,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 6.7348712949341465,
      "sensitivity": 0.0,
      "alpha_log_ineq": 4.185954305680475,
      "delta_interaction": 0.23702286954336016,
      "success": true,
      "log_likelihood": -9.90917542222754,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.365003876260207,
      "sensitivity": 0.47597878493568363,
      "alpha_log_ineq": 5.6576177021854575,
      "delta_interaction": 1.225209743522851,
      "success": true,
      "log_likelihood": -11.483578418157494,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 5.014544282672533,
      "sensitivity": 0.4687514027010387,
      "alpha_log_ineq": 1.645900117771436,
      "delta_interaction": -0.36267600516768417,
      "success": true,
      "log_likelihood": -9.543322554766567,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity": 4.085590460717418,
      "alpha_log_ineq": 10.0,
      "delta_interaction": -5.0,
      "success": true,
      "log_likelihood": -0.021276056597059816,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.6790885719972284,
      "sensitivity": 0.678504098979211,
      "alpha_log_ineq": 0.508680389886922,
      "delta_interaction": -0.13791035999030393,
      "success": true,
      "log_likelihood": -10.945576911417502,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.922537003538058,
      "sensitivity": 1.9747459103937686,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.912634698927045,
      "success": true,
      "log_likelihood": -15.124236672106456,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.688941619070804,
      "sensitivity": 1.3485240483272192,
      "alpha_log_ineq": 0.02497587184169284,
      "delta_interaction": -0.2880584488995307,
      "success": true,
      "log_likelihood": -14.34882722738168,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.1580337470655402,
      "sensitivity": 0.6388169133775892,
      "alpha_log_ineq": 0.017565861287521675,
      "delta_interaction": -0.2842312808963074,
      "success": true,
      "log_likelihood": -21.901110553928934,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.06848334689781078,
      "sensitivity": 2.2985427590660428,
      "alpha_log_ineq": 0.986213535952115,
      "delta_interaction": -1.2308686662776414,
      "success": true,
      "log_likelihood": -12.594952080864646,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 2.182381768309032,
      "sensitivity": 3.3873931456316435,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -2.057185892304574,
      "success": true,
      "log_likelihood": -5.2333229747156205,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.1556360987669216,
      "sensitivity": 0.23845580433903768,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.8781967537910099,
      "success": true,
      "log_likelihood": -5.311416145398489,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.198125731525601,
      "sensitivity": 0.8127365813937465,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.288092755473471,
      "success": true,
      "log_likelihood": -20.65038790530814,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.9421896223411323,
      "sensitivity": 0.6754588874977954,
      "alpha_log_ineq": 1.9884693639748698,
      "delta_interaction": 0.0017226812810585675,
      "success": true,
      "log_likelihood": -6.186914837992799,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.5196004794055716,
      "sensitivity": 0.4396823286661546,
      "alpha_log_ineq": 0.24826718948147303,
      "delta_interaction": -0.17157685642774864,
      "success": true,
      "log_likelihood": -22.706084207886768,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 2.5330675664206765,
      "sensitivity": 0.1275846664232848,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.15222527206363007,
      "success": true,
      "log_likelihood": -10.165271729540235,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.6880941614227947,
      "sensitivity": 0.4416698333990225,
      "alpha_log_ineq": 1.6239571673635955,
      "delta_interaction": 0.03719116343085451,
      "success": true,
      "log_likelihood": -9.452090941876731,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity": 4.810928131084095,
      "alpha_log_ineq": 1.132025815182211,
      "delta_interaction": -1.300340412387829,
      "success": true,
      "log_likelihood": -5.24650733278428,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.9775449814493764,
      "sensitivity": 0.18158301462656135,
      "alpha_log_ineq": 0.22112860099130777,
      "delta_interaction": -0.245908594195798,
      "success": true,
      "log_likelihood": -22.285974340768536,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.9052315652906905,
      "sensitivity": 0.2613836587820866,
      "alpha_log_ineq": 6.159025286410488,
      "delta_interaction": 0.6340235477919035,
      "success": true,
      "log_likelihood": -6.882807173550539,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.5697090306470576,
      "sensitivity": 0.7307096120786364,
      "alpha_log_ineq": 1.419546285019393,
      "delta_interaction": -0.3365855776812475,
      "success": true,
      "log_likelihood": -16.720193993357103,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.1889184334687726,
      "sensitivity": 0.0,
      "alpha_log_ineq": 5.939433784405615,
      "delta_interaction": 0.7686620075475024,
      "success": true,
      "log_likelihood": -12.045501598248627,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 5.502577966132641,
      "sensitivity": 4.676022201973387,
      "alpha_log_ineq": 0.14758454394558695,
      "delta_interaction": 4.404305168749193,
      "success": true,
      "log_likelihood": -46.01594454902723,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -6.107896837930962,
      "sensitivity": 2.506081369018764,
      "alpha_log_ineq": 6.643840482928576,
      "delta_interaction": 1.1056098203160836,
      "success": true,
      "log_likelihood": -5.767323409794098,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 0.01653393665544769,
      "sensitivity": 0.7931201109858909,
      "alpha_log_ineq": 0.0,
      "delta_interaction": -0.46902081802533696,
      "success": true,
      "log_likelihood": -19.16388438820096,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "bias": {
        "r": 0.7222343240981098,
        "p": 2.246020736835962e-17
      },
      "sensitivity": {
        "r": 0.43690840834853545,
        "p": 5.500765073488331e-06
      },
      "alpha_log_ineq": {
        "r": 0.4882565174132223,
        "p": 2.561053773756282e-07
      },
      "delta_interaction": {
        "r": 0.8419992016232035,
        "p": 5.147891723022007e-28
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 35.97104585892343,
  "bic_Control": 30.457640484511085,
  "bic_Cocaine": 40.91013817350115,
  "bic_results": {
    "average_bic": 35.97104585892343,
    "individual_bics": [
      26.707905415973187,
      44.23461004929805,
      33.44847333304796,
      38.48522024261378,
      30.090593848878832,
      36.25644639266055,
      14.33407574712889,
      34.02254534835822,
      14.334076234774557,
      31.479671568124118,
      18.323134529824166,
      29.05812490554903,
      27.083871810367974,
      14.334075747153353,
      14.33407574712889,
      14.33407574712889,
      14.33407574712889,
      15.130900268188613,
      24.39337854104538,
      14.33407574712889,
      38.961951355106955,
      27.92976433777299,
      44.70265546123082,
      45.27139322710626,
      33.20716674426961,
      41.147716762867304,
      35.35685033164461,
      21.769727626563952,
      29.815042951923644,
      40.94850531666624,
      14.33407574712889,
      26.707905457768824,
      50.79025562306998,
      38.584085645397025,
      14.33407574712889,
      32.83275729438698,
      29.13559154126196,
      40.0218143758981,
      45.56925172683954,
      29.510260366684268,
      44.81027930152234,
      34.49822931302535,
      60.385777607209846,
      45.41691434523114,
      40.569253351124004,
      44.48494142273724,
      43.06245732738853,
      47.80785418969519,
      31.13512490042995,
      59.20622215532785,
      49.26791633036689,
      36.72509276416683,
      45.9434125799293,
      53.79224644703136,
      50.2066248972354,
      22.07243245842593,
      35.51182536406979,
      38.53775040104116,
      30.580436408098834,
      40.51030829354393,
      51.37905227604277,
      38.24905917210154,
      26.707905552377188,
      51.08675448233885,
      31.387462075958258,
      38.774629135847235,
      27.841775053963637,
      34.15242659827952,
      37.30123259013943,
      33.42072086335757,
      14.37662786701856,
      36.225229576659444,
      44.58254909803735,
      43.0317302085878,
      58.13629686168231,
      39.52397991555373,
      24.800721703255682,
      24.956908044621418,
      55.63485156444072,
      26.70790542981004,
      59.74624416959797,
      34.66461921290491,
      33.2382576375779,
      24.827090419393002,
      58.906024435361516,
      28.099690100925518,
      47.77446374053865,
      38.42507895032169,
      106.3659648518789,
      25.868722573412636,
      52.66184453022636
    ],
    "group_enabled": true,
    "group_bics": {
      "Control": [
        26.707905415973187,
        44.23461004929805,
        33.44847333304796,
        38.48522024261378,
        30.090593848878832,
        36.25644639266055,
        14.33407574712889,
        34.02254534835822,
        14.334076234774557,
        31.479671568124118,
        18.323134529824166,
        29.05812490554903,
        27.083871810367974,
        14.334075747153353,
        14.33407574712889,
        14.33407574712889,
        14.33407574712889,
        15.130900268188613,
        24.39337854104538,
        14.33407574712889,
        38.961951355106955,
        27.92976433777299,
        44.70265546123082,
        45.27139322710626,
        33.20716674426961,
        41.147716762867304,
        35.35685033164461,
        21.769727626563952,
        29.815042951923644,
        40.94850531666624,
        14.33407574712889,
        26.707905457768824,
        50.79025562306998,
        38.584085645397025,
        14.33407574712889,
        32.83275729438698,
        29.13559154126196,
        40.0218143758981,
        45.56925172683954,
        29.510260366684268,
        44.81027930152234,
        34.49822931302535,
        60.385777607209846
      ],
      "Cocaine": [
        45.41691434523114,
        40.569253351124004,
        44.48494142273724,
        43.06245732738853,
        47.80785418969519,
        31.13512490042995,
        59.20622215532785,
        49.26791633036689,
        36.72509276416683,
        45.9434125799293,
        53.79224644703136,
        50.2066248972354,
        22.07243245842593,
        35.51182536406979,
        38.53775040104116,
        30.580436408098834,
        40.51030829354393,
        51.37905227604277,
        38.24905917210154,
        26.707905552377188,
        51.08675448233885,
        31.387462075958258,
        38.774629135847235,
        27.841775053963637,
        34.15242659827952,
        37.30123259013943,
        33.42072086335757,
        14.37662786701856,
        36.225229576659444,
        44.58254909803735,
        43.0317302085878,
        58.13629686168231,
        39.52397991555373,
        24.800721703255682,
        24.956908044621418,
        55.63485156444072,
        26.70790542981004,
        59.74624416959797,
        34.66461921290491,
        33.2382576375779,
        24.827090419393002,
        58.906024435361516,
        28.099690100925518,
        47.77446374053865,
        38.42507895032169,
        106.3659648518789,
        25.868722573412636,
        52.66184453022636
      ]
    },
    "num_parameters": 4,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- bias: r = 0.722\n- sensitivity: r = 0.437\n- alpha_log_ineq: r = 0.488\n- delta_interaction: r = 0.842",
  "previous_models": [
    "Specification: total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_split = contribution_ratio * combined_earning\ninequity_abs = max(0, deserved_split - split_self)\ninequity_log = log(inequity_abs + 1)\nUtility = bias + sensitivity * split_self - alpha_log_ineq * inequity_log + delta_interaction * split_self * inequity_log\nSummary: A utility model predicting responder acceptance based on absolute monetary values. Utility is determined by a baseline acceptance tendency (`bias`), sensitivity to the absolute amount offered (`sensitivity`), aversion to the logarithm of absolute disadvantageous inequity (`alpha_log_ineq`), and an interaction term (`delta_interaction`) capturing the interdependence between the offered amount and the log-inequity. It includes 4 learnable parameters. The model uses absolute values and an interaction term specifically to address parameter recovery issues observed in previous models.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 35.97104585892343\nOverall Accuracy: 0.8193\nGroup Accuracies:\n- Control: 0.8727\n- Cocaine: 0.7714\n\nParameter Recovery:\n- bias: r = 0.722\n- sensitivity: r = 0.437\n- alpha_log_ineq: r = 0.488\n- delta_interaction: r = 0.842"
  ]
}