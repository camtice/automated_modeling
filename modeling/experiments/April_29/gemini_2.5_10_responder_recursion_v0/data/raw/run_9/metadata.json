{
  "task_description": "In this ultimatum game experiment, the participant acts as both a proposer and a responsder. They are the proposer 14 times and the responsder 36 times. Each is designated by a trial number in the data set. This gives 50 instances for the learnable parameters to be trained (although really it may rather be 36 or 14 depending on how the computational model should be created). There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent. The rounds are a mixed, with the participant doing a handful of turns as a responder, then a handful as a proposer, and then a handful as a responder, and so on.\n\nAgain, the participant gets to act as both a proposer and responder - this is reflected in the data. If you are guessing the proposed amount, you should only be making this guess when trial_role == 2, since this is when the data within the proposed_perc and proposed_amount columns are relevent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\n2. You will have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n3. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "Okay, here are the updated instructions for the next run (Run 9):\n\n<instructions>\nThe previous run tested a linear model using proportional values (`Utility = bias + sensitivity_prop * split_perc - alpha_ineq_prop * inequity_perc`). This achieved the best BIC score so far (31.01) and excellent recovery for the `bias` parameter (r=0.91). However, it failed to meet the goals for accuracy (0.789 vs target >0.82) and, critically, resulted in poor parameter recovery for both `sensitivity_prop` (r=0.515) and `alpha_ineq_prop` (r=0.492), both well below the target of r > 0.75.\n\nThis suggests that simply using proportions in a linear model, while improving overall fit (BIC), did not resolve the identifiability issue between the gain and inequity sensitivity parameters. There might still be significant correlation between the proportional gain (`split_perc`) and proportional inequity (`inequity_perc`) terms, or the linear relationship might be insufficient to capture the decision process accurately.\n\n**Your Goal:** Develop a model that leverages the improved fit potential of proportional values (aiming for **BIC < 31**) while significantly improving **parameter recovery (all r > 0.75)** and achieving **good accuracy (Accuracy > 0.82)**.\n\n**New Direction: Non-Linearity on Proportional Inequity**\n\nSince the proportional representation yielded good BIC, let's retain that but re-introduce non-linearity. Specifically, let's apply a transformation to the proportional inequity term, mirroring a previous model (Run 5, which used log-inequity on absolute values and showed better sensitivity recovery). This might capture diminishing sensitivity to proportional unfairness and help decorrelate the inequity term from the proportional gain term.\n\n**Proposed Model Structure (Primary Focus):**\n\nTest a utility model using proportional gain and a logarithmically transformed proportional inequity term:\n\n1.  Calculate intermediate proportional terms as before:\n    *   `total_tokens = token_self + token_opp`\n    *   `contribution_ratio = (token_self / total_tokens) if total_tokens > 0 else 0.5`\n    *   `deserved_perc = contribution_ratio`\n    *   `split_perc = (split_self / combined_earning) if combined_earning > 0 else 0`\n    *   `inequity_perc = max(0, deserved_perc - split_perc)`\n2.  Apply logarithmic transformation to the proportional inequity:\n    *   Define a small constant `epsilon = 1e-6` (to avoid log(0)).\n    *   `log_inequity_perc = log(inequity_perc + epsilon)`\n3.  Calculate Utility:\n    *   `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`\n\nThis model uses 3 learnable parameters:\n*   `bias`: Baseline acceptance tendency.\n*   `sensitivity_prop`: Sensitivity to the *proportion* of the total earnings offered (linear term).\n*   `alpha_log_ineq_prop`: Sensitivity (aversion) to the *logarithm* of proportional disadvantageous inequity.\n\n**Emphasis:**\n*   Implement the **proportional model with log-transformed inequity** described above. Include the small constant `epsilon` in your model specification and variable descriptions (as a fixed value).\n*   This approach aims to combine the good fit of proportions (Run 8 BIC) with the potential recovery benefits of non-linear inequity (inspired by Run 5 results).\n*   Ensure your model uses exactly 3 learnable parameters (`bias`, `sensitivity_prop`, `alpha_log_ineq_prop`).\n*   Define appropriate, generous but finite numerical bounds for these parameters. Consider the scaling implications of the log transformation on `alpha_log_ineq_prop`.\n*   While this is the primary focus, briefly consider alternative ways non-linearity could be incorporated with proportions if you have strong reasons, but justify why the proposed log-inequity model is being prioritized or modified.\n\nPlease provide your reasoning step-by-step, justify your chosen model structure by explaining how it addresses the limitations of the previous model and aims to meet all performance goals (BIC, Accuracy, Recovery), and detail the model specification in the required format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>).\n</instructions>",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In this ultimatum game experiment, the participant acts as both a proposer and a responsder. They are the proposer 14 times and the responsder 36 times. Each is designated by a trial number in the data set. This gives 50 instances for the learnable parameters to be trained (although really it may rather be 36 or 14 depending on how the computational model should be created). There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent. The rounds are a mixed, with the participant doing a handful of turns as a responder, then a handful as a proposer, and then a handful as a responder, and so on.\n\nAgain, the participant gets to act as both a proposer and responder - this is reflected in the data. If you are guessing the proposed amount, you should only be making this guess when trial_role == 2, since this is when the data within the proposed_perc and proposed_amount columns are relevent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\n2. You will have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n3. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: Okay, here are the updated instructions for the next run (Run 9):\n\n<instructions>\nThe previous run tested a linear model using proportional values (`Utility = bias + sensitivity_prop * split_perc - alpha_ineq_prop * inequity_perc`). This achieved the best BIC score so far (31.01) and excellent recovery for the `bias` parameter (r=0.91). However, it failed to meet the goals for accuracy (0.789 vs target >0.82) and, critically, resulted in poor parameter recovery for both `sensitivity_prop` (r=0.515) and `alpha_ineq_prop` (r=0.492), both well below the target of r > 0.75.\n\nThis suggests that simply using proportions in a linear model, while improving overall fit (BIC), did not resolve the identifiability issue between the gain and inequity sensitivity parameters. There might still be significant correlation between the proportional gain (`split_perc`) and proportional inequity (`inequity_perc`) terms, or the linear relationship might be insufficient to capture the decision process accurately.\n\n**Your Goal:** Develop a model that leverages the improved fit potential of proportional values (aiming for **BIC < 31**) while significantly improving **parameter recovery (all r > 0.75)** and achieving **good accuracy (Accuracy > 0.82)**.\n\n**New Direction: Non-Linearity on Proportional Inequity**\n\nSince the proportional representation yielded good BIC, let's retain that but re-introduce non-linearity. Specifically, let's apply a transformation to the proportional inequity term, mirroring a previous model (Run 5, which used log-inequity on absolute values and showed better sensitivity recovery). This might capture diminishing sensitivity to proportional unfairness and help decorrelate the inequity term from the proportional gain term.\n\n**Proposed Model Structure (Primary Focus):**\n\nTest a utility model using proportional gain and a logarithmically transformed proportional inequity term:\n\n1.  Calculate intermediate proportional terms as before:\n    *   `total_tokens = token_self + token_opp`\n    *   `contribution_ratio = (token_self / total_tokens) if total_tokens > 0 else 0.5`\n    *   `deserved_perc = contribution_ratio`\n    *   `split_perc = (split_self / combined_earning) if combined_earning > 0 else 0`\n    *   `inequity_perc = max(0, deserved_perc - split_perc)`\n2.  Apply logarithmic transformation to the proportional inequity:\n    *   Define a small constant `epsilon = 1e-6` (to avoid log(0)).\n    *   `log_inequity_perc = log(inequity_perc + epsilon)`\n3.  Calculate Utility:\n    *   `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`\n\nThis model uses 3 learnable parameters:\n*   `bias`: Baseline acceptance tendency.\n*   `sensitivity_prop`: Sensitivity to the *proportion* of the total earnings offered (linear term).\n*   `alpha_log_ineq_prop`: Sensitivity (aversion) to the *logarithm* of proportional disadvantageous inequity.\n\n**Emphasis:**\n*   Implement the **proportional model with log-transformed inequity** described above. Include the small constant `epsilon` in your model specification and variable descriptions (as a fixed value).\n*   This approach aims to combine the good fit of proportions (Run 8 BIC) with the potential recovery benefits of non-linear inequity (inspired by Run 5 results).\n*   Ensure your model uses exactly 3 learnable parameters (`bias`, `sensitivity_prop`, `alpha_log_ineq_prop`).\n*   Define appropriate, generous but finite numerical bounds for these parameters. Consider the scaling implications of the log transformation on `alpha_log_ineq_prop`.\n*   While this is the primary focus, briefly consider alternative ways non-linearity could be incorporated with proportions if you have strong reasons, but justify why the proposed log-inequity model is being prioritized or modified.\n\nPlease provide your reasoning step-by-step, justify your chosen model structure by explaining how it addresses the limitations of the previous model and aims to meet all performance goals (BIC, Accuracy, Recovery), and detail the model specification in the required format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>).\n</instructions>\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Okay, let's outline the reasoning for the proposed model structure.\n\n**Step-by-Step Reasoning:**\n\n1.  **Goal Review:** The primary goal is to improve parameter recovery (r > 0.75) and accuracy (> 0.82) while maintaining or improving the good BIC score (< 31) achieved by the previous linear proportional model (Run 8). The failure points of Run 8 were poor recovery for gain sensitivity (`sensitivity_prop`) and inequity aversion (`alpha_ineq_prop`), suggesting collinearity or model misspecification.\n2.  **Leveraging Run 8 Strengths:** Run 8's model (`Utility = bias + sensitivity_prop * split_perc - alpha_ineq_prop * inequity_perc`) achieved the best BIC so far. This suggests that representing the offer (`split_perc`) and fairness (`inequity_perc`) in *proportional* terms, relative to the total pot and contributions respectively, is beneficial for model fit compared to using absolute monetary values. Therefore, we retain the use of `split_perc` and `inequity_perc` as core components.\n3.  **Addressing Run 8 Weaknesses (Recovery):** The poor recovery suggests the linear terms for gain (`sensitivity_prop * split_perc`) and inequity aversion (`alpha_ineq_prop * inequity_perc`) might be too closely related or that the relationship, particularly for inequity, isn't linear. People often exhibit diminishing sensitivity to unfairness \u2013 rejecting a slightly unfair offer might feel similarly strong to rejecting a very unfair offer. A linear term doesn't capture this saturation.\n4.  **Introducing Non-Linearity (Log Transform):** Inspired by previous attempts (like Run 5, which reportedly showed better sensitivity recovery using log-inequity on absolute values) and the concept of diminishing sensitivity, we apply a non-linear transformation specifically to the inequity term. The natural logarithm (`log`) is a common choice for modeling diminishing returns or sensitivity.\n    *   We calculate the proportional disadvantageous inequity: `inequity_perc = max(0, deserved_perc - split_perc)`, where `deserved_perc` is based on `token_self / (token_self + token_opp)`.\n    *   To handle cases where `inequity_perc` is exactly 0 (perfectly fair or advantageous offers), we add a small constant `epsilon` (1e-6) before taking the log: `log(inequity_perc + epsilon)`. This avoids `log(0)` which is undefined.\n    *   The utility component related to inequity becomes `- alpha_log_ineq_prop * log(inequity_perc + epsilon)`.\n5.  **Proposed Model Formula:** This leads to the utility function: `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`.\n    *   `bias`: Captures the baseline acceptance tendency.\n    *   `sensitivity_prop`: Captures the *linear* sensitivity to the proportion of the pot offered (`split_perc`). We keep this linear based on Run 8's success with proportional representation, focusing the non-linearity on the inequity term where diminishing sensitivity is more plausible.\n    *   `alpha_log_ineq_prop`: Captures the aversion to the *logarithm* of proportional disadvantageous inequity.\n6.  **Expected Benefits:**\n    *   **Improved Recovery:** The non-linear transformation of the inequity term should change its relationship with the linear `split_perc` term, potentially reducing collinearity and allowing the model fitting process to better distinguish the independent contributions of `sensitivity_prop` and `alpha_log_ineq_prop`.\n    *   **Better Fit/Accuracy:** Modeling diminishing sensitivity to inequity might provide a more psychologically plausible account of decision-making, potentially improving accuracy and BIC.\n    *   **Meeting Constraints:** The model uses 3 learnable parameters as requested and operates on the provided data variables.\n\n7.  **Parameter Bounds:** Generous but finite bounds are set. `sensitivity_prop` and `alpha_log_ineq_prop` are constrained to be non-negative, reflecting the assumption that higher offers increase utility and higher inequity decreases utility. The magnitude of the bounds considers the potential scaling effects of using proportions and the log transform.\n\nThis model structure directly implements the instructions by combining the proportional representation from Run 8 with a non-linear (logarithmic) treatment of the inequity term, aiming specifically to resolve the parameter recovery issues while maintaining good overall model fit.\n\n<MODEL>\ntotal_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"Predicted utility of accepting the offer. This value is used in a logistic function P(accept) = 1 / (1 + exp(-Utility)) to predict the choice.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency parameter, representing the inherent preference for accepting offers, independent of amount or fairness.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity_prop\": {\n      \"description\": \"Sensitivity to the proportion of the total combined earnings offered to the participant (`split_perc`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq_prop\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of proportional disadvantageous inequity (`log_inequity_perc`). Captures diminishing aversion to increasing unfairness.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total amount of money (\u00a3) available in the pot for the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The amount (\u00a3) of the combined earning proposed for the participant in the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n        \"description\": \"Sum of tokens found by participant and opponent.\",\n        \"range\": {\n            \"min\": 0,\n            \"max\": \"inf\"\n        },\n        \"learnable\": false,\n        \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n        \"description\": \"Participant's contribution proportion (token_self / total_tokens). Defaults to 0.5 if total_tokens is 0.\",\n        \"range\": {\n            \"min\": 0,\n            \"max\": 1\n        },\n        \"learnable\": false,\n        \"source\": \"calculated\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"The proportion of the combined earning the participant 'deserves' based on their contribution ratio.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"The proportion of the combined earning offered to the participant (`split_self / combined_earning`). Defaults to 0 if combined_earning is 0.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_perc\": {\n      \"description\": \"Proportional disadvantageous inequity: the difference between the deserved proportion and the offered proportion, floored at zero (`max(0, deserved_perc - split_perc)`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"A small constant (1e-6) added to inequity_perc before taking the logarithm to avoid log(0).\",\n      \"range\": {\n        \"min\": 1e-6,\n        \"max\": 1e-6\n      },\n      \"learnable\": false,\n      \"source\": \"fixed\"\n    },\n    \"log_inequity_perc\": {\n      \"description\": \"The natural logarithm of the proportional disadvantageous inequity plus epsilon (`log(inequity_perc + epsilon)`).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\" \n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model predicting responder acceptance. Utility is calculated as a linear combination of a baseline acceptance bias, the proportion of the total pot offered to the participant, and the negative logarithm of the proportional disadvantageous inequity (the difference between the proportion deserved based on contribution and the proportion offered, floored at zero). The log transformation on inequity aims to capture diminishing sensitivity to unfairness. The model has three learnable parameters: bias, sensitivity_prop (for offered proportion), and alpha_log_ineq_prop (for log-proportional-inequity aversion).\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['bias', 'sensitivity_prop', 'alpha_log_ineq_prop']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"Predicted utility of accepting the offer. This value is used in a logistic function P(accept) = 1 / (1 + exp(-Utility)) to predict the choice.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency parameter, representing the inherent preference for accepting offers, independent of amount or fairness.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity_prop\": {\n      \"description\": \"Sensitivity to the proportion of the total combined earnings offered to the participant (`split_perc`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq_prop\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of proportional disadvantageous inequity (`log_inequity_perc`). Captures diminishing aversion to increasing unfairness.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total amount of money (\\u00a3) available in the pot for the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The amount (\\u00a3) of the combined earning proposed for the participant in the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n      \"description\": \"Sum of tokens found by participant and opponent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n      \"description\": \"Participant's contribution proportion (token_self / total_tokens). Defaults to 0.5 if total_tokens is 0.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"The proportion of the combined earning the participant 'deserves' based on their contribution ratio.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"The proportion of the combined earning offered to the participant (`split_self / combined_earning`). Defaults to 0 if combined_earning is 0.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_perc\": {\n      \"description\": \"Proportional disadvantageous inequity: the difference between the deserved proportion and the offered proportion, floored at zero (`max(0, deserved_perc - split_perc)`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"A small constant (1e-6) added to inequity_perc before taking the logarithm to avoid log(0).\",\n      \"range\": {\n        \"min\": 1e-06,\n        \"max\": 1e-06,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"fixed\"\n    },\n    \"log_inequity_perc\": {\n      \"description\": \"The natural logarithm of the proportional disadvantageous inequity plus epsilon (`log(inequity_perc + epsilon)`).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, bias=0, sensitivity_prop=1, alpha_log_ineq_prop=1):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n\n        total_tokens = token_self + token_opp\n        contribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\n        deserved_perc = contribution_ratio\n        split_perc = split_self / combined_earning if combined_earning > 0 else 0\n        inequity_perc = max(0, deserved_perc - split_perc)\n        epsilon = 1e-6\n        log_inequity_perc = math.log(inequity_perc + epsilon)\n        Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\n        model_predictions.append(Utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 0, \"group\": \"control\", \"trial_number\": 1, \"trial_type\": 0, \"trial_role\": 1, \"token_opp\": 7, \"token_self\": 3, \"combined_earning\": 7, \"split_opp\": 4.9, \"split_self\": 2.1, \"splitperc_opp\": 70, \"splitperc_self\": 30, \"accept\": 1.0, \"accepted_amount\": 2.1, \"accepted_perc\": 30.0, \"proposed_perc\": 30.0, \"proposed_amount\": 2.1}, {\"ID\": 1, \"group\": \"control\", \"trial_number\": 2, \"trial_type\": 0, \"trial_role\": 1, \"token_opp\": 4, \"token_self\": 6, \"combined_earning\": 8, \"split_opp\": 2.4, \"split_self\": 5.6, \"splitperc_opp\": 30, \"splitperc_self\": 70, \"accept\": 1.0, \"accepted_amount\": 5.6, \"accepted_perc\": 70.0, \"proposed_perc\": 70.0, \"proposed_amount\": 5.6}]'\n\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1745950195.8646588
    }
  ],
  "learnable_parameters": {
    "bias": {
      "description": "Baseline tendency parameter, representing the inherent preference for accepting offers, independent of amount or fairness.",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sensitivity_prop": {
      "description": "Sensitivity to the proportion of the total combined earnings offered to the participant (`split_perc`).",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_log_ineq_prop": {
      "description": "Sensitivity (aversion) to the logarithm of proportional disadvantageous inequity (`log_inequity_perc`). Captures diminishing aversion to increasing unfairness.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc",
  "variable_descriptions": {
    "Utility": {
      "description": "Predicted utility of accepting the offer. This value is used in a logistic function P(accept) = 1 / (1 + exp(-Utility)) to predict the choice.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "bias": {
      "description": "Baseline tendency parameter, representing the inherent preference for accepting offers, independent of amount or fairness.",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "sensitivity_prop": {
      "description": "Sensitivity to the proportion of the total combined earnings offered to the participant (`split_perc`).",
      "range": {
        "min": 0,
        "max": 20,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "alpha_log_ineq_prop": {
      "description": "Sensitivity (aversion) to the logarithm of proportional disadvantageous inequity (`log_inequity_perc`). Captures diminishing aversion to increasing unfairness.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "token_self": {
      "description": "Number of tokens found by the participant, representing their contribution.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by the opponent, representing their contribution.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "Total amount of money (\u00a3) available in the pot for the current trial.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "split_self": {
      "description": "The amount (\u00a3) of the combined earning proposed for the participant in the current trial.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "total_tokens": {
      "description": "Sum of tokens found by participant and opponent.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "contribution_ratio": {
      "description": "Participant's contribution proportion (token_self / total_tokens). Defaults to 0.5 if total_tokens is 0.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "deserved_perc": {
      "description": "The proportion of the combined earning the participant 'deserves' based on their contribution ratio.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "split_perc": {
      "description": "The proportion of the combined earning offered to the participant (`split_self / combined_earning`). Defaults to 0 if combined_earning is 0.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "inequity_perc": {
      "description": "Proportional disadvantageous inequity: the difference between the deserved proportion and the offered proportion, floored at zero (`max(0, deserved_perc - split_perc)`).",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "epsilon": {
      "description": "A small constant (1e-6) added to inequity_perc before taking the logarithm to avoid log(0).",
      "range": {
        "min": 1e-06,
        "max": 1e-06,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "fixed"
    },
    "log_inequity_perc": {
      "description": "The natural logarithm of the proportional disadvantageous inequity plus epsilon (`log(inequity_perc + epsilon)`).",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    }
  },
  "model_summary": "A utility model predicting responder acceptance. Utility is calculated as a linear combination of a baseline acceptance bias, the proportion of the total pot offered to the participant, and the negative logarithm of the proportional disadvantageous inequity (the difference between the proportion deserved based on contribution and the proportion offered, floored at zero). The log transformation on inequity aims to capture diminishing sensitivity to unfairness. The model has three learnable parameters: bias, sensitivity_prop (for offered proportion), and alpha_log_ineq_prop (for log-proportional-inequity aversion).",
  "target_variable": "accept",
  "full_reasoning": "Okay, let's outline the reasoning for the proposed model structure.\n\n**Step-by-Step Reasoning:**\n\n1.  **Goal Review:** The primary goal is to improve parameter recovery (r > 0.75) and accuracy (> 0.82) while maintaining or improving the good BIC score (< 31) achieved by the previous linear proportional model (Run 8). The failure points of Run 8 were poor recovery for gain sensitivity (`sensitivity_prop`) and inequity aversion (`alpha_ineq_prop`), suggesting collinearity or model misspecification.\n2.  **Leveraging Run 8 Strengths:** Run 8's model (`Utility = bias + sensitivity_prop * split_perc - alpha_ineq_prop * inequity_perc`) achieved the best BIC so far. This suggests that representing the offer (`split_perc`) and fairness (`inequity_perc`) in *proportional* terms, relative to the total pot and contributions respectively, is beneficial for model fit compared to using absolute monetary values. Therefore, we retain the use of `split_perc` and `inequity_perc` as core components.\n3.  **Addressing Run 8 Weaknesses (Recovery):** The poor recovery suggests the linear terms for gain (`sensitivity_prop * split_perc`) and inequity aversion (`alpha_ineq_prop * inequity_perc`) might be too closely related or that the relationship, particularly for inequity, isn't linear. People often exhibit diminishing sensitivity to unfairness \u2013 rejecting a slightly unfair offer might feel similarly strong to rejecting a very unfair offer. A linear term doesn't capture this saturation.\n4.  **Introducing Non-Linearity (Log Transform):** Inspired by previous attempts (like Run 5, which reportedly showed better sensitivity recovery using log-inequity on absolute values) and the concept of diminishing sensitivity, we apply a non-linear transformation specifically to the inequity term. The natural logarithm (`log`) is a common choice for modeling diminishing returns or sensitivity.\n    *   We calculate the proportional disadvantageous inequity: `inequity_perc = max(0, deserved_perc - split_perc)`, where `deserved_perc` is based on `token_self / (token_self + token_opp)`.\n    *   To handle cases where `inequity_perc` is exactly 0 (perfectly fair or advantageous offers), we add a small constant `epsilon` (1e-6) before taking the log: `log(inequity_perc + epsilon)`. This avoids `log(0)` which is undefined.\n    *   The utility component related to inequity becomes `- alpha_log_ineq_prop * log(inequity_perc + epsilon)`.\n5.  **Proposed Model Formula:** This leads to the utility function: `Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc`.\n    *   `bias`: Captures the baseline acceptance tendency.\n    *   `sensitivity_prop`: Captures the *linear* sensitivity to the proportion of the pot offered (`split_perc`). We keep this linear based on Run 8's success with proportional representation, focusing the non-linearity on the inequity term where diminishing sensitivity is more plausible.\n    *   `alpha_log_ineq_prop`: Captures the aversion to the *logarithm* of proportional disadvantageous inequity.\n6.  **Expected Benefits:**\n    *   **Improved Recovery:** The non-linear transformation of the inequity term should change its relationship with the linear `split_perc` term, potentially reducing collinearity and allowing the model fitting process to better distinguish the independent contributions of `sensitivity_prop` and `alpha_log_ineq_prop`.\n    *   **Better Fit/Accuracy:** Modeling diminishing sensitivity to inequity might provide a more psychologically plausible account of decision-making, potentially improving accuracy and BIC.\n    *   **Meeting Constraints:** The model uses 3 learnable parameters as requested and operates on the provided data variables.\n\n7.  **Parameter Bounds:** Generous but finite bounds are set. `sensitivity_prop` and `alpha_log_ineq_prop` are constrained to be non-negative, reflecting the assumption that higher offers increase utility and higher inequity decreases utility. The magnitude of the bounds considers the potential scaling effects of using proportions and the log transform.\n\nThis model structure directly implements the instructions by combining the proportional representation from Run 8 with a non-linear (logarithmic) treatment of the inequity term, aiming specifically to resolve the parameter recovery issues while maintaining good overall model fit.\n\n<MODEL>\ntotal_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"Utility\": {\n      \"description\": \"Predicted utility of accepting the offer. This value is used in a logistic function P(accept) = 1 / (1 + exp(-Utility)) to predict the choice.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"bias\": {\n      \"description\": \"Baseline tendency parameter, representing the inherent preference for accepting offers, independent of amount or fairness.\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"sensitivity_prop\": {\n      \"description\": \"Sensitivity to the proportion of the total combined earnings offered to the participant (`split_perc`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 20\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"alpha_log_ineq_prop\": {\n      \"description\": \"Sensitivity (aversion) to the logarithm of proportional disadvantageous inequity (`log_inequity_perc`). Captures diminishing aversion to increasing unfairness.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent, representing their contribution.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total amount of money (\u00a3) available in the pot for the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The amount (\u00a3) of the combined earning proposed for the participant in the current trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"total_tokens\": {\n        \"description\": \"Sum of tokens found by participant and opponent.\",\n        \"range\": {\n            \"min\": 0,\n            \"max\": \"inf\"\n        },\n        \"learnable\": false,\n        \"source\": \"calculated\"\n    },\n    \"contribution_ratio\": {\n        \"description\": \"Participant's contribution proportion (token_self / total_tokens). Defaults to 0.5 if total_tokens is 0.\",\n        \"range\": {\n            \"min\": 0,\n            \"max\": 1\n        },\n        \"learnable\": false,\n        \"source\": \"calculated\"\n    },\n    \"deserved_perc\": {\n      \"description\": \"The proportion of the combined earning the participant 'deserves' based on their contribution ratio.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"The proportion of the combined earning offered to the participant (`split_self / combined_earning`). Defaults to 0 if combined_earning is 0.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"inequity_perc\": {\n      \"description\": \"Proportional disadvantageous inequity: the difference between the deserved proportion and the offered proportion, floored at zero (`max(0, deserved_perc - split_perc)`).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"epsilon\": {\n      \"description\": \"A small constant (1e-6) added to inequity_perc before taking the logarithm to avoid log(0).\",\n      \"range\": {\n        \"min\": 1e-6,\n        \"max\": 1e-6\n      },\n      \"learnable\": false,\n      \"source\": \"fixed\"\n    },\n    \"log_inequity_perc\": {\n      \"description\": \"The natural logarithm of the proportional disadvantageous inequity plus epsilon (`log(inequity_perc + epsilon)`).\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\" \n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model predicting responder acceptance. Utility is calculated as a linear combination of a baseline acceptance bias, the proportion of the total pot offered to the participant, and the negative logarithm of the proportional disadvantageous inequity (the difference between the proportion deserved based on contribution and the proportion offered, floored at zero). The log transformation on inequity aims to capture diminishing sensitivity to unfairness. The model has three learnable parameters: bias, sensitivity_prop (for offered proportion), and alpha_log_ineq_prop (for log-proportional-inequity aversion).\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\nSummary: A utility model predicting responder acceptance. Utility is calculated as a linear combination of a baseline acceptance bias, the proportion of the total pot offered to the participant, and the negative logarithm of the proportional disadvantageous inequity (the difference between the proportion deserved based on contribution and the proportion offered, floored at zero). The log transformation on inequity aims to capture diminishing sensitivity to unfairness. The model has three learnable parameters: bias, sensitivity_prop (for offered proportion), and alpha_log_ineq_prop (for log-proportional-inequity aversion).\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, bias=0, sensitivity_prop=1, alpha_log_ineq_prop=1):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n        split_self = trial.get(\"split_self\", 0)\n\n        total_tokens = token_self + token_opp\n        contribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\n        deserved_perc = contribution_ratio\n        split_perc = split_self / combined_earning if combined_earning > 0 else 0\n        inequity_perc = max(0, deserved_perc - split_perc)\n        epsilon = 1e-6\n        log_inequity_perc = math.log(inequity_perc + epsilon)\n        Utility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\n        model_predictions.append(Utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.8208180708180708,
  "group_accuracies": {
    "Control": 0.8604651162790697,
    "Cocaine": 0.7853009259259259
  },
  "group_parameter_averages": {
    "Control": {
      "bias": -4.306106421792441,
      "sensitivity_prop": 11.902209863328842,
      "alpha_log_ineq_prop": 4.015822307452028
    },
    "Cocaine": {
      "bias": -5.317206463630462,
      "sensitivity_prop": 11.398791395309402,
      "alpha_log_ineq_prop": 1.0098405725333475
    }
  },
  "fitting_results": [
    {
      "bias": -10.0,
      "sensitivity_prop": 19.62579016044022,
      "alpha_log_ineq_prop": 0.07841440271064357,
      "success": true,
      "log_likelihood": -2.9732855804378433,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.052115767860064,
      "sensitivity_prop": 8.925846890101619,
      "alpha_log_ineq_prop": 1.9124124338980335,
      "success": true,
      "log_likelihood": -14.28729311847071,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 1.6767746258206704,
      "alpha_log_ineq_prop": 6.0277087854919245,
      "success": true,
      "log_likelihood": -7.702503231147554,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.337211178264127,
      "sensitivity_prop": 15.344598717015089,
      "alpha_log_ineq_prop": 1.1287396295006442,
      "success": true,
      "log_likelihood": -13.529104771467964,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 5.697342416129965,
      "success": true,
      "log_likelihood": -5.8389187529585955,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.9942030755588975,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 1.9289085902270793,
      "success": true,
      "log_likelihood": -10.868731031953772,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 5.333184017583301,
      "sensitivity_prop": 2.5054085091276423,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -6.549052294937456e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.6712581923676755,
      "sensitivity_prop": 15.84076483221334,
      "alpha_log_ineq_prop": 2.6798629464688,
      "success": true,
      "log_likelihood": -10.959656284230991,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity_prop": 11.369727942091021,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -1.5699984304985753e-08,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -8.97970978287827,
      "sensitivity_prop": 8.018831832421684,
      "alpha_log_ineq_prop": 3.1702590821501695,
      "success": true,
      "log_likelihood": -9.84277580782462,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 9.126847794606023,
      "alpha_log_ineq_prop": 4.015402914426803,
      "success": true,
      "log_likelihood": -5.317902069172234,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -9.722068402891443,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.059799641883559164,
      "success": true,
      "log_likelihood": -5.722673664435873,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 11.970547443329584,
      "alpha_log_ineq_prop": 3.2375091944855217,
      "success": true,
      "log_likelihood": -8.073366875112978,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.748182486599084,
      "sensitivity_prop": 10.682473958999983,
      "alpha_log_ineq_prop": 9.981509636896785,
      "success": true,
      "log_likelihood": -4.054425440983041e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -3.6526224444948364e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.372520506834561,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -5.4762921361684095e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 10.0,
      "sensitivity_prop": 18.815468567702947,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -4.6516453137506166e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.5206140117958205,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 3.8814276015123426,
      "success": true,
      "log_likelihood": -4.327846616029623,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 12.34079693152459,
      "alpha_log_ineq_prop": 8.446041629908414,
      "success": true,
      "log_likelihood": -4.410089789950617,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 5.045005283753871,
      "sensitivity_prop": 3.6341100046789885,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -7.438629032629638e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.911247088279215,
      "sensitivity_prop": 5.808869596739847,
      "alpha_log_ineq_prop": 3.349525124384933,
      "success": true,
      "log_likelihood": -12.399944180891806,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -5.910197986757638,
      "sensitivity_prop": 14.542817118716943,
      "alpha_log_ineq_prop": 3.4174751134534187,
      "success": true,
      "log_likelihood": -7.495469780365566,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.370546242830875,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.15011101737098667,
      "success": true,
      "log_likelihood": -10.76199600092503,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.339319462308137,
      "sensitivity_prop": 17.70620401685258,
      "alpha_log_ineq_prop": 0.6564765325603528,
      "success": true,
      "log_likelihood": -14.674664020242867,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.537531211947924,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 4.532628945211057,
      "success": true,
      "log_likelihood": -10.920626875715065,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -7.129229653977162,
      "sensitivity_prop": 8.455893360720818,
      "alpha_log_ineq_prop": 3.1526596021341304,
      "success": true,
      "log_likelihood": -12.210604408552332,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -8.195628257452434,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 1.5204629791770297,
      "success": true,
      "log_likelihood": -7.990268325924815,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 9.791326119592524,
      "alpha_log_ineq_prop": 2.703646252572979,
      "success": true,
      "log_likelihood": -4.403824461908219,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.178891834096039,
      "sensitivity_prop": 1.7920176863623392,
      "alpha_log_ineq_prop": 4.699982724536857,
      "success": true,
      "log_likelihood": -7.864855194323644,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -3.0215989107725507,
      "sensitivity_prop": 2.971105830218095,
      "alpha_log_ineq_prop": 2.3758982631896384,
      "success": true,
      "log_likelihood": -13.612646913050858,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.695133596237785,
      "sensitivity_prop": 16.949026174956245,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -5.54572161515307e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 19.62579133749384,
      "alpha_log_ineq_prop": 0.07841436840933955,
      "success": true,
      "log_likelihood": -2.9732855804380445,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.577918426459434,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -13.686038537117117,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -9.243018492535032,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 1.2058896172001186,
      "success": true,
      "log_likelihood": -11.68385399013656,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 4.13645824374597,
      "sensitivity_prop": 12.544187287731212,
      "alpha_log_ineq_prop": 10.0,
      "success": true,
      "log_likelihood": -5.90444121188369e-06,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -5.849016156855026,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.4946954564813778,
      "success": true,
      "log_likelihood": -10.748066703826652,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -9.18318668484385,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 3.240017943392909,
      "success": true,
      "log_likelihood": -8.352412727431478,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.447016745231571,
      "sensitivity_prop": 4.1668425525113815,
      "alpha_log_ineq_prop": 3.0462690400188173,
      "success": true,
      "log_likelihood": -12.894844266626805,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -3.5396261083867757,
      "sensitivity_prop": 5.02312615575713,
      "alpha_log_ineq_prop": 1.7596183897772741,
      "success": true,
      "log_likelihood": -16.114141091714373,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -1.6680661480626526,
      "sensitivity_prop": 10.724444537192888,
      "alpha_log_ineq_prop": 1.0244012134791167,
      "success": true,
      "log_likelihood": -7.812797176142805,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -4.088512374237591,
      "sensitivity_prop": 8.759626847921815,
      "alpha_log_ineq_prop": 1.1927127765199435,
      "success": true,
      "log_likelihood": -16.62877889760501,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.039899226511545,
      "sensitivity_prop": 3.0557572902991885,
      "alpha_log_ineq_prop": 1.5702565486605078,
      "success": true,
      "log_likelihood": -9.273550298760943,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": 3.0145711513322313,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 0.2638784062157617,
      "success": true,
      "log_likelihood": -4.455552612616899,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Control",
      "n_trials": 36
    },
    {
      "bias": -6.486226270335795,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.48049267101482995,
      "success": true,
      "log_likelihood": -11.658197672897273,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.484638612450783,
      "sensitivity_prop": 19.026912526055618,
      "alpha_log_ineq_prop": 1.5762634147275654,
      "success": true,
      "log_likelihood": -12.081812363707597,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.6739146451590123,
      "sensitivity_prop": 11.246538826815094,
      "alpha_log_ineq_prop": 0.302889474966686,
      "success": true,
      "log_likelihood": -16.37572474340026,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.3908864910609395,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.8781637212297791,
      "success": true,
      "log_likelihood": -11.285948343651002,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -4.607133859797867,
      "sensitivity_prop": 9.189559025514827,
      "alpha_log_ineq_prop": 0.6058765622550681,
      "success": true,
      "log_likelihood": -16.699087055321144,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.393862361162264,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 3.902684150532713,
      "success": true,
      "log_likelihood": -10.38974572922402,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.345312412299462,
      "sensitivity_prop": 8.249361565651109,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -22.205420898738947,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.579217188657863,
      "sensitivity_prop": 9.792288500989473,
      "alpha_log_ineq_prop": 0.36835512899014194,
      "success": true,
      "log_likelihood": -17.41799119224609,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -8.98493715309868,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -7.024052273092348,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -5.808483877374295,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -14.454335372154228,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.652425963974296,
      "sensitivity_prop": 10.23122058494756,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -20.74891639995166,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.788781650321823,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 1.6974445003170926,
      "success": true,
      "log_likelihood": -15.583873336430347,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 7.259887234927441,
      "alpha_log_ineq_prop": 3.5076830622940895,
      "success": true,
      "log_likelihood": -5.749954834666423,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 17.938590443684063,
      "alpha_log_ineq_prop": 1.369001619479278,
      "success": true,
      "log_likelihood": -8.85582246800935,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.8942410597288315,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 0.06955777088688506,
      "success": true,
      "log_likelihood": -12.467242009914832,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -9.663221143470121,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.05020396186508387,
      "success": true,
      "log_likelihood": -4.760789113328389,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.1100627754631405,
      "sensitivity_prop": 16.694477169692334,
      "alpha_log_ineq_prop": 0.15078591431564747,
      "success": true,
      "log_likelihood": -12.259467324434246,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.1060609543001956,
      "sensitivity_prop": 9.831911772923643,
      "alpha_log_ineq_prop": 0.3833591554187013,
      "success": true,
      "log_likelihood": -18.513325701367677,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.039293711647919,
      "sensitivity_prop": 10.464665786073045,
      "alpha_log_ineq_prop": 2.2346235050742687,
      "success": true,
      "log_likelihood": -12.992659103042087,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 19.625765031505516,
      "alpha_log_ineq_prop": 0.0784152599723859,
      "success": true,
      "log_likelihood": -2.9732855804750846,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -5.616398039591625,
      "sensitivity_prop": 17.54149337570057,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -17.08848063409777,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.7269870296476193,
      "success": true,
      "log_likelihood": -6.0700178568647685,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -8.074989583216421,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 1.4447389854875778,
      "success": true,
      "log_likelihood": -10.119237767171379,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.17928984320432,
      "sensitivity_prop": 15.353520686512434,
      "alpha_log_ineq_prop": 0.7010955185435648,
      "success": true,
      "log_likelihood": -7.141052928877341,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.064721382027254,
      "sensitivity_prop": 6.20910799301234,
      "alpha_log_ineq_prop": 2.4326500989016537,
      "success": true,
      "log_likelihood": -10.118150340383622,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -6.206740711246823,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.3180708232088488,
      "success": true,
      "log_likelihood": -12.841852855535516,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.05979913641425618,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 1.6574478450196144,
      "success": true,
      "log_likelihood": -8.993649668261243,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 1.2345747712298691,
      "success": true,
      "log_likelihood": -0.022341653263931654,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -8.984933226780981,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -6.024052273591147,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -5.792440704283871,
      "sensitivity_prop": 14.959331982863572,
      "alpha_log_ineq_prop": 0.8059008247926797,
      "success": true,
      "log_likelihood": -15.342696950927284,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.675707895395152,
      "sensitivity_prop": 14.291692760853334,
      "alpha_log_ineq_prop": 0.07945010919793832,
      "success": true,
      "log_likelihood": -14.25162338075271,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.1563482929909066,
      "sensitivity_prop": 6.936162856830159,
      "alpha_log_ineq_prop": 0.02710497495407211,
      "success": true,
      "log_likelihood": -22.63689422433638,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -5.625170317515639,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.653025103444389,
      "success": true,
      "log_likelihood": -11.322428420550013,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.5092424972799736,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 5.4277209814271865,
      "success": true,
      "log_likelihood": -5.130852306233849,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -3.702469110256161,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 0.1838350102052234,
      "success": true,
      "log_likelihood": -6.7971881446321785,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.8615923113401902,
      "sensitivity_prop": 1.1637666084933858,
      "alpha_log_ineq_prop": 0.47807158075616685,
      "success": true,
      "log_likelihood": -21.3651848687313,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 19.62582762345308,
      "alpha_log_ineq_prop": 0.07841244942740373,
      "success": true,
      "log_likelihood": -2.973285580558774,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.2741974855758365,
      "sensitivity_prop": 6.52734952284058,
      "alpha_log_ineq_prop": 0.1891737168126218,
      "success": true,
      "log_likelihood": -21.158829011548764,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": 1.5243045615612354,
      "sensitivity_prop": 2.5733296242037733,
      "alpha_log_ineq_prop": 0.056525865537201084,
      "success": true,
      "log_likelihood": -10.131746978780935,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -9.365963535726904,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.0,
      "success": true,
      "log_likelihood": -7.8536486695835315,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -7.592362981137218,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.8581162087560041,
      "success": true,
      "log_likelihood": -9.333688568876216,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -0.498841557453925,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 0.45511937488714166,
      "success": true,
      "log_likelihood": -21.599900946595085,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -10.0,
      "sensitivity_prop": 18.804445961643573,
      "alpha_log_ineq_prop": 0.2006689917420929,
      "success": true,
      "log_likelihood": -3.3735196323414254,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -2.7595638204409823,
      "sensitivity_prop": 6.224647175966876,
      "alpha_log_ineq_prop": 1.113625986690548,
      "success": true,
      "log_likelihood": -16.952441953505073,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -8.626371035941242,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 3.526376492653151,
      "success": true,
      "log_likelihood": -52.7847927778862,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -5.677389813503844,
      "sensitivity_prop": 0.0,
      "alpha_log_ineq_prop": 7.807048227173007,
      "success": true,
      "log_likelihood": -4.381361060789179,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -6.620100871821774,
      "sensitivity_prop": 20.0,
      "alpha_log_ineq_prop": 0.20177372346519917,
      "success": true,
      "log_likelihood": -10.154691012366868,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    },
    {
      "bias": -1.6053626518324542,
      "sensitivity_prop": 7.380132333697912,
      "alpha_log_ineq_prop": 0.15903291429968736,
      "success": true,
      "log_likelihood": -19.16607468136475,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "group": "Cocaine",
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "bias": {
        "r": 0.7603772916946872,
        "p": 4.493956025001349e-20
      },
      "sensitivity_prop": {
        "r": 0.1182765516362208,
        "p": 0.2411912979203759
      },
      "alpha_log_ineq_prop": {
        "r": 0.4880346549033743,
        "p": 2.598082796485801e-07
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 31.199781898764737,
  "bic_Control": 25.6720640074649,
  "bic_Cocaine": 36.15169584305417,
  "bic_results": {
    "average_bic": 31.199781898764737,
    "individual_bics": [
      16.69712797624402,
      39.325143052309755,
      26.15556327766344,
      37.808766358304254,
      22.428394321285523,
      32.48801887927587,
      10.750569913472921,
      32.66986938383032,
      10.7505568467683,
      30.43610843101757,
      21.3863609537128,
      22.195904144240075,
      26.897290565594286,
      10.750564924219212,
      10.750556822673575,
      10.750567767952603,
      10.750556824671621,
      19.406250047427577,
      19.570736395269563,
      10.750571692626396,
      35.55044517715194,
      25.741496376099462,
      32.27454881721839,
      40.099884855854064,
      32.59181056679846,
      35.171765632473,
      26.73109346721796,
      19.55820573918477,
      26.480267204015618,
      37.975850641470046,
      10.750567906811561,
      16.69712797624442,
      38.12263388960257,
      34.11826479564145,
      10.750568624250754,
      32.24669022302163,
      27.455382270231286,
      36.54024534862194,
      42.97883899879707,
      26.37615116765394,
      44.008114610578346,
      29.297657412890217,
      19.66166204060213,
      34.066952161162874,
      34.914181542783524,
      43.50200630216885,
      33.322453502670335,
      44.148730926010614,
      31.53004827381637,
      55.16139861284623,
      45.58653919986051,
      24.798661361553027,
      39.659227559676786,
      52.24838961527165,
      41.91830348822903,
      22.250466484701178,
      28.46220175138703,
      35.685040835197995,
      20.27213504202511,
      35.26949146423682,
      47.77720821810368,
      36.7358750214525,
      16.697127976318498,
      44.92751808356387,
      22.890592529097866,
      30.98903234971109,
      25.032662673123014,
      30.986857496135574,
      36.43426252643936,
      28.737856151890817,
      10.795240121896194,
      22.798661362550625,
      41.435950717222894,
      39.25380357687375,
      56.02434526404109,
      33.39541365646836,
      21.01226142783603,
      24.344933104632688,
      53.48092655283094,
      16.69712797648588,
      53.06821483846586,
      31.0140507729302,
      26.457854154535394,
      29.417933953120762,
      53.9503587085585,
      17.49759608005118,
      44.65544072237847,
      116.32014237114073,
      19.51327893694669,
      31.059938840102067,
      49.08270617809784
    ],
    "group_enabled": true,
    "group_bics": {
      "Control": [
        16.69712797624402,
        39.325143052309755,
        26.15556327766344,
        37.808766358304254,
        22.428394321285523,
        32.48801887927587,
        10.750569913472921,
        32.66986938383032,
        10.7505568467683,
        30.43610843101757,
        21.3863609537128,
        22.195904144240075,
        26.897290565594286,
        10.750564924219212,
        10.750556822673575,
        10.750567767952603,
        10.750556824671621,
        19.406250047427577,
        19.570736395269563,
        10.750571692626396,
        35.55044517715194,
        25.741496376099462,
        32.27454881721839,
        40.099884855854064,
        32.59181056679846,
        35.171765632473,
        26.73109346721796,
        19.55820573918477,
        26.480267204015618,
        37.975850641470046,
        10.750567906811561,
        16.69712797624442,
        38.12263388960257,
        34.11826479564145,
        10.750568624250754,
        32.24669022302163,
        27.455382270231286,
        36.54024534862194,
        42.97883899879707,
        26.37615116765394,
        44.008114610578346,
        29.297657412890217,
        19.66166204060213
      ],
      "Cocaine": [
        34.066952161162874,
        34.914181542783524,
        43.50200630216885,
        33.322453502670335,
        44.148730926010614,
        31.53004827381637,
        55.16139861284623,
        45.58653919986051,
        24.798661361553027,
        39.659227559676786,
        52.24838961527165,
        41.91830348822903,
        22.250466484701178,
        28.46220175138703,
        35.685040835197995,
        20.27213504202511,
        35.26949146423682,
        47.77720821810368,
        36.7358750214525,
        16.697127976318498,
        44.92751808356387,
        22.890592529097866,
        30.98903234971109,
        25.032662673123014,
        30.986857496135574,
        36.43426252643936,
        28.737856151890817,
        10.795240121896194,
        22.798661362550625,
        41.435950717222894,
        39.25380357687375,
        56.02434526404109,
        33.39541365646836,
        21.01226142783603,
        24.344933104632688,
        53.48092655283094,
        16.69712797648588,
        53.06821483846586,
        31.0140507729302,
        26.457854154535394,
        29.417933953120762,
        53.9503587085585,
        17.49759608005118,
        44.65544072237847,
        116.32014237114073,
        19.51327893694669,
        31.059938840102067,
        49.08270617809784
      ]
    },
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- bias: r = 0.760\n- sensitivity_prop: r = 0.118\n- alpha_log_ineq_prop: r = 0.488",
  "previous_models": [
    "Specification: total_tokens = token_self + token_opp\ncontribution_ratio = token_self / total_tokens if total_tokens > 0 else 0.5\ndeserved_perc = contribution_ratio\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0\ninequity_perc = max(0, deserved_perc - split_perc)\nepsilon = 1e-6\nlog_inequity_perc = log(inequity_perc + epsilon)\nUtility = bias + sensitivity_prop * split_perc - alpha_log_ineq_prop * log_inequity_perc\nSummary: A utility model predicting responder acceptance. Utility is calculated as a linear combination of a baseline acceptance bias, the proportion of the total pot offered to the participant, and the negative logarithm of the proportional disadvantageous inequity (the difference between the proportion deserved based on contribution and the proportion offered, floored at zero). The log transformation on inequity aims to capture diminishing sensitivity to unfairness. The model has three learnable parameters: bias, sensitivity_prop (for offered proportion), and alpha_log_ineq_prop (for log-proportional-inequity aversion).\nTarget Variable: accept\nPrediction Type: utility\nBIC: 31.199781898764737\nOverall Accuracy: 0.8208\nGroup Accuracies:\n- Control: 0.8605\n- Cocaine: 0.7853\n\nParameter Recovery:\n- bias: r = 0.760\n- sensitivity_prop: r = 0.118\n- alpha_log_ineq_prop: r = 0.488"
  ]
}