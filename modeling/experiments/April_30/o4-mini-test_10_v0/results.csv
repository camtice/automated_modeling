run_number,average_bic,bic_control,bic_cocaine,overall_accuracy,model_specification,model_summary,version,instructions_used,intercept_recovery,weight_gain_recovery,weight_fairness_recovery,alpha_recovery,beta_recovery,bias_recovery,slope_recovery,disadvantage_aversion_recovery,advantageous_aversion_recovery,kappa_recovery,beta_bias_recovery,beta_fair_recovery,alpha_disadvantage_recovery,beta_advantage_recovery,theta0_recovery,beta_money_recovery,alpha_param_recovery,beta_param_recovery
3,30.475495580577572,27.527065362141375,33.11679765126,0.7905982905982906,U = bias + slope * (split_perc_self - 50),"A logistic responder model where the acceptance utility is a linear function of how the offered percentage deviates from a 50% fairness reference, plus a bias term. Two learnable parameters capture baseline acceptance bias and sensitivity to fairness deviations.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,0.7589075315578524,0.7635722984173262,,,,,,,,,,,
5,32.50490404236921,27.063498720334312,37.37949631002547,0.7710622710622711,U = bias + kappa * (share_prop - cont_prop),Utility is modeled as an intercept plus a sensitivity‐weighted fairness deviation between the offered share and the share justified by contributions; a logistic of this utility yields the probability of acceptance.,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,0.9493055396785194,,,,0.828890375721864,,,,,,,,
6,32.86197367027403,27.58098500048462,37.59285935362705,0.7655677655677656,U = beta_bias + beta_fair * (split_self - combined_earning * token_self / (token_self + token_opp)),Utility of accepting is modeled as a baseline bias plus a fairness term representing deviation of the offered share from a reference share proportional to contributions. Acceptance probability is given by a logistic function of this utility.,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,0.8485862053561728,0.7636547360849449,,,,,,
1,33.255554433168605,28.760719520043512,37.2821773761765,0.7817460317460317,U_accept = intercept + weight_gain * share_self_frac - weight_fairness * inequity,"Utility of acceptance is a linear function of the fraction of the pot offered and the absolute deviation from the participant’s deserved share, with three free parameters (baseline bias, gain weight, fairness penalty) fit to maximize choice likelihood under a logistic choice rule.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.9047404051147052,0.2816250808217052,0.3234908676436692,,,,,,,,,,,,,,,
9,34.208841881455356,29.726246578572034,38.224500173621664,0.782051282051282,U_accept = intercept + beta_money * split_self + beta_fair * (split_self/combined_earning - token_self/(token_self + token_opp)),"A logistic acceptance model where utility is the sum of an intercept, the participant's monetary gain weighted by beta_money, and the fairness deviation (their share minus their contribution proportion) weighted by beta_fair. Positive utility increases acceptance probability above 50%.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.622758459739747,,,,,,,,,,,0.21202234261095465,,,,0.5027016094409716,,
4,35.79623324148796,31.61305225221991,39.54366621104059,0.78998778998779,"U_accept = split_self - disadvantage_aversion * max(split_opp - split_self, 0) - advantageous_aversion * max(split_self - split_opp, 0)","Responder utility equals own monetary gain penalized by sensitivity to disadvantageous and advantageous inequity, mapped via logistic to acceptance probability.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,0.8234004199029024,0.03607341638493823,,,,,,,,,
7,36.122580430119484,32.97077216297741,38.946075336100925,0.7957875457875458,"U = intercept + split_self - alpha_disadvantage * max(split_opp - split_self, 0) - beta_advantage * max(split_self - split_opp, 0)",Utility of acceptance equals a baseline bias plus own share minus inequity‐aversion penalties: one for disadvantageous splits (opponent’s share exceeds own) and one for advantageous splits (own share exceeds opponent’s).,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",0.7885667608313962,,,,,,,,,,,,0.7226864238552292,0.0875010113721164,,,,
8,36.122580430536864,32.97077216397016,38.94607533600287,0.7887667887667887,"U = theta0 + split_self - alpha * max(combined_earning - 2 * split_self, 0) - beta * max(2 * split_self - combined_earning, 0)",Utility for acceptance combines the received share and a baseline with asymmetric penalties for disadvantageous and advantageous inequity relative to an equal split.,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,0.6835203073343888,0.26169223266412545,,,,,,,,,,0.819047238425693,,,
2,36.12258043162159,32.97077216427109,38.94607533778976,0.7948717948717948,"U = split_self - alpha * max(split_opp - split_self, 0) - beta * max(split_self - split_opp, 0) + bias","Utility is linear in the participant's share and penalized by inequity terms: disadvantageous offers are weighted by alpha, advantageous ones by beta, plus a constant bias. The resulting utility is mapped via a logistic function to predict acceptance.",v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,0.7822742939637722,-0.09438267994938644,0.8593029133925643,,,,,,,,,,,,
10,37.04285410431177,29.70691321096704,43.614634487933095,0.7912087912087912,"entitlement = token_self/(token_self + token_opp) * combined_earning  
U_accept = split_self - alpha_param * max(entitlement - split_self, 0) - beta_param * max(split_self - entitlement, 0)",Responder utility equals the offered share minus inequity costs: penalizing offers below the participant’s fair entitlement by alpha_param and offers above entitlement by beta_param. Probability of acceptance is a logistic transform of U_accept.,v0,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",,,,,,,,,,,,,,,,,0.9183316244702817,0.813924118757427
