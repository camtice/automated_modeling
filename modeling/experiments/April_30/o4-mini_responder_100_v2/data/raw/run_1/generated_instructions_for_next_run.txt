

Be creative and don’t fall back on the first linear combination that comes to mind. Aim for a compact, interpretable model (no more than 3 learnable parameters) that captures both self-interest and fairness sensitivity without introducing strong collinearity. In your design, please:

1. Reason step by step about  
   a. The core psychological drivers (e.g. self-interest, disadvantageous/advantageous inequity aversion, reference points)  
   b. How these drivers might interact or trade off  
   c. Suitable transformations (e.g. ratios, differences, non‐linear curvature) or orthogonalization to keep predictors independent  

2. Propose a mathematical form between <MODEL>…</MODEL> that:  
   • Uses at most three learnable parameters (including an intercept)  
   • Defines a fairness metric that is orthogonal or weakly correlated with absolute payoff (e.g. standardize each predictor or regress one predictor on another and use residuals)  
   • Clearly bounds each learnable parameter within a finite range (no infinities)  

3. Standardize or normalize all continuous predictors (e.g. z-scoring or scaling into [–1,1]) so that parameters have similar units and are identifiable.

4. Include, in your variable specification (<VARIABLES>…</VARIABLES>):  
   • A plan for testing parameter recovery (e.g. “simulate data from known parameter values, re-fit the model, and check that each recovery correlation r > 0.7”)  
   • Explicit, tight but plausible numeric bounds for each learnable parameter  
   • Distributional priors or initialization ranges  

5. Keep the model focused on predicting the binary responder choice (“accept”) via a logistic function (temperature fixed at 1).

Finally, in your <SUMMARY>…</SUMMARY>, briefly describe the psychological rationale, the predictors included, and why this specification should improve identifiability, BIC, and accuracy.