

New Instructions for Run 11:

1. Candidate Families (≤5 Learnable Parameters)  
   a. Quadratic‐Reference Model (3 params):  
      U = α + β·(z_share − 0.5) + β2·(z_share − 0.5)²  
   b. Piecewise‐Linear Inequity Model (4 params):  
      U = α + β_pos·max(z_share − 0.5,0) + β_neg·max(0.5 − z_share,0)  
   c. Saturating Fairness Model (5 params):  
      U = α + β·(z_share − 0.5) + γ·sign(z_share − 0.5)·[(|z_share − 0.5|^φ) / (|z_share − 0.5|^φ + ψ)]  

2. Feature Engineering & Orthogonalization  
   • Define contribution_share = token_self / (token_self + token_opp).  
   • Compute fairness_dev = (split_self/combined_earning) − contribution_share.  
   • Orthogonalize fairness_dev against z_share via Gram‐Schmidt; drop raw fairness_dev.  
   • Scale all features to [−1,1].  

3. Link Functions & Temperature  
   • Evaluate three links in parallel: logistic, probit, complementary‐log‐log.  
   • Fit a single temperature τ∈[0.1,2] per link.  
   • Use leave‐one‐subject‐out stacking to choose best link for final model.  

4. Priors, Bounds & Regularization  
   • All weights ∼ Normal(0,0.3), truncated to [−0.5,0.5].  
   • φ∈{1.0,2.0} (discrete) or ψ∈[0.1,5] Uniform, depending on family.  
   • Elastic‐Net penalty (L1 ratio=.7); tune global λ in recovery stage.  

5. Two‐Stage Simulation & Recovery  
   Stage 1: Simulate 2,000 synthetic datasets from priors; MAP estimation; compute Pearson r.  
   Stage 2: If any parameter r<0.80:  
     – Drop or fix the poorest‐recovering parameter (e.g. fix φ=1 or ψ=1)  
     – Refit until all remaining r≥0.80 or switch to simpler family.  

6. Validation & Model Selection  
   • Nested 10‐fold cross‐validation: report out‐of‐sample accuracy, log‐score, and calibration.  
   • Compute BIC, WAIC, LOO; require ≥7‐point BIC drop and ≥6% accuracy gain vs. baseline.  
   • Additionally report parameter‐recovery diagnostics for each fold.  

7. Deliverables  
   • <MODEL>…</MODEL>: Final chosen formula (no prose).  
   • <VARIABLES>…</VARIABLES>: Every feature and parameter with description, bounds, prior, source.  
   • <target_variable>accept</target_variable>  

8. Summary (<SUMMARY>…</SUMMARY>)  
   • State selected family and psychological story (e.g., diminishing‐sensitivity quadratic, piecewise inequity aversion, or saturating fairness).  
   • Emphasize strong shrinkage, narrow bounds, discrete φ or fixed curvature, elastic‐net, two‐stage recovery r≥0.80, and superior BIC/accuracy.  
   • Highlight novel elements: contribution‐based fairness, saturation function, alternative links, and dynamic penalty tuning.