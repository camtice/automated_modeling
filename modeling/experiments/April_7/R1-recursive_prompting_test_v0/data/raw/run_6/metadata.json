{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\n\nOkay, let's analyze the previous results. The last model had a BIC of around 33.94, which is okay, but there's room for improvement. The parameter recovery for alpha was decent (r=0.783), beta was excellent (0.956), and gamma was lower (0.682). The accuracy was around 0.785. The main area to improve is gamma's recovery and possibly BIC by simplifying or enhancing the model's structure.\n\nThe previous model used a linear combination of equity and equality with separate parameters for positive and negative deviations. However, gamma's lower recovery suggests that the baseline bias isn't being captured well. Maybe gamma is conflated with other parameters. To address this, perhaps introduce a non-linear interaction between gamma and the deviation terms. For example, gamma could modulate the baseline differently based on the direction of the deviation.\n\nAnother angle: The model could incorporate trial_type information to adjust alpha dynamically. For instance, in trials where the participant contributed more (trial_type=3), alpha might be more influential. This could be done by scaling alpha with a function of trial_type without adding new parameters. For example, alpha_effective = alpha * (1 + (trial_type == 3)), but since trial_type is a data variable, this doesn't add parameters. This could help alpha's recovery by making it context-sensitive.\n\nAlternatively, use a softmax function for alpha to ensure it stays within [0,1] while allowing it to vary based on trial features. For example, alpha = sigmoid(theta * (token_self - token_opp)), where theta is a learnable parameter. This would tie alpha to the actual contribution difference, making it more interpretable and improving recovery. However, this introduces a new parameter (theta), so we need to replace one of the existing parameters. Maybe replace gamma with theta, but that might reduce accuracy.\n\nWait, the constraint is to keep three parameters. So, perhaps replace gamma with a parameter that controls the dynamic weighting of alpha. For example, U = beta * [max(deviation,0) + gamma * min(deviation,0)] + delta, but that adds delta. Not allowed.\n\nAnother idea: Use a single parameter to control the asymmetry between positive and negative deviations. For example, U = beta * (split_self - fair_ref) + gamma * (split_self - fair_ref) * (split_self > fair_ref). This way, gamma only affects positive deviations, creating an interaction. But this might not capture the full asymmetry.\n\nAlternatively, model the utility as a piecewise function where beta applies to positive deviations and gamma to negative, but without using max/min functions. For example, U = beta * (split_self - fair_ref) * (split_self >= fair_ref) + gamma * (split_self - fair_ref) * (split_self < fair_ref). This explicitly separates the effects, which could help in parameter recovery.\n\nAdditionally, consider the role of combined_earning. The current model uses 0.5 * combined_earning for equality, but maybe participants have a different equality reference, like 50% of the combined earning scaled by a parameter. However, that would add another parameter. Instead, perhaps allow alpha to also scale the equality term nonlinearly. For example, fair_ref = alpha * 3 * token_self + (1 - alpha) * (0.5 * combined_earning)^theta, where theta is a learnable parameter. But again, this adds a parameter.\n\nGiven the three-parameter limit, the best approach might be to refine the asymmetry in the current model. Perhaps introduce a curvature parameter by applying a power function to the deviation. For example, U = beta * (split_self - fair_ref)^2 + gamma. This quadratic term could capture diminishing or increasing sensitivity to larger deviations. However, this might worsen BIC due to increased complexity without sufficient benefit.\n\nAlternatively, use an absolute value with separate coefficients: U = beta * |split_self - fair_ref| + gamma * sign(split_self - fair_ref). This separates the magnitude and direction effects, allowing beta to control sensitivity to deviation size and gamma to baseline direction bias. This could disentangle gamma's role, improving its recovery.\n\nIn summary, the key improvements could be:\n\n1. Explicitly separate magnitude and direction of deviations into different parameters.\n2. Introduce dynamic weighting of alpha based on trial features (like contribution ratio) without adding parameters.\n3. Apply nonlinear transformations to deviations to better capture human sensitivity.\n\nThese adjustments should enhance parameter identifiability, especially for gamma and alpha, leading to better recovery and potentially lower BIC.\n</think>\n\n**Instructions for Run 6:**  \n\nDesign a model that **explicitly decouples magnitude and direction sensitivity** while incorporating **dynamic fairness weighting**. Use these strategies:  \n\n1. **Directional Baseline Bias:** Replace the global bias term (\u03b3) with a parameter that *only activates when offers fall below the fairness reference*. For example:  \n   `U = \u03b2 * |deviation| + \u03b8 * (deviation < 0)`  \n   where \u03b8 acts as a rejection penalty for unfair offers.  \n\n2. **Contribution-Weighted \u03b1:** Dynamically scale \u03b1 by the participant\u2019s relative contribution:  \n   `\u03b1_effective = \u03b1 * (token_self / (token_self + token_opp))`  \n   This grounds fairness expectations in objective contribution ratios without new parameters.  \n\n3. **Diminishing Sensitivity:** Apply a logarithmic or square root transformation to |deviation| to capture human nonlinear valuation (e.g., `log(1 + |deviation|)`).  \n\n**Constraints:**  \n- Use \u22643 learnable parameters (e.g., \u03b1, \u03b2, \u03b8).  \n- Ensure parameters have distinct roles (magnitude vs. directional bias vs. fairness type).  \n- Bounds: Keep \u03b1 \u2208 [0,1], \u03b2 \u2208 [0,10], \u03b8 \u2208 [-5,0] to reflect penalty semantics.  \n\n**Goal:** Improve \u03b3/\u03b8 recovery (r > 0.8) while maintaining BIC < 33.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\n\nOkay, let's analyze the previous results. The last model had a BIC of around 33.94, which is okay, but there's room for improvement. The parameter recovery for alpha was decent (r=0.783), beta was excellent (0.956), and gamma was lower (0.682). The accuracy was around 0.785. The main area to improve is gamma's recovery and possibly BIC by simplifying or enhancing the model's structure.\n\nThe previous model used a linear combination of equity and equality with separate parameters for positive and negative deviations. However, gamma's lower recovery suggests that the baseline bias isn't being captured well. Maybe gamma is conflated with other parameters. To address this, perhaps introduce a non-linear interaction between gamma and the deviation terms. For example, gamma could modulate the baseline differently based on the direction of the deviation.\n\nAnother angle: The model could incorporate trial_type information to adjust alpha dynamically. For instance, in trials where the participant contributed more (trial_type=3), alpha might be more influential. This could be done by scaling alpha with a function of trial_type without adding new parameters. For example, alpha_effective = alpha * (1 + (trial_type == 3)), but since trial_type is a data variable, this doesn't add parameters. This could help alpha's recovery by making it context-sensitive.\n\nAlternatively, use a softmax function for alpha to ensure it stays within [0,1] while allowing it to vary based on trial features. For example, alpha = sigmoid(theta * (token_self - token_opp)), where theta is a learnable parameter. This would tie alpha to the actual contribution difference, making it more interpretable and improving recovery. However, this introduces a new parameter (theta), so we need to replace one of the existing parameters. Maybe replace gamma with theta, but that might reduce accuracy.\n\nWait, the constraint is to keep three parameters. So, perhaps replace gamma with a parameter that controls the dynamic weighting of alpha. For example, U = beta * [max(deviation,0) + gamma * min(deviation,0)] + delta, but that adds delta. Not allowed.\n\nAnother idea: Use a single parameter to control the asymmetry between positive and negative deviations. For example, U = beta * (split_self - fair_ref) + gamma * (split_self - fair_ref) * (split_self > fair_ref). This way, gamma only affects positive deviations, creating an interaction. But this might not capture the full asymmetry.\n\nAlternatively, model the utility as a piecewise function where beta applies to positive deviations and gamma to negative, but without using max/min functions. For example, U = beta * (split_self - fair_ref) * (split_self >= fair_ref) + gamma * (split_self - fair_ref) * (split_self < fair_ref). This explicitly separates the effects, which could help in parameter recovery.\n\nAdditionally, consider the role of combined_earning. The current model uses 0.5 * combined_earning for equality, but maybe participants have a different equality reference, like 50% of the combined earning scaled by a parameter. However, that would add another parameter. Instead, perhaps allow alpha to also scale the equality term nonlinearly. For example, fair_ref = alpha * 3 * token_self + (1 - alpha) * (0.5 * combined_earning)^theta, where theta is a learnable parameter. But again, this adds a parameter.\n\nGiven the three-parameter limit, the best approach might be to refine the asymmetry in the current model. Perhaps introduce a curvature parameter by applying a power function to the deviation. For example, U = beta * (split_self - fair_ref)^2 + gamma. This quadratic term could capture diminishing or increasing sensitivity to larger deviations. However, this might worsen BIC due to increased complexity without sufficient benefit.\n\nAlternatively, use an absolute value with separate coefficients: U = beta * |split_self - fair_ref| + gamma * sign(split_self - fair_ref). This separates the magnitude and direction effects, allowing beta to control sensitivity to deviation size and gamma to baseline direction bias. This could disentangle gamma's role, improving its recovery.\n\nIn summary, the key improvements could be:\n\n1. Explicitly separate magnitude and direction of deviations into different parameters.\n2. Introduce dynamic weighting of alpha based on trial features (like contribution ratio) without adding parameters.\n3. Apply nonlinear transformations to deviations to better capture human sensitivity.\n\nThese adjustments should enhance parameter identifiability, especially for gamma and alpha, leading to better recovery and potentially lower BIC.\n</think>\n\n**Instructions for Run 6:**  \n\nDesign a model that **explicitly decouples magnitude and direction sensitivity** while incorporating **dynamic fairness weighting**. Use these strategies:  \n\n1. **Directional Baseline Bias:** Replace the global bias term (\u03b3) with a parameter that *only activates when offers fall below the fairness reference*. For example:  \n   `U = \u03b2 * |deviation| + \u03b8 * (deviation < 0)`  \n   where \u03b8 acts as a rejection penalty for unfair offers.  \n\n2. **Contribution-Weighted \u03b1:** Dynamically scale \u03b1 by the participant\u2019s relative contribution:  \n   `\u03b1_effective = \u03b1 * (token_self / (token_self + token_opp))`  \n   This grounds fairness expectations in objective contribution ratios without new parameters.  \n\n3. **Diminishing Sensitivity:** Apply a logarithmic or square root transformation to |deviation| to capture human nonlinear valuation (e.g., `log(1 + |deviation|)`).  \n\n**Constraints:**  \n- Use \u22643 learnable parameters (e.g., \u03b1, \u03b2, \u03b8).  \n- Ensure parameters have distinct roles (magnitude vs. directional bias vs. fairness type).  \n- Bounds: Keep \u03b1 \u2208 [0,1], \u03b2 \u2208 [0,10], \u03b8 \u2208 [-5,0] to reflect penalty semantics.  \n\n**Goal:** Improve \u03b3/\u03b8 recovery (r > 0.8) while maintaining BIC < 33.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this step by step. The goal is to design a model that predicts whether a responder accepts or rejects a proposal based on the given dataset. The model needs to focus on responder behavior, so I'll filter the data where trial_role is 1 (responder). \n\nFirst, I need to identify the key variables that influence the responder's decision. The main target is 'accept', which is binary. The model should predict the utility of accepting, which then translates into a probability via a logistic function.\n\nThe variables provided include token_self, token_opp, combined_earning, split_self, split_opp, etc. Since the task mentions that fairness isn't just about equal splits but also considers contributions, the model should account for both equity (based on contributions) and equality (equal split).\n\nI recall that in ultimatum games, people often compare the offer to what they consider fair. Here, the fair reference could be a combination of equity (based on tokens contributed) and equality (50% of combined earnings). Let's define the fair reference as a weighted average between these two. Let\u2019s call the weight alpha. So, fair_ref = alpha * (3 * token_self) + (1 - alpha) * 0.5 * combined_earning. Here, 3*token_self is the participant's contribution in \u00a3, since each token is \u00a33. The combined_earning is total money, so half would be the equality reference.\n\nThe utility of an offer could then be the difference between the proposed split_self and this fair_ref. If the offer is higher than fair_ref, positive utility; if lower, negative. But people might have different sensitivities to gains and losses. So maybe we need separate parameters for positive and negative deviations. Let's say beta_plus for positive deviations (split_self >= fair_ref) and beta_minus for negative (split_self < fair_ref). However, to keep the number of parameters manageable, perhaps use a single beta but allow asymmetric sensitivity via a parameter that scales the negative deviation more. Alternatively, model the utility as beta*(split_self - fair_ref) + gamma, where gamma is a baseline bias towards acceptance or rejection.\n\nWait, the problem states that the utility should be such that less than 0 utility means less than 50% chance of accepting. So the probability of accepting is logistic(utility). So the utility function must capture how favorable the offer is relative to the responder's fairness criteria.\n\nAnother angle: The responder's decision could depend on how much the offer deviates from their perceived fair share. The fair share is a mix of their contribution-based equity and the equal split. The parameters to learn would be alpha (weighting equity vs equality), beta (sensitivity to deviation), and maybe a baseline term gamma (bias towards accept/reject regardless of fairness).\n\nSo, the utility U = beta*(split_self - fair_ref) + gamma. If U > 0, higher chance to accept. But to account for different sensitivity when the offer is below vs above fair_ref, maybe split beta into beta_plus and beta_minus. However, that adds another parameter. Since the user wants the model to have learnable parameters with finite bounds, perhaps stick to three parameters: alpha, beta, gamma.\n\nWait, the example in the task had three parameters. Let me check the constraints again. The model must predict responder behavior (accept), use variables appropriately, and have learnable parameters with bounds. The utility can be unbounded, but parameters need bounds.\n\nSo, formalizing:\n\nFair reference: fair_ref = alpha*(3*token_self) + (1-alpha)*(0.5*combined_earning)\n\nDeviation: deviation = split_self - fair_ref\n\nUtility U = beta * deviation + gamma\n\nBut perhaps people are more sensitive to negative deviations (offers below fair_ref) than positive. So maybe U = beta_pos * max(deviation, 0) + beta_neg * min(deviation, 0) + gamma. But that introduces two betas. To limit parameters, maybe use a single beta but allow the sign of deviation to affect the utility nonlinearly. Alternatively, use a single beta and let gamma capture the baseline bias.\n\nAlternatively, model U = beta*(split_self - fair_ref) + gamma. Here, beta is sensitivity to deviation, gamma is baseline bias. If gamma is positive, it's a tendency to accept even if the offer is slightly below fair_ref.\n\nBut the problem states that the utility should be such that U < 0 implies less than 50% chance. So the logistic function would be p(accept) = 1 / (1 + exp(-U)). So when U is negative, the probability is below 0.5.\n\nNow, considering the parameters:\n\n- alpha: determines the weight between equity and equality in fair_ref. Should be between 0 and 1.\n\n- beta: sensitivity to the deviation. Since the utility is linear in deviation, beta can be any real number, but for bounds, maybe set it between -10 and 10, but realistically, it's positive (higher deviation increases utility). So beta in [0, 10].\n\n- gamma: baseline bias. If positive, increases acceptance propensity. Bounds could be [-5,5], but need to think. If gamma is negative, it's a baseline tendency to reject, all else equal.\n\nWait, but the example in the task had parameters with ranges. Let's define:\n\nalpha: between 0 and 1 (inclusive), as it's a weight.\n\nbeta: positive, so [0, 10], as higher sensitivity.\n\ngamma: any real number, but to bound it, maybe [-5,5]. But the problem says parameters must have finite bounds. So gamma in [-5,5].\n\nBut the user said \"the utility variable may be unbounded\". So the parameters can have bounds, but the utility itself can be anything.\n\nSo the model would be:\n\nU = beta * (split_self - [alpha*(3*token_self) + (1-alpha)*(0.5*combined_earning)]) + gamma\n\nThen, p(accept) = 1 / (1 + exp(-U))\n\nThis model uses three parameters: alpha, beta, gamma.\n\nNow, variable descriptions:\n\n- alpha: learnable, [0,1], weight between equity and equality.\n\n- beta: learnable, [0,10], sensitivity to deviation.\n\n- gamma: learnable, [-5,5], baseline bias.\n\nOther variables:\n\nsplit_self: from data.\n\ntoken_self: from data.\n\ncombined_earning: from data.\n\n3*token_self is calculated as the participant's contribution.\n\n0.5*combined_earning is the equality reference.\n\nSo in the variables section, these would be data or calculated.\n\nNow, check if all variables in the model are accounted for.\n\nIn the model formula:\n\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n\nVariables used: split_self, token_self, combined_earning.\n\nThese are all present in the dataset.\n\nThe parameters are alpha, beta, gamma.\n\nThis should satisfy the requirements.\n\nNow, the target variable is 'accept', which is binary.\n\nThe model's utility function U is used in a logistic regression to predict the probability of acceptance.\n\nNow, the variable descriptions:\n\nFor the JSON:\n\nvariables: {\n  \"alpha\": {\n    \"description\": \"Weighting factor between equity (own contribution) and equality (50% split) in fairness reference\",\n    \"range\": {\"min\": 0, \"max\": 1, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"beta\": {\n    \"description\": \"Sensitivity to deviation from fairness reference\",\n    \"range\": {\"min\": 0, \"max\": 10, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"gamma\": {\n    \"description\": \"Baseline bias towards acceptance (positive) or rejection (negative)\",\n    \"range\": {\"min\": -5, \"max\": 5, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"split_self\": {\n    \"description\": \"Proposed share for the participant in \u00a3\",\n    \"source\": \"data\"\n  },\n  \"token_self\": {\n    \"description\": \"Number of tokens found by the participant\",\n    \"source\": \"data\"\n  },\n  \"combined_earning\": {\n    \"description\": \"Total money earned in \u00a3 (3 * sum of tokens)\",\n    \"source\": \"data\"\n  },\n  \"fair_ref\": {\n    \"description\": \"Fairness reference as weighted average of equity and equality\",\n    \"source\": \"calculated\",\n    \"range\": {\"min\": \"-inf\", \"max\": \"inf\"}\n  },\n  \"deviation\": {\n    \"description\": \"Difference between proposed share and fairness reference\",\n    \"source\": \"calculated\",\n    \"range\": {\"min\": \"-inf\", \"max\": \"inf\"}\n  }\n}\n\nBut according to the instructions, only variables used in the model formula need to be in the variables section. The calculated variables like fair_ref and deviation may not need to be listed if they are intermediate steps. However, the example included all variables, even calculated ones. Let me check the example.\n\nIn the example, variables like E and N were included even if they were data or calculated. So perhaps we should include all variables present in the model formula, even if they are calculated from others.\n\nWait, in the model formula, the variables are split_self, token_self, combined_earning, and the parameters alpha, beta, gamma. The fair_ref and deviation are intermediate terms but not explicitly in the model formula as variables. The model formula is written as a single equation.\n\nSo the model is:\n\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n\nThus, the variables directly used in the formula are split_self, token_self, combined_earning, and the parameters alpha, beta, gamma. The other terms (3*token_self and 0.5*combined_earning) are derived from existing variables but don't need to be listed as separate variables since they are calculated from token_self and combined_earning.\n\nTherefore, in the variables section, we list alpha, beta, gamma as learnable parameters, and split_self, token_self, combined_earning as data variables. The rest are calculated but not explicitly listed unless they are part of the model's formula as separate variables.\n\nWait, the example included variables like E and N which were data and calculated. So perhaps any variable that appears in the model equation must be listed. In this case, the equation includes split_self, token_self, combined_earning, alpha, beta, gamma. The 3 and 0.5 are constants, so they don't need variables. So the variables to list are:\n\n- split_self (data)\n- token_self (data)\n- combined_earning (data)\n- alpha (learnable)\n- beta (learnable)\n- gamma (learnable)\n\nThe fair_ref is part of the equation but is a combination of variables and parameters, so it's calculated but not a separate variable in the JSON unless it's explicitly in the model formula. Since the model formula is written as a single line without intermediate variables, perhaps only the variables directly present in the formula are listed.\n\nSo the JSON would include the three parameters and the three data variables.\n\nNow, the summary should describe the model concisely. The model combines equity and equality into a fairness reference, computes deviation from the offer, and uses sensitivity and baseline bias to determine utility.\n\nPutting it all together.\n</think>\n\n<MODEL>\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n</MODEL>\n\n<target_variable>accept</target_variable>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"alpha\": {\n      \"description\": \"Weighting between equity (own contribution) and equality (50% split) in fairness reference calculation\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to deviation from fairness reference\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"gamma\": {\n      \"description\": \"Baseline acceptance bias (positive values increase acceptance propensity)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in pounds\",\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token count (contribution to shared pot)\",\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (3*(token_self + token_opp))\",\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<SUMMARY>\nA fairness-weighted utility model where responders evaluate offers against a dynamic reference combining equity (proportional to contributions) and equality (50% split). Utility depends on linear sensitivity to deviations from this reference plus a baseline bias parameter. Three learnable parameters control the equity-equality tradeoff (\u03b1), deviation sensitivity (\u03b2), and baseline acceptance tendency (\u03b3).\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['alpha', 'beta', 'gamma']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"alpha\": {\n      \"description\": \"Weighting between equity (own contribution) and equality (50% split) in fairness reference calculation\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to deviation from fairness reference\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"gamma\": {\n      \"description\": \"Baseline acceptance bias (positive values increase acceptance propensity)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in pounds\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token count (contribution to shared pot)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (3*(token_self + token_opp))\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, alpha=0.5, beta=1, gamma=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        utility = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 1, \"group\": \"control\", \"trial_number\": 1, \"trial_type\": 0, \"trial_role\": 1, \"token_opp\": 10, \"token_self\": 10, \"combined_earning\": 60, \"split_opp\": 15.0, \"split_self\": 45.0, \"splitperc_opp\": 25, \"splitperc_self\": 75, \"accept\": 1.0, \"accepted_amount\": 45.0, \"accepted_perc\": 75.0, \"proposed_perc\": 75.0, \"proposed_amount\": 45.0}, {\"ID\": 2, \"group\": \"control\", \"trial_number\": 2, \"trial_type\": 0, \"trial_role\": 1, \"token_opp\": 10, \"token_self\": 6, \"combined_earning\": 48, \"split_opp\": 23.0, \"split_self\": 25.0, \"splitperc_opp\": 48, \"splitperc_self\": 52, \"accept\": 0.0, \"accepted_amount\": 0.0, \"accepted_perc\": 0.0, \"proposed_perc\": 52.0, \"proposed_amount\": 25.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744017978.505118
    }
  ],
  "learnable_parameters": {
    "alpha": {
      "description": "Weighting between equity (own contribution) and equality (50% split) in fairness reference calculation",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Linear sensitivity to deviation from fairness reference",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "gamma": {
      "description": "Baseline acceptance bias (positive values increase acceptance propensity)",
      "range": {
        "min": -5,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma",
  "variable_descriptions": {
    "alpha": {
      "description": "Weighting between equity (own contribution) and equality (50% split) in fairness reference calculation",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Linear sensitivity to deviation from fairness reference",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "gamma": {
      "description": "Baseline acceptance bias (positive values increase acceptance propensity)",
      "range": {
        "min": -5,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for participant in pounds",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant's token count (contribution to shared pot)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "Total money in shared pot (3*(token_self + token_opp))",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A fairness-weighted utility model where responders evaluate offers against a dynamic reference combining equity (proportional to contributions) and equality (50% split). Utility depends on linear sensitivity to deviations from this reference plus a baseline bias parameter. Three learnable parameters control the equity-equality tradeoff (\u03b1), deviation sensitivity (\u03b2), and baseline acceptance tendency (\u03b3).",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this step by step. The goal is to design a model that predicts whether a responder accepts or rejects a proposal based on the given dataset. The model needs to focus on responder behavior, so I'll filter the data where trial_role is 1 (responder). \n\nFirst, I need to identify the key variables that influence the responder's decision. The main target is 'accept', which is binary. The model should predict the utility of accepting, which then translates into a probability via a logistic function.\n\nThe variables provided include token_self, token_opp, combined_earning, split_self, split_opp, etc. Since the task mentions that fairness isn't just about equal splits but also considers contributions, the model should account for both equity (based on contributions) and equality (equal split).\n\nI recall that in ultimatum games, people often compare the offer to what they consider fair. Here, the fair reference could be a combination of equity (based on tokens contributed) and equality (50% of combined earnings). Let's define the fair reference as a weighted average between these two. Let\u2019s call the weight alpha. So, fair_ref = alpha * (3 * token_self) + (1 - alpha) * 0.5 * combined_earning. Here, 3*token_self is the participant's contribution in \u00a3, since each token is \u00a33. The combined_earning is total money, so half would be the equality reference.\n\nThe utility of an offer could then be the difference between the proposed split_self and this fair_ref. If the offer is higher than fair_ref, positive utility; if lower, negative. But people might have different sensitivities to gains and losses. So maybe we need separate parameters for positive and negative deviations. Let's say beta_plus for positive deviations (split_self >= fair_ref) and beta_minus for negative (split_self < fair_ref). However, to keep the number of parameters manageable, perhaps use a single beta but allow asymmetric sensitivity via a parameter that scales the negative deviation more. Alternatively, model the utility as beta*(split_self - fair_ref) + gamma, where gamma is a baseline bias towards acceptance or rejection.\n\nWait, the problem states that the utility should be such that less than 0 utility means less than 50% chance of accepting. So the probability of accepting is logistic(utility). So the utility function must capture how favorable the offer is relative to the responder's fairness criteria.\n\nAnother angle: The responder's decision could depend on how much the offer deviates from their perceived fair share. The fair share is a mix of their contribution-based equity and the equal split. The parameters to learn would be alpha (weighting equity vs equality), beta (sensitivity to deviation), and maybe a baseline term gamma (bias towards accept/reject regardless of fairness).\n\nSo, the utility U = beta*(split_self - fair_ref) + gamma. If U > 0, higher chance to accept. But to account for different sensitivity when the offer is below vs above fair_ref, maybe split beta into beta_plus and beta_minus. However, that adds another parameter. Since the user wants the model to have learnable parameters with finite bounds, perhaps stick to three parameters: alpha, beta, gamma.\n\nWait, the example in the task had three parameters. Let me check the constraints again. The model must predict responder behavior (accept), use variables appropriately, and have learnable parameters with bounds. The utility can be unbounded, but parameters need bounds.\n\nSo, formalizing:\n\nFair reference: fair_ref = alpha*(3*token_self) + (1-alpha)*(0.5*combined_earning)\n\nDeviation: deviation = split_self - fair_ref\n\nUtility U = beta * deviation + gamma\n\nBut perhaps people are more sensitive to negative deviations (offers below fair_ref) than positive. So maybe U = beta_pos * max(deviation, 0) + beta_neg * min(deviation, 0) + gamma. But that introduces two betas. To limit parameters, maybe use a single beta but allow the sign of deviation to affect the utility nonlinearly. Alternatively, use a single beta and let gamma capture the baseline bias.\n\nAlternatively, model U = beta*(split_self - fair_ref) + gamma. Here, beta is sensitivity to deviation, gamma is baseline bias. If gamma is positive, it's a tendency to accept even if the offer is slightly below fair_ref.\n\nBut the problem states that the utility should be such that U < 0 implies less than 50% chance. So the logistic function would be p(accept) = 1 / (1 + exp(-U)). So when U is negative, the probability is below 0.5.\n\nNow, considering the parameters:\n\n- alpha: determines the weight between equity and equality in fair_ref. Should be between 0 and 1.\n\n- beta: sensitivity to the deviation. Since the utility is linear in deviation, beta can be any real number, but for bounds, maybe set it between -10 and 10, but realistically, it's positive (higher deviation increases utility). So beta in [0, 10].\n\n- gamma: baseline bias. If positive, increases acceptance propensity. Bounds could be [-5,5], but need to think. If gamma is negative, it's a baseline tendency to reject, all else equal.\n\nWait, but the example in the task had parameters with ranges. Let's define:\n\nalpha: between 0 and 1 (inclusive), as it's a weight.\n\nbeta: positive, so [0, 10], as higher sensitivity.\n\ngamma: any real number, but to bound it, maybe [-5,5]. But the problem says parameters must have finite bounds. So gamma in [-5,5].\n\nBut the user said \"the utility variable may be unbounded\". So the parameters can have bounds, but the utility itself can be anything.\n\nSo the model would be:\n\nU = beta * (split_self - [alpha*(3*token_self) + (1-alpha)*(0.5*combined_earning)]) + gamma\n\nThen, p(accept) = 1 / (1 + exp(-U))\n\nThis model uses three parameters: alpha, beta, gamma.\n\nNow, variable descriptions:\n\n- alpha: learnable, [0,1], weight between equity and equality.\n\n- beta: learnable, [0,10], sensitivity to deviation.\n\n- gamma: learnable, [-5,5], baseline bias.\n\nOther variables:\n\nsplit_self: from data.\n\ntoken_self: from data.\n\ncombined_earning: from data.\n\n3*token_self is calculated as the participant's contribution.\n\n0.5*combined_earning is the equality reference.\n\nSo in the variables section, these would be data or calculated.\n\nNow, check if all variables in the model are accounted for.\n\nIn the model formula:\n\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n\nVariables used: split_self, token_self, combined_earning.\n\nThese are all present in the dataset.\n\nThe parameters are alpha, beta, gamma.\n\nThis should satisfy the requirements.\n\nNow, the target variable is 'accept', which is binary.\n\nThe model's utility function U is used in a logistic regression to predict the probability of acceptance.\n\nNow, the variable descriptions:\n\nFor the JSON:\n\nvariables: {\n  \"alpha\": {\n    \"description\": \"Weighting factor between equity (own contribution) and equality (50% split) in fairness reference\",\n    \"range\": {\"min\": 0, \"max\": 1, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"beta\": {\n    \"description\": \"Sensitivity to deviation from fairness reference\",\n    \"range\": {\"min\": 0, \"max\": 10, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"gamma\": {\n    \"description\": \"Baseline bias towards acceptance (positive) or rejection (negative)\",\n    \"range\": {\"min\": -5, \"max\": 5, \"inclusive_min\": true, \"inclusive_max\": true},\n    \"learnable\": true,\n    \"source\": \"learnable\"\n  },\n  \"split_self\": {\n    \"description\": \"Proposed share for the participant in \u00a3\",\n    \"source\": \"data\"\n  },\n  \"token_self\": {\n    \"description\": \"Number of tokens found by the participant\",\n    \"source\": \"data\"\n  },\n  \"combined_earning\": {\n    \"description\": \"Total money earned in \u00a3 (3 * sum of tokens)\",\n    \"source\": \"data\"\n  },\n  \"fair_ref\": {\n    \"description\": \"Fairness reference as weighted average of equity and equality\",\n    \"source\": \"calculated\",\n    \"range\": {\"min\": \"-inf\", \"max\": \"inf\"}\n  },\n  \"deviation\": {\n    \"description\": \"Difference between proposed share and fairness reference\",\n    \"source\": \"calculated\",\n    \"range\": {\"min\": \"-inf\", \"max\": \"inf\"}\n  }\n}\n\nBut according to the instructions, only variables used in the model formula need to be in the variables section. The calculated variables like fair_ref and deviation may not need to be listed if they are intermediate steps. However, the example included all variables, even calculated ones. Let me check the example.\n\nIn the example, variables like E and N were included even if they were data or calculated. So perhaps we should include all variables present in the model formula, even if they are calculated from others.\n\nWait, in the model formula, the variables are split_self, token_self, combined_earning, and the parameters alpha, beta, gamma. The fair_ref and deviation are intermediate terms but not explicitly in the model formula as variables. The model formula is written as a single equation.\n\nSo the model is:\n\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n\nThus, the variables directly used in the formula are split_self, token_self, combined_earning, and the parameters alpha, beta, gamma. The other terms (3*token_self and 0.5*combined_earning) are derived from existing variables but don't need to be listed as separate variables since they are calculated from token_self and combined_earning.\n\nTherefore, in the variables section, we list alpha, beta, gamma as learnable parameters, and split_self, token_self, combined_earning as data variables. The rest are calculated but not explicitly listed unless they are part of the model's formula as separate variables.\n\nWait, the example included variables like E and N which were data and calculated. So perhaps any variable that appears in the model equation must be listed. In this case, the equation includes split_self, token_self, combined_earning, alpha, beta, gamma. The 3 and 0.5 are constants, so they don't need variables. So the variables to list are:\n\n- split_self (data)\n- token_self (data)\n- combined_earning (data)\n- alpha (learnable)\n- beta (learnable)\n- gamma (learnable)\n\nThe fair_ref is part of the equation but is a combination of variables and parameters, so it's calculated but not a separate variable in the JSON unless it's explicitly in the model formula. Since the model formula is written as a single line without intermediate variables, perhaps only the variables directly present in the formula are listed.\n\nSo the JSON would include the three parameters and the three data variables.\n\nNow, the summary should describe the model concisely. The model combines equity and equality into a fairness reference, computes deviation from the offer, and uses sensitivity and baseline bias to determine utility.\n\nPutting it all together.\n</think>\n\n<MODEL>\nU = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n</MODEL>\n\n<target_variable>accept</target_variable>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"alpha\": {\n      \"description\": \"Weighting between equity (own contribution) and equality (50% split) in fairness reference calculation\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to deviation from fairness reference\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"gamma\": {\n      \"description\": \"Baseline acceptance bias (positive values increase acceptance propensity)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in pounds\",\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token count (contribution to shared pot)\",\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (3*(token_self + token_opp))\",\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<SUMMARY>\nA fairness-weighted utility model where responders evaluate offers against a dynamic reference combining equity (proportional to contributions) and equality (50% split). Utility depends on linear sensitivity to deviations from this reference plus a baseline bias parameter. Three learnable parameters control the equity-equality tradeoff (\u03b1), deviation sensitivity (\u03b2), and baseline acceptance tendency (\u03b3).\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\nSummary: A fairness-weighted utility model where responders evaluate offers against a dynamic reference combining equity (proportional to contributions) and equality (50% split). Utility depends on linear sensitivity to deviations from this reference plus a baseline bias parameter. Three learnable parameters control the equity-equality tradeoff (\u03b1), deviation sensitivity (\u03b2), and baseline acceptance tendency (\u03b3).\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, alpha=0.5, beta=1, gamma=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        utility = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.7945665445665446,
  "fitting_results": [
    {
      "alpha": 0.0,
      "beta": 10.0,
      "gamma": 3.5214003412911246,
      "success": true,
      "log_likelihood": -0.1766910634895642,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6121463470371494,
      "beta": 1.070901217924783,
      "gamma": 2.5019480771448537,
      "success": true,
      "log_likelihood": -17.27432990498736,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 1.3697937257129373,
      "gamma": 3.4809930882064153,
      "success": true,
      "log_likelihood": -13.10744118041955,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6221546415997309,
      "beta": 1.0429391369196768,
      "gamma": 1.9192448764561734,
      "success": true,
      "log_likelihood": -17.400899373396932,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 2.0019889307738548,
      "gamma": 3.9995483944252053,
      "success": true,
      "log_likelihood": -9.2776382111038,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.45586373020909127,
      "beta": 1.6119294813201182,
      "gamma": 4.854773208910931,
      "success": true,
      "log_likelihood": -12.619999724189396,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6648881517096151,
      "beta": 1.5523607608927634,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -11.100831189520916,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.804884368842308,
      "beta": 1.57960304550498,
      "gamma": 2.6721645885693253,
      "success": true,
      "log_likelihood": -12.701887043616406,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8917302183172551,
      "beta": 1.8983578532828957,
      "gamma": 3.800994627138129,
      "success": true,
      "log_likelihood": -10.346511526093487,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.24518075404174614,
      "beta": 2.3344527288644876,
      "gamma": 0.9822203953865034,
      "success": true,
      "log_likelihood": -6.690264765139326,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6405451010088575,
      "beta": 2.481403830610032,
      "gamma": 4.576442679494155,
      "success": true,
      "log_likelihood": -9.510156595592694,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3418451527805322,
      "beta": 0.9924847175894189,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -10.175144104185971,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.8880332998675177,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -6.901352641335645,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.36190325051678995,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.944064191697163,
      "beta": 1.2368790512565893,
      "gamma": 3.3547823695426326,
      "success": true,
      "log_likelihood": -14.338655977457456,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6621319895928646,
      "beta": 1.002659790191953,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -8.372830607849451,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.455160702349173,
      "gamma": 2.3780081541388496,
      "success": true,
      "log_likelihood": -15.958662710866072,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3228748370482279,
      "beta": 0.9538042180726243,
      "gamma": 2.3836867842591314,
      "success": true,
      "log_likelihood": -18.83752985081403,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 1.7763541262251097,
      "gamma": 4.194573129024419,
      "success": true,
      "log_likelihood": -10.386554193430724,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9831210670326483,
      "beta": 0.8125088274385044,
      "gamma": 2.4290530096730953,
      "success": true,
      "log_likelihood": -17.907292708155065,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.10552516808834914,
      "beta": 2.072103070494761,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -10.957326073536748,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7788878301029893,
      "beta": 4.5533571223242815,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -4.513769190928162,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.8624509453971521,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -8.082969191973346,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8286687333619225,
      "beta": 0.822699112991809,
      "gamma": 3.7341803539898186,
      "success": true,
      "log_likelihood": -14.198925046533564,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8162570658002055,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 10.0,
      "gamma": 3.5213989420599665,
      "success": true,
      "log_likelihood": -0.17669106349047908,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.3351197863694415,
      "gamma": 2.5161393389869633,
      "success": true,
      "log_likelihood": -16.914114154667086,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.22346530130934456,
      "beta": 1.740623761442555,
      "gamma": 3.0846558898662293,
      "success": true,
      "log_likelihood": -14.589292140008501,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -0.24175254198398927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.8061259523563629,
      "gamma": 2.643112282960806,
      "success": true,
      "log_likelihood": -18.84906121842359,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7634337139678774,
      "beta": 1.2806869579211726,
      "gamma": 4.5281551774978,
      "success": true,
      "log_likelihood": -13.17145175127374,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 1.2657568829411359,
      "gamma": 2.9914915949681427,
      "success": true,
      "log_likelihood": -13.966481522860075,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.805533121768477,
      "beta": 0.9317060077726523,
      "gamma": 3.2627534734464025,
      "success": true,
      "log_likelihood": -16.185401668604282,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.8193985344186818,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -7.8018613648554105,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.44737623362576046,
      "beta": 1.400461240568639,
      "gamma": 4.050394979092432,
      "success": true,
      "log_likelihood": -14.348967181071426,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7803843170487441,
      "beta": 1.2938352972989013,
      "gamma": 0.8386929927748569,
      "success": true,
      "log_likelihood": -12.47463354667234,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3665937958452242e-05,
      "beta": 0.45508474420778516,
      "gamma": 4.908421161516881,
      "success": true,
      "log_likelihood": -4.294553516962135,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.491865227322205,
      "gamma": 3.775807026932819,
      "success": true,
      "log_likelihood": -15.272457242392786,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.48681931914169957,
      "beta": 1.1476953720920033,
      "gamma": 3.401231971233898,
      "success": true,
      "log_likelihood": -16.059352414935223,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.6122805771403732,
      "gamma": 2.5967543984510377,
      "success": true,
      "log_likelihood": -18.408498708051606,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.09879760497111223,
      "beta": 2.1740527287122062,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -11.49993739927529,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.38865171593338027,
      "beta": 0.7365743391859492,
      "gamma": 1.167926596110767,
      "success": true,
      "log_likelihood": -20.15508171870405,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 2.29287623949929,
      "gamma": 4.152874354359018,
      "success": true,
      "log_likelihood": -8.21977506678474,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.2748821376218087,
      "gamma": 0.7790920853541277,
      "success": true,
      "log_likelihood": -24.145069876507847,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.22792504082170795,
      "beta": 0.7449000261910194,
      "gamma": 2.812062152457379,
      "success": true,
      "log_likelihood": -18.03949763718762,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 2.52090169808548,
      "gamma": 1.7171309446532563,
      "success": true,
      "log_likelihood": -7.21031578801163,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.9310125074660558,
      "gamma": 2.3237956650475793,
      "success": true,
      "log_likelihood": -19.295065177430747,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.3977751461258582,
      "gamma": 1.3205779840666665,
      "success": true,
      "log_likelihood": -22.96150108911615,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3611111111111111,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.7319996264410246,
      "gamma": 1.1097747022048225,
      "success": true,
      "log_likelihood": -18.6070514737432,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8959446178624426,
      "beta": 2.669136455143563,
      "gamma": 3.5896876884921687,
      "success": true,
      "log_likelihood": -8.182379518481692,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.49904207909646114,
      "beta": 2.650907723948635,
      "gamma": 3.3702839624941956,
      "success": true,
      "log_likelihood": -9.786919882879987,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "gamma": 2.079439461603504,
      "success": true,
      "log_likelihood": -12.557955443156848,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.582875806426283e-07,
      "beta": 3.743715218043851,
      "gamma": 2.2024684225930367,
      "success": true,
      "log_likelihood": -4.163253362852942,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.5850110590763086,
      "gamma": 3.0634744428480443,
      "success": true,
      "log_likelihood": -15.511453556356606,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.18699941718255564,
      "beta": 0.8391466763586836,
      "gamma": 2.5732503051513076,
      "success": true,
      "log_likelihood": -18.994470930690003,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.648714031661581,
      "beta": 1.522169421600429,
      "gamma": 3.5197781773533623,
      "success": true,
      "log_likelihood": -13.77225735225623,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 10.0,
      "gamma": 3.52140285750872,
      "success": true,
      "log_likelihood": -0.1766910634887269,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4212999873013853e-05,
      "beta": 0.7031524328756364,
      "gamma": 1.3862528006100288,
      "success": true,
      "log_likelihood": -21.14507639500751,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.2844177870450199,
      "beta": 2.8038080489187527,
      "gamma": 3.156785746761451,
      "success": true,
      "log_likelihood": -8.914965365345754,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.13247186625762805,
      "beta": 1.3919210836376297,
      "gamma": 3.5532240432168596,
      "success": true,
      "log_likelihood": -15.780452734384372,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.202488966893291e-09,
      "beta": 0.840671713393277,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -7.054780739723446,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7389844162333226,
      "beta": 0.8799345617134546,
      "gamma": 4.693859286819288,
      "success": true,
      "log_likelihood": -10.554034666743135,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.8227819639160614,
      "gamma": 2.2232309290728858,
      "success": true,
      "log_likelihood": -19.911600526742824,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.3238827701511319,
      "gamma": 3.3519363422814235,
      "success": true,
      "log_likelihood": -9.754721097793409,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8712388927544499,
      "beta": 10.0,
      "gamma": 2.9964539940359174,
      "success": true,
      "log_likelihood": -0.6691408178883794,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 3.7339103978690193,
      "gamma": 2.955905250944523,
      "success": true,
      "log_likelihood": -4.936691162371082,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.45282953077533894,
      "beta": 1.0907865889192996,
      "gamma": 2.7084695865121393,
      "success": true,
      "log_likelihood": -17.47581428415691,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.5082147178675431,
      "gamma": 2.6371665017836228,
      "success": true,
      "log_likelihood": -17.209134865945312,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.4685398967861756,
      "gamma": 1.1206551727878808,
      "success": true,
      "log_likelihood": -22.99096053243528,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.16360072990000674,
      "beta": 1.5890368588759367,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -8.539850106716345,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.6272040154109392,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -6.304689529576532,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.1634898493649741,
      "gamma": -1.005213115783239,
      "success": true,
      "log_likelihood": -6.2840015315720805,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9439006238003498,
      "beta": 0.12513061257163846,
      "gamma": 0.7614590937517375,
      "success": true,
      "log_likelihood": -23.812847886512092,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 10.0,
      "gamma": 3.5213975626296654,
      "success": true,
      "log_likelihood": -0.1766910634916948,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 8.229815114097247e-06,
      "beta": 0.5796030609841726,
      "gamma": 1.5083898084936078,
      "success": true,
      "log_likelihood": -22.072366299155597,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.2494515825848728,
      "gamma": 3.065596045015504,
      "success": true,
      "log_likelihood": -10.106604263817799,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.7284165494162125,
      "gamma": 0.48221445056938494,
      "success": true,
      "log_likelihood": -8.263949225819278,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.2867182104406653,
      "beta": 1.1295031200987107,
      "gamma": 2.612221441589311,
      "success": true,
      "log_likelihood": -17.75082734712557,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.23382368703894604,
      "gamma": 1.0394159596217332,
      "success": true,
      "log_likelihood": -23.201218119045052,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.29799491881626333,
      "beta": 9.063116476268512,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -1.1932950231877637,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6796732799272871,
      "beta": 0.7884331001928981,
      "gamma": 2.993102922536951,
      "success": true,
      "log_likelihood": -17.1099265158999,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.8292829340278447,
      "gamma": 0.16931474897960874,
      "success": true,
      "log_likelihood": -14.472753563665497,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0,
      "beta": 0.6613126353712717,
      "gamma": 5.0,
      "success": true,
      "log_likelihood": -5.4346378741775085,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.9407269902390308,
      "gamma": 2.0396809784074588,
      "success": true,
      "log_likelihood": -19.446833857185446,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.49677709735525044,
      "gamma": 2.116965986341736,
      "success": true,
      "log_likelihood": -20.094040764148613,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "alpha": {
        "r": 0.9043923696497346,
        "p": 0.00032525976414357204
      },
      "beta": {
        "r": 0.38809256299249145,
        "p": 0.26777242727119016
      },
      "gamma": {
        "r": 0.6809276326477302,
        "p": 0.03018638388275092
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 33.595981776759515,
  "bic_results": {
    "average_bic": 33.595981776759515,
    "individual_bics": [
      11.103938942347458,
      45.29921662534305,
      36.965439176207425,
      45.55235556216219,
      29.305833237575932,
      35.99055626374712,
      11.234061899336309,
      32.95221919441016,
      11.234061899336309,
      36.154330902601146,
      31.443579867555304,
      24.131086345646985,
      29.770870006553718,
      11.234061899336309,
      11.234061899336309,
      11.234061899336309,
      11.234061899336309,
      31.100845023740273,
      24.55326209803962,
      11.234061899336309,
      39.42786877028324,
      27.496218031067233,
      42.66788223710047,
      48.425616516996385,
      31.52366520222978,
      46.565142231678465,
      32.665208962441824,
      19.778095197224655,
      26.916495199315023,
      39.14840690843546,
      11.234061899336309,
      11.10393894234929,
      44.578785124702506,
      39.92914109538533,
      11.234061899336309,
      48.44867925221551,
      37.09346031791581,
      38.683519861088485,
      43.1213601525769,
      26.35427954507915,
      39.44849117751119,
      35.699823908713014,
      19.3396638492926,
      41.295471300153906,
      42.86926164523878,
      47.56755423147155,
      33.750431613918906,
      51.060720252776434,
      27.19010694893781,
      59.04069656838402,
      46.82955208974357,
      25.17118839139159,
      49.34068717022983,
      56.673558993600636,
      47.96465976285474,
      27.115315852331715,
      30.324396581128305,
      35.866467701682026,
      19.077063541074214,
      41.77346392808154,
      48.73949867674834,
      38.29507151988079,
      11.103938942345785,
      53.040709605383356,
      28.58048754605984,
      42.31146228413708,
      24.860118294815223,
      31.8586261488546,
      50.573757868853974,
      30.25999901095515,
      12.08883845114509,
      20.623939140110494,
      45.70218538368215,
      45.16882654725896,
      56.73247788023889,
      27.83025702880102,
      23.359935874521394,
      23.31855987851249,
      58.37625258839252,
      11.10393894235172,
      54.89528941367952,
      30.963765343003928,
      27.278455267006887,
      46.25221150961947,
      57.15299305345843,
      13.137146861743858,
      44.97040984716813,
      39.696063942699325,
      21.61983256372335,
      49.64422452973922,
      50.93863834366556
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- alpha: r = 0.904\n- beta: r = 0.388\n- gamma: r = 0.681",
  "previous_models": [
    "Specification: U = beta * (split_self - (alpha * 3 * token_self + (1 - alpha) * 0.5 * combined_earning)) + gamma\nSummary: A fairness-weighted utility model where responders evaluate offers against a dynamic reference combining equity (proportional to contributions) and equality (50% split). Utility depends on linear sensitivity to deviations from this reference plus a baseline bias parameter. Three learnable parameters control the equity-equality tradeoff (\u03b1), deviation sensitivity (\u03b2), and baseline acceptance tendency (\u03b3).\nTarget Variable: accept\nPrediction Type: utility\nBIC: 33.595981776759515\nOverall Accuracy: 0.7946\n\nParameter Recovery:\n- alpha: r = 0.904\n- beta: r = 0.388\n- gamma: r = 0.681"
  ]
}