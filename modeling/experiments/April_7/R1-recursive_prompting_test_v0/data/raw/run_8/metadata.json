{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\n\nOkay, let's analyze the previous run. The BIC was 41.36, which is higher than previous models, indicating worse fit. Accuracy was 0.675, lower than the previous average of ~0.79. Parameter recovery for alpha was 0.75 and theta 0.648, which is decent but could be better. The model used a prospect-theoretic approach with alpha and theta, but maybe the structure is causing issues.\n\nThe previous instructions suggested dynamic alpha anchoring with a logistic function, valence-specific utility, and prospect-theoretic transformation. However, the result was worse. Why? Maybe the model is too complex with three parameters (theta, beta_over, gamma) leading to overfitting. Or the nonlinear components (sigmoid and power function) made parameter recovery harder.\n\nTo improve, perhaps simplify the model. Instead of using a sigmoid for alpha, maybe use a direct ratio but introduce a nonlinearity in the deviation. For example, use a piecewise function with different exponents for gains and losses. Also, ensure parameters are orthogonal. Maybe separate the sensitivity to gains and losses with different parameters and apply a power function to each.\n\nAnother angle: The previous model had theta for fairness anchoring, beta_over for gains, and gamma for curvature. But combining these might create interactions that are hard to recover. Maybe use two parameters for gain and loss sensitivities, each with their own curvature. For example, U = beta_over * (max(deviation,0))^gamma_over + beta_under * (min(deviation,0))^gamma_under. But this adds four parameters. To keep it to three, fix gamma_under = 1 or tie gamma_over and gamma_under.\n\nAlternatively, use a single curvature parameter but different sensitivities. For example, U = beta_over * (max(deviation,0))^gamma + beta_under * (min(deviation,0))^gamma. This way, gamma affects both gains and losses but in different directions. However, beta_over and beta_under can capture asymmetric sensitivities.\n\nAnother idea: Replace the logistic function for alpha with a simpler interaction term. For example, alpha = theta * (token_self - token_opp)/(token_self + token_opp). This directly scales the contribution difference into the fairness reference, making theta a learnable weight.\n\nAlso, the previous model might not account for the total combined earning properly. Maybe participants care about absolute amounts more than percentages. So, the deviation should be in absolute terms, not relative. But the model already uses split_self minus fair_share in pounds.\n\nTo improve parameter recovery, ensure that each parameter affects a distinct aspect of the utility. For example, theta could control the fairness reference's dependence on contributions, beta_over scales positive deviations, and beta_under scales negative deviations. This separation might help in recovery.\n\nIn summary, the next model should:\n\n1. Simplify the dynamic fairness anchoring to a linear function of contribution difference.\n2. Use separate parameters for gain and loss sensitivities with a shared curvature.\n3. Apply power transformations to both gains and losses to capture diminishing sensitivity.\n4. Ensure parameters are orthogonal by design.\n\nThis approach reduces complexity, improves identifiability, and maintains the prospect-theoretic elements.\n</think>\n\n**Instructions for Run 8:**  \nDesign a model that **explicitly separates gain/loss curvature while using contribution-ratio-dependent fairness thresholds**. Implement these innovations:  \n\n1. **Linearized Fairness Threshold:**  \n   Define the fairness reference as:  \n   `fair_share = (token_self + \u03bb * token_opp) / (token_self + token_opp) * combined_earning`  \n   where \u03bb \u2208 [0,2] controls how much opponents\u2019 contributions are weighted (\u03bb=1 \u2192 strict proportionality).  \n\n2. **Dual-Curvature Utility:**  \n   Apply independent power transformations to gains/losses:  \n   ```  \n   U = \u03b2_gain * (max(deviation,0))^\u03b3_gain + \u03b2_loss * (min(deviation,0))^\u03b3_loss  \n   ```  \n   Constrain \u03b3_gain \u2208 [0.3,0.9] (concave gains) and \u03b3_loss \u2208 [1.1,2] (convex losses) to enforce prospect-theoretic shape.  \n\n3. **Identifiability Enforcement:**  \n   - Fix \u03b2_gain \u2208 [0,5] and \u03b2_loss \u2208 [-5,0] to force orthogonal effects  \n   - Prohibit baseline terms (no intercepts)  \n\n**Key Targets:**  \n- Achieve \u03b3_gain/\u03b3_loss recovery r > 0.7 while keeping BIC < 35  \n- Test if \u03bb > 1 implies participants overvalue opponents\u2019 contributions  \n- Use exactly 4 parameters: \u03bb, \u03b2_gain, \u03b2_loss, \u03b3_gain (fix \u03b3_loss = 2 - \u03b3_gain to reduce dimensionality)  \n\n**Radical Suggestion:** Explore whether letting \u03bb dynamically vary with trial type (e.g., \u03bb increases when token_opp > token_self) improves fit without overparameterization.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\n\nOkay, let's analyze the previous run. The BIC was 41.36, which is higher than previous models, indicating worse fit. Accuracy was 0.675, lower than the previous average of ~0.79. Parameter recovery for alpha was 0.75 and theta 0.648, which is decent but could be better. The model used a prospect-theoretic approach with alpha and theta, but maybe the structure is causing issues.\n\nThe previous instructions suggested dynamic alpha anchoring with a logistic function, valence-specific utility, and prospect-theoretic transformation. However, the result was worse. Why? Maybe the model is too complex with three parameters (theta, beta_over, gamma) leading to overfitting. Or the nonlinear components (sigmoid and power function) made parameter recovery harder.\n\nTo improve, perhaps simplify the model. Instead of using a sigmoid for alpha, maybe use a direct ratio but introduce a nonlinearity in the deviation. For example, use a piecewise function with different exponents for gains and losses. Also, ensure parameters are orthogonal. Maybe separate the sensitivity to gains and losses with different parameters and apply a power function to each.\n\nAnother angle: The previous model had theta for fairness anchoring, beta_over for gains, and gamma for curvature. But combining these might create interactions that are hard to recover. Maybe use two parameters for gain and loss sensitivities, each with their own curvature. For example, U = beta_over * (max(deviation,0))^gamma_over + beta_under * (min(deviation,0))^gamma_under. But this adds four parameters. To keep it to three, fix gamma_under = 1 or tie gamma_over and gamma_under.\n\nAlternatively, use a single curvature parameter but different sensitivities. For example, U = beta_over * (max(deviation,0))^gamma + beta_under * (min(deviation,0))^gamma. This way, gamma affects both gains and losses but in different directions. However, beta_over and beta_under can capture asymmetric sensitivities.\n\nAnother idea: Replace the logistic function for alpha with a simpler interaction term. For example, alpha = theta * (token_self - token_opp)/(token_self + token_opp). This directly scales the contribution difference into the fairness reference, making theta a learnable weight.\n\nAlso, the previous model might not account for the total combined earning properly. Maybe participants care about absolute amounts more than percentages. So, the deviation should be in absolute terms, not relative. But the model already uses split_self minus fair_share in pounds.\n\nTo improve parameter recovery, ensure that each parameter affects a distinct aspect of the utility. For example, theta could control the fairness reference's dependence on contributions, beta_over scales positive deviations, and beta_under scales negative deviations. This separation might help in recovery.\n\nIn summary, the next model should:\n\n1. Simplify the dynamic fairness anchoring to a linear function of contribution difference.\n2. Use separate parameters for gain and loss sensitivities with a shared curvature.\n3. Apply power transformations to both gains and losses to capture diminishing sensitivity.\n4. Ensure parameters are orthogonal by design.\n\nThis approach reduces complexity, improves identifiability, and maintains the prospect-theoretic elements.\n</think>\n\n**Instructions for Run 8:**  \nDesign a model that **explicitly separates gain/loss curvature while using contribution-ratio-dependent fairness thresholds**. Implement these innovations:  \n\n1. **Linearized Fairness Threshold:**  \n   Define the fairness reference as:  \n   `fair_share = (token_self + \u03bb * token_opp) / (token_self + token_opp) * combined_earning`  \n   where \u03bb \u2208 [0,2] controls how much opponents\u2019 contributions are weighted (\u03bb=1 \u2192 strict proportionality).  \n\n2. **Dual-Curvature Utility:**  \n   Apply independent power transformations to gains/losses:  \n   ```  \n   U = \u03b2_gain * (max(deviation,0))^\u03b3_gain + \u03b2_loss * (min(deviation,0))^\u03b3_loss  \n   ```  \n   Constrain \u03b3_gain \u2208 [0.3,0.9] (concave gains) and \u03b3_loss \u2208 [1.1,2] (convex losses) to enforce prospect-theoretic shape.  \n\n3. **Identifiability Enforcement:**  \n   - Fix \u03b2_gain \u2208 [0,5] and \u03b2_loss \u2208 [-5,0] to force orthogonal effects  \n   - Prohibit baseline terms (no intercepts)  \n\n**Key Targets:**  \n- Achieve \u03b3_gain/\u03b3_loss recovery r > 0.7 while keeping BIC < 35  \n- Test if \u03bb > 1 implies participants overvalue opponents\u2019 contributions  \n- Use exactly 4 parameters: \u03bb, \u03b2_gain, \u03b2_loss, \u03b3_gain (fix \u03b3_loss = 2 - \u03b3_gain to reduce dimensionality)  \n\n**Radical Suggestion:** Explore whether letting \u03bb dynamically vary with trial type (e.g., \u03bb increases when token_opp > token_self) improves fit without overparameterization.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nAlright, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal based on the given dataset. The model needs to focus on responder behavior, use the provided variables appropriately, and ensure parameter recovery is feasible alongside accuracy.\n\nFirst, I need to identify which variables are relevant for the responder's decision. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of the proposed split for the participant.\n\nKey variables to consider:\n- token_self and token_opp: These represent the contributions of the participant and opponent, which might influence the perceived fairness.\n- combined_earning: Total money available, which affects the actual monetary value of the splits.\n- split_self: The proposed amount for the participant, which directly impacts their utility.\n- split_opp: The opponent's proposed share, but since the participant is the responder, their own share (split_self) is more directly relevant.\n\nThe model should calculate the utility of accepting the proposal. Since the task mentions that equal split_self doesn't imply the same fairness due to varying combined_earning, the fairness perception likely depends on the proportion relative to contributions.\n\nA common approach in such economic games is to use a fairness model where participants compare the proposed split to a \"fair\" reference, often based on contributions. The utility could be the difference between the proposed share and the fair share, adjusted by some parameters.\n\nPotential parameters:\n- \u03b1 (alpha): Sensitivity to fairness deviations. If the proposed split is less than the fair share, this parameter scales the negative utility.\n- \u03b8 (theta): A parameter that determines the reference point for fairness. For example, \u03b8=0.5 might imply a 50-50 split is fair, but \u03b8 could be adjusted based on contributions.\n\nMathematical formulation idea:\nUtility = (split_self - fair_share) + \u03b8 * (some function of contributions)\nBut need to define fair_share based on contributions. Maybe fair_share is calculated as (token_self / (token_self + token_opp)) * combined_earning. However, participants might have a different notion of fairness, so \u03b8 could adjust this.\n\nAlternatively, using a prospect theory approach where losses (getting less than fair) are weighted more heavily than gains. So the utility could be nonlinear in the deviation from the fair share.\n\nAnother consideration: The acceptance decision is binary, so the utility needs to be passed through a logistic function to convert it into a probability. The model should output the utility, which is then used in a logistic regression with a temperature parameter (fixed at 1 as per instructions).\n\nPutting this together, the model could be:\n\nU = split_self - \u03b8 * fair_share + \u03b1 * (split_self - fair_share)\n\nBut this might not capture the nonlinearity. Alternatively, using a parameter to scale the deviation from fairness:\n\nU = \u03b2 * (split_self - \u03b8 * fair_share)\n\nHere, \u03b2 is a sensitivity parameter, and \u03b8 adjusts the fair reference. If \u03b8=1, fair_share is exactly proportional to contributions. If \u03b8>1, the participant expects more than their contribution share.\n\nWait, but fair_share could be defined as \u03b8 * (token_self / (token_self + token_opp)) * combined_earning. Then, the utility is split_self - fair_share. But \u03b8 here would scale the fair share. Alternatively, \u03b8 could represent the weight given to the opponent's contribution. For example, if \u03b8=0, the fair share is based entirely on the participant's contribution. If \u03b8=1, it's proportional.\n\nAlternatively, using a ratio-based fairness measure. For example, the fair split percentage could be token_self / (token_self + token_opp), and the proposed percentage is splitperc_self. The difference between these could be the fairness deviation.\n\nBut the problem states that two equal split_self values don't represent the same fairness because combined_earning varies. So the absolute split_self isn't enough; the proportion relative to contributions matters.\n\nSo, perhaps the fair share is (token_self / (token_self + token_opp)) * combined_earning. The utility is then the proposed split_self minus this fair share, scaled by a parameter \u03b1. Additionally, participants might have a baseline acceptance tendency, so a parameter \u03b2 could represent this.\n\nBut the model needs to predict the utility such that when U < 0, the probability of acceptance is less than 50%. Using a logistic function, P(accept) = 1 / (1 + exp(-U)). So U needs to be the log-odds of acceptance.\n\nThus, the model could be:\n\nU = \u03b1 * (split_self - fair_share) + \u03b2\n\nWhere fair_share = (token_self / (token_self + token_opp)) * combined_earning\n\nHere, \u03b1 is the sensitivity to deviations from the fair share, and \u03b2 is a bias term (e.g., overall tendency to accept). If \u03b1 is positive, participants are more likely to accept when they get more than their fair share. \u03b2 could capture a general acceptance bias.\n\nBut perhaps participants have nonlinear responses to deviations. For example, they might be more sensitive to undercuts than overages. So a prospect theory-inspired model where losses (getting less than fair) are weighted more heavily:\n\nU = \u03b1 * (split_self - fair_share) + \u03b3 * (split_self - fair_share)^2\n\nBut this introduces more parameters. Alternatively, using a piecewise function:\n\nIf split_self >= fair_share:\n    U = \u03b1 * (split_self - fair_share) + \u03b2\nElse:\n    U = \u03b4 * (split_self - fair_share) + \u03b2\n\nHere, \u03b4 > \u03b1, indicating higher sensitivity to losses. But this complicates the model with more parameters.\n\nGiven the need for parameter recovery and simplicity, starting with a linear model might be better. Let's define:\n\nfair_share = (token_self / (token_self + token_opp)) * combined_earning\ndeviation = split_self - fair_share\nU = \u03b1 * deviation + \u03b2\n\nBut the problem states that the model should predict utility where less than 0 corresponds to less than 50% acceptance. So the utility U directly maps to the log-odds via the logistic function.\n\nParameters:\n- \u03b1: Sensitivity to deviation from fair share. Bounds could be [-10, 10] to allow for strong positive or negative sensitivities.\n- \u03b2: Bias term. Bounds [-5, 5] to capture general acceptance tendency.\n\nHowever, maybe the fair share isn't strictly proportional. Participants might have a different notion of fairness, such as equal split regardless of contributions. So \u03b8 could adjust the reference:\n\nfair_share = \u03b8 * combined_earning / 2\n\nHere, \u03b8=1 implies a 50-50 split is fair. If \u03b8 is learned, it could capture whether participants expect equal splits or contribution-based.\n\nAlternatively, combining both ideas:\n\nfair_share = \u03b8 * (token_self / (token_self + token_opp)) * combined_earning + (1 - \u03b8) * (combined_earning / 2)\n\nThis way, \u03b8 blends between contribution-based and equal split fairness. \u03b8=1 is pure contribution-based, \u03b8=0 is equal split.\n\nBut this introduces \u03b8 as a learnable parameter between 0 and 1.\n\nSo the model becomes:\n\nfair_share = \u03b8 * (token_self / (token_self + token_opp)) * combined_earning + (1 - \u03b8) * (combined_earning / 2)\ndeviation = split_self - fair_share\nU = \u03b1 * deviation + \u03b2\n\nParameters:\n- \u03b8 \u2208 [0, 1]: Fairness reference blend between contribution-based and equal split.\n- \u03b1 \u2208 [-10, 10]: Sensitivity to deviation.\n- \u03b2 \u2208 [-5, 5]: Bias term.\n\nThis model allows the fairness reference to be a combination of equal split and contribution-based, with \u03b8 determining the mix. \u03b1 scales how much deviations from this reference affect utility, and \u03b2 is a baseline tendency.\n\nBut maybe the participant's perception of fairness is influenced by their own contribution relative to the opponent's. For example, if they contributed more, they might expect a higher share. So the fair_share could be calculated as:\n\nfair_share = (token_self / (token_self + token_opp)) * combined_earning\n\nBut participants might over-weight their own contribution. So introducing a parameter \u03b8 that scales the perceived contribution:\n\nfair_share = (\u03b8 * token_self) / (\u03b8 * token_self + token_opp) * combined_earning\n\nHere, \u03b8 > 1 means the participant over-weights their own contribution, \u03b8 < 1 under-weights. \u03b8 = 1 is the actual proportion.\n\nThis \u03b8 could be a learnable parameter with bounds [0.5, 2], for example.\n\nThen deviation is split_self - fair_share, and utility is \u03b1 * deviation + \u03b2.\n\nThis model has parameters:\n- \u03b8 \u2208 [0.5, 2]: Contribution weighting for fairness.\n- \u03b1 \u2208 [-10, 10]: Sensitivity to deviation.\n- \u03b2 \u2208 [-5, 5]: Bias term.\n\nThis seems plausible. The utility is linear in the deviation from the perceived fair share, which is determined by \u03b8 adjusting the contribution ratio.\n\nAnother consideration: The participant might also care about the opponent's share. For example, if the opponent is getting too much, even if the participant's share is fair, they might reject. But the problem states to predict responder behavior based on their own share, but perhaps the opponent's split (split_opp) could be a factor. However, the model should use variables appropriately, and since the responder's decision is about their own share, maybe focusing on split_self is sufficient.\n\nAlternatively, the utility could compare the participant's share to the opponent's:\n\nU = \u03b1 * (split_self - split_opp) + \u03b2\n\nBut this might not account for contributions. However, given that combined_earning varies, the absolute difference might not capture fairness.\n\nAlternatively, the ratio of splits compared to contributions:\n\nU = \u03b1 * (split_self / token_self - split_opp / token_opp) + \u03b2\n\nBut this could be problematic if token_opp is zero, but the dataset likely doesn't have that.\n\nGiven the complexity, sticking to the fair_share based on contributions with a \u03b8 parameter seems manageable.\n\nPutting it all together, the mathematical model would be:\n\n<MODEL>\nU = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\n</MODEL>\n\nVariables:\n- alpha: sensitivity to deviation from fair share.\n- theta: weighting of own contribution in fair share calculation.\n- beta: baseline acceptance tendency.\n\nParameters' bounds:\n- alpha: [-10, 10] to allow strong sensitivities.\n- theta: [0.5, 2] to allow over/under-weighting own contribution.\n- beta: [-5, 5] for baseline tendency.\n\nEach variable in the model must be described, including data variables like split_self, token_self, token_opp, combined_earning.\n\nThe target variable is \"accept\", so the model's utility U is used in a logistic function to predict P(accept) = 1 / (1 + exp(-U)).\n\nNow, structuring the variables section:\n\n- U: utility (calculated)\n- alpha: learnable parameter, range [-10, 10]\n- theta: learnable, range [0.5, 2]\n- beta: learnable, range [-5, 5]\n- split_self: from data\n- token_self: data\n- token_opp: data\n- combined_earning: data\n\nAll data variables are not learnable and sourced from the dataset.\n\nThe summary should explain that the model computes utility based on deviation from a contribution-weighted fair share, with parameters for sensitivity, contribution weighting, and baseline tendency.\n</think>\n\n<MODEL>\nU = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\n</MODEL>\n\n<target_variable>accept</target_variable>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviations from perceived fair share\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Weighting parameter for own contribution in fairness calculation\",\n      \"range\": {\n        \"min\": 0.5,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Baseline acceptance tendency\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (\u00a3)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<SUMMARY>\nA fairness-weighted utility model where participants evaluate offers relative to a contribution-adjusted reference point. The fair share is computed by non-linearly weighting the participant's own tokens (theta) against the opponent's. Utility combines deviation from this dynamic fairness threshold with a baseline acceptance bias (beta), scaled by sensitivity parameter alpha. Parameters allow recovery of strategic weighting of contributions and loss aversion characteristics.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['alpha', 'theta', 'beta']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviations from perceived fair share\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Weighting parameter for own contribution in fairness calculation\",\n      \"range\": {\n        \"min\": 0.5,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Baseline acceptance tendency\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (\\u00a3)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, alpha=0, theta=1, beta=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        fair_share = (theta * token_self / (theta * token_self + token_opp) * combined_earning) if (theta * token_self + token_opp) != 0 else 0\n\n        utility = alpha * (split_self - fair_share) + beta\n\n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744018160.646533
    }
  ],
  "learnable_parameters": {
    "alpha": {
      "description": "Sensitivity to deviations from perceived fair share",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Weighting parameter for own contribution in fairness calculation",
      "range": {
        "min": 0.5,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Baseline acceptance tendency",
      "range": {
        "min": -5,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "alpha": {
      "description": "Sensitivity to deviations from perceived fair share",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Weighting parameter for own contribution in fairness calculation",
      "range": {
        "min": 0.5,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Baseline acceptance tendency",
      "range": {
        "min": -5,
        "max": 5,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for participant in \u00a3",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant's token contribution",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Opponent's token contribution",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "Total money in shared pot (\u00a3)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A fairness-weighted utility model where participants evaluate offers relative to a contribution-adjusted reference point. The fair share is computed by non-linearly weighting the participant's own tokens (theta) against the opponent's. Utility combines deviation from this dynamic fairness threshold with a baseline acceptance bias (beta), scaled by sensitivity parameter alpha. Parameters allow recovery of strategic weighting of contributions and loss aversion characteristics.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nAlright, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal based on the given dataset. The model needs to focus on responder behavior, use the provided variables appropriately, and ensure parameter recovery is feasible alongside accuracy.\n\nFirst, I need to identify which variables are relevant for the responder's decision. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of the proposed split for the participant.\n\nKey variables to consider:\n- token_self and token_opp: These represent the contributions of the participant and opponent, which might influence the perceived fairness.\n- combined_earning: Total money available, which affects the actual monetary value of the splits.\n- split_self: The proposed amount for the participant, which directly impacts their utility.\n- split_opp: The opponent's proposed share, but since the participant is the responder, their own share (split_self) is more directly relevant.\n\nThe model should calculate the utility of accepting the proposal. Since the task mentions that equal split_self doesn't imply the same fairness due to varying combined_earning, the fairness perception likely depends on the proportion relative to contributions.\n\nA common approach in such economic games is to use a fairness model where participants compare the proposed split to a \"fair\" reference, often based on contributions. The utility could be the difference between the proposed share and the fair share, adjusted by some parameters.\n\nPotential parameters:\n- \u03b1 (alpha): Sensitivity to fairness deviations. If the proposed split is less than the fair share, this parameter scales the negative utility.\n- \u03b8 (theta): A parameter that determines the reference point for fairness. For example, \u03b8=0.5 might imply a 50-50 split is fair, but \u03b8 could be adjusted based on contributions.\n\nMathematical formulation idea:\nUtility = (split_self - fair_share) + \u03b8 * (some function of contributions)\nBut need to define fair_share based on contributions. Maybe fair_share is calculated as (token_self / (token_self + token_opp)) * combined_earning. However, participants might have a different notion of fairness, so \u03b8 could adjust this.\n\nAlternatively, using a prospect theory approach where losses (getting less than fair) are weighted more heavily than gains. So the utility could be nonlinear in the deviation from the fair share.\n\nAnother consideration: The acceptance decision is binary, so the utility needs to be passed through a logistic function to convert it into a probability. The model should output the utility, which is then used in a logistic regression with a temperature parameter (fixed at 1 as per instructions).\n\nPutting this together, the model could be:\n\nU = split_self - \u03b8 * fair_share + \u03b1 * (split_self - fair_share)\n\nBut this might not capture the nonlinearity. Alternatively, using a parameter to scale the deviation from fairness:\n\nU = \u03b2 * (split_self - \u03b8 * fair_share)\n\nHere, \u03b2 is a sensitivity parameter, and \u03b8 adjusts the fair reference. If \u03b8=1, fair_share is exactly proportional to contributions. If \u03b8>1, the participant expects more than their contribution share.\n\nWait, but fair_share could be defined as \u03b8 * (token_self / (token_self + token_opp)) * combined_earning. Then, the utility is split_self - fair_share. But \u03b8 here would scale the fair share. Alternatively, \u03b8 could represent the weight given to the opponent's contribution. For example, if \u03b8=0, the fair share is based entirely on the participant's contribution. If \u03b8=1, it's proportional.\n\nAlternatively, using a ratio-based fairness measure. For example, the fair split percentage could be token_self / (token_self + token_opp), and the proposed percentage is splitperc_self. The difference between these could be the fairness deviation.\n\nBut the problem states that two equal split_self values don't represent the same fairness because combined_earning varies. So the absolute split_self isn't enough; the proportion relative to contributions matters.\n\nSo, perhaps the fair share is (token_self / (token_self + token_opp)) * combined_earning. The utility is then the proposed split_self minus this fair share, scaled by a parameter \u03b1. Additionally, participants might have a baseline acceptance tendency, so a parameter \u03b2 could represent this.\n\nBut the model needs to predict the utility such that when U < 0, the probability of acceptance is less than 50%. Using a logistic function, P(accept) = 1 / (1 + exp(-U)). So U needs to be the log-odds of acceptance.\n\nThus, the model could be:\n\nU = \u03b1 * (split_self - fair_share) + \u03b2\n\nWhere fair_share = (token_self / (token_self + token_opp)) * combined_earning\n\nHere, \u03b1 is the sensitivity to deviations from the fair share, and \u03b2 is a bias term (e.g., overall tendency to accept). If \u03b1 is positive, participants are more likely to accept when they get more than their fair share. \u03b2 could capture a general acceptance bias.\n\nBut perhaps participants have nonlinear responses to deviations. For example, they might be more sensitive to undercuts than overages. So a prospect theory-inspired model where losses (getting less than fair) are weighted more heavily:\n\nU = \u03b1 * (split_self - fair_share) + \u03b3 * (split_self - fair_share)^2\n\nBut this introduces more parameters. Alternatively, using a piecewise function:\n\nIf split_self >= fair_share:\n    U = \u03b1 * (split_self - fair_share) + \u03b2\nElse:\n    U = \u03b4 * (split_self - fair_share) + \u03b2\n\nHere, \u03b4 > \u03b1, indicating higher sensitivity to losses. But this complicates the model with more parameters.\n\nGiven the need for parameter recovery and simplicity, starting with a linear model might be better. Let's define:\n\nfair_share = (token_self / (token_self + token_opp)) * combined_earning\ndeviation = split_self - fair_share\nU = \u03b1 * deviation + \u03b2\n\nBut the problem states that the model should predict utility where less than 0 corresponds to less than 50% acceptance. So the utility U directly maps to the log-odds via the logistic function.\n\nParameters:\n- \u03b1: Sensitivity to deviation from fair share. Bounds could be [-10, 10] to allow for strong positive or negative sensitivities.\n- \u03b2: Bias term. Bounds [-5, 5] to capture general acceptance tendency.\n\nHowever, maybe the fair share isn't strictly proportional. Participants might have a different notion of fairness, such as equal split regardless of contributions. So \u03b8 could adjust the reference:\n\nfair_share = \u03b8 * combined_earning / 2\n\nHere, \u03b8=1 implies a 50-50 split is fair. If \u03b8 is learned, it could capture whether participants expect equal splits or contribution-based.\n\nAlternatively, combining both ideas:\n\nfair_share = \u03b8 * (token_self / (token_self + token_opp)) * combined_earning + (1 - \u03b8) * (combined_earning / 2)\n\nThis way, \u03b8 blends between contribution-based and equal split fairness. \u03b8=1 is pure contribution-based, \u03b8=0 is equal split.\n\nBut this introduces \u03b8 as a learnable parameter between 0 and 1.\n\nSo the model becomes:\n\nfair_share = \u03b8 * (token_self / (token_self + token_opp)) * combined_earning + (1 - \u03b8) * (combined_earning / 2)\ndeviation = split_self - fair_share\nU = \u03b1 * deviation + \u03b2\n\nParameters:\n- \u03b8 \u2208 [0, 1]: Fairness reference blend between contribution-based and equal split.\n- \u03b1 \u2208 [-10, 10]: Sensitivity to deviation.\n- \u03b2 \u2208 [-5, 5]: Bias term.\n\nThis model allows the fairness reference to be a combination of equal split and contribution-based, with \u03b8 determining the mix. \u03b1 scales how much deviations from this reference affect utility, and \u03b2 is a baseline tendency.\n\nBut maybe the participant's perception of fairness is influenced by their own contribution relative to the opponent's. For example, if they contributed more, they might expect a higher share. So the fair_share could be calculated as:\n\nfair_share = (token_self / (token_self + token_opp)) * combined_earning\n\nBut participants might over-weight their own contribution. So introducing a parameter \u03b8 that scales the perceived contribution:\n\nfair_share = (\u03b8 * token_self) / (\u03b8 * token_self + token_opp) * combined_earning\n\nHere, \u03b8 > 1 means the participant over-weights their own contribution, \u03b8 < 1 under-weights. \u03b8 = 1 is the actual proportion.\n\nThis \u03b8 could be a learnable parameter with bounds [0.5, 2], for example.\n\nThen deviation is split_self - fair_share, and utility is \u03b1 * deviation + \u03b2.\n\nThis model has parameters:\n- \u03b8 \u2208 [0.5, 2]: Contribution weighting for fairness.\n- \u03b1 \u2208 [-10, 10]: Sensitivity to deviation.\n- \u03b2 \u2208 [-5, 5]: Bias term.\n\nThis seems plausible. The utility is linear in the deviation from the perceived fair share, which is determined by \u03b8 adjusting the contribution ratio.\n\nAnother consideration: The participant might also care about the opponent's share. For example, if the opponent is getting too much, even if the participant's share is fair, they might reject. But the problem states to predict responder behavior based on their own share, but perhaps the opponent's split (split_opp) could be a factor. However, the model should use variables appropriately, and since the responder's decision is about their own share, maybe focusing on split_self is sufficient.\n\nAlternatively, the utility could compare the participant's share to the opponent's:\n\nU = \u03b1 * (split_self - split_opp) + \u03b2\n\nBut this might not account for contributions. However, given that combined_earning varies, the absolute difference might not capture fairness.\n\nAlternatively, the ratio of splits compared to contributions:\n\nU = \u03b1 * (split_self / token_self - split_opp / token_opp) + \u03b2\n\nBut this could be problematic if token_opp is zero, but the dataset likely doesn't have that.\n\nGiven the complexity, sticking to the fair_share based on contributions with a \u03b8 parameter seems manageable.\n\nPutting it all together, the mathematical model would be:\n\n<MODEL>\nU = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\n</MODEL>\n\nVariables:\n- alpha: sensitivity to deviation from fair share.\n- theta: weighting of own contribution in fair share calculation.\n- beta: baseline acceptance tendency.\n\nParameters' bounds:\n- alpha: [-10, 10] to allow strong sensitivities.\n- theta: [0.5, 2] to allow over/under-weighting own contribution.\n- beta: [-5, 5] for baseline tendency.\n\nEach variable in the model must be described, including data variables like split_self, token_self, token_opp, combined_earning.\n\nThe target variable is \"accept\", so the model's utility U is used in a logistic function to predict P(accept) = 1 / (1 + exp(-U)).\n\nNow, structuring the variables section:\n\n- U: utility (calculated)\n- alpha: learnable parameter, range [-10, 10]\n- theta: learnable, range [0.5, 2]\n- beta: learnable, range [-5, 5]\n- split_self: from data\n- token_self: data\n- token_opp: data\n- combined_earning: data\n\nAll data variables are not learnable and sourced from the dataset.\n\nThe summary should explain that the model computes utility based on deviation from a contribution-weighted fair share, with parameters for sensitivity, contribution weighting, and baseline tendency.\n</think>\n\n<MODEL>\nU = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\n</MODEL>\n\n<target_variable>accept</target_variable>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviations from perceived fair share\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Weighting parameter for own contribution in fairness calculation\",\n      \"range\": {\n        \"min\": 0.5,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Baseline acceptance tendency\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 5,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Opponent's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Total money in shared pot (\u00a3)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<SUMMARY>\nA fairness-weighted utility model where participants evaluate offers relative to a contribution-adjusted reference point. The fair share is computed by non-linearly weighting the participant's own tokens (theta) against the opponent's. Utility combines deviation from this dynamic fairness threshold with a baseline acceptance bias (beta), scaled by sensitivity parameter alpha. Parameters allow recovery of strategic weighting of contributions and loss aversion characteristics.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\nSummary: A fairness-weighted utility model where participants evaluate offers relative to a contribution-adjusted reference point. The fair share is computed by non-linearly weighting the participant's own tokens (theta) against the opponent's. Utility combines deviation from this dynamic fairness threshold with a baseline acceptance bias (beta), scaled by sensitivity parameter alpha. Parameters allow recovery of strategic weighting of contributions and loss aversion characteristics.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, alpha=0, theta=1, beta=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        fair_share = (theta * token_self / (theta * token_self + token_opp) * combined_earning) if (theta * token_self + token_opp) != 0 else 0\n\n        utility = alpha * (split_self - fair_share) + beta\n\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.790903540903541,
  "fitting_results": [
    {
      "alpha": 1.3591790936979167,
      "theta": 0.5,
      "beta": -3.426718987975669,
      "success": true,
      "log_likelihood": -6.438525765159073,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.071211750102925,
      "theta": 0.5028454098924287,
      "beta": 0.541936489694836,
      "success": true,
      "log_likelihood": -17.237652564449974,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.814155916622823,
      "theta": 0.5,
      "beta": 1.7213664899919667,
      "success": true,
      "log_likelihood": -8.869684447792444,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3127008118933623,
      "theta": 0.5,
      "beta": 0.04429660219852165,
      "success": true,
      "log_likelihood": -15.179721276607458,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.581193561390933,
      "theta": 0.5303037939900428,
      "beta": 1.316798647680638,
      "success": true,
      "log_likelihood": -6.978440071427038,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.5961885718842965,
      "theta": 0.5,
      "beta": 1.9465744435096777,
      "success": true,
      "log_likelihood": -12.8845328962262,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -8.943693773072752,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.0067175019475651625,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.7040225510088685,
      "theta": 0.6859980082604031,
      "beta": 3.8677171968833597,
      "success": true,
      "log_likelihood": -11.431686095677914,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -9.971125721909257,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716199322428453,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.7541328501721365,
      "theta": 0.555360401224639,
      "beta": 0.3140877727121049,
      "success": true,
      "log_likelihood": -12.126453744359523,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 5.621213096675177,
      "theta": 0.5,
      "beta": 1.1700643610861994,
      "success": true,
      "log_likelihood": -4.67533359158259,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.388893229124157,
      "theta": 0.5,
      "beta": -2.987049452960952,
      "success": true,
      "log_likelihood": -7.5782982031927135,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.219962437942441,
      "theta": 0.6265360096392232,
      "beta": 1.4126205838771815,
      "success": true,
      "log_likelihood": -9.832123387978601,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -10.0,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716177383406953,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -9.41176566153919,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716759313074073,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -9.402502147457309,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716771172536034,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -9.04564557799693,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006717312460291939,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2700373922673172,
      "theta": 0.5,
      "beta": 3.691655859679119,
      "success": true,
      "log_likelihood": -9.111089784322942,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.7507120045968916,
      "theta": 0.5,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -5.175090759996517,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -9.959586808047819,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716208250814798,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.402261319717624,
      "theta": 0.6587738769575452,
      "beta": 2.1495218703384933,
      "success": true,
      "log_likelihood": -13.971995204521562,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.6643515969111056,
      "theta": 0.5,
      "beta": 4.49861161666678,
      "success": true,
      "log_likelihood": -7.69346266689786,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7315516707743897,
      "theta": 0.5,
      "beta": -0.38749422818412255,
      "success": true,
      "log_likelihood": -19.055742549059843,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8842184614457119,
      "theta": 0.5,
      "beta": 0.5943282116971713,
      "success": true,
      "log_likelihood": -18.748444229133245,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.8879468122589425,
      "theta": 0.844276755230167,
      "beta": 3.575691856192702,
      "success": true,
      "log_likelihood": -10.27008564482711,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2201228347879334,
      "theta": 0.5,
      "beta": 1.1733770476952066,
      "success": true,
      "log_likelihood": -15.78935308984704,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2498027975944712,
      "theta": 0.5,
      "beta": 1.0004085807084533,
      "success": true,
      "log_likelihood": -15.765299444527994,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.9642514406447624,
      "theta": 0.8165130540568081,
      "beta": 2.030749534889263,
      "success": true,
      "log_likelihood": -5.4092805494322755,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4009076490228123,
      "theta": 0.5,
      "beta": 4.3705304224768105,
      "success": true,
      "log_likelihood": -7.392688132676272,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8286276710429752,
      "theta": 0.7732067987207227,
      "beta": 3.1639729981244624,
      "success": true,
      "log_likelihood": -14.20163594377307,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -10.0,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716177383406953,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3591660526375968,
      "theta": 0.5,
      "beta": -3.4267156432708026,
      "success": true,
      "log_likelihood": -6.4385257646922565,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.46265123545602554,
      "theta": 0.5,
      "beta": -0.1543903510816025,
      "success": true,
      "log_likelihood": -22.132696171829185,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0261515143754714,
      "theta": 0.5,
      "beta": -0.19145839457476194,
      "success": true,
      "log_likelihood": -16.987492182937885,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -10.0,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -0.006716177383406953,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.795461526550101,
      "theta": 0.5,
      "beta": 1.1673160244598422,
      "success": true,
      "log_likelihood": -18.466144137319517,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.0947267781747243,
      "theta": 0.5,
      "beta": 3.085286473181155,
      "success": true,
      "log_likelihood": -9.895664316827013,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4340785487160392,
      "theta": 0.6993380503981971,
      "beta": 1.9726849053689561,
      "success": true,
      "log_likelihood": -13.658379517923535,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8882518510745199,
      "theta": 0.889680269442893,
      "beta": 2.8806968355959692,
      "success": true,
      "log_likelihood": -16.263890261759986,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5141701025008021,
      "theta": 1.6434719648646177,
      "beta": 4.773823879999929,
      "success": true,
      "log_likelihood": -8.574054136152155,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9425363461843659,
      "theta": 1.7361911323150077,
      "beta": 4.4446463321792224,
      "success": true,
      "log_likelihood": -15.345818709163268,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2959504649808835,
      "theta": 0.5196055851133692,
      "beta": -1.428556248722165,
      "success": true,
      "log_likelihood": -11.840872269485828,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.30981398236787494,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -4.1117342717009215,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8606719416452958,
      "theta": 0.5,
      "beta": 0.7388354822054912,
      "success": true,
      "log_likelihood": -18.823027054944987,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2519499975377995,
      "theta": 0.5,
      "beta": 1.3977835967042032,
      "success": true,
      "log_likelihood": -15.308359722084045,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5698667365067054,
      "theta": 0.5,
      "beta": 1.4278054337502646,
      "success": true,
      "log_likelihood": -18.453480045575343,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8691537021066615,
      "theta": 1.3719822444222873,
      "beta": 3.0069633116474295,
      "success": true,
      "log_likelihood": -17.09877390661603,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7521593440402095,
      "theta": 0.5,
      "beta": -0.22954241666628006,
      "success": true,
      "log_likelihood": -19.274267341172248,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.3732004792283057,
      "theta": 0.8985166903429581,
      "beta": 3.646604800686104,
      "success": true,
      "log_likelihood": -8.165337032711612,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.22734910646760403,
      "theta": 0.5,
      "beta": 0.22953954989008174,
      "success": true,
      "log_likelihood": -24.232572205472977,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6585557986142224,
      "theta": 0.5,
      "beta": 1.3582562064028851,
      "success": true,
      "log_likelihood": -18.49216979152554,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6986130392116654,
      "theta": 0.5,
      "beta": -1.933430118691253,
      "success": true,
      "log_likelihood": -12.138315565573459,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6032328453453668,
      "theta": 0.5,
      "beta": 0.43490966900042366,
      "success": true,
      "log_likelihood": -21.26346190558255,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.29217259649290783,
      "theta": 0.5,
      "beta": 0.5031109314153503,
      "success": true,
      "log_likelihood": -23.40789049476754,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.927908765364571,
      "theta": 0.5410065618496829,
      "beta": -0.023514146884805385,
      "success": true,
      "log_likelihood": -17.65082704859196,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 5.333032178439202,
      "theta": 0.5,
      "beta": -1.3002889478876902,
      "success": true,
      "log_likelihood": -5.1584715240972745,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.6772947605814155,
      "theta": 0.6030736387084954,
      "beta": -0.45516333150003424,
      "success": true,
      "log_likelihood": -10.976134091954924,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.4604548486000803,
      "theta": 1.396792150790699,
      "beta": 0.8387879652842629,
      "success": true,
      "log_likelihood": -11.348773851824857,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.167038883371092,
      "theta": 0.5,
      "beta": -2.7067429908442406,
      "success": true,
      "log_likelihood": -8.469186452436029,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.43359500357536357,
      "theta": 0.5,
      "beta": 1.800829957128931,
      "success": true,
      "log_likelihood": -16.28348307707472,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5883015629882721,
      "theta": 0.66805553650792,
      "beta": 1.3026919192685606,
      "success": true,
      "log_likelihood": -20.35665702645387,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2762872358147659,
      "theta": 0.8439747868040341,
      "beta": 2.4150170881388964,
      "success": true,
      "log_likelihood": -14.29244040576336,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.359179407538638,
      "theta": 0.5,
      "beta": -3.426753953888925,
      "success": true,
      "log_likelihood": -6.438525765185403,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5628707435919446,
      "theta": 0.5,
      "beta": 0.010395975646327035,
      "success": true,
      "log_likelihood": -21.500815751895306,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4679493341833136,
      "theta": 0.5,
      "beta": -1.6458119380929241,
      "success": true,
      "log_likelihood": -10.946032401000807,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0078944297833174,
      "theta": 0.5,
      "beta": 0.8367544320468729,
      "success": true,
      "log_likelihood": -17.592091655163998,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5479466907810923,
      "theta": 1.681391775825316,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -8.04410881646553,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9715847404892106,
      "theta": 0.5215418021433127,
      "beta": 3.23630813519716,
      "success": true,
      "log_likelihood": -10.446730846758841,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7569507374513431,
      "theta": 0.5,
      "beta": 0.6709187222283017,
      "success": true,
      "log_likelihood": -19.73425682787392,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -3.970037257667721,
      "theta": 2.0,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -68.97918288370244,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "theta": 0.794288378083295,
      "beta": -5.0,
      "success": true,
      "log_likelihood": -0.13409840088028432,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7933297305029138,
      "theta": 0.5,
      "beta": -2.001713863322191,
      "success": true,
      "log_likelihood": -11.632733527749272,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.0944811722233543,
      "theta": 0.5,
      "beta": 0.7159623865515456,
      "success": true,
      "log_likelihood": -17.026858935995755,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5006334852910879,
      "theta": 0.5,
      "beta": 1.6931823231444731,
      "success": true,
      "log_likelihood": -17.04872623139919,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3529995283439704,
      "theta": 0.5,
      "beta": 0.17617782440395252,
      "success": true,
      "log_likelihood": -23.45417380684749,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9596086568685762,
      "theta": 1.6906944215472115,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -12.20074270470188,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8345800867410093,
      "theta": 0.5,
      "beta": 4.113138188973804,
      "success": true,
      "log_likelihood": -6.014893708285562,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6554801849097094,
      "theta": 0.5,
      "beta": -3.0241889908206905,
      "success": true,
      "log_likelihood": -6.742278877286575,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.24676198011913275,
      "theta": 0.5,
      "beta": 0.5955407447353407,
      "success": true,
      "log_likelihood": -23.3106490135938,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3591735126036202,
      "theta": 0.5,
      "beta": -3.42671751035901,
      "success": true,
      "log_likelihood": -6.4385257648478404,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3862016906339461,
      "theta": 0.5,
      "beta": 0.31515268484059344,
      "success": true,
      "log_likelihood": -23.143065601684967,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.07206702420247864,
      "theta": 2.0,
      "beta": 2.721456414273289,
      "success": true,
      "log_likelihood": -10.29115588312093,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8163753588565934,
      "theta": 0.5,
      "beta": -2.32991544205626,
      "success": true,
      "log_likelihood": -10.035455107179642,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3409492033650836,
      "theta": 0.5,
      "beta": 0.6580120404499709,
      "success": true,
      "log_likelihood": -15.294929275063694,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.22903197694527086,
      "theta": 1.1355217783508822,
      "beta": 1.1112824725883075,
      "success": true,
      "log_likelihood": -23.198739437785328,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.8213915734914394,
      "theta": 0.8716377186384627,
      "beta": -1.036584935843181,
      "success": true,
      "log_likelihood": -6.719084919329779,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.751908490438833,
      "theta": 0.7228404901116724,
      "beta": 2.2321154211419736,
      "success": true,
      "log_likelihood": -17.22944541387378,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9854438487988515,
      "theta": 0.5162814032022365,
      "beta": -1.2979715154576494,
      "success": true,
      "log_likelihood": -13.766726184549134,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.2093667474549603,
      "theta": 0.5,
      "beta": 5.0,
      "success": true,
      "log_likelihood": -4.616099225601627,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9237242664971556,
      "theta": 0.5,
      "beta": 0.291882933698115,
      "success": true,
      "log_likelihood": -18.417793106569892,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.27542152229503253,
      "theta": 2.0,
      "beta": 2.0816850237434434,
      "success": true,
      "log_likelihood": -20.84947600831602,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "alpha": {
        "r": 0.9554319805624053,
        "p": 1.6355092411702007e-05
      },
      "theta": {
        "r": 0.6841259147137766,
        "p": 0.029120089144184003
      },
      "beta": {
        "r": 0.3777233068751741,
        "p": 0.2818692447459221
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 36.06997144602349,
  "bic_results": {
    "average_bic": 36.06997144602349,
    "individual_bics": [
      23.627608345686475,
      45.225861944268274,
      28.48992571095322,
      41.109999368583246,
      24.707436958222406,
      36.51962260782073,
      10.763991819263461,
      33.61392900672416,
      10.763989214013188,
      35.00346430408737,
      20.101223998533513,
      25.90715322175376,
      30.414803591325533,
      10.763989170135144,
      10.763990333994478,
      10.763990357713404,
      10.763991440288914,
      28.972736384014215,
      21.100738335361363,
      10.76398923186996,
      38.69454722441145,
      26.13748214916405,
      48.862041913488014,
      48.247445273634824,
      31.290728105022552,
      42.32926299506241,
      42.28115570442432,
      21.569117914232883,
      25.535933080720874,
      39.15382870291447,
      10.763989170135144,
      23.627608344752844,
      55.015949159026704,
      44.7255411812441,
      10.763989170135144,
      47.68284509000736,
      30.541885449022356,
      38.0673158512154,
      43.278337338888306,
      27.89866508767264,
      41.44219423369486,
      34.432301354339984,
      18.974025358770174,
      48.3966109252583,
      41.367276259536425,
      47.65751690651902,
      44.94810462860039,
      49.29909149771282,
      27.081230880791555,
      59.21570122631428,
      47.73489639841941,
      35.02718794651525,
      53.27748062653343,
      57.56633780490341,
      46.052210912552255,
      21.06749986356288,
      32.70282499927818,
      33.448104519018045,
      27.688929720240388,
      43.31752296951777,
      51.463870868276075,
      39.33543762689505,
      23.627608345739137,
      53.75218831915895,
      32.64262161736994,
      45.93474012569632,
      26.83877444829939,
      31.644018508886013,
      50.21907047111617,
      148.7089225827732,
      11.0187536171289,
      34.016023870866874,
      44.804274687359836,
      44.848009278166714,
      57.65890442906331,
      35.15204222477209,
      22.780344231939452,
      24.23511456994148,
      57.37185484255593,
      23.62760834506401,
      57.03668801873826,
      31.332868581610192,
      30.821467029727614,
      41.340415365495716,
      57.14803569093898,
      24.18872665402789,
      45.209447643115894,
      38.2840091844666,
      19.982755266571587,
      47.58614302850812,
      52.449508832000376
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 3,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- alpha: r = 0.955\n- theta: r = 0.684\n- beta: r = 0.378",
  "previous_models": [
    "Specification: U = alpha * (split_self - (theta * token_self / (theta * token_self + token_opp) * combined_earning)) + beta\nSummary: A fairness-weighted utility model where participants evaluate offers relative to a contribution-adjusted reference point. The fair share is computed by non-linearly weighting the participant's own tokens (theta) against the opponent's. Utility combines deviation from this dynamic fairness threshold with a baseline acceptance bias (beta), scaled by sensitivity parameter alpha. Parameters allow recovery of strategic weighting of contributions and loss aversion characteristics.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 36.06997144602349\nOverall Accuracy: 0.7909\n\nParameter Recovery:\n- alpha: r = 0.955\n- theta: r = 0.684\n- beta: r = 0.378"
  ]
}