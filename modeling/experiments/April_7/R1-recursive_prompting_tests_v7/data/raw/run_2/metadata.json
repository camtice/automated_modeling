{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\n\nOkay, let's look at the previous model's results. The BIC was 42.73, which is okay, but there's room for improvement. The accuracy was around 79.5%, which is decent but could be higher. The parameter recovery for theta_plus was 0.855 and theta_minus was 0.928. That's pretty good, especially for theta_minus, but theta_plus has a bit lower recovery.\n\nHmm, the previous instructions emphasized minimizing the number of parameters and avoiding covariance. The model had two parameters, which seems manageable. But maybe there's a way to improve the model's structure to better capture the underlying psychological mechanisms, leading to better accuracy and lower BIC.\n\nThe current model uses split_self and adjusts it based on deviation from the fair share (3*token_self) with separate parameters for advantageous and disadvantageous inequity. But perhaps there are other factors at play. For example, participants might also consider the opponent's split (split_opp) or the relative percentages. However, the problem states that the model should use the provided variables but not necessarily all. Including split_opp might add complexity, but maybe it's worth testing.\n\nAlternatively, the model could incorporate a non-linear transformation of the deviation. The current model is linear in theta_plus and theta_minus. Maybe using a sigmoid or exponential function for the deviation terms could better capture diminishing sensitivity or threshold effects. But that would add more parameters or require different functional forms.\n\nAnother angle: the current model assumes that the fair share is exactly 3*token_self. But maybe participants have a different notion of fairness, such as equal split (50%) regardless of contribution. That could be tested by comparing the current model's fairness calculation to an alternative. However, the problem's data includes trial_type, which indicates whether contributions are equal, opponent more, or participant more. Maybe incorporating trial_type as a moderator for theta_plus and theta_minus could improve the model. For example, participants might be more sensitive to disadvantageous inequity when they contributed more (trial_type=3).\n\nBut adding interaction terms with trial_type would increase the number of parameters. However, if it significantly improves model fit, it might be worth it. Alternatively, use trial_type to adjust the reference point. For instance, in trials where the participant contributed more, the fair share might be higher than 3*token_self. But that complicates the model.\n\nWait, the current model's fair share is based purely on the participant's contribution. But in reality, people might consider the opponent's contribution as well. For example, if the opponent contributed more, the participant might feel entitled to a smaller share. But according to the problem's data, the fair share calculation simplifies to 3*token_self, which might not account for the opponent's contribution. However, the combined_earning is (token_self + token_opp)*3, so the fair share based on contribution is (token_self / (token_self + token_opp)) * combined_earning = 3*token_self. So, the opponent's contribution doesn't affect the fair share in this calculation. But maybe participants actually consider the opponent's contribution when evaluating fairness. For example, if the opponent contributed more, the participant might accept a lower split_self. This could be modeled by including token_opp in the fairness calculation.\n\nWait, but according to the previous model, the fair share is 3*token_self, which doesn't involve token_opp. But maybe the correct fair share should be (token_self / (token_self + token_opp)) * combined_earning, which is 3*token_self. So, the model is correct. However, perhaps participants have a different perception, such as expecting an equal split (50%) regardless of contribution. In that case, the fair share would be combined_earning / 2. So, the deviation D would be split_self - (combined_earning / 2). This is a different fairness measure. Comparing these two fairness measures (contribution-based vs. equal split) could improve the model.\n\nSo, the new model could have two fairness terms: one based on contribution and another based on equal split. But that would add more parameters. Alternatively, let the model choose which fairness measure to use by including both and letting the parameters adjust their weights.\n\nAnother idea: include an intercept term. The current model doesn't have a baseline utility. Adding a parameter like beta_0 could capture the baseline tendency to accept or reject offers independent of the split. This might improve accuracy.\n\nAlso, the current model uses a logistic function with temperature 1. Maybe allowing the temperature parameter (inverse of decision noise) to be learned could help. But that adds another parameter, which might increase BIC. However, if it significantly improves fit, it could be worth it.\n\nAlternatively, consider non-linear interactions between the split_self and the fairness deviation. For example, the utility could be split_self * (1 + theta_plus * D) when D is positive, etc. But this complicates the model.\n\nThe previous instructions told the modeler to be considerate of parameter covariance and prefer fewer parameters. The current model has two parameters, which is good. To improve, maybe introduce a non-linear term without adding parameters. For example, use a piecewise linear function with a kink at zero, but that's what's already done.\n\nWait, the parameter recovery for theta_plus is lower than theta_minus. Maybe theta_plus and theta_minus are correlated, leading to estimation issues. To reduce covariance, perhaps orthogonalize the terms. For example, center the D variable or use orthogonal parameters. Alternatively, reparameterize the model to have one parameter for the overall sensitivity and another for the asymmetry between advantageous and disadvantageous inequity.\n\nFor example, let theta = (theta_plus + theta_minus)/2 and delta = (theta_plus - theta_minus)/2. This might reduce covariance between the parameters. But this is a reparameterization and doesn't change the model's predictive power, just the estimation stability.\n\nAlternatively, constrain one of the parameters. For example, set theta_plus to zero if advantageous inequity doesn't affect utility. But the data might show that theta_plus is non-zero.\n\nAnother approach: include a non-linear transformation of D, such as squaring it for disadvantageous inequity to capture increasing aversion as the deviation grows. But this would require additional parameters.\n\nAlternatively, model the utility as split_self + theta_plus * sqrt(max(D,0)) + theta_minus * sqrt(-min(D,0)). This assumes diminishing sensitivity to larger deviations. But without adding parameters, this might not be possible.\n\nWait, the current model is linear in D for both advantageous and disadvantageous cases. If the true relationship is non-linear, the model might miss that. However, adding non-linear terms without additional parameters is tricky. Maybe using an absolute value for D in the disadvantageous case: U = split_self + theta_plus * max(D,0) + theta_minus * abs(min(D,0)). But this is still linear in parameters.\n\nAlternatively, use a sigmoid function to cap the effect of large D, but that would require a parameter for the steepness.\n\nGiven the constraints, perhaps the best approach is to keep the model structure but suggest exploring additional psychological mechanisms, such as reference points or non-linear sensitivity, while maintaining a parsimonious parameter count. Also, encourage testing alternative fairness calculations, like equal splits, and including baseline acceptance tendencies.\n\nThe new instructions should guide the modeler to consider these possibilities, perhaps by suggesting incorporating alternative fairness reference points, non-linear effects, or intercept terms, while still being mindful of parameter count and covariance. Additionally, emphasize improving parameter recovery for theta_plus by suggesting orthogonalizing parameters or exploring different functional forms that might reduce covariance.\n</think>\n\n**Revised Instructions for Run 2/3:**  \nFocus on improving asymmetric fairness sensitivity modeling while maintaining parameter interpretability. Consider the following directions:  \n\n1. **Non-linear Fairness Effects**  \n   - Explore diminishing/increasing sensitivity to large deviations from fairness (e.g., log-transformed inequity terms or quadratic components)  \n   - Test if disadvantageous inequity requires stronger curvature than advantageous  \n\n2. **Alternative Reference Points**  \n   - Compare contribution-based fairness (current 3\u00d7token_self) vs. equal-split fairness (50% of combined_earning)  \n   - Consider hybrid fairness perceptions weighted by trial_type (participant/opponent contribution dominance)  \n\n3. **Strategic Baseline**  \n   - Add intercept parameter to capture baseline acceptance tendency independent of splits  \n   - Implement soft constraints to prevent overlap with existing fairness terms  \n\n4. **Parameter Orthogonalization**  \n   - Reparameterize theta_plus/theta_minus as (mean_sensitivity, asymmetry_ratio) to reduce covariance  \n   - Example: theta_plus = base_sensitivity * (1 + asymmetry), theta_minus = base_sensitivity * (1 - asymmetry)  \n\nMaintain \u22643 learnable parameters. Prioritize models where all recovered parameters achieve r > 0.9 in simulation tests. Explicitly compare BIC improvements from any added complexity against the base model.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\n\nOkay, let's look at the previous model's results. The BIC was 42.73, which is okay, but there's room for improvement. The accuracy was around 79.5%, which is decent but could be higher. The parameter recovery for theta_plus was 0.855 and theta_minus was 0.928. That's pretty good, especially for theta_minus, but theta_plus has a bit lower recovery.\n\nHmm, the previous instructions emphasized minimizing the number of parameters and avoiding covariance. The model had two parameters, which seems manageable. But maybe there's a way to improve the model's structure to better capture the underlying psychological mechanisms, leading to better accuracy and lower BIC.\n\nThe current model uses split_self and adjusts it based on deviation from the fair share (3*token_self) with separate parameters for advantageous and disadvantageous inequity. But perhaps there are other factors at play. For example, participants might also consider the opponent's split (split_opp) or the relative percentages. However, the problem states that the model should use the provided variables but not necessarily all. Including split_opp might add complexity, but maybe it's worth testing.\n\nAlternatively, the model could incorporate a non-linear transformation of the deviation. The current model is linear in theta_plus and theta_minus. Maybe using a sigmoid or exponential function for the deviation terms could better capture diminishing sensitivity or threshold effects. But that would add more parameters or require different functional forms.\n\nAnother angle: the current model assumes that the fair share is exactly 3*token_self. But maybe participants have a different notion of fairness, such as equal split (50%) regardless of contribution. That could be tested by comparing the current model's fairness calculation to an alternative. However, the problem's data includes trial_type, which indicates whether contributions are equal, opponent more, or participant more. Maybe incorporating trial_type as a moderator for theta_plus and theta_minus could improve the model. For example, participants might be more sensitive to disadvantageous inequity when they contributed more (trial_type=3).\n\nBut adding interaction terms with trial_type would increase the number of parameters. However, if it significantly improves model fit, it might be worth it. Alternatively, use trial_type to adjust the reference point. For instance, in trials where the participant contributed more, the fair share might be higher than 3*token_self. But that complicates the model.\n\nWait, the current model's fair share is based purely on the participant's contribution. But in reality, people might consider the opponent's contribution as well. For example, if the opponent contributed more, the participant might feel entitled to a smaller share. But according to the problem's data, the fair share calculation simplifies to 3*token_self, which might not account for the opponent's contribution. However, the combined_earning is (token_self + token_opp)*3, so the fair share based on contribution is (token_self / (token_self + token_opp)) * combined_earning = 3*token_self. So, the opponent's contribution doesn't affect the fair share in this calculation. But maybe participants actually consider the opponent's contribution when evaluating fairness. For example, if the opponent contributed more, the participant might accept a lower split_self. This could be modeled by including token_opp in the fairness calculation.\n\nWait, but according to the previous model, the fair share is 3*token_self, which doesn't involve token_opp. But maybe the correct fair share should be (token_self / (token_self + token_opp)) * combined_earning, which is 3*token_self. So, the model is correct. However, perhaps participants have a different perception, such as expecting an equal split (50%) regardless of contribution. In that case, the fair share would be combined_earning / 2. So, the deviation D would be split_self - (combined_earning / 2). This is a different fairness measure. Comparing these two fairness measures (contribution-based vs. equal split) could improve the model.\n\nSo, the new model could have two fairness terms: one based on contribution and another based on equal split. But that would add more parameters. Alternatively, let the model choose which fairness measure to use by including both and letting the parameters adjust their weights.\n\nAnother idea: include an intercept term. The current model doesn't have a baseline utility. Adding a parameter like beta_0 could capture the baseline tendency to accept or reject offers independent of the split. This might improve accuracy.\n\nAlso, the current model uses a logistic function with temperature 1. Maybe allowing the temperature parameter (inverse of decision noise) to be learned could help. But that adds another parameter, which might increase BIC. However, if it significantly improves fit, it could be worth it.\n\nAlternatively, consider non-linear interactions between the split_self and the fairness deviation. For example, the utility could be split_self * (1 + theta_plus * D) when D is positive, etc. But this complicates the model.\n\nThe previous instructions told the modeler to be considerate of parameter covariance and prefer fewer parameters. The current model has two parameters, which is good. To improve, maybe introduce a non-linear term without adding parameters. For example, use a piecewise linear function with a kink at zero, but that's what's already done.\n\nWait, the parameter recovery for theta_plus is lower than theta_minus. Maybe theta_plus and theta_minus are correlated, leading to estimation issues. To reduce covariance, perhaps orthogonalize the terms. For example, center the D variable or use orthogonal parameters. Alternatively, reparameterize the model to have one parameter for the overall sensitivity and another for the asymmetry between advantageous and disadvantageous inequity.\n\nFor example, let theta = (theta_plus + theta_minus)/2 and delta = (theta_plus - theta_minus)/2. This might reduce covariance between the parameters. But this is a reparameterization and doesn't change the model's predictive power, just the estimation stability.\n\nAlternatively, constrain one of the parameters. For example, set theta_plus to zero if advantageous inequity doesn't affect utility. But the data might show that theta_plus is non-zero.\n\nAnother approach: include a non-linear transformation of D, such as squaring it for disadvantageous inequity to capture increasing aversion as the deviation grows. But this would require additional parameters.\n\nAlternatively, model the utility as split_self + theta_plus * sqrt(max(D,0)) + theta_minus * sqrt(-min(D,0)). This assumes diminishing sensitivity to larger deviations. But without adding parameters, this might not be possible.\n\nWait, the current model is linear in D for both advantageous and disadvantageous cases. If the true relationship is non-linear, the model might miss that. However, adding non-linear terms without additional parameters is tricky. Maybe using an absolute value for D in the disadvantageous case: U = split_self + theta_plus * max(D,0) + theta_minus * abs(min(D,0)). But this is still linear in parameters.\n\nAlternatively, use a sigmoid function to cap the effect of large D, but that would require a parameter for the steepness.\n\nGiven the constraints, perhaps the best approach is to keep the model structure but suggest exploring additional psychological mechanisms, such as reference points or non-linear sensitivity, while maintaining a parsimonious parameter count. Also, encourage testing alternative fairness calculations, like equal splits, and including baseline acceptance tendencies.\n\nThe new instructions should guide the modeler to consider these possibilities, perhaps by suggesting incorporating alternative fairness reference points, non-linear effects, or intercept terms, while still being mindful of parameter count and covariance. Additionally, emphasize improving parameter recovery for theta_plus by suggesting orthogonalizing parameters or exploring different functional forms that might reduce covariance.\n</think>\n\n**Revised Instructions for Run 2/3:**  \nFocus on improving asymmetric fairness sensitivity modeling while maintaining parameter interpretability. Consider the following directions:  \n\n1. **Non-linear Fairness Effects**  \n   - Explore diminishing/increasing sensitivity to large deviations from fairness (e.g., log-transformed inequity terms or quadratic components)  \n   - Test if disadvantageous inequity requires stronger curvature than advantageous  \n\n2. **Alternative Reference Points**  \n   - Compare contribution-based fairness (current 3\u00d7token_self) vs. equal-split fairness (50% of combined_earning)  \n   - Consider hybrid fairness perceptions weighted by trial_type (participant/opponent contribution dominance)  \n\n3. **Strategic Baseline**  \n   - Add intercept parameter to capture baseline acceptance tendency independent of splits  \n   - Implement soft constraints to prevent overlap with existing fairness terms  \n\n4. **Parameter Orthogonalization**  \n   - Reparameterize theta_plus/theta_minus as (mean_sensitivity, asymmetry_ratio) to reduce covariance  \n   - Example: theta_plus = base_sensitivity * (1 + asymmetry), theta_minus = base_sensitivity * (1 - asymmetry)  \n\nMaintain \u22643 learnable parameters. Prioritize models where all recovered parameters achieve r > 0.9 in simulation tests. Explicitly compare BIC improvements from any added complexity against the base model.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant accepts or rejects a proposal, focusing on responder behavior. The model needs to use the given variables appropriately, pass parameter recovery tests, and predict utility such that a utility less than 0 corresponds to less than 50% likelihood of acceptance.\n\nFirst, I need to identify the key variables that influence the responder's decision. The target variable is \"accept\", which is binary. The main factors likely involve fairness considerations based on the participant's and opponent's contributions and the proposed splits.\n\nThe problem mentions that each token is worth \u00a33, so the combined earnings are (token_self + token_opp) * 3. The fair share based on contribution would be 3 * token_self. The proposed split for the participant is split_self. The deviation from the fair share is split_self - 3 * token_self. If this deviation is positive, the participant is getting more than their fair share (advantageous inequity), and if negative, less (disadvantageous inequity).\n\nResearch in behavioral economics suggests that people have different sensitivities to advantageous vs. disadvantageous inequity. So, the model should incorporate parameters that capture these sensitivities separately. Let's call them theta_plus (for advantageous) and theta_minus (for disadvantageous). These parameters will scale the utility based on the deviation from fairness.\n\nThe utility function could be structured as:\nUtility = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0)\nwhere D = split_self - 3 * token_self (deviation from fair share).\n\nThis way, when D is positive (advantageous), theta_plus affects the utility positively, and when D is negative (disadvantageous), theta_minus affects it negatively. The split_self is the direct monetary gain, which is a baseline.\n\nTo convert utility to a probability of acceptance, we use a logistic function. The probability P(accept) = 1 / (1 + exp(-Utility)). This ensures that when Utility is positive, the probability is above 50%, and vice versa.\n\nNow, considering parameter bounds. Theta_plus and theta_minus should be bounded to prevent unrealistic values. Theta_plus could range from -1 to 1, allowing for both positive and negative effects, though typically advantageous inequity might have a positive or negligible effect. Theta_minus, capturing aversion to disadvantageous inequity, should be negative, so a range from -5 to 0. These bounds are generous but finite.\n\nVariables like split_self and token_self come directly from the data. D is calculated as split_self - 3 * token_self. The parameters theta_plus and theta_minus are learnable.\n\nThe model should only use variables available in the dataset. Since the task is to predict responder behavior, we filter trials where trial_role is 1 (responder). The combined_earning is already accounted for in split_self and split_opp, so it's not directly needed unless there's an alternative fairness consideration, but the current model uses contribution-based fairness.\n\nTesting parameter recovery is crucial. By simulating data with known parameters and fitting the model, we can check if the estimated parameters match the true values. The model's structure should allow for distinct identification of theta_plus and theta_minus, avoiding high covariance between them.\n\nIn summary, the model uses the proposed split, adjusts for fairness based on contributions, and incorporates asymmetric sensitivity to inequity. The parameters are bounded to ensure identifiability and realistic interpretation.\n</think>\n\n<MODEL>\nU = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"theta_plus\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than fair share)\",\n      \"range\": {\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta_minus\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than fair share)\",\n      \"range\": {\n        \"min\": -5.0,\n        \"max\": 0.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's contribution in tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"D\": {\n      \"description\": \"Deviation from contribution-based fair share (split_self - 3*token_self)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA fairness-adjusted utility model where acceptance decisions depend on monetary gain and asymmetric sensitivity to deviations from contribution-based fairness. Participants derive utility from their proposed share (split_self), modified by parameters capturing different sensitivities to advantageous (theta_plus) and disadvantageous (theta_minus) inequity relative to their token contribution. The model uses two learnable parameters with constrained ranges to ensure identifiability.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['theta_plus', 'theta_minus']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"theta_plus\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than fair share)\",\n      \"range\": {\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta_minus\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than fair share)\",\n      \"range\": {\n        \"min\": -5.0,\n        \"max\": 0.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's contribution in tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"D\": {\n      \"description\": \"Deviation from contribution-based fair share (split_self - 3*token_self)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, theta_plus=0, theta_minus=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        D = split_self - 3 * token_self\n        utility = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0)\n\n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 0, \"group\": \"control\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 30, \"split_opp\": 15.0, \"split_self\": 15.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 15.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 15.0}, {\"ID\": 1, \"group\": \"control\", \"trial_number\": 2, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 30, \"split_opp\": 15.0, \"split_self\": 15.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 15.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 15.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n```",
      "timestamp": 1744031631.382137
    }
  ],
  "learnable_parameters": {
    "theta_plus": {
      "description": "Sensitivity to advantageous inequity (receiving more than fair share)",
      "range": {
        "min": -1.0,
        "max": 1.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {}
      },
      "learnable": true,
      "source": "learnable"
    },
    "theta_minus": {
      "description": "Sensitivity to disadvantageous inequity (receiving less than fair share)",
      "range": {
        "min": -5.0,
        "max": 0.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {}
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "theta_plus": {
      "description": "Sensitivity to advantageous inequity (receiving more than fair share)",
      "range": {
        "min": -1.0,
        "max": 1.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {}
      },
      "learnable": true,
      "source": "learnable"
    },
    "theta_minus": {
      "description": "Sensitivity to disadvantageous inequity (receiving less than fair share)",
      "range": {
        "min": -5.0,
        "max": 0.0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform",
        "parameters": {}
      },
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for participant in \u00a3",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant's contribution in tokens",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "D": {
      "description": "Deviation from contribution-based fair share (split_self - 3*token_self)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    }
  },
  "model_summary": "A fairness-adjusted utility model where acceptance decisions depend on monetary gain and asymmetric sensitivity to deviations from contribution-based fairness. Participants derive utility from their proposed share (split_self), modified by parameters capturing different sensitivities to advantageous (theta_plus) and disadvantageous (theta_minus) inequity relative to their token contribution. The model uses two learnable parameters with constrained ranges to ensure identifiability.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant accepts or rejects a proposal, focusing on responder behavior. The model needs to use the given variables appropriately, pass parameter recovery tests, and predict utility such that a utility less than 0 corresponds to less than 50% likelihood of acceptance.\n\nFirst, I need to identify the key variables that influence the responder's decision. The target variable is \"accept\", which is binary. The main factors likely involve fairness considerations based on the participant's and opponent's contributions and the proposed splits.\n\nThe problem mentions that each token is worth \u00a33, so the combined earnings are (token_self + token_opp) * 3. The fair share based on contribution would be 3 * token_self. The proposed split for the participant is split_self. The deviation from the fair share is split_self - 3 * token_self. If this deviation is positive, the participant is getting more than their fair share (advantageous inequity), and if negative, less (disadvantageous inequity).\n\nResearch in behavioral economics suggests that people have different sensitivities to advantageous vs. disadvantageous inequity. So, the model should incorporate parameters that capture these sensitivities separately. Let's call them theta_plus (for advantageous) and theta_minus (for disadvantageous). These parameters will scale the utility based on the deviation from fairness.\n\nThe utility function could be structured as:\nUtility = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0)\nwhere D = split_self - 3 * token_self (deviation from fair share).\n\nThis way, when D is positive (advantageous), theta_plus affects the utility positively, and when D is negative (disadvantageous), theta_minus affects it negatively. The split_self is the direct monetary gain, which is a baseline.\n\nTo convert utility to a probability of acceptance, we use a logistic function. The probability P(accept) = 1 / (1 + exp(-Utility)). This ensures that when Utility is positive, the probability is above 50%, and vice versa.\n\nNow, considering parameter bounds. Theta_plus and theta_minus should be bounded to prevent unrealistic values. Theta_plus could range from -1 to 1, allowing for both positive and negative effects, though typically advantageous inequity might have a positive or negligible effect. Theta_minus, capturing aversion to disadvantageous inequity, should be negative, so a range from -5 to 0. These bounds are generous but finite.\n\nVariables like split_self and token_self come directly from the data. D is calculated as split_self - 3 * token_self. The parameters theta_plus and theta_minus are learnable.\n\nThe model should only use variables available in the dataset. Since the task is to predict responder behavior, we filter trials where trial_role is 1 (responder). The combined_earning is already accounted for in split_self and split_opp, so it's not directly needed unless there's an alternative fairness consideration, but the current model uses contribution-based fairness.\n\nTesting parameter recovery is crucial. By simulating data with known parameters and fitting the model, we can check if the estimated parameters match the true values. The model's structure should allow for distinct identification of theta_plus and theta_minus, avoiding high covariance between them.\n\nIn summary, the model uses the proposed split, adjusts for fairness based on contributions, and incorporates asymmetric sensitivity to inequity. The parameters are bounded to ensure identifiability and realistic interpretation.\n</think>\n\n<MODEL>\nU = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"theta_plus\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than fair share)\",\n      \"range\": {\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta_minus\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than fair share)\",\n      \"range\": {\n        \"min\": -5.0,\n        \"max\": 0.0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\",\n        \"parameters\": {}\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's contribution in tokens\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"D\": {\n      \"description\": \"Deviation from contribution-based fair share (split_self - 3*token_self)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA fairness-adjusted utility model where acceptance decisions depend on monetary gain and asymmetric sensitivity to deviations from contribution-based fairness. Participants derive utility from their proposed share (split_self), modified by parameters capturing different sensitivities to advantageous (theta_plus) and disadvantageous (theta_minus) inequity relative to their token contribution. The model uses two learnable parameters with constrained ranges to ensure identifiability.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self\nSummary: A fairness-adjusted utility model where acceptance decisions depend on monetary gain and asymmetric sensitivity to deviations from contribution-based fairness. Participants derive utility from their proposed share (split_self), modified by parameters capturing different sensitivities to advantageous (theta_plus) and disadvantageous (theta_minus) inequity relative to their token contribution. The model uses two learnable parameters with constrained ranges to ensure identifiability.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, theta_plus=0, theta_minus=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        D = split_self - 3 * token_self\n        utility = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0)\n\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.5866910866910866,
  "fitting_results": [
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -112.52954496356355,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.08333333333333333,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -55.29973036975275,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -50.499730359208755,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -61.14973036698842,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -65.34973031134534,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -35.94973041925489,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.057843667266481845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -34.44973040338874,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.057843667266481845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -69.84973034567335,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -59.94973035576305,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -107.27954498261963,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.1388888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -66.99973031265198,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.057843667266481845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.057843667266481845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.05784366726648184,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.05784366726648185,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -9.54973044510446,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -10.599730441582453,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.05784366726648183,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -51.09973034215202,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -12.999730440263775,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -68.34973033306727,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -48.84973035919333,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -61.299730312872015,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -42.54973036878236,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -44.1997303962451,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -85.14973028474802,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.25,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -11.949730442144464,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -25.44973040960138,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.057843667266481845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -112.52954496356354,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.16666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -63.5497303305283,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -68.04973034874202,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -5.0,
      "success": true,
      "log_likelihood": -0.05784366726648185,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -29.799730432700972,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -27.249730433048292,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -57.69973034961613,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -38.49973036534462,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -10.149730437133503,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -46.14973036639821,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -93.0997302622652,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.2222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -0.17319944285329056,
      "success": true,
      "log_likelihood": -7.497333123241597,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -44.949730392745664,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -38.49973041392215,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -25.299730428404626,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -51.09973035500966,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -66.99973036711106,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -71.94973029749346,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -52.529545128507344,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -31.44973042375953,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -104.87954498371286,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.1388888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -47.34973036619037,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -41.72954516325691,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -75.54973028952712,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -76.29973030341034,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -84.69973027754493,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3333333333333333,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": -0.12180483349466423,
      "success": true,
      "log_likelihood": -15.857275205175432,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -107.72954497571375,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.2222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -18.099730423882225,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -43.44973038139805,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -57.999730325005295,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -112.52954496356355,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.16666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -59.34973035348744,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -89.79973030307198,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -43.8997303967674,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -9.249730443625719,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -15.249730422086815,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -40.14973042200599,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -12.54973040512413,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -107.9497302335795,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.16666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -104.12954497937089,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.1388888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -49.59973039252907,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -20.499730434611315,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -56.42954512714171,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -32.649730403977166,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -7.899730442310199,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -118.82954495286126,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.08333333333333333,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -42.39973039500306,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -112.52954496356354,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.19444444444444445,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -55.599730332116444,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -12.849730422433714,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -107.87954498170932,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.16666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -45.39973041725303,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -50.94973032992871,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -109.44973020223749,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.16666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -34.59973040380191,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": -1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -93.62954501563196,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -6.549730445241282,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -47.34973042052263,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "theta_plus": 1.0,
      "theta_minus": 0.0,
      "success": true,
      "log_likelihood": -36.09973039909788,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "theta_plus": {
        "r": 0.00763934738687619,
        "p": 0.9398693215632732
      },
      "theta_minus": {
        "r": 0.5168016945749871,
        "p": 3.701213981213462e-08
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 104.71914856021714,
  "bic_results": {
    "average_bic": 104.71914856021714,
    "individual_bics": [
      232.22612780403932,
      117.76649861641772,
      108.16649859532973,
      129.46649861088906,
      137.8664984996029,
      79.066498715422,
      7.282725211445183,
      76.0664986836897,
      7.282725211445183,
      146.86649856825892,
      127.06649858843832,
      221.72612784215147,
      141.16649850221617,
      7.282725211445183,
      7.282725211445183,
      7.282725211445183,
      7.282725211445183,
      26.266498767121142,
      28.36649876007713,
      7.282725211445183,
      109.36649856121626,
      33.16649875743977,
      143.86649854304676,
      104.86649859529888,
      129.76649850265625,
      92.26649861447694,
      95.56649866940242,
      177.46649844640825,
      31.066498761201146,
      58.06649869611498,
      7.282725211445183,
      232.2261278040393,
      134.26649853796883,
      143.26649857439625,
      7.282725211445183,
      66.76649874231417,
      61.6664987430088,
      122.56649857614448,
      84.16649860760145,
      27.466498751179223,
      99.46649860970864,
      193.3664984014426,
      22.161704123395413,
      97.06649866240355,
      84.16649870475652,
      57.76649873372147,
      109.36649858693154,
      141.16649861113433,
      151.06649847189914,
      112.2261281339269,
      70.06649872443128,
      216.92612784433794,
      101.86649860929296,
      90.62612820342603,
      158.26649845596646,
      159.7664984837329,
      176.56649843200208,
      38.881588287263085,
      222.62612782833972,
      43.36649872467667,
      94.06649863970831,
      123.16649852692281,
      232.22612780403932,
      125.8664985838871,
      186.76649848305618,
      94.96649867044702,
      25.666498764163656,
      37.66649872108585,
      87.46649872092419,
      32.26649868716048,
      223.06649834407122,
      215.426127835654,
      106.36649866197035,
      48.16649874613485,
      120.02612813119563,
      72.46649868486655,
      22.96649876153262,
      244.82612778263473,
      91.96649866691834,
      232.2261278040393,
      118.3664985411451,
      32.86649872177965,
      222.92612784033085,
      97.96649871141828,
      109.06649853676964,
      226.0664982813872,
      76.36649868451603,
      194.42612790817614,
      20.266498767394786,
      101.86649871795748,
      79.36649867510798
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 2,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- theta_plus: r = 0.008\n- theta_minus: r = 0.517",
  "previous_models": [
    "Specification: U = split_self + theta_plus * max(D, 0) + theta_minus * min(D, 0) where D = split_self - 3*token_self\nSummary: A fairness-adjusted utility model where acceptance decisions depend on monetary gain and asymmetric sensitivity to deviations from contribution-based fairness. Participants derive utility from their proposed share (split_self), modified by parameters capturing different sensitivities to advantageous (theta_plus) and disadvantageous (theta_minus) inequity relative to their token contribution. The model uses two learnable parameters with constrained ranges to ensure identifiability.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 104.71914856021714\nOverall Accuracy: 0.5867\n\nParameter Recovery:\n- theta_plus: r = 0.008\n- theta_minus: r = 0.517"
  ]
}