{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "Okay, let's analyze the results and craft the instructions for the next run.\n\n**Analysis:**\nThe previous run (Run 4) attempted to build on the success of Run 3 by adding a learnable temperature parameter (`tau`) to the proportional inequity model (`U = split_perc - k * abs(split_perc - fair_perc)`). The results were disappointing:\n*   BIC increased from 42.20 (Run 3) to 46.32 (Run 4).\n*   Accuracy decreased from 0.600 (Run 3) to 0.582 (Run 4).\n*   Parameter recovery plummeted from excellent (k: r = 0.855) to poor (k: r = 0.421, tau: r = -0.257).\n\nThis strongly suggests that adding `tau` introduced identifiability issues, likely because the scaling effect of `k` on the utility difference and the scaling effect of `tau` in the logistic function could not be disentangled (`P = 1 / (1 + exp(-U/tau))`). The successful proportional framework of Run 3 was not sufficient to make `tau` identifiable alongside `k`.\n\n**Goal for Next Run (Run 5):**\nImprove upon the best model so far (Run 3: BIC 42.20, Acc 0.600, k Recovery 0.855). The primary focus is to achieve **lower BIC and higher accuracy** than Run 3, while critically **maintaining excellent parameter recovery (r > 0.7 for *all* learnable parameters)**. Given the failure of adding `tau`, we need to explore other avenues for refinement.\n\n**New Instructions:**\n\nThe previous run (Run 4) attempted to improve the best model (Run 3) by introducing a learnable temperature parameter (`tau`). However, this led to worse BIC (46.3 vs 42.2), lower accuracy (0.582 vs 0.600), and critically, very poor parameter recovery (k: r=0.421, tau: r=-0.257), failing our target. This indicates an identifiability problem between `k` and `tau` even within the proportional framework.\n\nFor this next run, we will **abandon the learnable `tau` parameter for now** and revert to using a **fixed temperature of 1** in the logistic function (`P_accept = 1 / (1 + exp(-U))`). Our goal remains to improve BIC and accuracy compared to the successful Run 3, while ensuring parameter recovery stays high (r > 0.7 for all parameters).\n\nLet's explore a different refinement based on the successful proportional framework of Run 3 (`fair_perc = ...`, `split_perc = split_self / combined_earning if combined_earning > 0 else 0`):\n\n**Refinement Idea: Asymmetric Proportional Inequity Aversion**\n\nRun 3 used a single parameter `k` to penalize *any* deviation from the fair proportion (`abs(split_perc - fair_perc)`). However, classic models like Fehr-Schmidt posit that people react differently to disadvantageous inequity (getting less than fair share) versus advantageous inequity (getting more). While this asymmetry led to poor recovery when applied to *absolute* monetary values (Runs 1 & 2), it might be identifiable when applied to the more stable *proportional* framework that worked well in Run 3.\n\n*   **Proposed Model:** Implement a Fehr-Schmidt-like utility function using proportions, but without a learnable temperature parameter.\n    *   `fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5`\n    *   `split_perc = split_self / combined_earning if combined_earning > 0 else 0`\n    *   `U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)`\n    *   (Implicitly, `P_accept = 1 / (1 + exp(-U))`, as temperature is fixed at 1)\n*   **Learnable Parameters:**\n    *   `alpha`: Sensitivity to disadvantageous inequity (when `split_perc < fair_perc`). Bounds: [0, 10].\n    *   `beta`: Sensitivity to advantageous inequity (when `split_perc > fair_perc`). Bounds: [0, 10]. (Note: Theoretically, we often expect `alpha >= beta`, but let's keep the bounds symmetric for now to allow flexibility).\n*   **Rationale:** This model directly tests whether asymmetric inequity aversion can be captured reliably within the proportional framework, offering a more nuanced account of fairness preferences than the symmetric `k` model, while avoiding the problematic `tau` parameter. Success requires good recovery for *both* `alpha` and `beta`.\n\n**Alternative (If you foresee issues with the above):**\n\n*   Consider the \"Mixed Fairness Reference\" idea (Model Idea 2 from previous instructions): `effective_fair_perc = w * fair_perc_prop + (1 - w) * 0.5`, `U = split_perc - k * abs(split_perc - effective_fair_perc)`. This introduces a weight `w` [0, 1] instead of `alpha`/`beta`, testing if fairness combines proportional and equality norms. Keep `tau=1`.\n\n**Focus:**\nPlease prioritize the **Asymmetric Proportional Inequity Aversion** model described above. Ensure your variable descriptions clearly define `alpha` and `beta`, their bounds, and their role. Remember the target variable is `accept`. Maintain the standard output format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>). Justify why this model builds on previous results and aims to improve performance while maintaining identifiability.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: Okay, let's analyze the results and craft the instructions for the next run.\n\n**Analysis:**\nThe previous run (Run 4) attempted to build on the success of Run 3 by adding a learnable temperature parameter (`tau`) to the proportional inequity model (`U = split_perc - k * abs(split_perc - fair_perc)`). The results were disappointing:\n*   BIC increased from 42.20 (Run 3) to 46.32 (Run 4).\n*   Accuracy decreased from 0.600 (Run 3) to 0.582 (Run 4).\n*   Parameter recovery plummeted from excellent (k: r = 0.855) to poor (k: r = 0.421, tau: r = -0.257).\n\nThis strongly suggests that adding `tau` introduced identifiability issues, likely because the scaling effect of `k` on the utility difference and the scaling effect of `tau` in the logistic function could not be disentangled (`P = 1 / (1 + exp(-U/tau))`). The successful proportional framework of Run 3 was not sufficient to make `tau` identifiable alongside `k`.\n\n**Goal for Next Run (Run 5):**\nImprove upon the best model so far (Run 3: BIC 42.20, Acc 0.600, k Recovery 0.855). The primary focus is to achieve **lower BIC and higher accuracy** than Run 3, while critically **maintaining excellent parameter recovery (r > 0.7 for *all* learnable parameters)**. Given the failure of adding `tau`, we need to explore other avenues for refinement.\n\n**New Instructions:**\n\nThe previous run (Run 4) attempted to improve the best model (Run 3) by introducing a learnable temperature parameter (`tau`). However, this led to worse BIC (46.3 vs 42.2), lower accuracy (0.582 vs 0.600), and critically, very poor parameter recovery (k: r=0.421, tau: r=-0.257), failing our target. This indicates an identifiability problem between `k` and `tau` even within the proportional framework.\n\nFor this next run, we will **abandon the learnable `tau` parameter for now** and revert to using a **fixed temperature of 1** in the logistic function (`P_accept = 1 / (1 + exp(-U))`). Our goal remains to improve BIC and accuracy compared to the successful Run 3, while ensuring parameter recovery stays high (r > 0.7 for all parameters).\n\nLet's explore a different refinement based on the successful proportional framework of Run 3 (`fair_perc = ...`, `split_perc = split_self / combined_earning if combined_earning > 0 else 0`):\n\n**Refinement Idea: Asymmetric Proportional Inequity Aversion**\n\nRun 3 used a single parameter `k` to penalize *any* deviation from the fair proportion (`abs(split_perc - fair_perc)`). However, classic models like Fehr-Schmidt posit that people react differently to disadvantageous inequity (getting less than fair share) versus advantageous inequity (getting more). While this asymmetry led to poor recovery when applied to *absolute* monetary values (Runs 1 & 2), it might be identifiable when applied to the more stable *proportional* framework that worked well in Run 3.\n\n*   **Proposed Model:** Implement a Fehr-Schmidt-like utility function using proportions, but without a learnable temperature parameter.\n    *   `fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5`\n    *   `split_perc = split_self / combined_earning if combined_earning > 0 else 0`\n    *   `U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)`\n    *   (Implicitly, `P_accept = 1 / (1 + exp(-U))`, as temperature is fixed at 1)\n*   **Learnable Parameters:**\n    *   `alpha`: Sensitivity to disadvantageous inequity (when `split_perc < fair_perc`). Bounds: [0, 10].\n    *   `beta`: Sensitivity to advantageous inequity (when `split_perc > fair_perc`). Bounds: [0, 10]. (Note: Theoretically, we often expect `alpha >= beta`, but let's keep the bounds symmetric for now to allow flexibility).\n*   **Rationale:** This model directly tests whether asymmetric inequity aversion can be captured reliably within the proportional framework, offering a more nuanced account of fairness preferences than the symmetric `k` model, while avoiding the problematic `tau` parameter. Success requires good recovery for *both* `alpha` and `beta`.\n\n**Alternative (If you foresee issues with the above):**\n\n*   Consider the \"Mixed Fairness Reference\" idea (Model Idea 2 from previous instructions): `effective_fair_perc = w * fair_perc_prop + (1 - w) * 0.5`, `U = split_perc - k * abs(split_perc - effective_fair_perc)`. This introduces a weight `w` [0, 1] instead of `alpha`/`beta`, testing if fairness combines proportional and equality norms. Keep `tau=1`.\n\n**Focus:**\nPlease prioritize the **Asymmetric Proportional Inequity Aversion** model described above. Ensure your variable descriptions clearly define `alpha` and `beta`, their bounds, and their role. Remember the target variable is `accept`. Maintain the standard output format (<MODEL>, <VARIABLES>, <target_variable>, <SUMMARY>). Justify why this model builds on previous results and aims to improve performance while maintaining identifiability.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "Okay, let's craft the model based on the refined instructions.\n\n**Thinking Process:**\n\n1.  **Goal:** Improve on Run 3 (proportional inequity aversion, BIC 42.20, Acc 0.600, k Recovery 0.855) by introducing asymmetric inequity aversion (`alpha`, `beta`) instead of symmetric aversion (`k`), while keeping the temperature fixed at 1 (unlike Run 4 which failed due to `tau`). The key is to maintain or improve parameter recovery for *both* new parameters.\n2.  **Core Concept:** Adapt the Fehr-Schmidt utility structure to use proportions instead of absolute amounts. Utility = Own Payoff - Penalty for Disadvantageous Inequity - Penalty for Advantageous Inequity.\n3.  **Fairness Reference Point:** The fair share should be proportional to contribution. `fair_perc = token_self / (token_opp + token_self)`. Handle the edge case where `token_opp + token_self == 0` by setting `fair_perc = 0.5` (equal split).\n4.  **Received Payoff (Proportion):** The participant's received share as a proportion of the total. `split_perc = split_self / combined_earning`. Handle the edge case where `combined_earning == 0` by setting `split_perc = 0`.\n5.  **Inequity Terms:**\n    *   Disadvantageous Inequity: `max(0, fair_perc - split_perc)`. This is positive only when the participant gets less than their fair share.\n    *   Advantageous Inequity: `max(0, split_perc - fair_perc)`. This is positive only when the participant gets more than their fair share.\n6.  **Utility Formula:** `U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)`.\n    *   `split_perc` represents the direct utility from the monetary gain (normalized).\n    *   `alpha` parameterizes the aversion to getting *less* than the fair share.\n    *   `beta` parameterizes the aversion to getting *more* than the fair share.\n7.  **Learnable Parameters:** `alpha` and `beta`. Bounds should be generous but finite, e.g., [0, 10]. These capture individual differences in fairness preferences. Theory often suggests `alpha >= beta`, but we will allow flexibility with symmetric bounds initially.\n8.  **Prediction:** The utility `U` determines the probability of acceptance via a logistic function with fixed temperature = 1: `P(accept=1) = 1 / (1 + exp(-U))`. This means `U < 0` implies `P(accept=1) < 0.5`.\n9.  **Target Variable:** `accept`.\n10. **Variable Descriptions:** Need to define all terms used in the model (`U`, `split_perc`, `fair_perc`, `alpha`, `beta`) and the input data variables (`token_self`, `token_opp`, `split_self`, `combined_earning`). Specify ranges, learnability, and source.\n11. **Summary:** Briefly describe the model as an asymmetric proportional inequity aversion model, highlighting the use of proportions, the two inequity parameters (`alpha`, `beta`), and the fixed temperature.\n\n**Pre-computation/Analysis:**\n*   The calculation of `fair_perc` requires `token_self` and `token_opp`.\n*   The calculation of `split_perc` requires `split_self` and `combined_earning`.\n*   The model only applies to trials where `trial_role == 1` (responder). The dataset seems to contain both proposer and responder trials, so filtering will be necessary when applying the model.\n*   The handling of zero denominators in `fair_perc` and `split_perc` seems appropriate.\n\nConfidence Check: The model directly addresses the instructions, builds upon previous findings (using proportions from Run 3, avoiding `tau` from Run 4), introduces the desired asymmetric structure (`alpha`, `beta`), and aims to maintain parameter recoverability.\n\n<MODEL>\nfair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than the proportional fair share). Higher values mean stronger rejection of unfair offers against oneself.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than the proportional fair share). Higher values mean stronger aversion to benefiting unfairly.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fair_perc\": {\n      \"description\": \"Proportion of the combined earning considered fair for the participant based on relative token contributions. Defaults to 0.5 if total tokens are zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"Proportion of the combined earning proposed to the participant. Defaults to 0.0 if combined earning is zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \u00a3).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nAn asymmetric proportional inequity aversion model. Utility is calculated as the participant's proposed percentage (`split_perc`) minus penalties for disadvantageous inequity (`alpha * max(0, fair_perc - split_perc)`) and advantageous inequity (`beta * max(0, split_perc - fair_perc)`). The fair percentage (`fair_perc`) is based on relative token contributions. The model uses two learnable parameters (`alpha`, `beta`) capturing sensitivity to the two types of inequity. Acceptance probability is determined via a logistic function with a fixed temperature of 1.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['alpha', 'beta']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than the proportional fair share). Higher values mean stronger rejection of unfair offers against oneself.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than the proportional fair share). Higher values mean stronger aversion to benefiting unfairly.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fair_perc\": {\n      \"description\": \"Proportion of the combined earning considered fair for the participant based on relative token contributions. Defaults to 0.5 if total tokens are zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"Proportion of the combined earning proposed to the participant. Defaults to 0.0 if combined earning is zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \\u00a3).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, alpha=1, beta=1):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        split_self = trial.get(\"split_self\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        # Calculate fair_perc\n        if (token_opp + token_self) > 0:\n            fair_perc = token_self / (token_opp + token_self)\n        else:\n            fair_perc = 0.5\n\n        # Calculate split_perc\n        if combined_earning > 0:\n            split_perc = split_self / combined_earning\n        else:\n            split_perc = 0.0\n\n        # Calculate utility\n        U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\n        model_predictions.append(U)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 1, \"group\": \"group1\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 10, \"split_opp\": 5.0, \"split_self\": 5.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 5.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 5.0}, {\"ID\": 2, \"group\": \"group1\", \"trial_number\": 2, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 10, \"split_opp\": 5.0, \"split_self\": 5.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 5.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 5.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744035292.977397
    }
  ],
  "learnable_parameters": {
    "alpha": {
      "description": "Sensitivity to disadvantageous inequity (receiving less than the proportional fair share). Higher values mean stronger rejection of unfair offers against oneself.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Sensitivity to advantageous inequity (receiving more than the proportional fair share). Higher values mean stronger aversion to benefiting unfairly.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal.",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": false,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "alpha": {
      "description": "Sensitivity to disadvantageous inequity (receiving less than the proportional fair share). Higher values mean stronger rejection of unfair offers against oneself.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Sensitivity to advantageous inequity (receiving more than the proportional fair share). Higher values mean stronger aversion to benefiting unfairly.",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "fair_perc": {
      "description": "Proportion of the combined earning considered fair for the participant based on relative token contributions. Defaults to 0.5 if total tokens are zero.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "split_perc": {
      "description": "Proportion of the combined earning proposed to the participant. Defaults to 0.0 if combined earning is zero.",
      "range": {
        "min": 0,
        "max": 1,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "token_self": {
      "description": "Number of tokens found by the participant.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_opp": {
      "description": "Number of tokens found by the opponent.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "split_self": {
      "description": "The proposed share for the participant (in \u00a3).",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "combined_earning": {
      "description": "Amount of money earned in total for the trial.",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "An asymmetric proportional inequity aversion model. Utility is calculated as the participant's proposed percentage (`split_perc`) minus penalties for disadvantageous inequity (`alpha * max(0, fair_perc - split_perc)`) and advantageous inequity (`beta * max(0, split_perc - fair_perc)`). The fair percentage (`fair_perc`) is based on relative token contributions. The model uses two learnable parameters (`alpha`, `beta`) capturing sensitivity to the two types of inequity. Acceptance probability is determined via a logistic function with a fixed temperature of 1.",
  "target_variable": "accept",
  "full_reasoning": "Okay, let's craft the model based on the refined instructions.\n\n**Thinking Process:**\n\n1.  **Goal:** Improve on Run 3 (proportional inequity aversion, BIC 42.20, Acc 0.600, k Recovery 0.855) by introducing asymmetric inequity aversion (`alpha`, `beta`) instead of symmetric aversion (`k`), while keeping the temperature fixed at 1 (unlike Run 4 which failed due to `tau`). The key is to maintain or improve parameter recovery for *both* new parameters.\n2.  **Core Concept:** Adapt the Fehr-Schmidt utility structure to use proportions instead of absolute amounts. Utility = Own Payoff - Penalty for Disadvantageous Inequity - Penalty for Advantageous Inequity.\n3.  **Fairness Reference Point:** The fair share should be proportional to contribution. `fair_perc = token_self / (token_opp + token_self)`. Handle the edge case where `token_opp + token_self == 0` by setting `fair_perc = 0.5` (equal split).\n4.  **Received Payoff (Proportion):** The participant's received share as a proportion of the total. `split_perc = split_self / combined_earning`. Handle the edge case where `combined_earning == 0` by setting `split_perc = 0`.\n5.  **Inequity Terms:**\n    *   Disadvantageous Inequity: `max(0, fair_perc - split_perc)`. This is positive only when the participant gets less than their fair share.\n    *   Advantageous Inequity: `max(0, split_perc - fair_perc)`. This is positive only when the participant gets more than their fair share.\n6.  **Utility Formula:** `U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)`.\n    *   `split_perc` represents the direct utility from the monetary gain (normalized).\n    *   `alpha` parameterizes the aversion to getting *less* than the fair share.\n    *   `beta` parameterizes the aversion to getting *more* than the fair share.\n7.  **Learnable Parameters:** `alpha` and `beta`. Bounds should be generous but finite, e.g., [0, 10]. These capture individual differences in fairness preferences. Theory often suggests `alpha >= beta`, but we will allow flexibility with symmetric bounds initially.\n8.  **Prediction:** The utility `U` determines the probability of acceptance via a logistic function with fixed temperature = 1: `P(accept=1) = 1 / (1 + exp(-U))`. This means `U < 0` implies `P(accept=1) < 0.5`.\n9.  **Target Variable:** `accept`.\n10. **Variable Descriptions:** Need to define all terms used in the model (`U`, `split_perc`, `fair_perc`, `alpha`, `beta`) and the input data variables (`token_self`, `token_opp`, `split_self`, `combined_earning`). Specify ranges, learnability, and source.\n11. **Summary:** Briefly describe the model as an asymmetric proportional inequity aversion model, highlighting the use of proportions, the two inequity parameters (`alpha`, `beta`), and the fixed temperature.\n\n**Pre-computation/Analysis:**\n*   The calculation of `fair_perc` requires `token_self` and `token_opp`.\n*   The calculation of `split_perc` requires `split_self` and `combined_earning`.\n*   The model only applies to trials where `trial_role == 1` (responder). The dataset seems to contain both proposer and responder trials, so filtering will be necessary when applying the model.\n*   The handling of zero denominators in `fair_perc` and `split_perc` seems appropriate.\n\nConfidence Check: The model directly addresses the instructions, builds upon previous findings (using proportions from Run 3, avoiding `tau` from Run 4), introduces the desired asymmetric structure (`alpha`, `beta`), and aims to maintain parameter recoverability.\n\n<MODEL>\nfair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal.\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": false,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to disadvantageous inequity (receiving less than the proportional fair share). Higher values mean stronger rejection of unfair offers against oneself.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Sensitivity to advantageous inequity (receiving more than the proportional fair share). Higher values mean stronger aversion to benefiting unfairly.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"fair_perc\": {\n      \"description\": \"Proportion of the combined earning considered fair for the participant based on relative token contributions. Defaults to 0.5 if total tokens are zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"split_perc\": {\n      \"description\": \"Proportion of the combined earning proposed to the participant. Defaults to 0.0 if combined earning is zero.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_opp\": {\n      \"description\": \"Number of tokens found by the opponent.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_self\": {\n      \"description\": \"The proposed share for the participant (in \u00a3).\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"combined_earning\": {\n      \"description\": \"Amount of money earned in total for the trial.\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nAn asymmetric proportional inequity aversion model. Utility is calculated as the participant's proposed percentage (`split_perc`) minus penalties for disadvantageous inequity (`alpha * max(0, fair_perc - split_perc)`) and advantageous inequity (`beta * max(0, split_perc - fair_perc)`). The fair percentage (`fair_perc`) is based on relative token contributions. The model uses two learnable parameters (`alpha`, `beta`) capturing sensitivity to the two types of inequity. Acceptance probability is determined via a logistic function with a fixed temperature of 1.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\nSummary: An asymmetric proportional inequity aversion model. Utility is calculated as the participant's proposed percentage (`split_perc`) minus penalties for disadvantageous inequity (`alpha * max(0, fair_perc - split_perc)`) and advantageous inequity (`beta * max(0, split_perc - fair_perc)`). The fair percentage (`fair_perc`) is based on relative token contributions. The model uses two learnable parameters (`alpha`, `beta`) capturing sensitivity to the two types of inequity. Acceptance probability is determined via a logistic function with a fixed temperature of 1.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, alpha=1, beta=1):\n    model_predictions = []\n    for trial in trial_data:\n        token_self = trial.get(\"token_self\", 0)\n        token_opp = trial.get(\"token_opp\", 0)\n        split_self = trial.get(\"split_self\", 0)\n        combined_earning = trial.get(\"combined_earning\", 0)\n\n        # Calculate fair_perc\n        if (token_opp + token_self) > 0:\n            fair_perc = token_self / (token_opp + token_self)\n        else:\n            fair_perc = 0.5\n\n        # Calculate split_perc\n        if combined_earning > 0:\n            split_perc = split_self / combined_earning\n        else:\n            split_perc = 0.0\n\n        # Calculate utility\n        U = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\n        model_predictions.append(U)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.6111111111111112,
  "fitting_results": [
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.756799342287673,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.9102133701643726,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.644564495422372,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.649067013356788,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.184273279767098,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 5.729276170047592,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -18.424666437323115,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.888298520991411,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -16.53895456767862,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.776270181242669,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.836603213743263,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.1712327198886904e-16,
      "success": true,
      "log_likelihood": -20.004406575765763,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4067465649079802,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.954758612126906,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.004406575765756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 7.593298684060256,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -15.90414587064717,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.816050317414702,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -16.303155936042927,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.90679934225756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.744877126131619,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -16.76616219525683,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.004406575765763,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.004406575765756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.004406575765756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.00440657576576,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.704406575625125,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.6544065756349,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.6445009767008958e-17,
      "success": true,
      "log_likelihood": -20.004406575765753,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.4770524044094078,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.771271266579607,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 1.924113636956825e-18,
      "success": true,
      "log_likelihood": -20.854406575594233,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 5.450637251496719,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.34038837050005,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.0350503614168343,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.522009196395636,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.74283733823447,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.527746305735576,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.928712217392477,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.221096841841987,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.9287126981045892,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.121096841866255,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.923466008917748,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.804406575604283,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.80440657540167,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.004406575765756,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.756799342287671,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.6702324387401823,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.723508243818454,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.147763060537389,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.98218573367013,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 3.9193728130538524e-16,
      "success": true,
      "log_likelihood": -20.00440657576576,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.1645729765351578,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.226149987018783,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.134466860120319,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.795308688500494,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.421514604131826,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.912148570449883,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8649011497184445,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.59523640085685,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 8.421831684028935e-17,
      "success": true,
      "log_likelihood": -20.554406575654937,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.5596592964804603,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.581167724976922,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 2.6387407329701826e-16,
      "success": true,
      "log_likelihood": -12.156799341597628,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.304406575704853,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.3844063785901457,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.92872268184017,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.1563386232744346,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.743548201062122,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.20440657532012,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.999432366533811,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.422296283862025,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 5.084659979150373,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.00469233165517,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.8882710537967995,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -16.938954567477616,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.3459449095674378,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.900636279858674,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.504406575259466,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.506799341313506,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.5172443682475634,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.165345132964926,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.6265064906238268,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.59465605410565,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 6.338712229531473,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -18.62005537183024,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -12.656799341843527,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.040132675052881,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 7.552513493008321e-17,
      "success": true,
      "log_likelihood": -21.30440657550046,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -11.356799342160345,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.35440657549319,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.104415690359659,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.96396607621775,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.117783855366923,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.260115823173855,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.756799342287675,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.7095821458779827,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.512010116137894,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -12.306799341819417,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.8586470365757033,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.317551037733868,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.504406575665193,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.004406575563614,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.417434461818873,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.938707487637167,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.804406575603075,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -8.790132676075292,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.623466007872661,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.289421517959984,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.203170993497007,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.654406575432688,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 2.124174962170064,
      "beta": 10.0,
      "success": true,
      "log_likelihood": -23.1485676863814,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.35855649098520775,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.11853987132788,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.454406575674966,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 10.0,
      "success": true,
      "log_likelihood": -11.842814687871224,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.298926037498841,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.72949805710428,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.756799342287671,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.4983308642354316,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.732133595369753,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.804406575603682,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 10.0,
      "success": true,
      "log_likelihood": -10.959481355728848,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 4.075672382736272,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.978394154777067,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.32874769283081406,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.87426742172353,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3611111111111111,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.356799342369824,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.11961090932945923,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.550431111817762,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 10.0,
      "success": true,
      "log_likelihood": -12.409481355078508,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 3.7480780050440237e-17,
      "success": true,
      "log_likelihood": -20.404406575684817,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 3.9102121277285358,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.54456449555613,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0,
      "beta": 6.190547447807491e-17,
      "success": true,
      "log_likelihood": -22.65440657523027,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "alpha": {
        "r": 0.842836112290185,
        "p": 4.05375062679424e-28
      },
      "beta": {
        "r": 0.11142338990428662,
        "p": 0.269738037253336
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 45.151753816683296,
  "bic_results": {
    "average_bic": 45.151753816683296,
    "individual_bics": [
      28.680636561487567,
      48.45616686775696,
      45.53558443644641,
      44.01637075155845,
      40.244947012269456,
      50.840244304398745,
      47.175851028443745,
      51.07655510116603,
      47.17585102844373,
      38.97532961820656,
      39.77334974899807,
      28.98063656142734,
      40.699362267425876,
      47.175851028443745,
      47.17585102844373,
      47.17585102844373,
      47.17585102844374,
      48.57585102816247,
      48.47585102818202,
      47.175851028443724,
      48.70958041007143,
      48.87585102810068,
      45.84781461791232,
      50.21105626970349,
      46.22253048838337,
      49.60923156059619,
      49.40923156064473,
      29.013969894747717,
      48.77585102812078,
      50.77585102771556,
      47.17585102844373,
      28.68063656148756,
      50.614054364549126,
      43.131409344252475,
      47.17585102844374,
      51.61933785094978,
      50.75765525391321,
      46.991335017811984,
      52.35751067862592,
      48.27585102822209,
      52.32937332686606,
      31.480636560107477,
      47.775851028321924,
      51.02448324059256,
      50.65413427903646,
      51.57585102755246,
      50.01163044463627,
      47.17642254022256,
      41.04494701186745,
      54.968310436629565,
      52.17585102743115,
      34.18063655953923,
      51.49772814284207,
      54.356349985123515,
      44.4071486205727,
      32.48063656059927,
      33.24730322701798,
      49.77585102791314,
      29.88063656123291,
      49.8758510278986,
      53.09497002934772,
      47.68726952325993,
      28.680636561487567,
      50.191058109188006,
      31.780636560551052,
      49.80213995237995,
      48.175851028242604,
      49.175851028039446,
      51.04445285218655,
      48.77585102811837,
      24.7473032290628,
      34.41396989265754,
      49.57337986390623,
      50.475851027777594,
      53.46417324967502,
      51.40411761956798,
      48.07585102826215,
      30.85266725265467,
      54.62603399112078,
      28.68063656148756,
      54.631305067651724,
      48.77585102811958,
      29.086000588369913,
      47.12382618646635,
      54.91557272035928,
      27.88063656165187,
      52.26790010054774,
      31.986000587069235,
      47.97585102828185,
      48.25616686802448,
      52.475851027372755
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 2,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- alpha: r = 0.843\n- beta: r = 0.111",
  "previous_models": [
    "Specification: fair_perc = (token_self / (token_opp + token_self)) if (token_opp + token_self) > 0 else 0.5\nsplit_perc = split_self / combined_earning if combined_earning > 0 else 0.0\nU = split_perc - alpha * max(0, fair_perc - split_perc) - beta * max(0, split_perc - fair_perc)\nSummary: An asymmetric proportional inequity aversion model. Utility is calculated as the participant's proposed percentage (`split_perc`) minus penalties for disadvantageous inequity (`alpha * max(0, fair_perc - split_perc)`) and advantageous inequity (`beta * max(0, split_perc - fair_perc)`). The fair percentage (`fair_perc`) is based on relative token contributions. The model uses two learnable parameters (`alpha`, `beta`) capturing sensitivity to the two types of inequity. Acceptance probability is determined via a logistic function with a fixed temperature of 1.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 45.151753816683296\nOverall Accuracy: 0.6111\n\nParameter Recovery:\n- alpha: r = 0.843\n- beta: r = 0.111"
  ]
}