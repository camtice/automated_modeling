Okay, here are the improved instructions for the next run (Run 47), building on the results of the previous runs.

Instructions for Run 47 of 100:

The unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters. This is the critical benchmark for model usability. While improved BIC and accuracy are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

One of the recently tested models, the piecewise log-log ratio model (where utility was `beta_gain_log_sens * log(R_val)` for `R_val >= 1` and `beta_loss_log_sens * log(R_val)` for `R_val < 1`), successfully achieved parameter recovery values above the 0.7 threshold for *both* of its learnable parameters (`beta_gain_log_sens: r = 0.795`, `beta_loss_log_sens: r = 0.962`). This makes it the current best *recoverable* model found so far. Its BIC (40.45) and accuracy (0.662) are acceptable but indicate room for improvement.

The core challenge persists: designing a mathematical structure for utility using exactly **2 learnable parameters** that ensures both parameters have distinct, identifiable influences on responder decisions (`trial_role == 1`). The piecewise structure, particularly splitting based on the ratio `R_val` being >= or < 1.0, appears key to the parameter identifiability success seen in recent models.

For this run, let's continue to explore the *piecewise structure* based on the ratio `R_val` split at 1.0, maintaining exactly **2 learnable parameters**, but try a new functional form: **piecewise linear based on the *difference* from the fair ratio (i.e., `R_val - 1.0`)**. This approach aligns with behavioral economic concepts of deviations from a reference point (fairness) and may offer a better fit to the data compared to the log function, while preserving parameter identifiability through the piecewise split and scaling of deviations.

Design a computational model that predicts the utility of accepting an offer based on a **piecewise linear function of the *difference* between the ratio of the proposed percentage share to the participant's fair percentage share, and 1.0**.

*   **Structural Direction (Piecewise Linear Difference):** Model utility (`U`) based on the difference `R_val - 1.0`, using different linear scaling parameters depending on whether this difference is non-negative (fair or generous offers) or negative (unfair offers).
    *   Calculate the necessary intermediate variables as before:
        *   `sum_tokens = token_self + token_opp`
        *   `fair_perc_self_calc = IF(sum_tokens > 0, (token_self / sum_tokens) * 100.0, 50.0)` (Ensures `fair_perc_self_calc` is >= 0).
        *   `epsilon_val = 1e-6` (Small constant for numerical stability).
        *   `R_val = (split_perc_self + epsilon_val) / (fair_perc_self_calc + epsilon_val)` (Calculate the ratio, ensuring `R_val` is always positive).
    *   Calculate the difference from the fair ratio: `R_diff = R_val - 1.0`.
    *   Structure the utility (`U`) using a conditional statement based on the value of `R_diff` (or equivalently, `R_val`):\n
        *   If `R_diff >= 0.0` (i.e., `R_val >= 1.0`), `U = beta_gain_linear_diff * R_diff` (Linear scaling for gain/favorable offers).
        *   If `R_diff < 0.0` (i.e., `R_val < 1.0`), `U = beta_loss_linear_diff * R_diff` (Linear scaling for loss/unfair offers). Note that `R_diff` will be negative for `R_val < 1`.
    *   This structure uses two distinct learnable parameters (`beta_gain_linear_diff` and `beta_loss_linear_diff`) that scale the positive or negative deviation from the fair ratio (1.0). This modification explores whether a linear relationship around the reference point provides a better fit and if scaling the difference (which is positive for gains and negative for losses) further aids parameter identifiability compared to scaling the positive ratio itself (as in the previous piecewise linear ratio model).

*   **Key Inputs & Calculated Variables:**
    *   Use `split_perc_self`, `token_self`, `token_opp` as data variables.
    *   Calculate `sum_tokens`, `fair_perc_self_calc`, `epsilon_val`, `R_val`, `R_diff`, and `U`.
    *   Ensure these calculated variables are included in your <MODEL> tag calculations and <VARIABLES> descriptions.

*   **Model Formula:** Define the utility (`U`) based on the conditional logic applied to `R_val` (or `R_diff`) and your 2 learnable parameters. Include the calculation steps for necessary derived variables (`sum_tokens`, `fair_perc_self_calc`, `epsilon_val`, `R_val`, `R_diff`) before the final formula for `U`. Use clear mathematical notation (IF/ELSE or similar conditional structure).

*   **Learnable Parameters:** Your model *must* have exactly **2 learnable parameters**.
    *   `beta_gain_linear_diff`: Sensitivity parameter scaling the *difference* (`R_val - 1.0`) when the ratio is greater than or equal to 1 (fair or favorable offers). Suggest generous bounds like [-10.0, 10.0].
    *   `beta_loss_linear_diff`: Sensitivity parameter scaling the *difference* (`R_val - 1.0`) when the ratio is less than 1 (unfair offers). Suggest generous bounds like [-10.0, 10.0].
    Choose descriptive names suitable for Python code that reflect the functional form (linear) and the value they scale (the difference) and the ratio range (gain vs loss). Define clear, generous, finite numerical bounds for both.

*   **Calculated Variables:** Ensure all calculated variables used in the model (`sum_tokens`, `fair_perc_self_calc`, `epsilon_val`, `R_val`, `R_diff`, `U`) are included in your <VARIABLES> descriptions with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`). Be mindful of the range for `R_diff` given its calculation (it can be negative).

*   **Model Specification:** Provide the formal mathematical formula between <MODEL> tags. Include the calculation steps for necessary derived variables before the final formula for `U`. Use clear mathematical notation.

*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables used in the <MODEL> formula (data, calculated, learnable). Include source, range (with inclusive flags), distribution (if applicable), and learnable status.

*   **Target Variable:** Specify "accept" as the target variable using <target_variable> tags.

*   **Summary:** Provide a concise summary between <SUMMARY> tags, describing your model. Explain the core idea of how utility is determined by a piecewise linear function of the *difference* between the proposed ratio and 1.0 (the fair reference point), scaled by `beta_gain_linear_diff` for differences >= 0 (gain/favorable offers) and by `beta_loss_linear_diff` for differences < 0 (loss/unfair offers). Explain how this piecewise linear structure on the difference from the reference point is the next attempt to improve fit (BIC/Accuracy) while building on the success of the piecewise approach for parameter identifiability.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability *within* the constraints of **exactly 2 learnable parameters** is the absolute priority. Your goal is to find a mathematical structure where both parameters can be uniquely and reliably estimated from the data by ensuring their influences are clearly distinguishable. This piecewise linear difference approach is a promising alternative to the piecewise ratio models, potentially capturing deviations from fairness in a more direct way. If this structure also meets recovery but doesn't significantly improve BIC/Accuracy, or if it fails recovery for either parameter, be prepared to think even further outside the box for the next iteration – consider entirely different inputs, different ways of combining inputs (e.g., non-ratio based interactions, exponential terms, incorporating absolute values or amounts), or conceptualizing fairness\'s role differently (e.g., as a non-linear modulator of sensitivity, or a threshold in a non-standard way). The key is finding a structure where the two parameters’ contributions to utility are as independent as possible across the dataset.