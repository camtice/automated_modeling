Okay, here are the improved instructions for the next run (Run 59), building on the results of the previous runs and focusing intensely on parameter identifiability.

Instructions for Run 59 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

The previous run implemented a promising asymmetric piecewise model structure (`U = beta_value * split_perc_self + beta_unfairness_effect * unfair_deviation_magnitude`). This model achieved the best BIC (286.16) and accuracy (0.767) seen so far, and successfully recovered one parameter (`beta_value`, r = 0.774). However, the second parameter, `beta_unfairness_effect`, failed to meet the primary objective (r = 0.659).

Analysis of the previous model's failure: Despite the asymmetric structure where `beta_unfairness_effect` only influenced utility for unfair offers, its influence within that regime was still linear with respect to the magnitude of the unfair deviation (`fair_perc_self_calc - split_perc_self`). In the unfair regime, the utility calculation effectively became a linear combination of `split_perc_self` and `fair_perc_self_calc` with coefficients related to both betas. This linear-linear relationship for unfair offers likely still causes confounding between the two parameters, preventing the unique estimation of `beta_unfairness_effect`.

We need to find a mathematical structure for utility, still using exactly **2 learnable parameters**, where their influence on responder decisions (`trial_role == 1`) is fundamentally more separable, especially for the parameter intended to capture sensitivity to unfairness. This requires modifying the mathematical form in the unfair regime to create a more distinct contribution for the fairness parameter.

Based on the persistent difficulty with the linear fairness term's recovery, focus your exploration for Run 59 on refining the asymmetric piecewise structure by introducing a *non-linear* transformation for the unfairness component.

Consider the following strategy to enhance identifiability by making the second parameter's influence non-linear and distinct:

*   **Refined Asymmetric Piecewise Model with Squared Unfairness:** Maintain the structure where one parameter scales the *absolute proposed percentage share* (active on all trials) and the second parameter scales a term related to unfairness (active *only* on unfair trials). However, make the unfairness term scale the *squared* magnitude of the unfair deviation, rather than the linear magnitude.
    *   *Example Idea:* Let one parameter (`beta_value`) scale `split_perc_self`. Let the second parameter (`beta_unfairness_penalty_sensitivity`) scale the *squared* magnitude of the negative deviation from fairness (`fair_perc_self_calc - split_perc_self`), but only when this deviation is positive (i.e., when `split_perc_self` is less than `fair_perc_self_calc`). Add a small epsilon for numerical stability before squaring.
        *   `sum_tokens = token_self + token_opp`
        *   `fair_perc_self_calc = IF(sum_tokens > 0.0, (token_self / sum_tokens) * 100.0, 50.0)` (Ensure this handles `sum_tokens=0`).
        *   `deviation_from_fair = fair_perc_self_calc - split_perc_self` (Positive if unfair, 0 or negative if fair/favorable).
        *   `epsilon = 1e-6` // Small constant for numerical stability.
        *   `squared_unfair_deviation = IF(deviation_from_fair > 0, (deviation_from_fair + epsilon)^2, 0)` (This term is 0 if the offer is fair or better, and positive and squared if unfair).
        *   `U = beta_value * split_perc_self + beta_unfairness_penalty_sensitivity * squared_unfair_deviation` (Combine linear value with a term representing the squared magnitude of unfairness, expecting `beta_unfairness_penalty_sensitivity` to be negative to apply a penalty).
    *   *Structural Principle:* This structure attempts identifiability by having `beta_value` exert a linear influence across the entire range of `split_perc_self`, while `beta_unfairness_penalty_sensitivity` *only* exerts influence in the specific regime of unfair offers, scaling a term (`squared_unfair_deviation`) that has a *non-linear* relationship with the deviation magnitude. This combination of asymmetric influence and different functional forms (linear vs. squared) scaled by the two parameters is intended to create more separable effects than previous additive or linear piecewise models.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc`, `deviation_from_fair`, `epsilon`, `squared_unfair_deviation`, and `U`. Ensure `fair_perc_self_calc` is handled correctly when `sum_tokens` is 0.
*   **Model Formula:** Define the utility (`U`). Include calculation steps for necessary derived variables *before* the final formula for `U`. Use clear mathematical notation within the <MODEL> tags. Include calculation steps for intermediate variables like `sum_tokens`, `fair_perc_self_calc`, `deviation_from_fair`, `epsilon`, `squared_unfair_deviation` *before* the final utility `U` calculation within the <MODEL> tags.
*   **Learnable Parameters:** Your model *must* have exactly **2 learnable parameters**. For the suggested model, use names like `beta_value` and `beta_unfairness_penalty_sensitivity`. Choose descriptive names suitable for Python code. Define clear, generous, finite numerical bounds (e.g., [-10.0, 10.0] or wider/narrower if appropriate for the scale of your terms). Consider the expected sign (e.g., `beta_unfairness_penalty_sensitivity` should likely be negative), but keep bounds wide enough.
*   **Calculated Variables:** Ensure all calculated variables used in the model formula (including `sum_tokens`, `fair_perc_self_calc`, `deviation_from_fair`, `epsilon`, `squared_unfair_deviation`, and `U`) are included in your <VARIABLES> descriptions with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`. Ensure the description for `fair_perc_self_calc` explicitly mentions the `sum_tokens > 0` condition and the default value. The description for `squared_unfair_deviation` should clarify what it represents, its piecewise nature, and the squaring.
*   **Model Specification:** Provide the formal mathematical formula between <MODEL> tags. Only the formula should be inside these tags.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables used in the <MODEL> formula (data, calculated, learnable). Include source, range (with inclusive flags), distribution (if applicable), and learnable status. Use `split_perc_self` as the variable name for the participant's proposed percentage share percentage.
*   **Target Variable:** Specify "accept" as the target variable using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea and, crucially, explain *how its specific mathematical structure (e.g., the asymmetric piecewise influence combined with the non-linear, squared term for unfairness in the loss domain) is designed to ensure parameter identifiability for *both* learnable parameters*, making their roles distinct from previously attempted additive or linear piecewise models.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters is the absolute priority. Your goal is to find a mathematical structure where both parameters can be uniquely and reliably estimated from the data by ensuring their influences are clearly distinguishable. Explore models with asymmetric piecewise structures like the one suggested, where parameters target different aspects (overall value vs. specific unfairness magnitude) and different regimes (all offers vs. only unfair offers), using *non-linear* transformations for at least one of the components, to create more separable influences. Be creative in designing the mathematical relationship between inputs, parameters, and utility to achieve this separation.