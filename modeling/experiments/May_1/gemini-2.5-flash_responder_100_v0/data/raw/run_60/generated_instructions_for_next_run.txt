Okay, here are the improved instructions for the next run, focusing intensely on designing a model structure that ensures parameter identifiability for *both* learnable parameters.

Instructions for Run 61 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

The previous attempts have consistently struggled to achieve sufficient parameter identifiability for *both* of the two learnable parameters. The most recent model, which used a multiplicative interaction term (`split_perc_self * deviation_from_fairness`), resulted in recovery values of 0.336 and 0.628, failing the criterion for both parameters. This further reinforces that simple additive or linear/multiplicative interaction terms, even when combining value and fairness, do not create mathematically distinct enough contributions across the data space.

However, reviewing previous runs, one model (BIC ~286) achieved a recovery of 0.774 for its `beta_value` parameter by using a structure that combined a linear value term (`split_perc_self`) with a *piecewise linear* penalty term for unfairness (`max(0, fair_perc_self_calc - split_perc_self)`), scaled by a second parameter (`beta_unfairness_effect`, which had recovery 0.659). This suggests that separating the influence into a general value component and a specific fairness deviation component, particularly active for unfair offers, is a promising direction for `beta_value` identifiability.

The challenge for this run is to build upon this intuition and design a structure that maintains good recovery for the value parameter while significantly improving the recovery for the second parameter (the one associated with fairness/unfairness). This requires making the influence of the second parameter even *more* mathematically distinct from the first, especially for the range of unfair offers.

We need to find a mathematical structure for utility, still using exactly **2 learnable parameters**, where their influence on responder decisions (`trial_role == 1`) is fundamentally more separable and distinguishable than in previous models.

Based on the persistent difficulty with the second parameter's identifiability, focus your exploration for Run 61 on designing a utility function where:
1. One parameter primarily scales a term related to the perceived *value* of the offer (e.g., `split_perc_self`).
2. The second parameter scales a term that specifically captures sensitivity to *unfairness*, but crucially, this term should have a **stronger non-linear form** than previously attempted (linear or squared deviations), especially when the offer is *unfair* (`split_perc_self < fair_perc_self_calc`).

Consider strategies for the unfairness term (active when `split_perc_self < fair_perc_self_calc`):
*   **Strongly Non-linear Penalties:** Instead of piecewise linear or squared functions of `fair_perc_self_calc - split_perc_self`, explore exponential penalties (e.g., scaling `exp(k * (fair_perc_self_calc - split_perc_self))`), cubic penalties (scaling `(fair_perc_self_calc - split_perc_self)^3`), or other non-linear functions that increase rapidly as unfairness increases. You may need a fixed 'steepness' parameter (like `k`) within the function if you only have 2 learnable parameters.
*   **Ratio-based Non-linearities:** Explore non-linear functions (e.g., inverse, exponential of the inverse, polynomial) of the ratio of fair share to proposed share (`fair_perc_self_calc / split_perc_self`) when the offer is unfair.
*   **Threshold-dependent Sensitivity:** Design a model where the sensitivity to `split_perc_self` itself is modulated by fairness, but the modulation is highly non-linear or has sharp changes around the fairness point, controlled by the second parameter.

The goal is to create a structure where changes in the first parameter primarily affect the baseline utility across all offers, while changes in the second parameter have a disproportionately strong and non-linear effect *only* when offers are unfair, making their influences clearly distinguishable.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate necessary intermediate variables like `sum_tokens`, `fair_perc_self_calc`, and any other derived measures of value, fairness, or their interactions as needed by your model structure. Ensure `fair_perc_self_calc` is handled correctly when `sum_tokens` is 0. Use a small epsilon for numerical stability where necessary (e.g., in denominators, logarithms, exponential inputs if they could cause overflow/underflow).
*   **Model Formula:** Define the utility (`U`). Include calculation steps for necessary derived variables *before* the final formula for `U`. Use clear mathematical notation within the <MODEL> tags. Only the formula should be inside these tags.
*   **Learnable Parameters:** Your model *must* have exactly **2 learnable parameters**. Choose descriptive names suitable for Python code (e.g., `beta_value`, `beta_unfairness_penalty`, `beta_non_linear_fairness_sensitivity`, etc., reflecting their specific roles in your new non-linear/asymmetric structure). Define clear, generous, finite numerical bounds (e.g., [-10.0, 10.0] or wider/narrower if appropriate).
*   **Calculated Variables:** Ensure all calculated variables used in the model formula (including U) are included in your <VARIABLES> descriptions with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`. Provide detailed descriptions for *calculated* variables, explaining how they are derived and what they represent.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables used in the <MODEL> formula (data, calculated, learnable). Include source, range (with inclusive flags), distribution (if applicable), and learnable status. Use `split_perc_self` as the variable name for the participant's proposed percentage share percentage.
*   **Target Variable:** Specify "accept" as the target variable using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea and, crucially, explain *how its specific non-linear, asymmetric, or threshold-dependent mathematical structure is designed to ensure parameter identifiability for *both* learnable parameters*, making their roles mathematically distinct from previously attempted additive, linear, or simple piecewise structures.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters is the absolute priority. Your goal is to find a mathematical structure where both parameters can be uniquely and reliably estimated from the data by ensuring their influences are clearly distinguishable across the range of possible offers and fairness conditions, particularly by making the 'fairness penalty' term highly non-linear and distinct from the basic 'value' term. Be creative in designing this non-linear interaction.