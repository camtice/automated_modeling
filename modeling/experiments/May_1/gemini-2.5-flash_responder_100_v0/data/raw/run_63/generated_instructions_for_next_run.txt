Okay, here are the improved instructions for the next run, focusing intensely on designing a model structure that ensures parameter identifiability for *both* learnable parameters while building on the successes and addressing the failures of the previous attempts.

Instructions for Run 64 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

The previous run (Run 63) implemented a ratio model (`U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * unfairness_penalty_term)`, where `unfairness_penalty_term = max(0.0, fair_perc_self_calc - split_perc_self)`). This model achieved promising results for BIC (46.17) and Accuracy (0.691), and excellent recovery for `beta_value` (r = 0.925). However, it critically failed the parameter recovery test for `beta_unfairness` (r = 0.608).

Comparing this to the cubic additive penalty model (Run 61: BIC 44.74, Accuracy 0.661, `beta_value` r=0.917, `beta_unfairness` r=-0.172), we see a pattern: models combining a value term (`beta_value * split_perc_self`) with a fairness/penalty term struggle to recover the parameter associated with the penalty. While Run 63's ratio structure showed better recovery for the second parameter (0.608) than Run 61's additive structure (-0.172), it still wasn't sufficient.

The consistent challenge lies in designing the mathematical interaction such that the influence of `beta_value` and the influence of `beta_unfairness` are sufficiently independent across the data to allow for reliable simultaneous estimation of both. Simply scaling a linear or cubic penalty term (whether added, subtracted, or in a denominator) by the second parameter hasn't achieved this separation for `beta_unfairness`.

The challenge for this run is to refine the model structure, perhaps building on the promise of the ratio approach or exploring other non-linear combinations, specifically focusing on making the influence of `beta_unfairness` profoundly distinct and reliably estimable.

We need a mathematical structure for utility, still using exactly **2 learnable parameters**, where their influence on responder decisions (`trial_role == 1`) is profoundly separable and distinguishable. Given the failures so far, consider fundamentally different ways `beta_unfairness` interacts with the unfairness deviation (`max(0, fair_perc_self_calc - split_perc_self)`).

Think **"Out of the Box" Again**: The problem might be that `beta_unfairness` is just linearly scaling a penalty term. What if `beta_unfairness` interacts with the *shape* of the penalty function itself? Or if the penalty term scaled by `beta_unfairness` is itself a non-linear function of the deviation?

Consider alternative strategies focusing on creating mathematically distinct parameter influences, building on previous attempts:

*   **Ratio with Non-linear Penalty Component:** Enhance the ratio structure from Run 63. Instead of `1.0 + beta_unfairness * unfairness_penalty_term`, make the penalty term in the denominator a non-linear function of `unfairness_penalty_term`, where `beta_unfairness` scales *that* non-linear function. For example, `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * max(0.0, fair_perc_self_calc - split_perc_self)^2)`. (Using a quadratic penalty term scaled by beta_unfairness in the denominator). This structure makes the disutility grow quadratically with unfairness, controlled by `beta_unfairness`.
*   **Additive with Different Non-linear Penalty:** Revisit the additive penalty structure, but use a different non-linear function than the cubic one that failed in Run 61. For instance, `U = beta_value * split_perc_self - beta_unfairness * max(0, fair_perc_self_calc - split_perc_self)^2`. (Using a quadratic penalty term scaled by beta_unfairness). This might provide a less aggressive, more stable penalty shape than the cubic, potentially improving `beta_unfairness` recovery.
*   **Multiplicative with Non-linear Penalty Factor:** Explore `U = beta_value * split_perc_self * (1.0 - beta_unfairness * max(0, fair_perc_self_calc - split_perc_self)^2)`. This is similar to the ratio structure for large denominators, but the interaction is multiplicative. Be careful with the range of the penalty factor `(1.0 - ...)`.

The goal is to design a utility calculation `U` involving `split_perc_self`, `fair_perc_self_calc` (derived from `token_self`, `token_opp`), and exactly two learnable parameters (`beta_value`, `beta_unfairness`) such that the influence of `beta_value` on `U` is mathematically distinct from the influence of `beta_unfairness` across the range of possible offers. Focus on making `beta_unfairness` influence the utility in a way that is clearly non-linear and specifically tied to the *degree* of unfairness, distinguishing it from the general value sensitivity captured by `beta_value`.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc`, and any other necessary intermediate variables like `deviation` and `unfairness_penalty_term = max(0.0, deviation)`. Ensure `fair_perc_self_calc` handles `sum_tokens == 0` correctly (defaulting to 0.5 or 50.0 depending on scale). Use a small epsilon (`1e-6` or similar) for numerical stability if needed (e.g., denominators, logarithms).
*   **Model Formula:** Define `U`. Include calculation steps for derived variables *before* the formula for `U`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**. Choose descriptive, Python-safe names (e.g., `beta_value`, `beta_unfairness`). Define clear, generous, finite numerical bounds (e.g., [-10.0, 10.0], [-50.0, 50.0], [0.0, 100.0], etc. appropriate for the scale of their influence). For parameters scaling penalty terms (like `beta_unfairness`), consider if a positive constraint `[0.0, 10.0]` makes theoretical sense and aids recovery.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including U) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea and, crucially, explain *how its specific non-linear, asymmetric, or interactive mathematical structure is fundamentally different from the previous failed models (simple additive/subtractive, simple multiplicative exponential, and the linear penalty in the ratio denominator) and how this difference is specifically intended to ensure robust parameter identifiability for *both* learnable parameters*, particularly improving the recovery of the fairness/penalty parameter. Explicitly explain why this new structure should allow for better recovery of the second parameter compared to previous attempts, referencing the previous results (especially Run 63's near-miss).

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative and explore structures that make the second parameter's influence on utility more non-linear and distinct than simple linear scaling of a deviation term.

Please think through this step by step, then provide your model specification and variable descriptions.
</previous_instructions>