Okay, here are the improved instructions for the next run, focusing intensely on designing a model structure that ensures parameter identifiability for *both* learnable parameters while building on the successes and addressing the failures of the previous attempts.

Instructions for Run 65 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

Run 64 continued the exploration of ratio models, using `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * unfairness_penalty_term^2)`, which applied a quadratic penalty in the denominator. While it achieved a reasonable BIC (44.42) and Accuracy (0.690), and maintained excellent recovery for `beta_value` (r = 0.830), it again failed to recover `beta_unfairness` reliably (r = 0.451). This is an improvement over Run 61's cubic additive model (-0.172) and slightly worse than Run 63's linear ratio model (0.608) for the second parameter, but still below the critical 0.7 threshold. The consistent failure to recover the fairness/penalty parameter across various structures (additive, ratio, multiplicative exponential) suggests that simply scaling a deviation-based penalty term linearly or with a fixed power is insufficient to create a mathematically distinct influence from the `beta_value * split_perc_self` component. The problem is likely rooted in the correlation between the value term (`split_perc_self`) and the deviation term (`unfairness_penalty_term`), making it hard to disentangle the two beta influences.

For Run 65, we need a more sophisticated interaction that makes the role of `beta_unfairness` clearly distinguishable. Let's move away from `beta_unfairness` just scaling a deviation term and instead have it influence the *way* unfairness impacts utility. Consider a multiplicative structure where utility is the inherent value scaled by a penalty *factor* that depends on unfairness, and `beta_unfairness` controls the *rate* or *shape* of this penalty factor.

Think **"Out of the Box" Again**: A promising approach is a power-law multiplicative decay: `U = beta_value * split_perc_self * (penalty_factor)^beta_unfairness`. Here, `penalty_factor` is a value between 0 and 1 that decreases as unfairness increases (e.g., calculated as `max(0.0, 1.0 - unfairness_penalty_term / MaximumPossibleUnfairness)`, where `MaximumPossibleUnfairness` is 100%). In this structure, `beta_unfairness` is in the exponent. A higher `beta_unfairness` means a steeper decline in utility as offers become more unfair (the penalty factor is raised to a larger positive power, making it smaller). This non-linear role for `beta_unfairness` should create a more distinct signature on the utility function, less correlated with the linear scaling of `split_perc_self` by `beta_value`, thereby improving parameter identifiability for *both* parameters. Design the model using this concept or another novel multiplicative interaction where `beta_unfairness` controls the *shape* of the penalty function.

The goal is to design a utility calculation `U` involving `split_perc_self`, `fair_perc_self_calc` (derived from `token_self`, `token_opp`), and exactly two learnable parameters (`beta_value`, `beta_unfairness`) such that the influence of `beta_value` on `U` is mathematically distinct from the influence of `beta_unfairness` across the range of possible offers. Focus on making `beta_unfairness` influence the utility in a way that is clearly non-linear and specifically tied to the *degree* of unfairness, distinguishing it from the general value sensitivity captured by `beta_value`.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc`, and any other necessary intermediate variables like `deviation`, `unfairness_penalty_term = max(0.0, deviation)`, and a `penalty_factor` (e.g., `max(0.0, 1.0 - unfairness_penalty_term / 100.0)`). Ensure `fair_perc_self_calc` handles `sum_tokens == 0` correctly (defaulting to 50.0 when using percentage scale, e.g., `IF sum_tokens == 0 THEN 50.0 ELSE (token_self / sum_tokens) * 100.0 END IF`).
*   **Model Formula:** Define `U`. Include calculation steps for derived variables *before* the formula for `U`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**. Choose descriptive, Python-safe names (e.g., `beta_value`, `beta_unfairness`). Define clear, generous, finite numerical bounds (e.g., [-10.0, 10.0], [-50.0, 50.0], [0.0, 100.0], etc. appropriate for the scale of their influence). For `beta_unfairness` in an exponent as suggested, a non-negative constraint like `[0.0, 10.0]` or `[0.0, 50.0]` is theoretically plausible (higher beta = stronger penalty) and may aid recovery.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including U, sum_tokens, fair_perc_self_calc, deviation, unfairness_penalty_term, penalty_factor) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea and, crucially, explain *how its specific non-linear, asymmetric, or interactive mathematical structure (especially the role of `beta_unfairness`, e.g., in the exponent) is fundamentally different from the previous failed models (linear additive, cubic additive, linear ratio, quadratic ratio, simple multiplicative exponential) and how this difference is specifically intended to ensure robust parameter identifiability for *both* learnable parameters*, particularly improving the recovery of the fairness/penalty parameter (which failed in Run 64 at 0.451).

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative and explore structures that make the second parameter's influence on utility more non-linear and distinct than simple linear scaling of a deviation term.

Please think through this step by step, then provide your model specification and variable descriptions.