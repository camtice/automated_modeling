Okay, here are the improved instructions for the next run, focusing intensely on designing a model structure that ensures parameter identifiability for *both* learnable parameters while building on the successes and addressing the failures of the previous attempts.

Instructions for Run 66 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery. A model with excellent fit but poor parameter identifiability is not suitable for drawing meaningful conclusions about the underlying cognitive processes.

Run 65 explored a power-law multiplicative decay structure: `U = beta_value * split_perc_self * (penalty_factor)^beta_unfairness`, where `penalty_factor` was based on the simple unfairness difference. This attempt was unfortunately unsuccessful, yielding poor parameter recovery for *both* `beta_value` (r = -0.086) and `beta_unfairness` (r = -0.179), alongside worse BIC (57.07) and accuracy (0.495) compared to previous models. This indicates that placing `beta_unfairness` directly in the exponent of a penalty factor derived from the simple difference did not create the necessary distinct mathematical influence and likely introduced new identifiability or modeling issues, potentially related to how the penalty factor reaches its bounds or how the exponent interacts with the value term.

Previous attempts have shown that linear additive models struggle with the unfairness parameter (Run 61: cubic additive, `beta_unfairness` r = -0.172) and ratio models applying a penalty based on the *difference* also haven't consistently reached the 0.7 threshold for the unfairness parameter (Run 63: linear ratio, `beta_unfairness` r = 0.608; Run 64: quadratic ratio, `beta_unfairness` r = 0.451). While Run 63's linear ratio model achieved the best `beta_unfairness` recovery so far (0.608), it was still just shy of the target, suggesting the simple difference-based penalty term (`max(0.0, fair_perc_self_calc - split_perc_self)`) might be too correlated with the value term (`split_perc_self`) to allow perfect separation of the two parameters' influences in these structures.

For Run 66, let's try a different approach to defining the *unfairness penalty term* itself. Instead of using the *absolute difference* between the fair share and the offered share, let's define the penalty based on the *ratio* of the fair share to the offered share. This captures *relative* unfairness â€“ how much smaller the offer is *compared to* the fair share.

Consider an additive model structure similar to Run 61, but using this new ratio-based penalty term.
Proposed Structure Concept: `U = beta_value * split_perc_self - beta_unfairness * RatioPenaltyTerm`.
Here, `RatioPenaltyTerm` should be zero for fair or generous offers and increase as the offer becomes more unfair relative to the fair share. A possible calculation for `RatioPenaltyTerm` is `max(0.0, (fair_perc_self_calc / split_perc_self) - 1.0)`. This term represents the proportional difference between the fair share and the offered share, but only when the offer is less than fair. *Care must be taken to handle the case where `split_perc_self` is zero or very small, which would represent a maximally unfair offer*. Using `max(1e-6, split_perc_self)` in the denominator can prevent division errors and produce a very large penalty term for zero/very small offers, which is conceptually appropriate.

The goal is to design a utility calculation `U` involving `split_perc_self`, `fair_perc_self_calc` (derived from `token_self`, `token_opp`), and exactly two learnable parameters (`beta_value`, `beta_unfairness`). Design the model using an additive structure where `beta_value` scales the `split_perc_self` and `beta_unfairness` scales a *ratio-based* penalty term calculated as described above. Focus on clearly defining this new penalty term and articulating how its unique mathematical relationship with the input variables (compared to the simple difference penalty) is intended to help disentangle the influences of `beta_value` and `beta_unfairness` and improve parameter identifiability.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc` (handling `sum_tokens == 0` defaulting to 50.0), and a new `ratio_penalty_term` based on `max(0.0, (fair_perc_self_calc / max(1e-6, split_perc_self)) - 1.0)` or a similar ratio-based definition of relative unfairness. Include any other necessary intermediate variables.
*   **Model Formula:** Define `U` using an additive structure: `U = beta_value * split_perc_self - beta_unfairness * RatioPenaltyTerm`. Include calculation steps for derived variables *before* the formula for `U`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**: `beta_value` and `beta_unfairness`. Choose descriptive, Python-safe names. Define clear, generous, finite numerical bounds. Given the additive structure and penalty term definition, non-negative bounds for both parameters (e.g., `[0.0, 50.0]`, `[0.0, 100.0]`) are theoretically appropriate (higher `beta_value` increases utility for better offers, higher `beta_unfairness` increases penalty for unfairness) and may aid recovery.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including U, sum_tokens, fair_perc_self_calc, and your chosen ratio-based penalty term variable) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea (additive structure, value and penalty components). Crucially, explain *how the definition of the penalty term based on the *ratio* of fair share to offered share (instead of the simple difference) creates a different mathematical relationship between the terms scaled by `beta_value` and `beta_unfairness`, and how this difference is specifically intended to improve robust parameter identifiability for *both* learnable parameters*, particularly for `beta_unfairness`, which has struggled in previous models. Explain why this ratio-based approach might be better at separating the influences than previous additive or ratio models using the simple difference penalty.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative in how you define and utilize the ratio-based penalty term to maximize this distinction.