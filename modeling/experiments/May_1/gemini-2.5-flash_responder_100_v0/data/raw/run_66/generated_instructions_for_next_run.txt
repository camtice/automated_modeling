Okay, here are the improved instructions for the next run (Run 67), building on the analysis of previous attempts and focusing intensely on achieving robust parameter identifiability for *both* learnable parameters.

Instructions for Run 67 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery.

Run 66 attempted an additive model structure `U = beta_value * split_perc_self - beta_unfairness * ratio_penalty_term` using a ratio penalty term defined as `max(0.0, (fair_perc_self_calc / safe_split_perc_self) - 1.0)`. This model performed poorly across the board: high BIC (527.89), moderate accuracy (0.656), and critically, terrible parameter recovery for *both* `beta_value` (r=0.293) and `beta_unfairness` (r=0.052). This suggests that the additive structure combined with this specific, potentially unbounded ratio penalty term did not effectively separate the influences of the two parameters, possibly due to numerical instability or high correlation between the terms being scaled.

In contrast, Run 63, which used a *ratio* model structure (`U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * unfairness_penalty_term)`) with a *difference-based* penalty term (`max(0.0, fair_perc_self_calc - split_perc_self)`), showed significantly better performance: lower BIC (46.17), higher accuracy (0.691), and better parameter recovery, particularly for `beta_value` (r=0.925). While `beta_unfairness` recovery (r=0.608) in Run 63 was still just shy of the 0.7 target, it was the best recovery for the unfairness parameter seen in models using a difference-based penalty term.

This suggests that a *ratio structure* might be more conducive to parameter identifiability for this task than additive structures. However, the simple difference penalty term used in Run 63 might still have too much correlation with `split_perc_self` to allow `beta_unfairness` to be fully disentangled from `beta_value`.

For Run 67, let's combine the promising *ratio structure* from Run 63 with a *different approach to the unfairness penalty term* â€“ specifically, a ratio-based penalty, but one that is **bounded** and potentially less correlated with the value term than the simple difference.

Let's define the penalty based on the *relative* shortfall: `1 - (offered_share / fair_share)`, applicable only when the offer is less than fair. This term naturally ranges from 0 (when offered == fair) up to 1 (when offered == 0 and fair > 0).

Proposed Model Structure: A ratio model where the utility is the scaled value term divided by a term that increases with unfairness.
`U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * BoundedRatioPenaltyTerm)`

Here, `BoundedRatioPenaltyTerm` should be 0 for fair or generous offers and increase as the offer becomes more unfair *relative to the fair share*. A suitable definition that is bounded between 0 and 1 (when `split_perc_self >= 0`) is `max(0.0, 1.0 - (split_perc_self / fair_perc_self_calc))`. Special care must be taken when `fair_perc_self_calc` is 0 (which happens when `token_self` is 0 and `token_opp` > 0). If `fair_perc_self_calc` is 0, any non-negative offer is "fair" or "generous" relative to a 0 fair share, so the penalty should be 0.

The goal is to design a utility calculation `U` involving `split_perc_self`, `fair_perc_self_calc` (derived from `token_self`, `token_opp`), and exactly two learnable parameters (`beta_value`, `beta_unfairness`). Design the model using the ratio structure `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * BoundedRatioPenaltyTerm)` where `BoundedRatioPenaltyTerm` is calculated as `max(0.0, 1.0 - (split_perc_self / fair_perc_self_calc))` but is explicitly set to 0 if `fair_perc_self_calc` is 0.

Focus on clearly defining this new, bounded ratio penalty term and articulating how its unique mathematical relationship with the input variables (compared to the simple difference penalty or the unbounded ratio penalty from Run 66) is intended to help disentangle the influences of `beta_value` and `beta_unfairness` and improve parameter identifiability within the ratio structure.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc` (handling `sum_tokens == 0` defaulting to 50.0), and a new `bounded_ratio_penalty_term` based on `max(0.0, 1.0 - (split_perc_self / fair_perc_self_calc))`, explicitly handling the case where `fair_perc_self_calc` is 0 (setting the penalty to 0 in that case). Include any other necessary intermediate variables.
*   **Model Formula:** Define `U` using the ratio structure: `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * BoundedRatioPenaltyTerm)`. Include calculation steps for derived variables *before* the formula for `U`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**: `beta_value` and `beta_unfairness`. Choose descriptive, Python-safe names. Define clear, generous, finite numerical bounds. Non-negative bounds (e.g., `[0.0, 100.0]` for both) are theoretically appropriate (higher `beta_value` increases utility for better offers, higher `beta_unfairness` increases the denominator penalty for unfairness) and may aid recovery.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including U, sum_tokens, fair_perc_self_calc, and your chosen bounded ratio-based penalty term variable) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea (ratio structure, value numerator, penalty denominator). Crucially, explain *how the definition of the penalty term based on the *bounded ratio* of offered share to fair share (instead of the simple difference or unbounded ratio) within the denominator of the ratio structure is intended to improve robust parameter identifiability for *both* learnable parameters*, particularly `beta_unfairness`, by creating distinct mathematical influences for the two parameters across the range of offers. Explain why this approach builds on the relative success of the Run 63 ratio model while attempting to address its parameter recovery limitations by using a better-behaved penalty term.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative in how you define and utilize the bounded ratio-based penalty term to maximize this distinction within the ratio structure. Find a model structure that truly shines in parameter recovery.