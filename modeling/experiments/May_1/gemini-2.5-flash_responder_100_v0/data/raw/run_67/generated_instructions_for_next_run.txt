Okay, here are the improved instructions for the next run (Run 68), building on the analysis of previous attempts and maintaining the intense focus on achieving robust parameter identifiability for *both* learnable parameters.

Instructions for Run 68 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery.

Run 67 attempted to combine the promising *ratio structure* from Run 63 (`U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * BoundedRatioPenaltyTerm)`) with a *bounded ratio-based* penalty term (`max(0.0, 1.0 - (split_perc_self / fair_perc_self_calc))`). This approach resulted in extremely poor parameter recovery for *both* `beta_value` (r=0.034) and `beta_unfairness` (r=-0.029), indicating that this specific combination of structure and penalty term completely failed to create distinguishable parameter influences. Despite the theoretical reasoning, the mathematical relationship between the scaled value term and the scaled penalty term was too collinear or interdependent within this model form.

The historical performance suggests that ratio structures have shown *potential* for better `beta_value` recovery (Run 63: r=0.925), but consistently struggle with `beta_unfairness` recovery when using simple difference or ratio-based penalty terms. This strongly indicates that the *form* of the penalty term and *how it enters the utility function* relative to the value term is the key challenge for disentangling `beta_unfairness`.

For Run 68, let's continue to explore the ratio structure as it has shown the best single-parameter recovery, but we must drastically change the approach to the *penalty term* to improve `beta_unfairness` identifiability. The failure of simple difference (Run 63) and bounded ratio (Run 67) penalties suggests that these terms, when scaled by `beta_unfairness` in the denominator `1 + beta_unfairness * penalty`, still have an influence profile too similar to the `beta_value * split_perc_self` term in the numerator, making them hard to tell apart during fitting.

To achieve better identifiability for `beta_unfairness`, its impact needs to be mathematically distinct. A promising avenue is to make the penalty term itself a **non-linear function** of the difference or ratio that quantifies unfairness. This non-linearity should ideally create a shape of influence for `beta_unfairness` that is less correlated with the linear effect of `beta_value` across the range of `split_perc_self` values in the dataset.

Let's define a `NonLinearPenaltyTerm` that is zero for fair or generous offers, but increases non-linearly as the offer becomes less than the fair share. A concrete approach to explore is using the **squared positive difference** between the fair share and the offered share percentage: `max(0.0, fair_perc_self_calc - split_perc_self)^2`. This penalizes increasingly unfair offers at an accelerating rate.

Proposed Model Structure: Continue with the ratio model form, but use this new non-linear penalty term in the denominator.
`U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * NonLinearPenaltyTerm)`

Here, `NonLinearPenaltyTerm` is calculated as `max(0.0, fair_perc_self_calc - split_perc_self)^2`. This ensures the penalty is zero for fair or generous offers (`split_perc_self >= fair_perc_self_calc`) and applies a squared penalty otherwise. Special care must be taken in calculating `fair_perc_self_calc` when `sum_tokens` is zero (as before, default to 50.0).

The goal is to design a utility calculation `U` involving `split_perc_self`, `fair_perc_self_calc` (derived from `token_self`, `token_opp`), and exactly two learnable parameters (`beta_value`, `beta_unfairness`). Design the model using the ratio structure `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * NonLinearPenaltyTerm)` where `NonLinearPenaltyTerm` is calculated as `max(0.0, fair_perc_self_calc - split_perc_self)^2`.

Focus on clearly defining this new, non-linear penalty term and articulating in the summary how its non-linear relationship with the degree of unfairness is intended to help disentangle the influences of `beta_value` (scaling the linear value) and `beta_unfairness` (scaling the non-linear penalty) and thus significantly improve robust parameter identifiability for *both* parameters within the ratio structure. Explain why this approach represents a departure from previous attempts that used linear or simple ratio-based penalty terms.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc` (handling `sum_tokens == 0` defaulting to 50.0), and a new `non_linear_penalty_term` based on `max(0.0, fair_perc_self_calc - split_perc_self)^2`. Include any other necessary intermediate variables.
*   **Model Formula:** Define `U` using the ratio structure: `U = (beta_value * split_perc_self) / (1.0 + beta_unfairness * NonLinearPenaltyTerm)`. Include calculation steps for derived variables *before* the formula for `U`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**: `beta_value` and `beta_unfairness`. Choose descriptive, Python-safe names. Define clear, generous, finite numerical bounds. Non-negative bounds (e.g., `[0.0, 100.0]` for both) are theoretically appropriate and may aid recovery.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including U, sum_tokens, fair_perc_self_calc, and your chosen non-linear penalty term variable) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.\
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea (ratio structure, value numerator, non-linear penalty denominator). Crucially, explain *how the definition of the penalty term as the squared positive difference between fair share and offered share percentage* within the denominator of the ratio structure is specifically intended to improve robust parameter identifiability for *both* learnable parameters by creating mathematically distinct non-linear influences for `beta_unfairness` compared to the linear influence of `beta_value`. Explain how this builds on previous attempts by addressing the suspected collinearity issues arising from linear or simple ratio penalties.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative in how you define and utilize the non-linear penalty term or alternative interactions to maximize this distinction within a plausible utility framework. Find a model structure that truly shines in parameter recovery.