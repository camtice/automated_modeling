Design a computational model for the described ultimatum game responder task. Your model must meet the following criteria:
1.  **Predict only responder behavior** (target variable: "accept").
2.  **Achieve excellent parameter recovery (>= 0.7 correlation) for ALL learnable parameters.** This remains the *single most important* objective. Previous attempts have failed here, including the most recent one. A model is unusable if any learnable parameter cannot be reliably recovered, regardless of other metrics (like BIC or accuracy). Prioritize model structures that inherently enhance parameter identifiability from the data.
3.  **Be applicable to the dataset:** Use only the provided data structure and variables available during responder trials (trial_role == 1).
4.  **Predict utility:** Utility values will be converted to acceptance probabilities using a logistic function (with temperature 1). A utility > 0 implies > 50% probability of acceptance.

**Analysis of Previous Attempt (Run 7):** The most recent model (`beta_gain * split_perc_self - gamma_unfairness * max(0, fair_perc_self - split_perc_self)`) showed promising signs in terms of BIC (76.39) and accuracy (0.821), improving significantly over earlier models on these metrics. However, it **failed parameter recovery** (`beta_gain: r=0.576`, `gamma_unfairness: r=0.638`). Both parameters were below the critical 0.7 threshold, rendering the model unusable for reliable inference about participant strategies. This suggests that even this simple piecewise structure, with linear scaling of the offer value and a linear penalty below the proportional norm (`fair_perc_self`), still allows for the parameters' effects to be too correlated or substitutable given the data pattern. For example, the effect of increasing the offer percentage and the effect of reducing the unfairness penalty below the norm might overlap too much in how they influence the utility curve.

**Guidance for the Next Model (Radically Prioritizing Parameter Recovery - Continued):** The core challenge remains the design of a utility function where each learnable parameter has a truly unique "signature" on the utility curve, making its contribution statistically separable from the others during parameter fitting. Simple additive components scaled by parameters, even with basic thresholds (`max(0,...)`), have consistently failed to produce identifiable parameters in this dataset.

We need to explore model structures where parameters exert influence in more distinct, non-overlapping ways. Think beyond simple linear terms and single penalty thresholds. Consider how parameters can control the *shape* or *structure* of the utility function itself, especially around the crucial reference points (50% and the proportional share `fair_perc_self`).

*   **Model Multiple Norms Distinctly:** Explicitly incorporate both the 50% norm and the proportional norm (`fair_perc_self`). Can parameters control the sensitivity or type of penalty/bonus *relative to each norm separately*?
*   **Thresholds and Switching Points:** Design parameters that act as thresholds or switching points in the utility function based on the offer percentage (`split_perc_self`) relative to the norms. For instance, a parameter could define how far below 50% an offer must be to trigger a specific strong rejection tendency, while another parameter controls the sensitivity to offers *between* 50% and the proportional share, and another for offers *above* the proportional share.
*   **Parameterize the Shape/Exponent:** Could a parameter control the exponent of the fairness deviation (`max(0, fair_perc_self - split_perc_self)^parameter_exponent`) or the offer value (`split_perc_self^parameter_exponent`)? Parameters controlling exponents or non-linear transformations often have very different effects on the utility function shape than simple linear scales.
*   **Multiplicative Interactions:** Explore models where parameters scale *interactions* between different components, rather than just additive terms. For example, `Utility = split_perc_self * (1 - fairness_parameter * deviation)` or `Utility = split_perc_self - penalty_parameter * (deviation_below_50 + deviation_below_prop)`.
*   **Parameters Controlling Relative Weights of Norms:** Design a parameter that explicitly weighs the influence of the 50% norm versus the proportional norm in determining fairness sensitivity or the reference point, potentially in a non-linear or threshold-dependent manner (this was attempted in Run 1 but recovery was poor there too, suggesting the weighting mechanism needs refinement).

Focus on defining parameters whose effect on utility cannot be replicated by adjusting other parameters. This might involve parameters that:
- Change the slope of the utility function in specific ranges.
- Control the curvature (e.g., quadratic or exponential terms).
- Define thresholds where the functional form of utility changes.
- Modify how different factors (offer, 50% deviation, proportional deviation) combine, not just additively.

Continue to build the model using percentage-based values (`split_perc_self`, `fair_perc_self`). Aim for the minimum number of learnable parameters necessary *only if* their effects are clearly separable and identifiable. A model with fewer, identifiable parameters is vastly preferred over one with many, unidentifiable ones, regardless of seemingly good BIC or accuracy scores on validation data.

For any learnable parameters, you must specify generous, finite numerical bounds. The utility variable may be unbounded (-inf to inf).

Provide your formal mathematical model between <MODEL> tags. Ensure *only* the mathematical formula is within these tags.
Provide variable descriptions in JSON format between <VARIABLES> tags. Ensure learnable parameter names are clear and suitable for coding. Spell out Greek variables.
Specify the target variable using <target_variable> tags.
Provide a concise, descriptive summary of the model between <SUMMARY> tags.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
Remember to only model responder trials (where trial_role == 1) and use variables available in that context. The `fair_perc_self` variable (calculated as `(token_self / (token_self + token_opp)) * 100`) is useful for fairness calculations.

For run 8 of 100, please think through this step by step, focusing intently on how the *specific mathematical structure* of the model guarantees parameter identifiability and distinguishes the influence of each parameter, minimizing covariance based on the *specific* data characteristics. How can you define learnable parameters that control fundamentally different aspects of the utility function (e.g., slope, threshold, exponent, interaction weight, switching points based on norms) rather than just scaling additive components? Think creatively about non-linear and piecewise structures relative to *both* the 50% and proportional norms. Then provide your model specification, variable descriptions, target variable, and summary.

Previous Models:Not Provided

Please think through this step by step, then provide your model specification and variable descriptions.