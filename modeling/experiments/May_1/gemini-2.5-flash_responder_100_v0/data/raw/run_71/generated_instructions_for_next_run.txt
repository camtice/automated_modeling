Okay, here are the improved instructions for the next run (Run 72), based on the results of previous attempts, with the absolute focus remaining on achieving robust parameter identifiability.

Instructions for Run 72 of 100:

The **unwavering primary objective remains achieving parameter recovery >= 0.7 for *all* learnable parameters**. This is the critical benchmark for model usability. While improved BIC (lower is better) and accuracy (higher is better) are valuable secondary goals, they must not come at the expense of robust parameter recovery.

The previous run (Run 71) implemented an additive model structure with a squared positive deviation penalty (`U_accept = beta_value * split_perc_self - beta_unfairness * squared_positive_deviation`). Despite the theoretical rationale that the squared penalty would create a distinct non-linear influence compared to the linear value term, the results showed *very poor* parameter recovery for both parameters (beta_value: r=0.167, beta_unfairness: r=0.256). This indicates that this specific additive structure, even with a non-linear penalty form, did not sufficiently disentangle the influences of the parameters. Run 71 also showed poor BIC (586.67) and accuracy (0.650) compared to some earlier attempts, further confirming this structure was not effective.

Previous attempts using simple additive structures or ratio structures with various penalty terms (including the squared deviation penalty which performed better on BIC in a ratio model in Run 68, though still with poor recovery) have consistently failed to achieve robust parameter identifiability. This suggests that these common model structures may inherently lead to confounding between a 'value' parameter and an 'unfairness' parameter when both influence the overall utility calculation in a straightforward linear-additive or simple multiplicative/ratio manner.

For Run 72, we need a fundamentally different conceptual approach to model structure that is more likely to create mathematically distinct contributions for `beta_value` and `beta_unfairness`. Instead of viewing utility as `Value - Penalty`, let's explore a **reference-dependent framework**. The fair share percentage (`fair_perc_self_calc`) can naturally serve as a reference point. Utility could then be defined based on deviations *above* this reference (gains) and deviations *below* this reference (losses/unfairness), with potentially different sensitivities for these gains and losses.

This approach, inspired by concepts like Prospect Theory in behavioral economics, posits that the impact of an outcome depends on its relation to a reference point, and that losses relative to the reference point loom larger than equivalent gains. Applying this here, we can hypothesize that participants evaluate offers based on how much they deviate from their perceived fair share, with separate sensitivities for favorable deviations (above fair) and unfavorable deviations (below fair).

Proposed Model Structure: A reference-dependent additive model where utility is calculated based on deviations from the fair share percentage, with separate parameters for gains and losses relative to this reference.
`U_accept = beta_value * GainAboveFair - beta_unfairness * LossBelowFair`

Here:
Calculate `fair_perc_self_calc` handling the `sum_tokens == 0` case (defaulting to 50.0).
Calculate `GainAboveFair = max(0.0, split_perc_self - fair_perc_self_calc)`. This term is non-zero only for offers above or equal to the fair share.
Calculate `LossBelowFair = max(0.0, fair_perc_self_calc - split_perc_self)`. This term is non-zero only for offers below or equal to the fair share.
Finally, `U_accept = beta_value * GainAboveFair - beta_unfairness * LossBelowFair`. Note the subtraction, representing the negative utility (disutility) from a loss.

In this structure, `beta_value` scales the utility derived from exceeding the fair share (Gain sensitivity), and `beta_unfairness` scales the *disutility* derived from falling short of the fair share (Loss/Unfairness sensitivity). The key hypothesis for improved identifiability is that `beta_value` primarily influences utility for offers *at or above* the fair share, while `beta_unfairness` primarily influences utility for offers *at or below* the fair share. Because these two "domains" (gains vs. losses relative to fair) are largely disjoint in terms of where the respective terms (`GainAboveFair` and `LossBelowFair`) are active, the influence of `beta_value` on the overall utility profile should be mathematically distinct from the influence of `beta_unfairness`, leading to better identifiability.

Design the model using this reference-dependent additive structure: `U_accept = beta_value * gain_above_fair - beta_unfairness * loss_below_fair`, where `gain_above_fair` and `loss_below_fair` are calculated as specified above using `fair_perc_self_calc` as the reference.

Focus on clearly defining the `gain_above_fair` and `loss_below_fair` terms and articulating in the summary how this specific structure, by assigning `beta_value` to scale 'gains' relative to fairness and `beta_unfairness` to scale 'losses' relative to fairness, is intended to achieve robust parameter identifiability. Explain why this reference-dependent approach is being tested as a way to overcome the identifiability failures seen in previous additive and ratio structures that used single penalty terms. This is a more "out-of-the-box" structure compared to previous attempts, aimed directly at the identifiability challenge.

*   **Key Inputs & Calculated Variables:** Use `split_perc_self`, `token_self`, `token_opp` as data variables. Calculate `sum_tokens`, `fair_perc_self_calc` (handling `sum_tokens == 0`), `gain_above_fair`, `loss_below_fair`, and `U_accept`. Include any other necessary intermediate variables.
*   **Model Formula:** Define `U_accept` using the reference-dependent additive structure: `U_accept = beta_value * gain_above_fair - beta_unfairness * loss_below_fair`. Include calculation steps for derived variables *before* the formula for `U_accept`. Use clear mathematical notation within the <MODEL> tags (only the formula).
*   **Learnable Parameters:** Exactly **2 learnable parameters**: `beta_value` (gain sensitivity) and `beta_unfairness` (loss/unfairness sensitivity). Choose descriptive, Python-safe names. Define clear, generous, finite numerical bounds. Non-negative bounds (e.g., `[0.0, 100.0]` for both) are theoretically appropriate and may aid recovery. Stick with `[0.0, 100.0]` for both.
*   **Calculated Variables:** Include descriptions for *all* calculated variables used in the model (including `U_accept`, `sum_tokens`, `fair_perc_self_calc`, `gain_above_fair`, and `loss_below_fair`) with `source: "calculated"`. Include descriptions for all data variables used as inputs (`token_self`, `token_opp`, `split_perc_self`) with `source: "data"`.
*   **Variable Descriptions:** Provide variable descriptions in JSON format between <VARIABLES> tags for *all* variables in the <MODEL> formula. Include source, range (with inclusive flags), distribution (if applicable), and learnable status. Remember variable names must exactly match the model.
*   **Target Variable:** Specify "accept" using <target_variable> tags.
*   **Summary:** Provide a concise summary between <SUMMARY> tags. Describe the model's core idea (reference-dependent additive structure, fair share as reference, separate gain/loss sensitivities). Crucially, explain *how* this structure, by having `beta_value` scale gains (above fair) and `beta_unfairness` scale losses (below fair), is specifically intended to improve robust parameter identifiability by creating mathematically distinct influences across different offers, addressing the limitations of previous simple additive/ratio structures.
*   **Think Outside the Box:** Recognize that previous attempts with standard additive/ratio forms and various penalty definitions have failed parameter recovery. This new model structure is a significant departure intended to directly tackle the identifiability problem by assigning parameters roles in distinct parts of the outcome space relative to a reference. Continue to consider non-obvious ways parameters might interact or influence decisions beyond simple linear combinations.

Available Data Variables:
- trial_type, trial_role, token_opp, token_self, combined_earning, split_opp, split_self, splitperc_opp, split_perc_self, accept, accepted_amount, accepted_perc, proposed_perc, proposed_amount.
(Note: Use `split_perc_self` for the participant's proposed percentage share percentage).

Please think through this step by step, then provide your model specification and variable descriptions. Remember that robust parameter identifiability for *both* learnable parameters (>= 0.7 recovery for both) is the absolute priority. Your goal is to find a structure where both parameters' influences are clearly distinguishable across the range of possible offers, leading to reliable estimates. Be creative in how you define and utilize the different functional forms and structures to maximize this distinction while remaining theoretically plausible. Find a model structure that truly shines in parameter recovery.