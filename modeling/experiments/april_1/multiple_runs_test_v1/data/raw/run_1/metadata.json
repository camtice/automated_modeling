{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.\n\nFirst, reason step by step about:\n* The key psychological mechanisms involved\n* How these mechanisms interact\n* What mathematical form could capture these interactions\n* What parameters would be needed to calibrate the model\n* How the model variables map to observable behavior",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function, and then used to predict binary decisions.\n\n\nInstructions: Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.\n\nFirst, reason step by step about:\n* The key psychological mechanisms involved\n* How these mechanisms interact\n* What mathematical form could capture these interactions\n* What parameters would be needed to calibrate the model\n* How the model variables map to observable behavior\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this problem step by step. The goal is to design a computational model that predicts whether a participant (acting as the responder) accepts or rejects a proposal in the given experiment. The model needs to focus on responder behavior, use the provided variables appropriately, and ensure parameter recovery is feasible. Also, the utility should be modeled such that a negative utility corresponds to less than 50% probability of acceptance.\n\nFirst, I need to understand the key variables involved. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of accepting the proposal. The utility function should incorporate factors that influence the responder's decision.\n\nLooking at the dataset variables, important ones for the responder's decision might include:\n\n- token_self and token_opp: These represent the contributions of the participant and the opponent to the shared pot. The combined_earning is the total money, which is 3*(token_self + token_opp). \n\n- split_self and split_opp: The proposed shares in \u00a3. For the responder, split_self is what they get if they accept. \n\n- trial_type: Indicates whether contributions are equal, opponent more, or participant more. This might affect fairness perceptions.\n\nBut since the model should use variables from the dataset, and trial_role is 1 for responder, we can filter trials where trial_role is 1.\n\nThe key psychological factors here are likely fairness considerations and self-interest. The responder's utility might depend on both their own monetary gain (split_self) and the fairness of the split relative to contributions.\n\nSo, the utility could be a function of the monetary offer (split_self) and some measure of fairness. Fairness might be calculated as the difference between the proposed split percentage (splitperc_self) and what would be considered a \"fair\" percentage based on contributions.\n\nWhat's a fair percentage? If contributions are based on tokens, then the fair split might be proportional to each person's contribution. For example, the participant's fair share would be (token_self / (token_self + token_opp)) * 100%. The proposed splitperc_self is given, so the difference between the proposed and fair percentage could be a measure of unfairness.\n\nLet me formalize this. The fair percentage for the participant is (token_self / (token_self + token_opp)) * 100. The proposed percentage is splitperc_self. The difference (splitperc_self - fair_percentage) would indicate how much more or less the participant is getting compared to their contribution. A positive difference means they're getting more than fair, negative means less.\n\nBut maybe participants have different sensitivities to this unfairness. Some might be more tolerant, others less. So, a parameter (like \u03b1) could represent the sensitivity to unfairness. Additionally, the monetary gain (split_self) would naturally influence utility. So, the utility could be a combination of split_self and the unfairness term.\n\nBut wait, the combined_earning is fixed per trial, so split_self is part of that. However, the absolute amount might matter. For example, getting \u00a35 in a \u00a310 pot vs. \u00a350 in a \u00a3100 pot\u2014same percentage but different absolute amounts. So, the model should consider both the absolute split and the fairness relative to contributions.\n\nAlternatively, the utility could be modeled as:\n\nUtility = \u03b2 * split_self + \u03b1 * (splitperc_self - fair_percentage)\n\nBut fair_percentage is (token_self / (token_self + token_opp)) * 100. So, splitperc_self - (token_self / (token_self + token_opp)*100) is the deviation from the contribution-based fair split.\n\nIf the participant cares about both their monetary gain and fairness, then these two terms would capture that. \u03b2 represents the sensitivity to monetary gain, \u03b1 the sensitivity to fairness. If \u03b1 is positive, then participants prefer offers that are more than their fair share; if negative, they might reject unfair offers even if it costs them (but in this case, since the responder's alternative to accepting is presumably getting nothing, maybe \u03b1 is positive, so they dislike being under their fair share).\n\nWait, but in the responder's case, if they reject, they might get nothing. So, the utility of rejecting is 0 (assuming), and the utility of accepting is the split_self plus any fairness considerations. But perhaps the fairness term is a disutility if the offer is below the fair share. So, the utility could be:\n\nUtility = split_self + \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nBut that complicates things. Alternatively, using the percentage difference:\n\nUtility = \u03b2 * split_self + \u03b1 * (splitperc_self - fair_percentage)\n\nBut split_self is in \u00a3, and fair_percentage is a percentage. Maybe scaling is an issue here. Alternatively, since split_self is 3 * token_self * (splitperc_self / 100), but maybe that's complicating.\n\nAlternatively, the fair amount in \u00a3 would be (token_self / (token_self + token_opp)) * combined_earning. Then, the difference between split_self and fair_amount could be the unfairness in monetary terms. So:\n\nfair_amount = (token_self / (token_self + token_opp)) * combined_earning\nunfairness = split_self - fair_amount\n\nThen, the utility could be:\n\nUtility = \u03b2 * split_self + \u03b1 * unfairness\n\nBut split_self is part of the unfairness term. Wait, that would be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - fair_amount)\n\nWhich simplifies to:\n\nUtility = (\u03b2 + \u03b1) * split_self - \u03b1 * fair_amount\n\nBut fair_amount is (token_self/(token_self + token_opp)) * combined_earning. Since combined_earning is 3*(token_self + token_opp), then fair_amount = 3 * token_self. Because combined_earning is 3*(tokens), so (token_self / (token_self + token_opp)) * 3*(token_self + token_opp) = 3*token_self. So fair_amount is 3*token_self. Therefore, split_self is the proposed amount, and the fair amount is 3*token_self. So the unfairness is split_self - 3*token_self.\n\nWait, that's interesting. Because if the participant contributed token_self tokens, each worth \u00a33, their contribution is 3*token_self. The fair split would be that they get their contribution back. But in the combined earning, which is 3*(token_self + token_opp), the proposer is offering split_self to the responder. So, if split_self is less than 3*token_self, the responder is getting less than their contribution. If it's more, they get more. So the unfairness could be split_self - 3*token_self. But maybe participants feel negative utility if split_self is less than their contribution (they're losing out), and positive if it's more.\n\nSo, the utility could be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self)\n\nBut this combines the monetary gain (split_self) with the difference between the offer and their contribution. Alternatively, maybe participants compare the offer to their contribution. If the offer is less than their contribution, they perceive it as unfair, leading to a disutility. If it's more, they might feel it's favorable.\n\nBut perhaps the model should have two parameters: one for the weight on the monetary gain (\u03b2) and another for the weight on the fairness term (\u03b1). The fairness term is (split_self - 3*token_self). So:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self)\n\nThis can be rewritten as:\n\nUtility = (\u03b2 + \u03b1) * split_self - 3*\u03b1 * token_self\n\nBut maybe this is redundant. Alternatively, perhaps the fairness term is (split_self - fair_share), where fair_share is 3*token_self. Then, the utility is:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - fair_share)\n\nWhich is the same as above. But perhaps participants have different sensitivities to gains versus fairness. For example, \u03b2 represents the utility per pound received, and \u03b1 represents the sensitivity to deviations from the fair share. If \u03b1 is positive, then getting more than fair share increases utility; if negative, getting less than fair share decreases utility. But in the responder's case, rejecting gives zero, so they might be particularly sensitive to offers below their fair share.\n\nAlternatively, maybe the fairness term is asymmetric. For example, participants might be more sensitive to offers below their fair share than above. But that would complicate the model with more parameters. Since the instruction says to have a slight bias towards fewer parameters, perhaps a linear term is better.\n\nAnother consideration is the alternative to accepting. If the responder rejects, they might get nothing. So the utility of rejecting is 0, and the utility of accepting is as calculated. The probability of accepting is then a logistic function of the utility. If utility > 0, the probability is >50%.\n\nWait, the problem states: \"Predict utility, where less than 0 is less than 50% likely.\" So the utility is passed through a logistic function to get the probability of acceptance. So the model's utility function should be such that when utility is negative, the probability is below 0.5.\n\nSo, the model needs to compute a utility value, and the probability of acceptance is 1 / (1 + exp(-Utility)).\n\nNow, considering the parameters. The model needs learnable parameters with finite bounds. Let's think about \u03b2 and \u03b1. But perhaps there's another parameter, like a baseline term. For example, even if the offer is zero, maybe there's a baseline tendency to accept or reject. But in the task, if they reject, they get nothing. So maybe the utility should be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self) + gamma\n\nBut gamma is a constant term. However, adding gamma might complicate parameter recovery. Alternatively, maybe gamma is not needed. Let's see.\n\nIf the offer is exactly equal to 3*token_self, then the fairness term is zero. The utility is \u03b2 * split_self. If split_self is 3*token_self, then the utility is \u03b2 * 3*token_self. Whether this is positive or negative depends on \u03b2. But \u03b2 is a learnable parameter. If \u03b2 is positive, higher split_self increases utility. But maybe participants have a baseline acceptance tendency beyond the split. Alternatively, maybe gamma is necessary to capture any bias towards accepting or rejecting regardless of the terms. For example, some participants might generally be more accepting, others more rejecting. So gamma would be an intercept term.\n\nSo, the utility could be:\n\nUtility = gamma + beta_split * split_self + alpha_fairness * (split_self - 3*token_self)\n\nBut this can be rewritten as:\n\nUtility = gamma + (beta_split + alpha_fairness) * split_self - 3*alpha_fairness * token_self\n\nAlternatively, combining terms:\n\nUtility = gamma + beta * split_self + alpha * (split_self - 3*token_self)\n\nBut this is the same as before. Alternatively, perhaps gamma is not needed, but given that when split_self is zero, the utility would be -3*alpha*token_self. But in reality, if split_self is zero, the responder would definitely reject. So the utility should be negative in that case. But maybe the model can capture that with the existing terms.\n\nAlternatively, including gamma allows for a baseline tendency. For example, even if split_self is zero, if gamma is positive enough, the utility could be positive. But that's unlikely. So perhaps gamma is necessary.\n\nBut adding more parameters increases the risk of overfitting and complicates parameter recovery. The instructions suggest a slight bias towards fewer parameters. So maybe start with two parameters: beta (sensitivity to monetary gain) and alpha (sensitivity to fairness). Or three parameters including gamma.\n\nAlternatively, perhaps the model should have:\n\nUtility = beta * (split_self - reference_point)\n\nWhere the reference point could be a function of the fair share. For example, reference_point = theta * 3*token_self. Then:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nHere, theta is a parameter that determines the reference point. If theta=1, the reference is the fair share. If theta <1, the reference is lower. This captures how much the participant expects relative to their contribution. Then, beta is the sensitivity to the difference between the offer and the reference.\n\nBut this would have two parameters: beta and theta. However, theta could be constrained between 0 and some upper limit. For example, if theta is 0, the reference is zero, so utility is just beta*split_self. If theta is 1, it's the fair share. If theta is 0.5, the reference is half the fair share.\n\nBut this might capture different types of participants: those who expect at least their fair share (theta=1), those who are okay with less (theta <1), or even those who are altruistic (theta <0, but that's unlikely). However, theta would need to be bounded. For example, theta could be between 0 and 2, allowing for some flexibility.\n\nThe utility would then be:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nIf beta is positive, higher offers increase utility. Theta determines the reference point. If the offer is above theta*3*token_self, utility is positive; below, negative. Then, the probability of acceptance is logistic(Utility). So when split_self > theta*3*token_self, utility is positive, leading to higher acceptance probability.\n\nThis model has two parameters: beta (sensitivity) and theta (reference point). But beta could be positive, as higher offers should increase utility. Theta could be constrained between 0 and, say, 2. This allows for participants who have a reference point up to twice their contribution.\n\nAlternatively, maybe theta is fixed at 1 (fair share), and beta is the only parameter. But that might be too restrictive. Including theta allows for individual differences in what is considered a fair reference.\n\nAnother approach is to model inequity aversion, where participants care about both their own payoff and the difference between their payoff and the opponent's. For example, in Fehr & Schmidt's model, utility is own payoff minus alpha times the difference if the other has more, and minus beta times the difference if self has more. But in this case, the opponent's payoff after split is split_opp, which is (combined_earning - split_self). So the responder's utility could be:\n\nUtility = split_self - alpha * max(split_opp - split_self, 0) - beta * max(split_self - split_opp, 0)\n\nBut this introduces two parameters, alpha and beta. However, the problem states that the model should predict responder behavior, and the dataset includes variables like split_opp. But in the responder's role, the proposer's split_opp is their own proposed share. Wait, when the participant is the responder, the proposer is the opponent. So in the responder's trial, split_opp is the amount the opponent proposed to keep for themselves, and split_self is what the responder would get. So the responder's own payoff is split_self, and the proposer's payoff is split_opp. So inequity aversion would compare split_self and split_opp.\n\nBut Fehr & Schmidt's model is:\n\nU_i = x_i - \u03b1 * max(x_j - x_i, 0) - \u03b2 * max(x_i - x_j, 0)\n\nWhere x_i is own payoff, x_j is other's payoff. \u03b1 and \u03b2 are parameters for disadvantageous and advantageous inequality aversion, respectively.\n\nIn this case, x_i = split_self, x_j = split_opp. So:\n\nUtility = split_self - \u03b1 * max(split_opp - split_self, 0) - \u03b2 * max(split_self - split_opp, 0)\n\nThis model has two parameters, \u03b1 and \u03b2. However, the problem states that the model should utilize the given variables appropriately. But split_opp is available in the dataset, so this is feasible.\n\nBut the original task also involves the contributions (token_self and token_opp). The Fehr & Schmidt model doesn't take contributions into account, only the final split. However, the fairness consideration in the original problem might be based on contributions, not just the final split. For example, if the proposer contributed less but is taking more, that might be seen as unfair.\n\nSo perhaps the model should combine both the Fehr-Schmidt inequity aversion and the contribution-based fairness. But that would add more parameters. Let's think.\n\nAlternatively, the fairness term could be based on the difference between the proposed split and the contribution-based fair split. As before, the fair split is 3*token_self for the responder. The proposed split_self may be more or less than this. So the difference (split_self - 3*token_self) could be a term in the utility, along with the inequity aversion terms.\n\nBut this might lead to a model with too many parameters. The instructions suggest a slight bias towards fewer parameters. Let's aim for 2-3 parameters.\n\nAnother angle: the utility could depend on the ratio of the proposed split to the fair split. For example, (split_self / (3*token_self)) - 1. If this is positive, the offer is more than fair; if negative, less. Then, the utility could be:\n\nUtility = beta * split_self + alpha * ((split_self / (3*token_self)) - 1)\n\nBut this introduces a non-linear term. Alternatively, using the ratio directly:\n\nUtility = beta * split_self + alpha * (split_self / (3*token_self))\n\nBut this might not capture the deviation from fairness linearly. Alternatively, log terms, but that complicates.\n\nAlternatively, the utility could be:\n\nUtility = beta * split_self + alpha * (split_self - 3*token_self) + gamma * (split_opp - 3*token_opp)\n\nHere, split_opp is the opponent's proposed share. The term (split_opp - 3*token_opp) represents how much the opponent is taking relative to their own contribution. If the opponent is taking more than their contribution, the responder might find this unfair. But this adds another parameter (gamma), making three parameters. However, the problem allows for learnable parameters as long as they are justified.\n\nBut perhaps the key factors are the responder's own monetary gain and the fairness relative to their contribution. The opponent's share might matter less, or be part of the inequity aversion. Alternatively, the combined earning is 3*(token_self + token_opp), so split_opp = combined_earning - split_self. So split_opp is determined once split_self is known. Therefore, including split_opp might be redundant if combined_earning is known. But in the dataset, split_opp is a separate variable.\n\nBut given that combined_earning is 3*(token_self + token_opp), split_opp = combined_earning - split_self. So perhaps it's better to model based on split_self and the contributions, rather than split_opp.\n\nPutting this all together, perhaps the best approach is to model utility as a function of the responder's monetary gain (split_self) and the deviation from their fair share (split_self - 3*token_self). This captures both self-interest and contribution-based fairness. Additionally, including a term for the proposer's share relative to their contribution might add another layer, but that could complicate the model.\n\nSo, the model would have:\n\nUtility = beta * split_self + alpha * (split_self - 3*token_self)\n\nThis can be simplified to:\n\nUtility = (beta + alpha) * split_self - 3*alpha * token_self\n\nBut this combines the two parameters into a linear combination. However, beta and alpha are separate parameters, allowing the model to capture different sensitivities to absolute monetary gain versus fairness.\n\nAlternatively, to avoid redundancy, perhaps one parameter is sufficient. For example:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nHere, theta represents the proportion of their contribution that the responder expects. If theta=1, they expect exactly their contribution. If theta=0.8, they are willing to accept 80% of their contribution. Beta is the sensitivity to the difference between the offer and theta times their contribution.\n\nThis model has two parameters: beta (sensitivity) and theta (reference proportion). Theta can be bounded between 0 and, say, 2, allowing for participants who are either very tolerant (theta <1) or demand more than their contribution (theta >1).\n\nAnother consideration is the intercept. If the utility is zero when split_self equals theta*3*token_self, then the probability of acceptance is 50% at that point. If the offer is higher, the probability increases; lower, decreases. This seems reasonable.\n\nSo, the model would be:\n\nUtility = beta * (split_self - theta * 3 * token_self)\n\nBeta is a scaling parameter, and theta is the reference proportion. Both are learnable parameters. Beta should be positive, as higher offers should increase utility. Theta can be constrained between 0 and 2, for example.\n\nThis model has two parameters, which is manageable for parameter recovery. The variables used are split_self and token_self, which are available in the dataset. The combined_earning is 3*(token_self + token_opp), but we don't need to include it directly since split_self is already provided.\n\nNow, considering the probability of acceptance. The utility is passed through a logistic function:\n\nP(accept=1) = 1 / (1 + exp(-Utility))\n\nIf Utility > 0, the probability is >50%; if <0, <50%. This aligns with the requirement that utility <0 corresponds to less than 50% likelihood.\n\nNow, the parameters beta and theta need to be defined with their ranges. Beta should be positive, as a higher offer should increase utility. Theta is the reference proportion, so it's reasonable to bound it between 0 and 2. For example, a participant with theta=0.5 would accept offers that are at least half of their contribution. Theta=1 is the fair share, theta=1.5 means they demand 1.5 times their contribution.\n\nSo, the variables in the model are:\n\n- beta: sensitivity parameter, positive, range [0.01, 10] (to avoid zero and allow reasonable scaling)\n- theta: reference proportion, range [0, 2]\n\nBut the bounds should be generous. For beta, maybe [0, 20], but with a lower bound of 0 (since negative beta would invert the effect). Theta could be [0, 3], but 0 to 2 is probably sufficient.\n\nWait, but beta can't be negative, because that would mean higher offers decrease utility, which doesn't make sense. So beta must be positive. Therefore, beta's range is [0, ...], but to have a finite upper bound, maybe [0, 10] or [0, 20]. Similarly, theta's range is [0, 2], inclusive.\n\nNow, the mathematical model:\n\nUtility = beta * (split_self - theta * 3 * token_self)\n\nVariables used:\n\n- split_self (from data)\n- token_self (from data)\n\nParameters:\n\n- beta (learnable, range [0, 10])\n- theta (learnable, range [0, 2])\n\nThis model uses two parameters, which is manageable. It captures the idea that participants compare the offer to a reference point (theta times their contribution) and have a sensitivity (beta) to the difference. The utility directly influences the probability of acceptance via the logistic function.\n\nAnother possible addition is a term for the proposer's share relative to their contribution. For example, the proposer's split_opp is their proposed share. The fair share for the proposer is 3*token_opp. So, the proposer's over/under share is (split_opp - 3*token_opp). The responder might care not only about their own fairness but also the proposer's. For example, if the proposer is taking more than their fair share, the responder might be more likely to reject. This would add another term:\n\nUtility = beta*(split_self - theta*3*token_self) + gamma*(split_opp - 3*token_opp)\n\nBut this introduces another parameter (gamma), making three parameters. However, this might improve the model's accuracy but complicate parameter recovery. Given the instruction to have a slight bias towards fewer parameters, maybe stick with two parameters.\n\nAlternatively, the proposer's fairness could be incorporated into the theta term. But that's not straightforward. \n\nAlternatively, the model could include a term for the ratio of the proposer's share to their contribution. For example:\n\nUtility = beta*(split_self - theta*3*token_self) + gamma*(split_opp/(3*token_opp) - 1)\n\nBut this adds gamma as a parameter. However, this might capture the responder's aversion to the proposer's unfairness. But again, more parameters.\n\nGiven the trade-off between model complexity and parameter recovery, starting with two parameters (beta and theta) seems reasonable.\n\nNow, checking if the model meets the requirements:\n\n1. Predicts responder behavior (accept) using the given variables. The model uses split_self and token_self, which are available when trial_role is responder.\n\n2. Applicable to the dataset: Yes, as the variables are present.\n\n3. Utility <0 corresponds to <50% probability. Yes, because of the logistic function.\n\nLearnable parameters: beta and theta, with specified bounds.\n\nNow, formalizing the model:\n\n<MODEL>\nUtility = beta * (split_self - theta * 3 * token_self)\n</MODEL>\n\nVariables:\n\n- beta: learnable, range [0, 10] (inclusive)\n- theta: learnable, range [0, 2] (inclusive)\n- split_self: from data\n- token_self: from data\n\nThe variable descriptions in JSON:\n\nFor beta:\n- description: Sensitivity to the difference between the offer and the reference amount.\n- range: min 0, max 10, inclusive both.\n- learnable: true\n- source: learnable\n\nFor theta:\n- description: Reference proportion of the participant's contribution (3*token_self) that they expect.\n- range: min 0, max 2, inclusive both.\n- learnable: true\n- source: learnable\n\nsplit_self and token_self are data variables.\n\nAdditionally, the utility variable is calculated.\n\nSo the JSON would look like:\n\n{\n  \"variables\": {\n    \"beta\": {\n      \"description\": \"Sensitivity to the difference between the offer and the reference amount\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Reference proportion of the participant's contribution (3*token_self) they expect as fair\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"Utility\": {\n      \"description\": \"Calculated utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nThe target variable is \"accept\".\n\nSummary: The model assumes that responders evaluate offers based on both the absolute monetary value and a reference point derived from their contribution. The reference point is a proportion (theta) of their contribution's value, and the utility is the sensitivity (beta) weighted difference between the offer and this reference. This captures self-interest and contribution-based fairness considerations, with two learnable parameters for parsimony and recoverability.\n</think>\n\n<MODEL>\nUtility = beta * (split_self - theta * 3 * token_self)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"beta\": {\n      \"description\": \"Sensitivity to the difference between the offer and the reference amount\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Reference proportion of the participant's contribution (3*token_self) they expect as fair\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"Utility\": {\n      \"description\": \"Calculated utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model where responders evaluate offers relative to a reference point based on their contribution. Utility increases with higher monetary offers (split_self) and decreases when offers fall below a proportion (theta) of their contribution's value (3*token_self). Two learnable parameters (beta, theta) balance parsimony and interpretability, capturing sensitivity to monetary gains and fairness expectations.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['beta', 'theta']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                Utility = beta * (split_self - theta * 3 * token_self)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"beta\": {\n      \"description\": \"Sensitivity to the difference between the offer and the reference amount\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Reference proportion of the participant's contribution (3*token_self) they expect as fair\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"Utility\": {\n      \"description\": \"Calculated utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, beta=1, theta=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        utility = beta * (split_self - theta * 3 * token_self)\n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1743515003.662745
    }
  ],
  "learnable_parameters": {
    "beta": {
      "description": "Sensitivity to the difference between the offer and the reference amount",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Reference proportion of the participant's contribution (3*token_self) they expect as fair",
      "range": {
        "min": 0,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "Utility = beta * (split_self - theta * 3 * token_self)",
  "variable_descriptions": {
    "beta": {
      "description": "Sensitivity to the difference between the offer and the reference amount",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Reference proportion of the participant's contribution (3*token_self) they expect as fair",
      "range": {
        "min": 0,
        "max": 2,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for the participant in \u00a3",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by the participant",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "Utility": {
      "description": "Calculated utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    }
  },
  "model_summary": "A utility model where responders evaluate offers relative to a reference point based on their contribution. Utility increases with higher monetary offers (split_self) and decreases when offers fall below a proportion (theta) of their contribution's value (3*token_self). Two learnable parameters (beta, theta) balance parsimony and interpretability, capturing sensitivity to monetary gains and fairness expectations.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this problem step by step. The goal is to design a computational model that predicts whether a participant (acting as the responder) accepts or rejects a proposal in the given experiment. The model needs to focus on responder behavior, use the provided variables appropriately, and ensure parameter recovery is feasible. Also, the utility should be modeled such that a negative utility corresponds to less than 50% probability of acceptance.\n\nFirst, I need to understand the key variables involved. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of accepting the proposal. The utility function should incorporate factors that influence the responder's decision.\n\nLooking at the dataset variables, important ones for the responder's decision might include:\n\n- token_self and token_opp: These represent the contributions of the participant and the opponent to the shared pot. The combined_earning is the total money, which is 3*(token_self + token_opp). \n\n- split_self and split_opp: The proposed shares in \u00a3. For the responder, split_self is what they get if they accept. \n\n- trial_type: Indicates whether contributions are equal, opponent more, or participant more. This might affect fairness perceptions.\n\nBut since the model should use variables from the dataset, and trial_role is 1 for responder, we can filter trials where trial_role is 1.\n\nThe key psychological factors here are likely fairness considerations and self-interest. The responder's utility might depend on both their own monetary gain (split_self) and the fairness of the split relative to contributions.\n\nSo, the utility could be a function of the monetary offer (split_self) and some measure of fairness. Fairness might be calculated as the difference between the proposed split percentage (splitperc_self) and what would be considered a \"fair\" percentage based on contributions.\n\nWhat's a fair percentage? If contributions are based on tokens, then the fair split might be proportional to each person's contribution. For example, the participant's fair share would be (token_self / (token_self + token_opp)) * 100%. The proposed splitperc_self is given, so the difference between the proposed and fair percentage could be a measure of unfairness.\n\nLet me formalize this. The fair percentage for the participant is (token_self / (token_self + token_opp)) * 100. The proposed percentage is splitperc_self. The difference (splitperc_self - fair_percentage) would indicate how much more or less the participant is getting compared to their contribution. A positive difference means they're getting more than fair, negative means less.\n\nBut maybe participants have different sensitivities to this unfairness. Some might be more tolerant, others less. So, a parameter (like \u03b1) could represent the sensitivity to unfairness. Additionally, the monetary gain (split_self) would naturally influence utility. So, the utility could be a combination of split_self and the unfairness term.\n\nBut wait, the combined_earning is fixed per trial, so split_self is part of that. However, the absolute amount might matter. For example, getting \u00a35 in a \u00a310 pot vs. \u00a350 in a \u00a3100 pot\u2014same percentage but different absolute amounts. So, the model should consider both the absolute split and the fairness relative to contributions.\n\nAlternatively, the utility could be modeled as:\n\nUtility = \u03b2 * split_self + \u03b1 * (splitperc_self - fair_percentage)\n\nBut fair_percentage is (token_self / (token_self + token_opp)) * 100. So, splitperc_self - (token_self / (token_self + token_opp)*100) is the deviation from the contribution-based fair split.\n\nIf the participant cares about both their monetary gain and fairness, then these two terms would capture that. \u03b2 represents the sensitivity to monetary gain, \u03b1 the sensitivity to fairness. If \u03b1 is positive, then participants prefer offers that are more than their fair share; if negative, they might reject unfair offers even if it costs them (but in this case, since the responder's alternative to accepting is presumably getting nothing, maybe \u03b1 is positive, so they dislike being under their fair share).\n\nWait, but in the responder's case, if they reject, they might get nothing. So, the utility of rejecting is 0 (assuming), and the utility of accepting is the split_self plus any fairness considerations. But perhaps the fairness term is a disutility if the offer is below the fair share. So, the utility could be:\n\nUtility = split_self + \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nBut that complicates things. Alternatively, using the percentage difference:\n\nUtility = \u03b2 * split_self + \u03b1 * (splitperc_self - fair_percentage)\n\nBut split_self is in \u00a3, and fair_percentage is a percentage. Maybe scaling is an issue here. Alternatively, since split_self is 3 * token_self * (splitperc_self / 100), but maybe that's complicating.\n\nAlternatively, the fair amount in \u00a3 would be (token_self / (token_self + token_opp)) * combined_earning. Then, the difference between split_self and fair_amount could be the unfairness in monetary terms. So:\n\nfair_amount = (token_self / (token_self + token_opp)) * combined_earning\nunfairness = split_self - fair_amount\n\nThen, the utility could be:\n\nUtility = \u03b2 * split_self + \u03b1 * unfairness\n\nBut split_self is part of the unfairness term. Wait, that would be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - fair_amount)\n\nWhich simplifies to:\n\nUtility = (\u03b2 + \u03b1) * split_self - \u03b1 * fair_amount\n\nBut fair_amount is (token_self/(token_self + token_opp)) * combined_earning. Since combined_earning is 3*(token_self + token_opp), then fair_amount = 3 * token_self. Because combined_earning is 3*(tokens), so (token_self / (token_self + token_opp)) * 3*(token_self + token_opp) = 3*token_self. So fair_amount is 3*token_self. Therefore, split_self is the proposed amount, and the fair amount is 3*token_self. So the unfairness is split_self - 3*token_self.\n\nWait, that's interesting. Because if the participant contributed token_self tokens, each worth \u00a33, their contribution is 3*token_self. The fair split would be that they get their contribution back. But in the combined earning, which is 3*(token_self + token_opp), the proposer is offering split_self to the responder. So, if split_self is less than 3*token_self, the responder is getting less than their contribution. If it's more, they get more. So the unfairness could be split_self - 3*token_self. But maybe participants feel negative utility if split_self is less than their contribution (they're losing out), and positive if it's more.\n\nSo, the utility could be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self)\n\nBut this combines the monetary gain (split_self) with the difference between the offer and their contribution. Alternatively, maybe participants compare the offer to their contribution. If the offer is less than their contribution, they perceive it as unfair, leading to a disutility. If it's more, they might feel it's favorable.\n\nBut perhaps the model should have two parameters: one for the weight on the monetary gain (\u03b2) and another for the weight on the fairness term (\u03b1). The fairness term is (split_self - 3*token_self). So:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self)\n\nThis can be rewritten as:\n\nUtility = (\u03b2 + \u03b1) * split_self - 3*\u03b1 * token_self\n\nBut maybe this is redundant. Alternatively, perhaps the fairness term is (split_self - fair_share), where fair_share is 3*token_self. Then, the utility is:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - fair_share)\n\nWhich is the same as above. But perhaps participants have different sensitivities to gains versus fairness. For example, \u03b2 represents the utility per pound received, and \u03b1 represents the sensitivity to deviations from the fair share. If \u03b1 is positive, then getting more than fair share increases utility; if negative, getting less than fair share decreases utility. But in the responder's case, rejecting gives zero, so they might be particularly sensitive to offers below their fair share.\n\nAlternatively, maybe the fairness term is asymmetric. For example, participants might be more sensitive to offers below their fair share than above. But that would complicate the model with more parameters. Since the instruction says to have a slight bias towards fewer parameters, perhaps a linear term is better.\n\nAnother consideration is the alternative to accepting. If the responder rejects, they might get nothing. So the utility of rejecting is 0, and the utility of accepting is as calculated. The probability of accepting is then a logistic function of the utility. If utility > 0, the probability is >50%.\n\nWait, the problem states: \"Predict utility, where less than 0 is less than 50% likely.\" So the utility is passed through a logistic function to get the probability of acceptance. So the model's utility function should be such that when utility is negative, the probability is below 0.5.\n\nSo, the model needs to compute a utility value, and the probability of acceptance is 1 / (1 + exp(-Utility)).\n\nNow, considering the parameters. The model needs learnable parameters with finite bounds. Let's think about \u03b2 and \u03b1. But perhaps there's another parameter, like a baseline term. For example, even if the offer is zero, maybe there's a baseline tendency to accept or reject. But in the task, if they reject, they get nothing. So maybe the utility should be:\n\nUtility = \u03b2 * split_self + \u03b1 * (split_self - 3*token_self) + gamma\n\nBut gamma is a constant term. However, adding gamma might complicate parameter recovery. Alternatively, maybe gamma is not needed. Let's see.\n\nIf the offer is exactly equal to 3*token_self, then the fairness term is zero. The utility is \u03b2 * split_self. If split_self is 3*token_self, then the utility is \u03b2 * 3*token_self. Whether this is positive or negative depends on \u03b2. But \u03b2 is a learnable parameter. If \u03b2 is positive, higher split_self increases utility. But maybe participants have a baseline acceptance tendency beyond the split. Alternatively, maybe gamma is necessary to capture any bias towards accepting or rejecting regardless of the terms. For example, some participants might generally be more accepting, others more rejecting. So gamma would be an intercept term.\n\nSo, the utility could be:\n\nUtility = gamma + beta_split * split_self + alpha_fairness * (split_self - 3*token_self)\n\nBut this can be rewritten as:\n\nUtility = gamma + (beta_split + alpha_fairness) * split_self - 3*alpha_fairness * token_self\n\nAlternatively, combining terms:\n\nUtility = gamma + beta * split_self + alpha * (split_self - 3*token_self)\n\nBut this is the same as before. Alternatively, perhaps gamma is not needed, but given that when split_self is zero, the utility would be -3*alpha*token_self. But in reality, if split_self is zero, the responder would definitely reject. So the utility should be negative in that case. But maybe the model can capture that with the existing terms.\n\nAlternatively, including gamma allows for a baseline tendency. For example, even if split_self is zero, if gamma is positive enough, the utility could be positive. But that's unlikely. So perhaps gamma is necessary.\n\nBut adding more parameters increases the risk of overfitting and complicates parameter recovery. The instructions suggest a slight bias towards fewer parameters. So maybe start with two parameters: beta (sensitivity to monetary gain) and alpha (sensitivity to fairness). Or three parameters including gamma.\n\nAlternatively, perhaps the model should have:\n\nUtility = beta * (split_self - reference_point)\n\nWhere the reference point could be a function of the fair share. For example, reference_point = theta * 3*token_self. Then:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nHere, theta is a parameter that determines the reference point. If theta=1, the reference is the fair share. If theta <1, the reference is lower. This captures how much the participant expects relative to their contribution. Then, beta is the sensitivity to the difference between the offer and the reference.\n\nBut this would have two parameters: beta and theta. However, theta could be constrained between 0 and some upper limit. For example, if theta is 0, the reference is zero, so utility is just beta*split_self. If theta is 1, it's the fair share. If theta is 0.5, the reference is half the fair share.\n\nBut this might capture different types of participants: those who expect at least their fair share (theta=1), those who are okay with less (theta <1), or even those who are altruistic (theta <0, but that's unlikely). However, theta would need to be bounded. For example, theta could be between 0 and 2, allowing for some flexibility.\n\nThe utility would then be:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nIf beta is positive, higher offers increase utility. Theta determines the reference point. If the offer is above theta*3*token_self, utility is positive; below, negative. Then, the probability of acceptance is logistic(Utility). So when split_self > theta*3*token_self, utility is positive, leading to higher acceptance probability.\n\nThis model has two parameters: beta (sensitivity) and theta (reference point). But beta could be positive, as higher offers should increase utility. Theta could be constrained between 0 and, say, 2. This allows for participants who have a reference point up to twice their contribution.\n\nAlternatively, maybe theta is fixed at 1 (fair share), and beta is the only parameter. But that might be too restrictive. Including theta allows for individual differences in what is considered a fair reference.\n\nAnother approach is to model inequity aversion, where participants care about both their own payoff and the difference between their payoff and the opponent's. For example, in Fehr & Schmidt's model, utility is own payoff minus alpha times the difference if the other has more, and minus beta times the difference if self has more. But in this case, the opponent's payoff after split is split_opp, which is (combined_earning - split_self). So the responder's utility could be:\n\nUtility = split_self - alpha * max(split_opp - split_self, 0) - beta * max(split_self - split_opp, 0)\n\nBut this introduces two parameters, alpha and beta. However, the problem states that the model should predict responder behavior, and the dataset includes variables like split_opp. But in the responder's role, the proposer's split_opp is their own proposed share. Wait, when the participant is the responder, the proposer is the opponent. So in the responder's trial, split_opp is the amount the opponent proposed to keep for themselves, and split_self is what the responder would get. So the responder's own payoff is split_self, and the proposer's payoff is split_opp. So inequity aversion would compare split_self and split_opp.\n\nBut Fehr & Schmidt's model is:\n\nU_i = x_i - \u03b1 * max(x_j - x_i, 0) - \u03b2 * max(x_i - x_j, 0)\n\nWhere x_i is own payoff, x_j is other's payoff. \u03b1 and \u03b2 are parameters for disadvantageous and advantageous inequality aversion, respectively.\n\nIn this case, x_i = split_self, x_j = split_opp. So:\n\nUtility = split_self - \u03b1 * max(split_opp - split_self, 0) - \u03b2 * max(split_self - split_opp, 0)\n\nThis model has two parameters, \u03b1 and \u03b2. However, the problem states that the model should utilize the given variables appropriately. But split_opp is available in the dataset, so this is feasible.\n\nBut the original task also involves the contributions (token_self and token_opp). The Fehr & Schmidt model doesn't take contributions into account, only the final split. However, the fairness consideration in the original problem might be based on contributions, not just the final split. For example, if the proposer contributed less but is taking more, that might be seen as unfair.\n\nSo perhaps the model should combine both the Fehr-Schmidt inequity aversion and the contribution-based fairness. But that would add more parameters. Let's think.\n\nAlternatively, the fairness term could be based on the difference between the proposed split and the contribution-based fair split. As before, the fair split is 3*token_self for the responder. The proposed split_self may be more or less than this. So the difference (split_self - 3*token_self) could be a term in the utility, along with the inequity aversion terms.\n\nBut this might lead to a model with too many parameters. The instructions suggest a slight bias towards fewer parameters. Let's aim for 2-3 parameters.\n\nAnother angle: the utility could depend on the ratio of the proposed split to the fair split. For example, (split_self / (3*token_self)) - 1. If this is positive, the offer is more than fair; if negative, less. Then, the utility could be:\n\nUtility = beta * split_self + alpha * ((split_self / (3*token_self)) - 1)\n\nBut this introduces a non-linear term. Alternatively, using the ratio directly:\n\nUtility = beta * split_self + alpha * (split_self / (3*token_self))\n\nBut this might not capture the deviation from fairness linearly. Alternatively, log terms, but that complicates.\n\nAlternatively, the utility could be:\n\nUtility = beta * split_self + alpha * (split_self - 3*token_self) + gamma * (split_opp - 3*token_opp)\n\nHere, split_opp is the opponent's proposed share. The term (split_opp - 3*token_opp) represents how much the opponent is taking relative to their own contribution. If the opponent is taking more than their contribution, the responder might find this unfair. But this adds another parameter (gamma), making three parameters. However, the problem allows for learnable parameters as long as they are justified.\n\nBut perhaps the key factors are the responder's own monetary gain and the fairness relative to their contribution. The opponent's share might matter less, or be part of the inequity aversion. Alternatively, the combined earning is 3*(token_self + token_opp), so split_opp = combined_earning - split_self. So split_opp is determined once split_self is known. Therefore, including split_opp might be redundant if combined_earning is known. But in the dataset, split_opp is a separate variable.\n\nBut given that combined_earning is 3*(token_self + token_opp), split_opp = combined_earning - split_self. So perhaps it's better to model based on split_self and the contributions, rather than split_opp.\n\nPutting this all together, perhaps the best approach is to model utility as a function of the responder's monetary gain (split_self) and the deviation from their fair share (split_self - 3*token_self). This captures both self-interest and contribution-based fairness. Additionally, including a term for the proposer's share relative to their contribution might add another layer, but that could complicate the model.\n\nSo, the model would have:\n\nUtility = beta * split_self + alpha * (split_self - 3*token_self)\n\nThis can be simplified to:\n\nUtility = (beta + alpha) * split_self - 3*alpha * token_self\n\nBut this combines the two parameters into a linear combination. However, beta and alpha are separate parameters, allowing the model to capture different sensitivities to absolute monetary gain versus fairness.\n\nAlternatively, to avoid redundancy, perhaps one parameter is sufficient. For example:\n\nUtility = beta * (split_self - theta * 3*token_self)\n\nHere, theta represents the proportion of their contribution that the responder expects. If theta=1, they expect exactly their contribution. If theta=0.8, they are willing to accept 80% of their contribution. Beta is the sensitivity to the difference between the offer and theta times their contribution.\n\nThis model has two parameters: beta (sensitivity) and theta (reference proportion). Theta can be bounded between 0 and, say, 2, allowing for participants who are either very tolerant (theta <1) or demand more than their contribution (theta >1).\n\nAnother consideration is the intercept. If the utility is zero when split_self equals theta*3*token_self, then the probability of acceptance is 50% at that point. If the offer is higher, the probability increases; lower, decreases. This seems reasonable.\n\nSo, the model would be:\n\nUtility = beta * (split_self - theta * 3 * token_self)\n\nBeta is a scaling parameter, and theta is the reference proportion. Both are learnable parameters. Beta should be positive, as higher offers should increase utility. Theta can be constrained between 0 and 2, for example.\n\nThis model has two parameters, which is manageable for parameter recovery. The variables used are split_self and token_self, which are available in the dataset. The combined_earning is 3*(token_self + token_opp), but we don't need to include it directly since split_self is already provided.\n\nNow, considering the probability of acceptance. The utility is passed through a logistic function:\n\nP(accept=1) = 1 / (1 + exp(-Utility))\n\nIf Utility > 0, the probability is >50%; if <0, <50%. This aligns with the requirement that utility <0 corresponds to less than 50% likelihood.\n\nNow, the parameters beta and theta need to be defined with their ranges. Beta should be positive, as a higher offer should increase utility. Theta is the reference proportion, so it's reasonable to bound it between 0 and 2. For example, a participant with theta=0.5 would accept offers that are at least half of their contribution. Theta=1 is the fair share, theta=1.5 means they demand 1.5 times their contribution.\n\nSo, the variables in the model are:\n\n- beta: sensitivity parameter, positive, range [0.01, 10] (to avoid zero and allow reasonable scaling)\n- theta: reference proportion, range [0, 2]\n\nBut the bounds should be generous. For beta, maybe [0, 20], but with a lower bound of 0 (since negative beta would invert the effect). Theta could be [0, 3], but 0 to 2 is probably sufficient.\n\nWait, but beta can't be negative, because that would mean higher offers decrease utility, which doesn't make sense. So beta must be positive. Therefore, beta's range is [0, ...], but to have a finite upper bound, maybe [0, 10] or [0, 20]. Similarly, theta's range is [0, 2], inclusive.\n\nNow, the mathematical model:\n\nUtility = beta * (split_self - theta * 3 * token_self)\n\nVariables used:\n\n- split_self (from data)\n- token_self (from data)\n\nParameters:\n\n- beta (learnable, range [0, 10])\n- theta (learnable, range [0, 2])\n\nThis model uses two parameters, which is manageable. It captures the idea that participants compare the offer to a reference point (theta times their contribution) and have a sensitivity (beta) to the difference. The utility directly influences the probability of acceptance via the logistic function.\n\nAnother possible addition is a term for the proposer's share relative to their contribution. For example, the proposer's split_opp is their proposed share. The fair share for the proposer is 3*token_opp. So, the proposer's over/under share is (split_opp - 3*token_opp). The responder might care not only about their own fairness but also the proposer's. For example, if the proposer is taking more than their fair share, the responder might be more likely to reject. This would add another term:\n\nUtility = beta*(split_self - theta*3*token_self) + gamma*(split_opp - 3*token_opp)\n\nBut this introduces another parameter (gamma), making three parameters. However, this might improve the model's accuracy but complicate parameter recovery. Given the instruction to have a slight bias towards fewer parameters, maybe stick with two parameters.\n\nAlternatively, the proposer's fairness could be incorporated into the theta term. But that's not straightforward. \n\nAlternatively, the model could include a term for the ratio of the proposer's share to their contribution. For example:\n\nUtility = beta*(split_self - theta*3*token_self) + gamma*(split_opp/(3*token_opp) - 1)\n\nBut this adds gamma as a parameter. However, this might capture the responder's aversion to the proposer's unfairness. But again, more parameters.\n\nGiven the trade-off between model complexity and parameter recovery, starting with two parameters (beta and theta) seems reasonable.\n\nNow, checking if the model meets the requirements:\n\n1. Predicts responder behavior (accept) using the given variables. The model uses split_self and token_self, which are available when trial_role is responder.\n\n2. Applicable to the dataset: Yes, as the variables are present.\n\n3. Utility <0 corresponds to <50% probability. Yes, because of the logistic function.\n\nLearnable parameters: beta and theta, with specified bounds.\n\nNow, formalizing the model:\n\n<MODEL>\nUtility = beta * (split_self - theta * 3 * token_self)\n</MODEL>\n\nVariables:\n\n- beta: learnable, range [0, 10] (inclusive)\n- theta: learnable, range [0, 2] (inclusive)\n- split_self: from data\n- token_self: from data\n\nThe variable descriptions in JSON:\n\nFor beta:\n- description: Sensitivity to the difference between the offer and the reference amount.\n- range: min 0, max 10, inclusive both.\n- learnable: true\n- source: learnable\n\nFor theta:\n- description: Reference proportion of the participant's contribution (3*token_self) that they expect.\n- range: min 0, max 2, inclusive both.\n- learnable: true\n- source: learnable\n\nsplit_self and token_self are data variables.\n\nAdditionally, the utility variable is calculated.\n\nSo the JSON would look like:\n\n{\n  \"variables\": {\n    \"beta\": {\n      \"description\": \"Sensitivity to the difference between the offer and the reference amount\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Reference proportion of the participant's contribution (3*token_self) they expect as fair\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"Utility\": {\n      \"description\": \"Calculated utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n\nThe target variable is \"accept\".\n\nSummary: The model assumes that responders evaluate offers based on both the absolute monetary value and a reference point derived from their contribution. The reference point is a proportion (theta) of their contribution's value, and the utility is the sensitivity (beta) weighted difference between the offer and this reference. This captures self-interest and contribution-based fairness considerations, with two learnable parameters for parsimony and recoverability.\n</think>\n\n<MODEL>\nUtility = beta * (split_self - theta * 3 * token_self)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"beta\": {\n      \"description\": \"Sensitivity to the difference between the offer and the reference amount\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Reference proportion of the participant's contribution (3*token_self) they expect as fair\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 2,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"Utility\": {\n      \"description\": \"Calculated utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA utility model where responders evaluate offers relative to a reference point based on their contribution. Utility increases with higher monetary offers (split_self) and decreases when offers fall below a proportion (theta) of their contribution's value (3*token_self). Two learnable parameters (beta, theta) balance parsimony and interpretability, capturing sensitivity to monetary gains and fairness expectations.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: Utility = beta * (split_self - theta * 3 * token_self)\nSummary: A utility model where responders evaluate offers relative to a reference point based on their contribution. Utility increases with higher monetary offers (split_self) and decreases when offers fall below a proportion (theta) of their contribution's value (3*token_self). Two learnable parameters (beta, theta) balance parsimony and interpretability, capturing sensitivity to monetary gains and fairness expectations.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, beta=1, theta=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        utility = beta * (split_self - theta * 3 * token_self)\n        model_predictions.append(utility)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.7735042735042734,
  "fitting_results": [
    {
      "beta": 7.457860655311858,
      "theta": 1.301890823019217,
      "success": true,
      "log_likelihood": -46.05170185660667,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14441855730957817,
      "theta": 0.6008806252205516,
      "success": true,
      "log_likelihood": -16.185000307301205,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.302470595292035,
      "theta": 0.5895044127638827,
      "success": true,
      "log_likelihood": -10.035792650354765,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.19003517675253886,
      "theta": 0.63583084978445,
      "success": true,
      "log_likelihood": -13.578819671399682,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.2909247936089887,
      "theta": 0.6565702552216067,
      "success": true,
      "log_likelihood": -9.819975863426409,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 8.546624649819146,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -299.33606208692606,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.826643445789875,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.24179593063397462,
      "theta": 0.5026118394404776,
      "success": true,
      "log_likelihood": -11.086287519434666,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.6154894039264724,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.23538572361112586,
      "theta": 0.6812204389995122,
      "success": true,
      "log_likelihood": -11.098965124694859,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.6166742848061285,
      "success": true,
      "log_likelihood": -0.020191641793644736,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 8.158666867279463,
      "theta": 0.6796221972611531,
      "success": true,
      "log_likelihood": -23.026017914069342,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 9.837045454407138,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.614776033471365,
      "theta": 0.04857132745789411,
      "success": true,
      "log_likelihood": -5.002636628967003e-07,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.057126249380251,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 2.5399227684930916,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.599884390401579e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.6492076394473584,
      "theta": 0.3240451588507195,
      "success": true,
      "log_likelihood": -2.7461713738568756,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.2545091665260624,
      "theta": 0.2988583755192539,
      "success": true,
      "log_likelihood": -6.649222401249659,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.239037332386334,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.16385889211200433,
      "theta": 0.5805635201596495,
      "success": true,
      "log_likelihood": -15.173720830940557,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.23239969429199844,
      "theta": 0.32396612141299636,
      "success": true,
      "log_likelihood": -7.937681433175445,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -24.95329849295801,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1330760421739787,
      "theta": 0.5602817446744336,
      "success": true,
      "log_likelihood": -16.90654053583106,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.18369812127988455,
      "theta": 0.6365205969907034,
      "success": true,
      "log_likelihood": -13.859066460399978,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.16612000562541607,
      "theta": 0.5332235899794113,
      "success": true,
      "log_likelihood": -14.849334653664057,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.2444617901978793,
      "theta": 0.556041037404742,
      "success": true,
      "log_likelihood": -11.605490343041343,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.6604843696999427,
      "theta": 0.7756853271402105,
      "success": true,
      "log_likelihood": -3.9308899680990113,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1618111116022535,
      "theta": 0.2657766364573804,
      "success": true,
      "log_likelihood": -9.356513244539272,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.10635882317808462,
      "theta": 0.3609280013530487,
      "success": true,
      "log_likelihood": -15.866696222437879,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 8.028361554318002,
      "theta": 0.006270259285658941,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14848548316565235,
      "theta": 1.054504013852084,
      "success": true,
      "log_likelihood": -7.832009869180599,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.07278578320713988,
      "theta": 0.6443092965022575,
      "success": true,
      "log_likelihood": -20.860634350756065,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1461666041311601,
      "theta": 0.6755927799947723,
      "success": true,
      "log_likelihood": -15.260151513075053,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.214338291643594,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.17351065693458398,
      "theta": 0.45421950255054394,
      "success": true,
      "log_likelihood": -13.342189489081257,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.39214516764571483,
      "theta": 0.4700699645959706,
      "success": true,
      "log_likelihood": -7.00886677941371,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.18138682670057918,
      "theta": 0.617530776320019,
      "success": true,
      "log_likelihood": -14.154610524327904,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.11223322972723714,
      "theta": 0.47978626129458685,
      "success": true,
      "log_likelihood": -17.651202720368378,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.11112701988411966,
      "theta": 0.14411254266968973,
      "success": true,
      "log_likelihood": -9.535871202974729,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1199861379952822,
      "theta": 0.537940339264825,
      "success": true,
      "log_likelihood": -17.659856709666474,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.8841008665933122,
      "success": true,
      "log_likelihood": -46.07708014333748,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.09348713901756418,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -7.745036530259174,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14542250716576446,
      "theta": 0.5409117713820363,
      "success": true,
      "log_likelihood": -16.075393783151302,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.19497817520314958,
      "theta": 0.5172385540937198,
      "success": true,
      "log_likelihood": -13.231795131932238,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1089149635536054,
      "theta": 0.3633974951607071,
      "success": true,
      "log_likelihood": -15.705250878917138,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.16385876158719748,
      "theta": 0.5805635406425687,
      "success": true,
      "log_likelihood": -15.173720833620669,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.09548351208121186,
      "theta": 0.6721639408130301,
      "success": true,
      "log_likelihood": -18.788232117353346,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.22666013493139325,
      "theta": 0.6934792503539112,
      "success": true,
      "log_likelihood": -11.187166322909809,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.496258118814672,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -391.43946580708797,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.10275839450165172,
      "theta": 0.4124435875996845,
      "success": true,
      "log_likelihood": -17.285312600725522,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.906118162460775,
      "theta": 1.4603241686495674,
      "success": true,
      "log_likelihood": -92.10348557695725,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.10057988448378995,
      "theta": 0.5321604447530659,
      "success": true,
      "log_likelihood": -18.98060231578224,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.053532737345512366,
      "theta": 0.4072281933449272,
      "success": true,
      "log_likelihood": -21.69773362545506,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.08266464286343825,
      "theta": 0.7423631237187397,
      "success": true,
      "log_likelihood": -18.864729915864885,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.6618675372452768,
      "theta": 0.712884053324562,
      "success": true,
      "log_likelihood": -4.333388289659982,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.2107955912258982,
      "theta": 0.7794466808873742,
      "success": true,
      "log_likelihood": -10.188636962026106,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.312741073133846,
      "theta": 0.8749533580647701,
      "success": true,
      "log_likelihood": -577.0284546252367,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.2777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.12688797795477985,
      "theta": 1.0165480274083114,
      "success": true,
      "log_likelihood": -9.764375053422613,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.09458341379217347,
      "theta": 0.24566216531746746,
      "success": true,
      "log_likelihood": -14.041447828690972,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.08766561047117544,
      "theta": 0.49310959097000756,
      "success": true,
      "log_likelihood": -19.669605909577314,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1703268679414213,
      "theta": 0.618453170978195,
      "success": true,
      "log_likelihood": -14.681843501018205,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14848298187318587,
      "theta": 1.0545051072588199,
      "success": true,
      "log_likelihood": -7.832009869925781,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.07948276331613768,
      "theta": 0.6119957554961803,
      "success": true,
      "log_likelihood": -20.530303294124035,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.17725214289112495,
      "theta": 0.8242100199021244,
      "success": true,
      "log_likelihood": -10.75514638265369,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1764712487771551,
      "theta": 0.5435689593842838,
      "success": true,
      "log_likelihood": -14.395054273309995,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14228928103217248,
      "theta": 0.18985017849703184,
      "success": true,
      "log_likelihood": -8.403241118639853,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 9.41160251435552,
      "theta": 1.081425336391239,
      "success": true,
      "log_likelihood": -667.7496769674648,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.19444444444444445,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14261156022177482,
      "theta": 0.510093842614467,
      "success": true,
      "log_likelihood": -15.975401361157713,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.853977216910896,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -69.07755278652137,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 5.441124376674103,
      "theta": 0.966603974399188,
      "success": true,
      "log_likelihood": -5.644718307264452e-05,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.766781796776911,
      "theta": 1.3455129767083354,
      "success": true,
      "log_likelihood": -92.10412856825866,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1569429660317836,
      "theta": 0.5709614359576604,
      "success": true,
      "log_likelihood": -15.53835581750969,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.09810738596145571,
      "theta": 0.28812287728947983,
      "success": true,
      "log_likelihood": -14.807708480990138,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.04822500288525636,
      "theta": 0.5712712233701127,
      "success": true,
      "log_likelihood": -22.949124661688217,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.17871400975416007,
      "theta": 0.47601063842699853,
      "success": true,
      "log_likelihood": -13.445532730281167,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.11426039598569057,
      "theta": 0.0900698311196688,
      "success": true,
      "log_likelihood": -7.799478452861279,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.048567093231379733,
      "theta": 1.6943541216090452,
      "success": true,
      "log_likelihood": -8.322814655205603,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.040913987457445344,
      "theta": 0.3443985115918012,
      "success": true,
      "log_likelihood": -22.304590078313538,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.538642549785759,
      "theta": 1.349087177440346,
      "success": true,
      "log_likelihood": -46.05367062123568,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.05210375452102332,
      "theta": 0.5528100974871725,
      "success": true,
      "log_likelihood": -22.665935966972043,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.06669463172892985,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -11.741860654221094,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.08247689002394645,
      "theta": 1.1150704953969792,
      "success": true,
      "log_likelihood": -11.459594183262087,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.28690605015013626,
      "theta": 0.565678495804289,
      "success": true,
      "log_likelihood": -10.329254822056358,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.00013580504069370374,
      "theta": 0.8710230657525244,
      "success": true,
      "log_likelihood": -24.953250427280345,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.7656056025430744,
      "theta": 0.9986202832374456,
      "success": true,
      "log_likelihood": -24.373425100600308,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.10067821992675165,
      "theta": 0.4368709023619334,
      "success": true,
      "log_likelihood": -17.897569580185852,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0978373321550533,
      "theta": 0.905737505051048,
      "success": true,
      "log_likelihood": -14.260850278434914,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.1887257224808493,
      "theta": 0.17877273247591138,
      "success": true,
      "log_likelihood": -5.816782397566231,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.17389421948190745,
      "theta": 0.5620063874216412,
      "success": true,
      "log_likelihood": -14.62859522634119,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.05253848004368612,
      "theta": 0.32572180215033036,
      "success": true,
      "log_likelihood": -20.77331515642588,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "beta": {
        "r": 0.005903246065342106,
        "p": 0.9535170147875761
      },
      "theta": {
        "r": 0.9449746127636126,
        "p": 2.364042080078241e-49
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 80.20745921390393,
  "bic_results": {
    "average_bic": 80.20745921390393,
    "individual_bics": [
      99.27044159012556,
      39.53703849151463,
      27.238623177621747,
      34.32467721971158,
      26.80698960376504,
      605.8391620507643,
      7.167037869712219,
      29.33961291578155,
      7.167037869712219,
      29.36496812630194,
      7.207421160499509,
      57.073634862828236,
      53.2190737050509,
      7.167037869712219,
      7.167038877439546,
      7.167037869712219,
      7.167037869712451,
      12.659380624625971,
      20.465482679411537,
      7.167037869712219,
      37.51447953879333,
      23.04240074326311,
      57.073634862828236,
      40.98011894857434,
      34.88517079771218,
      36.865707184240335,
      30.378018562994903,
      15.028817813110242,
      25.880064365990762,
      38.90043032178798,
      7.167037869712219,
      22.831057615273416,
      48.88830657842435,
      37.68734090306233,
      7.167037869712219,
      33.85141685507473,
      21.18477143573964,
      35.476258925568025,
      42.469443317648974,
      26.238780282861676,
      42.48675129624517,
      99.32119816358718,
      22.657110937430566,
      39.31782544321482,
      33.63062814077669,
      38.57753963474649,
      37.51447954415356,
      44.74350211161891,
      29.54137052273184,
      790.0459694910882,
      41.73766307836326,
      191.37400903082673,
      45.128242508476696,
      50.56250512782234,
      44.89649770864199,
      15.833814456232183,
      27.54431180096443,
      1161.2239471273856,
      26.695787983757448,
      35.249933534294165,
      46.506249696066845,
      36.53072487894863,
      22.831057616763783,
      48.22764446516029,
      28.6773306422196,
      35.95714642353221,
      23.973520114191928,
      1342.6663918118418,
      39.11784059922765,
      145.32214344995495,
      7.167150771278365,
      191.37529501342954,
      38.2437495119316,
      36.7824548388925,
      53.06528720028865,
      34.058103337474556,
      22.765994782634777,
      23.812667187323427,
      51.776218033539294,
      99.27437911938358,
      52.498909810856304,
      30.65075918535441,
      30.086226243436393,
      27.825547521024937,
      57.07353873147291,
      55.913888078112834,
      42.96217703728392,
      35.68873843378205,
      18.800602672044683,
      36.4242283295946,
      48.71366818976398
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 2,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- beta: r = 0.006\n- theta: r = 0.945",
  "previous_models": [
    "Specification: Utility = beta * (split_self - theta * 3 * token_self)\nSummary: A utility model where responders evaluate offers relative to a reference point based on their contribution. Utility increases with higher monetary offers (split_self) and decreases when offers fall below a proportion (theta) of their contribution's value (3*token_self). Two learnable parameters (beta, theta) balance parsimony and interpretability, capturing sensitivity to monetary gains and fairness expectations.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 80.20745921390393\nOverall Accuracy: 0.7735\n\nParameter Recovery:\n- beta: r = 0.006\n- theta: r = 0.945"
  ]
}