run_number,average_bic,bic_control,bic_cocaine,overall_accuracy,model_specification,model_summary,version,instructions_used,alpha_fairness_recovery,alpha_type_recovery,alpha_gain_recovery
1,148.922123578306,,,0.5577403245942572,"U = α_fairness * (split_self / combined_earning) * (1 + α_type * (trial_type - 1.5)) +  α_gain * (split_self / combined_earning) +  ϵ
P(accept = 1) = 1 / (1 + exp(-U))","A logistic regression model predicting responder acceptance. Utility is a weighted sum of fairness (participant share relative to combined earnings, modulated by trial type) and relative gain (participant share relative to combined earnings), plus normally distributed noise. Three learnable parameters determine the weights of these components.",v12,"Be VERY considerate of high covariance between learnable parameters as the model. Have an appropriate number or learnable parameters, with a slight bias for less learnable paramters.

First, reason step by step about:
* The key psychological mechanisms involved
* How these mechanisms interact
* What mathematical form could capture these interactions
* What parameters would be needed to calibrate the model
* How the model variables map to observable behavior",-0.11721470042277106,0.058810395599264285,-0.10267269676885428
2,,,,,logit(P(accept = 1)) = β₀ + β₁ (split_self / combined_earning - 0.5) + β₂ (split_self) + β₃ trial_type + β₄ (token_self - token_opp) + β₅ (split_self / combined_earning - 0.5) * trial_type + β₆ (split_self / combined_earning - 0.5)² + β₇ (split_self)² + β₈ (token_self - token_opp)² + λ (Regularization Term),"A logit model predicting responder acceptance in a bargaining game.  The model incorporates fairness (relative gain), absolute gain, trial type, token difference, and their interactions and quadratic terms,  with L2 regularization to control complexity.  Fairness is defined as the deviation from a 50% split.",v12,"<think>The previous model had low parameter recovery and accuracy.  The BIC wasn't terrible, but could be improved. The model structure was relatively simple, focusing on fairness and gain, but the interaction between them wasn't well captured. The parameter recovery suggests that the parameters are not well-identified and potentially highly correlated. Let's try to address this by encouraging more complex, yet still interpretable models. We'll explicitly suggest considering interaction terms and potentially adding other relevant variables that may improve accuracy.</think>

Explore more complex models that incorporate interactions between variables and the inclusion of additional variables. Consider interaction effects between fairness, gain, and trial type.  For example, the effect of fairness might be different depending on the trial type.   Explore transformations of variables to see if they improve model fit and interpretability (e.g., logarithmic or power transformations).  Consider non-linear models, but ensure the chosen model remains interpretable and does not suffer from overfitting.

Specifically consider:

* **Interaction terms:** Include multiplicative terms to capture interactions between  `split_self/combined_earning`, `trial_type`, and potentially other variables like `token_self` and `token_opp`.
* **Non-linear relationships:** Explore the possibility that the relationship between variables and utility isn't purely linear. Consider using polynomial terms or other non-linear functions.
* **Additional variables:**  Explore adding other variables from the dataset to increase the model accuracy.  Consider including variables measuring the perceived fairness from the perspective of the participant and opponant.
* **Regularization:**  Consider using regularization techniques (L1 or L2) to help to penalize complex models and reduce overfitting, improving generalization.
* **Model Selection:**  Explore several different models and compare them using AIC or BIC to ensure the selection of the most parsimonious model that fits the data.

Focus on achieving better parameter recovery.  This is crucial for understanding the model's meaning. While accuracy is important, a model with high accuracy but poor parameter recovery is less useful.  Clearly define the ranges of all parameters within the variable descriptions, to allow for more stable estimation.

Reason step by step about:
* The key psychological mechanisms involved, and how uncertainty might influence choices
* How these mechanisms interact, and whether these interactions are additive or multiplicative
* What mathematical form could best capture these complex interactions (including non-linear forms)
* What parameters would be needed to calibrate the model, and how many are truly necessary
* How the model variables map to observable behavior, with special attention to potential biases and uncertainties.
* How to avoid overfitting and maintain interpretability.

Prioritize interpretability. While complexity can improve fit, the resulting model must remain understandable and insightful.",,,
2,,,,,Error: unsupported format string passed to NoneType.__format__,,v12,,,,
3,,,,,"P(accept) = 1 / (1 + exp(-U))

U = α + β1*(split_self/combined_earning) + β2*(token_self/(token_self + token_opp)) + β3*trial_type + β4*(split_self/combined_earning)*trial_type + β5*((token_self/(token_self + token_opp))*trial_type) + β6*(split_self/combined_earning)^2 + β7*(token_self/(token_self+token_opp))^2 + λ*L2_regularization","A logistic regression model predicting acceptance of a proposal.  Utility is a function of the proportion of earnings received, the ratio of participant to total tokens, trial type, and their interactions. Quadratic terms capture non-linear effects.  L2 regularization prevents overfitting.",v12,"<think>The previous model had low parameter recovery and accuracy.  The BIC wasn't terrible, but could be improved. The model structure was relatively simple, focusing on fairness and gain, but the interaction between them wasn't well captured. The parameter recovery suggests that the parameters are not well-identified and potentially highly correlated. Let's try to address this by encouraging more complex, yet still interpretable models. We'll explicitly suggest considering interaction terms and potentially adding other relevant variables that may improve accuracy.</think>

Explore more complex models that incorporate interactions between variables and the inclusion of additional variables. Consider interaction effects between fairness, gain, and trial type.  For example, the effect of fairness might be different depending on the trial type.   Explore transformations of variables to see if they improve model fit and interpretability (e.g., logarithmic or power transformations).  Consider non-linear models, but ensure the chosen model remains interpretable and does not suffer from overfitting.

Specifically consider:

* **Interaction terms:** Include multiplicative terms to capture interactions between  `split_self/combined_earning`, `trial_type`, and potentially other variables like `token_self` and `token_opp`.
* **Non-linear relationships:** Explore the possibility that the relationship between variables and utility isn't purely linear. Consider using polynomial terms or other non-linear functions.
* **Additional variables:**  Explore adding other variables from the dataset to increase the model accuracy.  Consider including variables measuring the perceived fairness from the perspective of the participant and opponant.
* **Regularization:**  Consider using regularization techniques (L1 or L2) to help to penalize complex models and reduce overfitting, improving generalization.
* **Model Selection:**  Explore several different models and compare them using AIC or BIC to ensure the selection of the most parsimonious model that fits the data.

Focus on achieving better parameter recovery.  This is crucial for understanding the model's meaning. While accuracy is important, a model with high accuracy but poor parameter recovery is less useful.  Clearly define the ranges of all parameters within the variable descriptions, to allow for more stable estimation.

Reason step by step about:
* The key psychological mechanisms involved, and how uncertainty might influence choices
* How these mechanisms interact, and whether these interactions are additive or multiplicative
* What mathematical form could best capture these complex interactions (including non-linear forms)
* What parameters would be needed to calibrate the model, and how many are truly necessary
* How the model variables map to observable behavior, with special attention to potential biases and uncertainties.
* How to avoid overfitting and maintain interpretability.

Prioritize interpretability. While complexity can improve fit, the resulting model must remain understandable and insightful.",,,
