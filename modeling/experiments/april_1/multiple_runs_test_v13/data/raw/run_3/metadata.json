{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nOkay, let's analyze the previous results. The second model had a higher BIC (164.39) compared to the first (124.65), which is worse. The accuracy slightly dropped to 0.844. The parameter recovery for theta was really low at 0.507, which is a problem. So the main issues are the increased BIC and poor theta recovery.\n\nThe previous instructions suggested nonlinear penalties, contextual modulation, etc., but the second model didn't implement those. Maybe the model needs to enforce more distinct roles for parameters. Theta's low recovery suggests it's not being well-identified in the data. Perhaps the penalty term isn't capturing enough variance or is confounded with beta.\n\nTo improve theta's recovery, the model needs a component that theta uniquely influences. Maybe introducing a nonlinearity in the penalty term, like squaring the deficit, would make theta's effect more pronounced when offers are very unfair. Alternatively, using a piecewise function where theta has different effects based on the deficit's magnitude.\n\nAnother angle: the current model uses split_self directly. Maybe participants evaluate fairness relative to both their own and the opponent's contributions. For example, the fair share could be (3 * token_self) / (3 * (token_self + token_opp)) * combined_earning. But combined_earning is 3*(token_self + token_opp), so that simplifies to split_self should be 3*token_self. Wait, that's what's already used. Hmm.\n\nAlternatively, participants might compare their split to the opponent's split. If split_opp is much higher, they might feel unfair. But in the responder role, split_opp is determined by the proposer. Including split_opp in the model could add another term, like theta_opp * split_opp, but that adds a parameter. However, maybe a ratio of split_self to split_opp could capture relative fairness without adding parameters if combined with existing terms.\n\nAnother idea: use the percentage split (split_perc_self) instead of absolute values. The fair percentage would be (token_self / (token_self + token_opp)) * 100. The deficit could be the difference between split_perc_self and this fair percentage. This might align better with how participants perceive fairness.\n\nAlso, trial_type indicates whether contributions are equal, which might affect sensitivity. For trial_type=3 (participant contributed more), theta could be higher. Adding an interaction term between trial_type and the penalty could help. For example, theta * (3*token_self - split_self) * (trial_type == 3). This would introduce a new parameter for the interaction, but maybe improves theta's identifiability.\n\nTo keep the number of parameters low, maybe use a single additional parameter for the interaction. Alternatively, allow theta to vary by trial_type with separate parameters. But that increases the parameter count, which could affect BIC. However, if the fit improves significantly, the BIC might still be better.\n\nAnother approach: model the utility as split_self minus a nonlinear function of the deficit. For example, using a quadratic term: theta * (max(3*token_self - split_self, 0))^2. This would make the penalty increase more steeply for larger deficits, which might better capture strong aversion to very unfair offers. This could help theta's recovery because the effect becomes more distinct in cases of large deficits.\n\nAdditionally, the baseline beta might be influenced by the total combined earnings. For example, in higher stakes (larger combined_earning), participants might be more cautious. Adding an interaction between beta and combined_earning could model this, but again adds a parameter. Alternatively, scale split_self by combined_earning to make the utility relative to the total amount.\n\nIn summary, the revised instructions should encourage:\n\n1. Nonlinear transformations of the fairness penalty (e.g., quadratic).\n2. Interaction terms between trial_type and the penalty.\n3. Relative fairness measures (percentage-based or ratio-based).\n4. Ensuring parameters have distinct roles to improve recovery.\n5. Keeping the number of parameters \u22643 to balance model complexity.\n\nThe goal is to make theta's effect more pronounced and distinct from beta, thereby improving its recovery while maintaining or reducing BIC.\n</think>\n\n**Instructions for Run 2/3:**  \n**Core Objective:** *Radically differentiate parameter roles* while maintaining \u22643 parameters. Target theta recovery through **mechanistic specialization** and **nonlinear fairness encoding**.  \n\n1. **Dynamic Fairness Scaling:**  \n   - Replace linear penalties with **curvilinear responses** (e.g., `theta * (fairness_deficit)^\u03b3` where \u03b3 is either fixed [1.5-2.5] or learnable).  \n   - Test **asymmetric sensitivity** (steeper penalties for deficits >\u00a35 vs. small inequities).  \n\n2. **Contribution-Contextualized Utility:**  \n   - Encode fairness relative to *both* players' contributions:  \n     `fair_share = (3*token_self) / (3*(token_self + token_opp)) * combined_earning`  \n   - Penalize deviations from this proportionally weighted value rather than absolute \u00a3 amounts.  \n\n3. **Trial-Type Gating:**  \n   - Implement **conditional fairness thresholds** using `trial_type`:  \n     - If `trial_type=3` (participant contributed more), use stricter fairness criteria (e.g., 4*token_self vs. 3*token_self).  \n     - Gate penalty activation with trial-type modifiers (e.g., `theta * [condition] * deficit`).  \n\n4. **Monetary Utility Saturation:**  \n   - Apply **diminishing returns** to `split_self` (e.g., `log(split_self + 1)` or `sqrt(split_self)`) to capture sublinear value scaling.  \n\n5. **Parameter Orthogonality Enforcement:**  \n   - Assign `beta` to handle **context-independent biases** (e.g., default rejection tendencies)  \n   - Reserve `theta` exclusively for **context-modulated fairness violations** (e.g., interacting with trial_type or contribution ratios)  \n\n**Forbidden:** Simple linear deficit terms. Prioritize models where beta and theta cannot be swapped without breaking interpretability.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function, and then used to predict binary decisions.\n\n\nInstructions: <think>\nOkay, let's analyze the previous results. The second model had a higher BIC (164.39) compared to the first (124.65), which is worse. The accuracy slightly dropped to 0.844. The parameter recovery for theta was really low at 0.507, which is a problem. So the main issues are the increased BIC and poor theta recovery.\n\nThe previous instructions suggested nonlinear penalties, contextual modulation, etc., but the second model didn't implement those. Maybe the model needs to enforce more distinct roles for parameters. Theta's low recovery suggests it's not being well-identified in the data. Perhaps the penalty term isn't capturing enough variance or is confounded with beta.\n\nTo improve theta's recovery, the model needs a component that theta uniquely influences. Maybe introducing a nonlinearity in the penalty term, like squaring the deficit, would make theta's effect more pronounced when offers are very unfair. Alternatively, using a piecewise function where theta has different effects based on the deficit's magnitude.\n\nAnother angle: the current model uses split_self directly. Maybe participants evaluate fairness relative to both their own and the opponent's contributions. For example, the fair share could be (3 * token_self) / (3 * (token_self + token_opp)) * combined_earning. But combined_earning is 3*(token_self + token_opp), so that simplifies to split_self should be 3*token_self. Wait, that's what's already used. Hmm.\n\nAlternatively, participants might compare their split to the opponent's split. If split_opp is much higher, they might feel unfair. But in the responder role, split_opp is determined by the proposer. Including split_opp in the model could add another term, like theta_opp * split_opp, but that adds a parameter. However, maybe a ratio of split_self to split_opp could capture relative fairness without adding parameters if combined with existing terms.\n\nAnother idea: use the percentage split (split_perc_self) instead of absolute values. The fair percentage would be (token_self / (token_self + token_opp)) * 100. The deficit could be the difference between split_perc_self and this fair percentage. This might align better with how participants perceive fairness.\n\nAlso, trial_type indicates whether contributions are equal, which might affect sensitivity. For trial_type=3 (participant contributed more), theta could be higher. Adding an interaction term between trial_type and the penalty could help. For example, theta * (3*token_self - split_self) * (trial_type == 3). This would introduce a new parameter for the interaction, but maybe improves theta's identifiability.\n\nTo keep the number of parameters low, maybe use a single additional parameter for the interaction. Alternatively, allow theta to vary by trial_type with separate parameters. But that increases the parameter count, which could affect BIC. However, if the fit improves significantly, the BIC might still be better.\n\nAnother approach: model the utility as split_self minus a nonlinear function of the deficit. For example, using a quadratic term: theta * (max(3*token_self - split_self, 0))^2. This would make the penalty increase more steeply for larger deficits, which might better capture strong aversion to very unfair offers. This could help theta's recovery because the effect becomes more distinct in cases of large deficits.\n\nAdditionally, the baseline beta might be influenced by the total combined earnings. For example, in higher stakes (larger combined_earning), participants might be more cautious. Adding an interaction between beta and combined_earning could model this, but again adds a parameter. Alternatively, scale split_self by combined_earning to make the utility relative to the total amount.\n\nIn summary, the revised instructions should encourage:\n\n1. Nonlinear transformations of the fairness penalty (e.g., quadratic).\n2. Interaction terms between trial_type and the penalty.\n3. Relative fairness measures (percentage-based or ratio-based).\n4. Ensuring parameters have distinct roles to improve recovery.\n5. Keeping the number of parameters \u22643 to balance model complexity.\n\nThe goal is to make theta's effect more pronounced and distinct from beta, thereby improving its recovery while maintaining or reducing BIC.\n</think>\n\n**Instructions for Run 2/3:**  \n**Core Objective:** *Radically differentiate parameter roles* while maintaining \u22643 parameters. Target theta recovery through **mechanistic specialization** and **nonlinear fairness encoding**.  \n\n1. **Dynamic Fairness Scaling:**  \n   - Replace linear penalties with **curvilinear responses** (e.g., `theta * (fairness_deficit)^\u03b3` where \u03b3 is either fixed [1.5-2.5] or learnable).  \n   - Test **asymmetric sensitivity** (steeper penalties for deficits >\u00a35 vs. small inequities).  \n\n2. **Contribution-Contextualized Utility:**  \n   - Encode fairness relative to *both* players' contributions:  \n     `fair_share = (3*token_self) / (3*(token_self + token_opp)) * combined_earning`  \n   - Penalize deviations from this proportionally weighted value rather than absolute \u00a3 amounts.  \n\n3. **Trial-Type Gating:**  \n   - Implement **conditional fairness thresholds** using `trial_type`:  \n     - If `trial_type=3` (participant contributed more), use stricter fairness criteria (e.g., 4*token_self vs. 3*token_self).  \n     - Gate penalty activation with trial-type modifiers (e.g., `theta * [condition] * deficit`).  \n\n4. **Monetary Utility Saturation:**  \n   - Apply **diminishing returns** to `split_self` (e.g., `log(split_self + 1)` or `sqrt(split_self)`) to capture sublinear value scaling.  \n\n5. **Parameter Orthogonality Enforcement:**  \n   - Assign `beta` to handle **context-independent biases** (e.g., default rejection tendencies)  \n   - Reserve `theta` exclusively for **context-modulated fairness violations** (e.g., interacting with trial_type or contribution ratios)  \n\n**Forbidden:** Simple linear deficit terms. Prioritize models where beta and theta cannot be swapped without breaking interpretability.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this step by step. The goal is to design a model that predicts whether a responder accepts or rejects a proposal, focusing on parameter recovery and accuracy. The model needs to use the given variables appropriately, especially targeting the 'accept' variable.\n\nFirst, the model should predict responder behavior, so I'll focus on trials where trial_role is 1 (responder). The key variables here are split_self, token_self, token_opp, and combined_earning. The utility function should capture the participant's perceived fairness and the monetary gain.\n\nThe previous attempt used a linear penalty for fairness deficit. To improve parameter recovery, especially for theta, introducing a nonlinear term might help. Let's consider a quadratic penalty on the fairness deficit. This makes the penalty increase more sharply with larger deficits, which could make theta's effect more distinct.\n\nAlso, the fair share should be based on the participant's contribution. Since each token is \u00a33, the fair share would be (3 * token_self) / (combined_earning) * combined_earning, which simplifies to 3 * token_self. But combined_earning is 3*(token_self + token_opp), so the fair percentage is token_self / (token_self + token_opp). However, the split_self is in absolute terms. The deficit could be the difference between the proposed split_self and the fair share (3*token_self). But maybe participants perceive fairness relative to the total, so using percentages might be better. Alternatively, the deficit could be split_self - fair_share, where fair_share is 3*token_self.\n\nWait, combined_earning is 3*(token_self + token_opp), so the fair split_self would be 3*token_self. So if the proposed split_self is less than that, it's unfair. The deficit is max(3*token_self - split_self, 0). Penalizing this deficit quadratically: theta * (deficit)^2.\n\nIncluding trial_type to modulate the penalty. For example, if trial_type is 3 (participant contributed more), maybe the penalty is higher. So introduce a parameter gamma that scales theta based on trial_type. But to keep parameters low, maybe have trial_type act as a multiplier. Alternatively, use a fixed multiplier for trial_type.\n\nBut the instructions say to keep parameters \u22643. Let's see. The previous model had beta and theta. Adding a gamma for the quadratic term would make three parameters: beta, theta, gamma. But gamma could be fixed, say gamma=2, making it a squared term without a learnable parameter. That way, we keep two parameters.\n\nAlternatively, make gamma a learnable parameter with a lower bound of 1. But the problem states that parameters must have finite bounds. If gamma is learnable, we can set its range between 1 and 3, for example.\n\nWait, the user's example in the problem statement had parameters with ranges. So in the variables section, each learnable parameter needs a range.\n\nAnother angle: the utility could be split_self minus a nonlinear penalty. So U = beta * split_self - theta * (max(3*token_self - split_self, 0))^gamma. Here, beta is the sensitivity to the offered amount, theta is the fairness sensitivity, and gamma controls the nonlinearity of the penalty. If gamma is fixed (e.g., 2), then only beta and theta are learnable. If gamma is learnable, it's a third parameter.\n\nBut the user's instructions for this run say to keep parameters \u22643. Let's try gamma as a fixed exponent (e.g., 2) to keep two parameters. That way, theta's effect is amplified in cases of larger deficits, which might help in parameter recovery.\n\nAdditionally, trial_type could modulate theta. For example, in trial_type=3 (participant contributed more), theta is multiplied by a factor. But that would require an additional parameter. However, the user's latest instructions mention using trial_type to gate penalties. Maybe introduce a binary indicator where if trial_type is 3, the deficit is calculated differently. For example, the fair share could be higher in trial_type=3. But that complicates the model.\n\nAlternatively, use trial_type to scale the deficit. For instance, in trial_type=3, the fair share is increased by a factor, say 1.2, making the deficit max(3*token_self*1.2 - split_self, 0). But this introduces another parameter. However, the problem states that the model should use the provided variables, so maybe trial_type can be used as a categorical variable to adjust the fair share.\n\nBut perhaps a simpler approach is better. Let's proceed with the quadratic penalty on the deficit, keeping two parameters: beta and theta. The utility function would be:\n\nU = beta * split_self - theta * (max(3*token_self - split_self, 0))^2\n\nThen, the probability of accepting is logistic(U). If U > 0, the probability is greater than 0.5.\n\nThis model introduces a nonlinear penalty for unfairness, which should make theta's effect more pronounced when the deficit is large, aiding in parameter recovery. Beta captures the sensitivity to the monetary offer, while theta captures the aversion to unfairness, with the penalty increasing quadratically.\n\nNow, checking the variables:\n\n- split_self is from the data.\n- token_self is from the data.\n- 3*token_self is calculated.\n- The max() function ensures only deficits (when split_self is less than fair share) are penalized.\n\nVariables in the model:\n\n- beta: learnable, positive, as it scales the benefit of split_self.\n- theta: learnable, positive, as it scales the penalty.\n- The exponent is fixed at 2, so no gamma parameter.\n\nFor the variables section:\n\n- beta: range min 0, max maybe 10 (generous, but inclusive).\n- theta: range min 0, max 10.\n- The other terms (split_self, token_self) are from data.\n\nThis model uses only the necessary variables and introduces a nonlinear term to differentiate theta's role. The quadratic term should help in parameter recovery as larger deficits have a more significant impact, making theta's estimation more robust.\n\nTesting parameter recovery: If simulated data has a true theta, the model should recover it accurately because the quadratic term creates a distinct pattern in the utility function that's not easily confounded with beta's linear term.\n\nThus, the final model would be:\n\nU = beta * split_self - theta * (D)^2, where D = max(3*token_self - split_self, 0)\n\nAnd the probability of accept is 1 / (1 + exp(-U)).\n</think>\n\n<MODEL>\nU = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to monetary gains\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Nonlinear penalty sensitivity to fairness violations\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA quadratic utility model where acceptance depends on linear monetary gain and a nonlinear penalty for fairness violations. The fairness penalty grows quadratically with the deficit between the participant's equitable share (3\u00d7their tokens) and the proposed split. Beta captures baseline value of money, while theta quantifies aversion to inequitable offers, with parameters orthogonally constrained by linear vs. squared terms.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['beta', 'theta']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to monetary gains\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Nonlinear penalty sensitivity to fairness violations\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, beta=1, theta=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        deficit = max(3 * token_self - split_self, 0)\n        U = beta * split_self - theta * (deficit**2)\n        model_predictions.append(U)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\":1,\"group\":\"control\",\"trial_number\":1,\"trial_type\":1,\"trial_role\":1,\"token_opp\":5,\"token_self\":5,\"combined_earning\":30,\"split_opp\":15.0,\"split_self\":15.0,\"splitperc_opp\":50,\"splitperc_self\":50,\"accept\":1.0,\"accepted_amount\":15.0,\"accepted_perc\":50.0,\"proposed_perc\":50.0,\"proposed_amount\":15.0},{\"ID\":2,\"group\":\"control\",\"trial_number\":2,\"trial_type\":1,\"trial_role\":1,\"token_opp\":5,\"token_self\":5,\"combined_earning\":30,\"split_opp\":21.0,\"split_self\":9.0,\"splitperc_opp\":70,\"splitperc_self\":30,\"accept\":0.0,\"accepted_amount\":0.0,\"accepted_perc\":0.0,\"proposed_perc\":30.0,\"proposed_amount\":9.0},{\"ID\":3,\"group\":\"control\",\"trial_number\":3,\"trial_type\":1,\"trial_role\":1,\"token_opp\":5,\"token_self\":5,\"combined_earning\":30,\"split_opp\":15.0,\"split_self\":15.0,\"splitperc_opp\":50,\"splitperc_self\":50,\"accept\":1.0,\"accepted_amount\":15.0,\"accepted_perc\":50.0,\"proposed_perc\":50.0,\"proposed_amount\":15.0},{\"ID\":4,\"group\":\"control\",\"trial_number\":4,\"trial_type\":1,\"trial_role\":1,\"token_opp\":5,\"token_self\":5,\"combined_earning\":30,\"split_opp\":21.0,\"split_self\":9.0,\"splitperc_opp\":70,\"splitperc_self\":30,\"accept\":0.0,\"accepted_amount\":0.0,\"accepted_perc\":0.0,\"proposed_perc\":30.0,\"proposed_amount\":9.0},{\"ID\":5,\"group\":\"control\",\"trial_number\":5,\"trial_type\":1,\"trial_role\":1,\"token_opp\":5,\"token_self\":5,\"combined_earning\":30,\"split_opp\":15.0,\"split_self\":15.0,\"splitperc_opp\":50,\"splitperc_self\":50,\"accept\":1.0,\"accepted_amount\":15.0,\"accepted_perc\":50.0,\"proposed_perc\":50.0,\"proposed_amount\":15.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n```",
      "timestamp": 1743524016.559853
    }
  ],
  "learnable_parameters": {
    "beta": {
      "description": "Linear sensitivity to monetary gains",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Nonlinear penalty sensitivity to fairness violations",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "beta": {
      "description": "Linear sensitivity to monetary gains",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "theta": {
      "description": "Nonlinear penalty sensitivity to fairness violations",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for participant in \u00a3",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant's token contribution",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A quadratic utility model where acceptance depends on linear monetary gain and a nonlinear penalty for fairness violations. The fairness penalty grows quadratically with the deficit between the participant's equitable share (3\u00d7their tokens) and the proposed split. Beta captures baseline value of money, while theta quantifies aversion to inequitable offers, with parameters orthogonally constrained by linear vs. squared terms.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this step by step. The goal is to design a model that predicts whether a responder accepts or rejects a proposal, focusing on parameter recovery and accuracy. The model needs to use the given variables appropriately, especially targeting the 'accept' variable.\n\nFirst, the model should predict responder behavior, so I'll focus on trials where trial_role is 1 (responder). The key variables here are split_self, token_self, token_opp, and combined_earning. The utility function should capture the participant's perceived fairness and the monetary gain.\n\nThe previous attempt used a linear penalty for fairness deficit. To improve parameter recovery, especially for theta, introducing a nonlinear term might help. Let's consider a quadratic penalty on the fairness deficit. This makes the penalty increase more sharply with larger deficits, which could make theta's effect more distinct.\n\nAlso, the fair share should be based on the participant's contribution. Since each token is \u00a33, the fair share would be (3 * token_self) / (combined_earning) * combined_earning, which simplifies to 3 * token_self. But combined_earning is 3*(token_self + token_opp), so the fair percentage is token_self / (token_self + token_opp). However, the split_self is in absolute terms. The deficit could be the difference between the proposed split_self and the fair share (3*token_self). But maybe participants perceive fairness relative to the total, so using percentages might be better. Alternatively, the deficit could be split_self - fair_share, where fair_share is 3*token_self.\n\nWait, combined_earning is 3*(token_self + token_opp), so the fair split_self would be 3*token_self. So if the proposed split_self is less than that, it's unfair. The deficit is max(3*token_self - split_self, 0). Penalizing this deficit quadratically: theta * (deficit)^2.\n\nIncluding trial_type to modulate the penalty. For example, if trial_type is 3 (participant contributed more), maybe the penalty is higher. So introduce a parameter gamma that scales theta based on trial_type. But to keep parameters low, maybe have trial_type act as a multiplier. Alternatively, use a fixed multiplier for trial_type.\n\nBut the instructions say to keep parameters \u22643. Let's see. The previous model had beta and theta. Adding a gamma for the quadratic term would make three parameters: beta, theta, gamma. But gamma could be fixed, say gamma=2, making it a squared term without a learnable parameter. That way, we keep two parameters.\n\nAlternatively, make gamma a learnable parameter with a lower bound of 1. But the problem states that parameters must have finite bounds. If gamma is learnable, we can set its range between 1 and 3, for example.\n\nWait, the user's example in the problem statement had parameters with ranges. So in the variables section, each learnable parameter needs a range.\n\nAnother angle: the utility could be split_self minus a nonlinear penalty. So U = beta * split_self - theta * (max(3*token_self - split_self, 0))^gamma. Here, beta is the sensitivity to the offered amount, theta is the fairness sensitivity, and gamma controls the nonlinearity of the penalty. If gamma is fixed (e.g., 2), then only beta and theta are learnable. If gamma is learnable, it's a third parameter.\n\nBut the user's instructions for this run say to keep parameters \u22643. Let's try gamma as a fixed exponent (e.g., 2) to keep two parameters. That way, theta's effect is amplified in cases of larger deficits, which might help in parameter recovery.\n\nAdditionally, trial_type could modulate theta. For example, in trial_type=3 (participant contributed more), theta is multiplied by a factor. But that would require an additional parameter. However, the user's latest instructions mention using trial_type to gate penalties. Maybe introduce a binary indicator where if trial_type is 3, the deficit is calculated differently. For example, the fair share could be higher in trial_type=3. But that complicates the model.\n\nAlternatively, use trial_type to scale the deficit. For instance, in trial_type=3, the fair share is increased by a factor, say 1.2, making the deficit max(3*token_self*1.2 - split_self, 0). But this introduces another parameter. However, the problem states that the model should use the provided variables, so maybe trial_type can be used as a categorical variable to adjust the fair share.\n\nBut perhaps a simpler approach is better. Let's proceed with the quadratic penalty on the deficit, keeping two parameters: beta and theta. The utility function would be:\n\nU = beta * split_self - theta * (max(3*token_self - split_self, 0))^2\n\nThen, the probability of accepting is logistic(U). If U > 0, the probability is greater than 0.5.\n\nThis model introduces a nonlinear penalty for unfairness, which should make theta's effect more pronounced when the deficit is large, aiding in parameter recovery. Beta captures the sensitivity to the monetary offer, while theta captures the aversion to unfairness, with the penalty increasing quadratically.\n\nNow, checking the variables:\n\n- split_self is from the data.\n- token_self is from the data.\n- 3*token_self is calculated.\n- The max() function ensures only deficits (when split_self is less than fair share) are penalized.\n\nVariables in the model:\n\n- beta: learnable, positive, as it scales the benefit of split_self.\n- theta: learnable, positive, as it scales the penalty.\n- The exponent is fixed at 2, so no gamma parameter.\n\nFor the variables section:\n\n- beta: range min 0, max maybe 10 (generous, but inclusive).\n- theta: range min 0, max 10.\n- The other terms (split_self, token_self) are from data.\n\nThis model uses only the necessary variables and introduces a nonlinear term to differentiate theta's role. The quadratic term should help in parameter recovery as larger deficits have a more significant impact, making theta's estimation more robust.\n\nTesting parameter recovery: If simulated data has a true theta, the model should recover it accurately because the quadratic term creates a distinct pattern in the utility function that's not easily confounded with beta's linear term.\n\nThus, the final model would be:\n\nU = beta * split_self - theta * (D)^2, where D = max(3*token_self - split_self, 0)\n\nAnd the probability of accept is 1 / (1 + exp(-U)).\n</think>\n\n<MODEL>\nU = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Linear sensitivity to monetary gains\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"theta\": {\n      \"description\": \"Nonlinear penalty sensitivity to fairness violations\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA quadratic utility model where acceptance depends on linear monetary gain and a nonlinear penalty for fairness violations. The fairness penalty grows quadratically with the deficit between the participant's equitable share (3\u00d7their tokens) and the proposed split. Beta captures baseline value of money, while theta quantifies aversion to inequitable offers, with parameters orthogonally constrained by linear vs. squared terms.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2\nSummary: A quadratic utility model where acceptance depends on linear monetary gain and a nonlinear penalty for fairness violations. The fairness penalty grows quadratically with the deficit between the participant's equitable share (3\u00d7their tokens) and the proposed split. Beta captures baseline value of money, while theta quantifies aversion to inequitable offers, with parameters orthogonally constrained by linear vs. squared terms.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, beta=1, theta=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        deficit = max(3 * token_self - split_self, 0)\n        U = beta * split_self - theta * (deficit**2)\n        model_predictions.append(U)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.81990231990232,
  "fitting_results": [
    {
      "beta": 2.2070116944560363,
      "theta": 3.664545264438604,
      "success": true,
      "log_likelihood": -207.23023430619935,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 5.181390517571955,
      "theta": 9.939497524629356,
      "success": true,
      "log_likelihood": -138.15517865958554,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.427827943552341,
      "theta": 4.514559514086795,
      "success": true,
      "log_likelihood": -92.10340746682473,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.5366665826902515,
      "theta": 5.547874615676044,
      "success": true,
      "log_likelihood": -161.1806780009083,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.07249950411885775,
      "theta": 0.053273223543393644,
      "success": true,
      "log_likelihood": -9.252144134914246,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 9.380127005429573,
      "theta": 2.5990641177076372,
      "success": true,
      "log_likelihood": -92.10340371656255,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 4.770146259422407,
      "theta": 1.1024923634578179,
      "success": true,
      "log_likelihood": -69.07805970357892,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.040746158621214175,
      "theta": 0.03276886480317085,
      "success": true,
      "log_likelihood": -13.465645371368833,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 2.6089233449172107,
      "theta": 1.693682620418288,
      "success": true,
      "log_likelihood": -44.20241873390142,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.005256034791998949,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -48.773622370224814,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.8142608979172214,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -23.125071505466575,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -115.12925464660226,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.895671311742648,
      "theta": 0.1193711315369328,
      "success": true,
      "log_likelihood": -92.1034014961182,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.04347126389206082,
      "theta": 0.016727650469501653,
      "success": true,
      "log_likelihood": -17.11089442271194,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -115.12925464660225,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 4.243114223781142,
      "theta": 5.4203028033198795,
      "success": true,
      "log_likelihood": -207.71988682322785,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.814578718317617,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -161.2801762541331,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.1110199322700094,
      "theta": 2.1606397999660993,
      "success": true,
      "log_likelihood": -69.07865617200234,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.04595316015578105,
      "theta": 0.012474876497138946,
      "success": true,
      "log_likelihood": -17.63810190416264,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 5.897502966240559,
      "theta": 7.5415647414148825,
      "success": true,
      "log_likelihood": -138.3907603608012,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 2.29525410848493,
      "theta": 4.170589148676254,
      "success": true,
      "log_likelihood": -46.04604180372308,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.32252090802295036,
      "success": true,
      "log_likelihood": -69.07755278652138,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.568184590157791,
      "theta": 2.5227272602312216,
      "success": true,
      "log_likelihood": -139.5415136437109,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.005257333288215197,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -25.74777143681122,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.44803467361132,
      "theta": 6.049048782900799,
      "success": true,
      "log_likelihood": -253.28436023215846,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.371114734869854,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -138.15510557664308,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 9.72268759229488,
      "theta": 0.0,
      "success": true,
      "log_likelihood": 3.600000297685338e-09,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.4450001951520133,
      "theta": 1.833028607164243,
      "success": true,
      "log_likelihood": -253.61624548333273,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 8.268393725065513,
      "theta": 2.0500149913778096,
      "success": true,
      "log_likelihood": -70.46384714543089,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.05253051552997925,
      "theta": 0.0272907240609803,
      "success": true,
      "log_likelihood": -14.108380437770647,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 5.470242210045268,
      "theta": 6.837629188949302,
      "success": true,
      "log_likelihood": -208.61949752060852,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -69.07755278652135,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.045175640334559966,
      "theta": 0.014343561231973436,
      "success": true,
      "log_likelihood": -17.41714569321554,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.7309432124081271,
      "theta": 9.857564750046109,
      "success": true,
      "log_likelihood": -46.051740231832206,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.30237264780407,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -23.02585092644049,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.4410257484960525,
      "theta": 8.051244493013913,
      "success": true,
      "log_likelihood": -208.61908001474504,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.728113000957592,
      "theta": 0.8389044695817471,
      "success": true,
      "log_likelihood": -207.23279795910796,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.9238033782674115,
      "theta": 2.3087537728085525,
      "success": true,
      "log_likelihood": -207.23265784062232,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.5787805202244676,
      "theta": 1.9532939760459358,
      "success": true,
      "log_likelihood": -139.4578447633165,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 1.77800674279971,
      "theta": 8.99991669960831,
      "success": true,
      "log_likelihood": -161.1810155157443,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.05838041652491099,
      "theta": 0.05659512144853126,
      "success": true,
      "log_likelihood": -9.624591831788644,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.959504195064162,
      "theta": 8.902882560299782,
      "success": true,
      "log_likelihood": -299.482347734258,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.051210864549520965,
      "theta": 0.008081016915652226,
      "success": true,
      "log_likelihood": -17.16441502651708,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.00526077244682109,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -71.79947068573233,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.03220108459179262,
      "theta": 0.008647135288472451,
      "success": true,
      "log_likelihood": -20.277517131767517,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.008630528390217,
      "theta": 0.6949912950400047,
      "success": true,
      "log_likelihood": -276.3102116918236,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.012263031778751278,
      "theta": 0.012687782698080964,
      "success": true,
      "log_likelihood": -19.987195253512784,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.667301988769336,
      "theta": 9.939410215033387,
      "success": true,
      "log_likelihood": -24.42413457812275,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.031460951684758175,
      "theta": 0.05907919102036487,
      "success": true,
      "log_likelihood": -10.81607092462538,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -92.1034037165618,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.005257108911696828,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -48.77362236699902,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -161.18095650668326,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.03423287269131059,
      "theta": 0.00761221971369996,
      "success": true,
      "log_likelihood": -20.158830342890532,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 4.792347552231292,
      "theta": 5.989962793979589,
      "success": true,
      "log_likelihood": -70.46534563070809,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0052567310611081166,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -25.747771437617892,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.392907934636777,
      "theta": 8.177568440904137,
      "success": true,
      "log_likelihood": -230.44724482085314,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.14192486880648703,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -92.12260088690324,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.7011067385149223,
      "theta": 1.9324156202230935,
      "success": true,
      "log_likelihood": -161.18095651948846,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -69.07755278652131,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -115.1292546466023,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.5880465831032446,
      "theta": 6.342090557093083,
      "success": true,
      "log_likelihood": -230.25850930389606,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -69.07755278652137,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 4.021296472047821,
      "theta": 6.884595905583709,
      "success": true,
      "log_likelihood": -184.15958126208986,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.005257388811589632,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -71.79947329688379,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 7.814480026353491,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -161.2801757289742,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 4.76767566989369,
      "theta": 0.8199420269813231,
      "success": true,
      "log_likelihood": -115.12937490760672,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.01282125368476811,
      "theta": 0.0034482694969929623,
      "success": true,
      "log_likelihood": -23.85043937156598,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0877405178879572,
      "theta": 0.02205263831755839,
      "success": true,
      "log_likelihood": -11.67635478802801,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -46.051701856480875,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0,
      "theta": 0.07733319092616808,
      "success": true,
      "log_likelihood": -9.94076178563477,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 6.990133224172638,
      "theta": 9.06179822050137,
      "success": true,
      "log_likelihood": -300.7411296902001,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.005257321783528302,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -25.74777143681435,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.018206770427349032,
      "theta": 0.005391211451758906,
      "success": true,
      "log_likelihood": -22.816125420006568,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -69.07755278652131,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.0,
      "theta": 0.07859359956227191,
      "success": true,
      "log_likelihood": -9.888137938451072,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 8.764305961848311,
      "theta": 3.9886277841221975,
      "success": true,
      "log_likelihood": -161.18095650561858,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 3.2734043544768014,
      "theta": 8.784851918044255,
      "success": true,
      "log_likelihood": -299.33606208695596,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.01656807240665551,
      "theta": 10.0,
      "success": true,
      "log_likelihood": -25.365258951033983,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.047345264660603716,
      "theta": 0.008428993399814847,
      "success": true,
      "log_likelihood": -17.848319516229136,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 0.003926162643656959,
      "theta": 0.026409139388614066,
      "success": true,
      "log_likelihood": -14.814622112133046,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -46.05170185648088,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 5.524565641826392,
      "theta": 7.063838094506678,
      "success": true,
      "log_likelihood": -207.5107932083334,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "beta": 10.0,
      "theta": 0.0,
      "success": true,
      "log_likelihood": -253.28436022684528,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "beta": {
        "r": 0.5796737449782955,
        "p": 2.626489052827309e-10
      },
      "theta": {
        "r": 0.45679367331157805,
        "p": 1.7787459141682744e-06
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 190.5377293891108,
  "bic_results": {
    "average_bic": 190.5377293891108,
    "individual_bics": [
      421.6275064893109,
      283.4773951960833,
      191.3738528105617,
      329.5283938787288,
      25.67132614674071,
      191.37384531003732,
      7.167037869712219,
      145.32315728407005,
      7.167037869712219,
      34.098328619649884,
      95.57187534471505,
      104.71428261736185,
      53.41718088784537,
      7.167037869712219,
      7.167037869712219,
      7.167037869712219,
      7.167037869712219,
      237.42554717011674,
      191.3738408691486,
      7.167037869712219,
      41.3888267223361,
      237.42554717011672,
      422.6068115233679,
      329.7273903851784,
      145.3243502209169,
      42.443241685237496,
      283.94855859851464,
      99.25912148435837,
      145.32214344995498,
      286.25006516433405,
      7.167037869712219,
      58.66258075053466,
      513.7357583412291,
      283.4772490301984,
      7.167037869712219,
      514.3995288435777,
      148.094732167774,
      35.383798752453515,
      424.40603291812926,
      145.32214344995492,
      42.0013292633433,
      99.27051834057663,
      53.2187397297932,
      424.4051979064023,
      421.63263379512813,
      421.63235355815686,
      286.0827274035452,
      329.5290689084008,
      26.41622154048951,
      606.1317333454282,
      41.49586792994638,
      150.76597924837688,
      47.72207214044725,
      559.7874612605594,
      47.141428383937786,
      56.01530703315772,
      28.799179726162983,
      191.37384531003582,
      104.71428261091026,
      329.52895089027874,
      47.48469856269328,
      148.0977291383284,
      58.662580752148,
      468.0615275186185,
      191.4122396507187,
      329.52895091588914,
      145.32214344995484,
      237.42554717011683,
      467.68405648470434,
      145.32214344995495,
      375.48620040109193,
      150.7659844706798,
      329.7273893348606,
      237.42578769212565,
      54.86791662004418,
      30.51974745296824,
      99.27044158987397,
      27.048561448181758,
      608.6492972573125,
      58.66258075054092,
      52.79928871692535,
      145.32214344995484,
      26.943313753814365,
      329.5289508881494,
      605.8391620508241,
      57.897555778980184,
      42.86367690937049,
      36.79628210117831,
      99.27044158987398,
      422.18862429357904,
      513.7357583306028
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 2,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- beta: r = 0.580\n- theta: r = 0.457",
  "previous_models": [
    "Specification: U = beta * split_self - theta * (max(3 * token_self - split_self, 0))^2\nSummary: A quadratic utility model where acceptance depends on linear monetary gain and a nonlinear penalty for fairness violations. The fairness penalty grows quadratically with the deficit between the participant's equitable share (3\u00d7their tokens) and the proposed split. Beta captures baseline value of money, while theta quantifies aversion to inequitable offers, with parameters orthogonally constrained by linear vs. squared terms.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 190.5377293891108\nOverall Accuracy: 0.8199\n\nParameter Recovery:\n- beta: r = 0.580\n- theta: r = 0.457"
  ]
}