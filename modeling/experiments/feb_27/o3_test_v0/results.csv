run_number,average_bic,model_specification,model_summary,version,theta_recovery,phi_recovery,delta_recovery,mu_recovery
1,,"U = split_self + theta - phi * max((token_self/(token_self + token_opp)) * combined_earning - split_self, 0)","A model of responder utility based on comparing the actual monetary offer (split_self) to a fairness benchmark calculated from the participant’s proportional token contribution to the total combined earning. The utility discounts the offer by a penalty (scaled by phi) when it falls below the fair share, with an additive bias (theta) capturing overall acceptance tendency.",v0,0.6355281681899272,0.7460716232531172,,
2,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning.
Then the utility of accepting an offer is:
 U = theta + split_self * (1 + delta * log(split_self / fair_share)).","A model of responder utility that integrates the monetary offer and its fairness relative to a benchmark computed from token contributions. The utility is given by a baseline bias (theta) plus the offer (split_self) scaled by a factor that adjusts for the log deviation from fairness (delta). Negative deviations from the fairness benchmark reduce utility, while positive deviations enhance it.",v0,0.8090926106997359,,-0.02656966898606717,
3,,U = split_self + delta * (split_self - (token_self/(token_self+token_opp))*combined_earning) - mu * (split_self - (token_self/(token_self+token_opp))*combined_earning)^2,"A utility model for responder behavior where the subjective utility of an accepted offer is calculated as the sum of the monetary amount (split_self) and adjustments based on the deviation from a fairness benchmark (computed from token_self, token_opp, and combined_earning). The deviation is linearly promoted by a learnable sensitivity parameter (delta) and quadratically penalized by another learnable parameter (mu), thereby capturing both minor and substantial deviations from fairness.",v0,,,0.8498494399493781,0.49508738971524574
