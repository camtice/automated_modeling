run_number,average_bic,bic_control,bic_cocaine,model_specification,model_summary,version,rho_recovery,alpha_recovery,beta_recovery,lambda_param_recovery,b_recovery,gamma_recovery,delta_param_recovery,kappa_recovery,psi_recovery,base_bias_recovery,fairness_param_recovery,beta_param_recovery
6,63.33566917355406,,,U_accept = kappa + psi * (split_self - combined_earning * (token_self / (token_self + token_opp))),"The model computes the utility of accepting an offer by comparing the offered monetary share to a fair share calculated from the participant’s token contribution relative to the total tokens. Two learnable parameters are employed: a baseline bias (kappa) and a fairness sensitivity (psi), which modulate the impact of deviations from this fair split.",v0,,,,,,,,0.4925336540018302,0.44448904064480066,,,
1,68.48853769144237,,,"U = rho * split_self - alpha * max(0, (combined_earning * (token_self/(token_self+token_opp))) - split_self)",The model computes the utility of accepting an offer by weighting the offered share with a monetary sensitivity parameter (rho) and subtracting a fairness-related penalty (alpha) if the offered share falls below a fairness norm computed from the participant’s token count relative to total tokens. This two-parameter model captures basic inequity aversion and monetary valuation in responder decisions.,v0,0.2517972836148048,0.8142434290491444,,,,,,,,,,
9,68.50928669914178,,,"U = beta * split_self - alpha * (max(0, (token_self/(token_self + token_opp))*combined_earning - split_self))^2","The model computes the utility of accepting an offer by combining a monetary gain term (scaled by beta) and a quadratic penalty for offers that fall short of a fairness benchmark, computed as the proportional share based on token contributions. Two learnable parameters, beta and alpha, modulate the weight on direct gain and fairness sensitivity, respectively.",v0,,0.7487681375237728,0.32066619604472446,,,,,,,,,
7,74.16340629404733,,,U = base_bias + (1 + fairness_param)*split_self - fairness_param*((token_self/(token_self+token_opp))*combined_earning),"A responder utility model that compares the offered monetary share with a fair share benchmark derived from the participant's relative token count. The model linearly combines the offer with a fairness-adjusted term, using a baseline bias and fairness sensitivity as the two learnable parameters.",v0,,,,,,,,,,0.6695578463810129,0.5140470729306729,
5,87.73991456275105,,,"U = split_self - lambda_param * max(((token_self/(token_self+token_opp))*combined_earning - split_self),0) - delta_param * max((split_self - (token_self/(token_self+token_opp))*combined_earning),0)",A fairness-based utility model in which the responder’s offer is evaluated by comparing the received monetary split to a fairness norm computed from the participant's and opponent's token counts scaled by the combined earning. Two learnable parameters capture sensitivity to disadvantageous and advantageous deviations from this fairness benchmark.,v0,,,,0.5844530642905157,,,0.1286683574887325,,,,,
3,99.04798424175945,,,U_accept = b + gamma*(split_self - (token_self/(token_self+token_opp))*combined_earning),A fairness-based utility model for responder behavior where the utility of accepting an offer is computed as a baseline bias plus a sensitivity parameter multiplied by the difference between the actual received offer and a fairness benchmark. The fairness benchmark is derived from the participant's share of the tokens relative to the total tokens and scaled by the combined earnings. Two learnable parameters (b and gamma) with finite generous bounds allow the model to capture individual differences in fairness sensitivity.,v0,,,,,0.919332888846753,0.5187430799910807,,,,,,
8,118.27121968235485,,,U = beta + split_self - lambda_param*abs(split_self - (token_self/(token_self + token_opp))*combined_earning),A utility model for responders in which the offered share is augmented by a baseline bias and diminished by a penalty that is proportional to the deviation of the offer from a fairness benchmark based on relative token contributions.,v0,,,0.8793390264444976,0.3457012389418429,,,,,,,,
2,128.83374706406772,,,"U = beta + split_self - lambda_param * max(0, (token_self/(token_self+token_opp))*combined_earning - split_self)","A utility model for responder behavior that computes the accept utility as the offered monetary gain minus a fairness penalty. The fairness expectation is determined by the participant's relative token contribution to the total tokens, scaled by the combined earning. Two learnable parameters, beta and lambda_param, adjust the baseline utility and the sensitivity to fairness deviations respectively.",v0,,,0.8849632366523679,0.44895794481234536,,,,,,,,
10,136.92376146317136,,,"U_accept = beta_param + split_self - lambda_param * max((token_self/(token_self+token_opp))*combined_earning - split_self, 0)","A utility model for responder behavior where the utility of accepting an offer is computed as the sum of the received monetary share and a baseline bias, minus a penalty applied when the offer falls below a fair share determined by the participant's contribution relative to the total. Two learnable parameters control the overall acceptance bias and the sensitivity to deviations from fairness.",v0,,,,0.31802471867176774,,,,,,,,0.8764533587827119
4,,,,"U = beta + split_self - lambda * (max(0, ((token_self/(token_self+token_opp))*combined_earning - split_self)))^2",A utility model for responder behavior in which the utility of accepting an offer is computed by adding a baseline bias to the monetary offer (split_self) and subtracting a quadratic penalty if the offer falls below a fairness norm defined by the participant’s token contribution relative to the combined tokens. Two learnable parameters (beta and lambda) capture baseline bias and fairness sensitivity.,v0,,,,,,,,,,,,
