run_number,average_bic,bic_control,bic_cocaine,model_specification,model_summary,version,beta_recovery,alpha_recovery,beta_reward_recovery,beta_horizon_recovery,bias_recovery,beta_temp_recovery,gamma_recovery
1,3248.1702339797516,,,P(choice=1) = 1/(1 + exp(- (beta * (expected_reward1 - expected_reward0) + alpha))),"A binary logistic choice model in which the decision variable is a linear function of the difference between the observed mean rewards of the two options, scaled by a reward sensitivity parameter and shifted by a bias term. The resulting logistic function yields the probability of selecting option 1 on free-choice trials.",v1,-0.1698583597236596,0.008461905155321825,,,,,
2,3256.538984742863,,,p = 1/(1+exp(-(beta_reward*(expected_reward1 - expected_reward0) + beta_horizon*((horizon-1)/5) + bias))),"A logistic choice model where free-choice behavior is driven by the weighted difference in observed expected rewards between the two options and a bonus factor associated with longer horizons, plus an intercept bias. Only three learnable parameters are estimated with carefully chosen finite bounds to minimize covariance.",v1,,,0.4306306290892081,0.30478021924309373,-0.03196864005705157,,
3,3258.2905742047633,,,p(choice=1) = 1/(1 + exp(- ( beta_temp * ( (expected_reward1 - expected_reward0) + gamma * horizon * ((n1)^(-0.5) - (n0)^(-0.5)) ) + bias )),"A binary choice model where on free‐choice trials each option’s utility is computed as its observed mean reward augmented by an exploration bonus that is proportional to the inverse square-root of the observed count. The bonus is scaled by the horizon and a learnable exploration parameter. The difference in utilities is then mapped through a logistic function, with an additional bias term, to predict the probability of choosing option 1.",v1,,,,,0.5784232573417148,0.330557234843036,-0.003940223782423476
