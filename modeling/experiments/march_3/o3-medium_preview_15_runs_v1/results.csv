run_number,average_bic,bic_control,bic_cocaine,model_specification,model_summary,version,alpha_recovery,tau_recovery,tau_param_recovery,rho_param_recovery,beta_recovery
15,32.71468133634373,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning
Let d = split_self - fair_share
U_accept = split_self + tau * tanh(d)","The model computes the utility for accepting an offer as the monetary amount provided (split_self) adjusted by a fairness deviation term. The fairness reference is derived from the participant’s token share of the combined earnings. This deviation is transformed by a hyperbolic tangent function and then scaled by a single learnable parameter, tau, capturing both the bonus for favorable offers and the penalty for offers that fall below fairness.",v1,,0.9594892366666464,,,
4,33.91799996790353,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning

Then:
  U_accept = { split_self             if split_self ≥ fair_share
         split_self – alpha · (fair_share – split_self)² if split_self < fair_share }","A piecewise utility model for responder behavior where the utility of accepting an offer equals the monetary amount offered, except when the offer falls below a fairness reference computed from the participant’s token share of the total earning. In such cases, a quadratic penalty—scaled by the learnable inequity sensitivity parameter alpha—is applied, capturing an escalating aversion to receiving an unfair split.",v1,0.8754421676369657,,,,
5,33.930812889198855,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning.
Then, the utility for accepting an offer is defined as:
  U_accept = split_self + tau * log((split_self + epsilon) / fair_share)","A model of responder behavior where the utility for accepting an offer integrates the direct monetary benefit with a logarithmic fairness adjustment. The fairness reference is derived from the participant's token share of the combined earnings, and a single learnable parameter, tau, scales the impact of deviations from this fairness standard.",v1,,0.9507158842630405,,,
9,34.25802432850235,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning.
Then:
  U_accept = split_self - tau * (split_self - fair_share)^2.",The model calculates a fairness reference based on the token ratio multiplied by the combined earnings. It then derives the utility for accepting an offer by subtracting a quadratic penalty—scaled by a single learnable parameter tau—from the offered monetary amount. This symmetric penalty for any deviation from the fairness benchmark captures the responder's sensitivity to unfair splits.,v1,,0.7698875698592718,,,
1,34.61021336553505,,,"U_accept = split_self - alpha * max(0, ( (token_self / (token_self + token_opp)) * combined_earning - split_self ))","The model computes the utility for a responder’s acceptance decision by comparing the actual monetary offer to a fair share calculated from the participant's proportional contribution. If the offer falls short of this fair share, a penalty—scaled by the inequity aversion parameter alpha—is applied. The formulation captures a psychological sensitivity to disadvantageous inequity in a single-parameter specification.",v1,0.9221887560301775,,,,
8,34.81986374486485,,,"Let fair_share = (token_self/(token_self + token_opp)) * combined_earning  
Let d = max(0, fair_share - split_self)  
U_accept = split_self - alpha * d - tau * (d)^2","A two-parameter utility model for responder decisions where the utility of accepting an offer is the proposed monetary share reduced by a penalty applied when the offer falls short of a fairness benchmark (derived from the participant’s token contribution). The penalty is composed of a linear term and an additional quadratic term, capturing both the immediate sensitivity and the escalating aversion to unfair splits.",v1,0.5076442769605956,0.36436280784749253,,,
12,34.82214294286025,,,"Let fair_share = (token_self/(token_self+token_opp)) * combined_earning  
Let d = split_self - fair_share  
U_accept = split_self - alpha * ( log(1+exp(-d)) - log(2) ) + beta * ( log(1+exp(d)) - log(2) )","A smooth, reference-dependent utility model in which the utility of accepting an offer is given by the monetary amount (split_self) adjusted by asymmetrically penalizing shortfalls and optionally rewarding surpluses relative to a fairness benchmark computed as the participant’s token share of the total earnings. The adjustments are implemented using centered logarithmic transforms of the deviation, weighted by two learnable parameters (alpha and beta).",v1,0.31678736878082386,,,,0.319457488710847
2,35.25002573222929,,,"U_accept = split_self - alpha * max(0, (tau * (token_self / (token_self + token_opp)) * combined_earning) - split_self)","A two-parameter utility model for responder behavior where utility is derived from the actual offer (split_self) reduced by a penalty applied when the offer falls short of a scaled fairness reference. The fairness reference is computed from the participant’s token share of the total tokens multiplied by the combined earning, and is modulated by the fairness scaling parameter tau. The inequity aversion parameter alpha determines the sensitivity to deviations below the (tau-scaled) reference.",v1,0.5014110957377108,0.863499592686393,,,
7,37.49636326995195,,,"U_accept = log(1 + split_self) - alpha * log(1 + max(0, ((token_self / (token_self + token_opp)) * combined_earning) - split_self))","A reference-dependent utility model that applies logarithmic (diminishing) sensitivity to both the offered monetary amount and any shortfall relative to a fairness benchmark computed from token contributions. The single learnable parameter, alpha, scales the penalty for offers below the fairness reference.",v1,0.9158604354458594,,,,
11,40.96325099527113,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning
Let shortfall = max(0, fair_share - split_self)
Let surplus = max(0, split_self - fair_share)
U_accept = ln(1 + split_self) - alpha * ln(1 + shortfall) - beta * ln(1 + surplus)","This model computes the utility of accepting an offer by first establishing a fairness benchmark based on the participant's token share of total tokens and combined earnings. The utility is given by the log-transformed offered amount minus logarithmically scaled penalties for deviations from fairness. Two learnable parameters, alpha and beta, separately modulate sensitivity to receiving less than or more than the fairness benchmark.",v1,0.8695943214349307,,,,0.5194088536325399
14,42.91428856572754,,,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning  
U_accept = split_self * (split_self / fair_share)^alpha","A one-parameter, multiplicative fairness adjustment model where the utility of accepting an offer equals the offered monetary amount scaled by the ratio of the offer to a fairness benchmark (computed from token contributions and combined earnings) raised to the power of the fairness sensitivity parameter alpha.",v1,0.6559154393265455,,,,
3,45.67592971143451,,,U_accept = (1 - alpha) * split_self + alpha * (tau * ((token_self) / (token_self + token_opp)) * combined_earning),"This model posits that responders compute the utility of accepting an offer by balancing the actual monetary offer with an expected fair share derived from their token contribution. The model uses a convex combination of split_self and a scaled fairness reference, where alpha (0 to 1) determines the weighting of fairness relative to pure self-interest, and tau (0 to 10) scales the fairness reference.",v1,0.455530689923537,0.59225854953536,,,
13,51.04425856409312,,,"fair_share = (token_self / (token_self + token_opp)) * combined_earning
relative_short = max(0, fair_share - split_self) / fair_share
U_accept = split_self * (1 - tau * relative_short)","A reference-dependent utility model for responders that computes a fairness benchmark based on token contributions and combined earnings. When the monetary offer falls below this fairness standard, the utility is multiplicatively discounted by a factor proportional to the relative shortfall, scaled by the single fairness sensitivity parameter tau.",v1,,0.3430727862669579,,,
10,66.80233137460259,,,"Let fair_share = (token_self/(token_self + token_opp)) * combined_earning

U_accept = [ (1 - tau_param) * (split_self)^(rho_param) + tau_param * (fair_share)^(rho_param) ]^(1/rho_param)",This model computes the utility for a responder’s acceptance decision as a constant elasticity of substitution (CES) aggregator between the actual offered amount (split_self) and a fairness reference derived from token contributions (fair_share). Two learnable parameters govern the integration: tau_param sets the relative weight of fairness and rho_param controls the curvature of substitution between self-interest and fairness.,v1,,,0.34081355345089737,0.3357979620562248,
6,,,,"U_accept = split_self - beta * ( max(0, (token_self/(token_self + token_opp))*combined_earning - split_self) )^(gamma)","A utility model for responder behavior that computes a fairness reference based on token contributions and total earnings, then applies a non-linear penalty to offers falling short of this reference. The utility is the actual monetary offer (split_self) reduced by beta times the fairness shortfall raised to the power of gamma.",v1,,,,,
