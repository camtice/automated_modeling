run_number,average_bic,model_specification,model_summary,timestamp,alpha_recovery,beta_recovery,b_recovery,lambda_fair_recovery,lambda_param_recovery,mu_param_recovery,beta_0_recovery,beta_1_recovery,kappa_param_recovery,beta_param_recovery,bias_recovery,fairness_weight_recovery,delta_recovery,theta_recovery,xi_param_recovery,fairness_sensitivity_recovery
3,29.956575198861255,U_accept = b + (1 + lambda_fair) * split_self - lambda_fair * ((token_self / (token_self + token_opp)) * combined_earning),A linear utility model for responder behavior that computes the utility of accepting an offer by comparing the offered amount to a fair share based on individual token contributions. The model includes two learnable parameters: a baseline bias (b) and a fairness sensitivity parameter (lambda_fair) that weight the monetary offer and the deviation from fairness.,20250128_153032,,,0.9140579629482107,0.7812830974544676,,,,,,,,,,,,
17,30.172903374266983,"U_accept = beta + split_self - alpha * max(0, (combined_earning * token_self / (token_self + token_opp)) - split_self)",A utility model for responders that integrates the received monetary offer with fairness-based adjustments. The model computes a fair share from the combined earnings weighted by token contributions and penalizes disadvantageous deviations via an inequity aversion parameter (alpha). A baseline bias (beta) adjusts overall utility. Both learnable parameters are constrained to finite ranges.,20250128_153032,0.7800482031735019,0.8052845350744708,,,,,,,,,,,,,,
11,30.185236212395782,"U_accept = bias + split_self - fairness_weight * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","A utility model for responder behavior that computes the utility of accepting an offer as the sum of a baseline bias and the actual offer amount, penalized by the extent to which the offer falls below the fair share (calculated from the participant’s token count relative to total tokens and the combined earnings). Two learnable parameters (bias and fairness_weight) calibrate this trade-off.",20250128_153032,,,,,,,,,,,0.9258182932992319,0.7322877310621811,,,,
5,30.720452286633474,U_accept = beta_0 + split_self - beta_1 * abs(split_self - ((token_self / (token_self + token_opp)) * combined_earning)),"A utility model for responder behavior in which the utility of accepting an offer is given by the offered monetary share adjusted downward by a penalty proportional to the deviation from a fair share computed based on relative token contributions. Two learnable parameters determine a baseline intercept (beta_0) and fairness sensitivity (beta_1), with all inputs coming directly from the dataset.",20250128_153032,,,,,,,0.8283592197609209,0.7488876865417878,,,,,,,,
9,31.602073049858763,U_accept = alpha * split_self - beta * |split_self - ((token_self / (token_self + token_opp)) * combined_earning)|,"A utility model for responder behavior where the computed utility of accepting an offer is the difference between a scaled monetary gain and a penalty for deviations from fairness. The fairness criterion is calculated as the proportional share of a combined earning based on the participant’s tokens relative to the total tokens. The two learnable parameters (alpha and beta) capture, respectively, the weight given to personal monetary gain and the aversion to unfair offers.",20250128_153032,0.8650539851055655,0.8261117099061079,,,,,,,,,,,,,,
19,31.71992398210481,"U = split_self - fairness_sensitivity * max((combined_earning * (token_self / (token_self + token_opp))) - split_self, 0)",A utility model for responder behavior in which the utility of accepting an offer is computed as the monetary amount received (split_self) minus a penalty for any shortfall relative to a fairness norm. The fairness norm is defined as the proportion of tokens contributed by the participant (token_self divided by the total tokens) multiplied by the combined earnings. The single learnable parameter (fairness_sensitivity) governs the aversiveness to disadvantageous inequality.,20250128_153032,,,,,,,,,,,,,,,,0.9416181329363215
12,32.991548188970114,"U_accept = delta + split_self - theta * max(((token_self/(token_self + token_opp)) * combined_earning - split_self), 0)","A linear utility model for responder behavior, where the utility of accepting an offer is determined by the sum of an intercept (baseline acceptance tendency) and the offered amount, reduced by a penalty proportional to the shortfall relative to a fair share. The fair share is computed from participants’ token contributions relative to total tokens and the combined earnings. Two learnable parameters (delta and theta) calibrate the baseline and fairness sensitivity.",20250128_153032,,,,,,,,,,,,,0.8169586839522519,0.7416043883133171,,
6,33.158253960411656,"Let fair_split = (token_self / (token_self + token_opp)) × combined_earning
U = lambda_param × split_self − kappa_param × (split_self − fair_split)²","A utility model for responder behavior that computes the subjective benefit of accepting an offer as a weighted monetary gain diminished by a quadratic penalty for deviating from a fairness expectation. The fair share is derived from the participant’s token count relative to the total tokens and the monetary pot available, with two learnable parameters governing the gain sensitivity and fairness penalty.",20250128_153032,,,,,0.8301275391106986,,,,0.7730767986847166,,,,,,,
1,34.88900523391942,"Let fair_share = (token_self / (token_self + token_opp)) × combined_earning.

Then, the utility of accepting is defined as:
 U_accept = { split_self − alpha × (fair_share − split_self), if split_self < fair_share
         split_self + beta × (split_self − fair_share),  if split_self ≥ fair_share }.","A piecewise linear utility model for responder behavior that computes a fairness benchmark from the proportion of tokens contributed relative to the total tokens and adjusts the offered share accordingly. When the offer is below fairness, a penalty weighted by parameter alpha is applied; when above, a bonus weighted by parameter beta is added. Only the utility of accepting is modeled, with two learnable parameters ensuring tractability in parameter recovery.",20250128_153032,0.9256313814858972,0.17932699931243412,,,,,,,,,,,,,,
13,34.889094693179054,"Let fair_share = (token_self / (token_self + token_opp)) * combined_earning.

Then the utility for accepting an offer, U_accept, is defined piecewise as:

  U_accept = { 
    split_self - lambda_param * (fair_share - split_self),   if split_self < fair_share,
    split_self + xi_param * (split_self - fair_share),         if split_self ≥ fair_share.
  }","A piecewise linear utility model for responder behavior that judges proposals based on a fairness reference computed from token contributions and total earnings. Offers below the fair share incur a penalty weighted by lambda_param, whereas offers above fairness receive a boost weighted by xi_param. Only responder acceptance is modeled with two learnable parameters.",20250128_153032,,,,,0.8974418765828699,,,,,,,,,,0.17541052165706406,
4,34.95611342857145,"U_responder = split_self - lambda_param * max( (token_self / (token_self + token_opp)) * combined_earning - split_self, 0 ) - mu_param * max( split_self - (token_self / (token_self + token_opp)) * combined_earning, 0 )","A fairness-based utility model for responders that computes an expected fair share from token contributions and combined earnings, then penalizes deviations from this fair share using distinct sensitivity parameters for disadvantageous and advantageous deviations. The model uses two learnable parameters to calibrate the inequity cost.",20250128_153032,,,,,0.8258667491708062,0.6172266840788766,,,,,,,,,,
7,35.00456495905321,"Let F = (token_self / (token_self + token_opp)) × combined_earning.
Then,
 U_accept = split_self − lambda_param × max(F − split_self, 0) − beta_param × max(split_self − F, 0)",A utility model for responder behavior where the utility of acceptance is computed as the monetary offer (split_self) minus an inequity penalty that depends on the deviation from a fair share. The fair share is defined proportionally from the participant’s tokens relative to the total tokens and scaled by the combined earning. Two learnable parameters (lambda_param and beta_param) modulate the sensitivity to disadvantageous and advantageous deviations from fairness.,20250128_153032,,,,,0.913333506054787,,,,,0.6404516472015978,,,,,,
15,35.0045649604591,"U_accept = split_self - [ alpha · I(d < 0) · (fS - split_self) + delta · I(d > 0) · (split_self - fS) ]
where
 fS = (token_self / (token_self + token_opp)) · combined_earning,
 d = split_self - fS,
 I(condition) = 1 if condition holds, 0 otherwise.","A fairness-based utility model for responder decisions that computes a fairness reference from the participant’s token contribution relative to the total tokens. The offered share (split_self) is compared to this fair share, and the utility is reduced proportionally by one of two learnable parameters: alpha for disadvantageous deviation (when the offer is lower than fair) and delta for advantageous deviation (when the offer is higher than fair). This model uses only two learnable parameters and maps directly to the observed trial variables.",20250128_153032,0.9069778816583428,,,,,,,,,,,,0.6709110426486017,,,
18,42.535235771910116,U_accept = beta_0 + split_self + lambda_param * (split_self - (combined_earning * token_self / (token_self + token_opp))),"A linear utility model for responder behavior wherein the utility of acceptance is computed as the sum of the offer’s monetary value and a fairness adjustment term. The fairness term is the difference between the offered share and a fair share computed from the participant’s token contribution relative to the total tokens, weighted by a fairness sensitivity parameter. An additive baseline bias parameter allows for systematic shifts in the utility.",20250128_153032,,,,,0.34107039082515583,,0.8612442606660978,,,,,,,,,
2,,U = phi * split_self - lambda * (split_self - (token_self / (token_self + token_opp)) * combined_earning)^2,The model computes the utility for a responder’s acceptance decision as a weighted sum of the monetary value offered (split_self) and a quadratic penalty for deviation from a normative fair share. The normative fair share is derived from the ratio of the participant’s tokens to the total tokens times the combined earning. Two learnable parameters – phi (monetary sensitivity) and lambda (fairness sensitivity) – allow the model to adaptively weigh these influences.,20250128_153032,,,,,,,,,,,,,,,,
8,,"U_accept = delta * split_self - lambda * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","This model computes the utility for a responder accepting an offer by combining a positive valuation on the money received with a penalty for receiving less than what is deemed fair based on token contributions. The fairness benchmark is derived from the ratio of participant tokens to the total tokens available. Two learnable parameters (delta and lambda) scale the monetary benefit and the penalty from disadvantageous inequity, respectively.",20250128_153032,,,,,,,,,,,,,,,,
10,,"U_accept = delta * split_self - lambda * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","A utility model for responder behavior that computes the utility of accepting an offer. The model values the monetary reward (split_self) scaled by a gain sensitivity parameter (delta), and subtracts a penalty (scaled by lambda) if the monetary split falls below the fair share, computed from the participant’s token contribution relative to the total and the combined earning.",20250128_153032,,,,,,,,,,,,,,,,
14,,"F = combined_earning * (token_self / (token_self + token_opp))
U = beta * split_self - gamma * F","A linear utility model for responders that calculates utility by weighting the proposed monetary share (split_self) and subtracting a penalty proportional to a fairness benchmark (F), where F is computed from the participant’s contribution relative to the opponent’s in generating the combined earnings. The two learnable parameters, beta and gamma, capture sensitivity to monetary reward and fairness, respectively.",20250128_153032,,,,,,,,,,,,,,,,
16,,"U_accept = beta + split_self - lambda_param * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","The model calculates the utility of accepting an offer as the sum of a baseline bias and the monetary offer, minus a fairness penalty applied when the offer is below the fair share (computed based on the participant’s tokens and the combined earning). Two learnable parameters control the bias (beta) and sensitivity to unfairness (lambda_param), ensuring the model can capture responder behavior under inequity aversion.",20250128_153032,,,,,,,,,,,,,,,,
20,,"U = beta + split_self - theta * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","A utility model for responders that computes the value of accepting an offer as the sum of the offered share and a baseline bias, minus a fairness penalty when the offer falls short of the equitable share based on token contributions. The model incorporates two learnable parameters: a baseline parameter (beta) and a fairness sensitivity parameter (theta).",20250128_153032,,,,,,,,,,,,,,,,
