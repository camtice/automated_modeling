{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nOkay, let's analyze the previous model's performance to figure out how to improve the instructions for the next run. The previous model had a BIC of around 47.92, which is okay, but there's room for improvement. The accuracy was about 59.4%, which is slightly better than chance but not great. The parameter recovery for alpha was moderate (r=0.631) and better for beta (r=0.729). \n\nFirst, the model used two parameters: alpha for sensitivity to deviation from contribution-based fairness and beta for inequity aversion. The BIC is a function of both the likelihood and the number of parameters. Since the model has two parameters, maybe adding another parameter could help if it significantly improves the fit, but we need to balance that with BIC's penalty for complexity. However, the current accuracy is low, so perhaps the model isn't capturing some key psychological factors.\n\nLooking at the parameter recovery, alpha's lower correlation suggests that it's harder to estimate accurately. This could be due to covariance between alpha and beta, or maybe the model's structure doesn't properly isolate the effects of each parameter. For example, if the terms involving alpha and beta are correlated in the data, the parameters might be harder to recover. \n\nThe previous instructions emphasized avoiding high covariance between parameters and a slight bias towards fewer parameters. The model had two parameters, which is reasonable. However, the moderate recovery and accuracy suggest that the model might be missing important components of the decision-making process.\n\nPossible improvements:\n\n1. **Non-linear Terms**: The current model is linear in alpha and beta. Introducing non-linear interactions (e.g., multiplicative terms, thresholds) might better capture how these factors combine. For example, maybe the effect of inequity aversion (beta) is only relevant when the participant's share is below a certain threshold.\n\n2. **Reference Points**: The model uses 3*token_self as the fair share. Perhaps participants have different reference points, such as equal split (combined_earning/2) or a combination of contribution and equal split. Adding a parameter to weight between these reference points could help.\n\n3. **Loss Aversion**: Participants might be more sensitive to losses (getting less than fair) than gains. Introducing a loss aversion parameter that amplifies the negative deviations could improve fit.\n\n4. **Intercept Term**: Including a baseline tendency to accept or reject (e.g., a constant term in the utility) might capture general response biases not explained by fairness or inequity.\n\n5. **Separate Parameters for Advantageous and Disadvantageous Inequity**: The current model uses a single beta for the difference (split_opp - split_self), which could be positive or negative. But people might react differently to being ahead vs. behind. Splitting beta into two parameters (e.g., beta_adv for when split_self > split_opp and beta_dis for the opposite) could capture this.\n\n6. **Interaction with Trial Type**: The trial_type variable indicates whether contributions were equal, opponent more, or participant more. Including interaction terms with trial_type might capture how fairness perceptions vary in these contexts.\n\n7. **Alternative Fairness Calculations**: The model assumes fairness is strictly proportional to contribution. Maybe participants consider other factors, like the ratio of contributions or absolute differences. For example, (token_self - token_opp) could be a term affecting fairness perception.\n\n8. **Temperature Parameter in Logistic Function**: The current model uses a logistic function with temperature 1. Adding a temperature parameter could allow varying decision noise, improving fit.\n\nHowever, adding parameters increases model complexity, which could hurt BIC unless the fit improves enough. The challenge is to find a balance. Since the previous model had two parameters, maybe adding one more could be justified if it significantly boosts accuracy and recovery.\n\nAnother angle: The current model's terms might not be scaled properly. For example, split_self - 3*token_self could be a large value compared to split_opp - split_self, leading to one parameter dominating. Standardizing the terms or introducing scaling factors might help.\n\nAlso, the model doesn't account for the total combined earning. Maybe participants care about the absolute amount they receive relative to the total. For example, split_self/combined_earning could be a term, but that's similar to splitperc_self, which is already a variable. However, including it might interact with fairness perceptions.\n\nIn the next instructions, I should encourage exploring these possibilities. Specifically, suggest considering non-linear interactions, alternative reference points, and separating advantageous/disadvantageous inequity. Also, mention the possibility of adding an intercept or temperature parameter. However, caution against overcomplicating the model without justification. Emphasize testing models that address potential covariance issues (e.g., orthogonal terms) and improve parameter identifiability.\n\nAdditionally, since the previous model had moderate parameter recovery for alpha, suggest ways to make the alpha term more identifiable. Maybe by including a term that only affects alpha's component, reducing its correlation with beta.\n\nFinally, encourage creativity but stress the importance of maintaining a balance between complexity and identifiability. Maybe suggest models with 2-3 parameters, exploring different psychological mechanisms beyond the initial fairness and inequity factors.\n</think>\n\n**Revised Instructions for Run 2/200:**\n\nDesign a model that explicitly addresses *non-linear interactions* between fairness and inequity components. Consider these enhancements:  \n1. **Mechanistic Innovations**  \n   - Explore asymmetric responses to advantageous vs. disadvantageous inequity (e.g., separate parameters for split_opp > split_self vs. split_self > split_opp)  \n   - Test hybrid fairness norms (e.g., weighted combinations of contribution-based and equal-split fairness)  \n   - Introduce a loss aversion coefficient for deviations below contribution-based fairness  \n\n2. **Identifiability Constraints**  \n   - Use orthogonal utility components (e.g., interaction terms that reduce covariance between parameters)  \n   - If adding parameters, ensure they control distinct behavioral phenomena (e.g., baseline acceptance bias vs. context-sensitive fairness)  \n\n3. **Parameterization Guidance**  \n   - Prioritize models with 2-3 parameters maximum  \n   - Allow non-linear transformations (e.g., sigmoidal scaling of fairness deviations)  \n   - Consider bounded parameters with psychological interpretability (e.g., [0,1] for weighting terms)  \n\n4. **Behavioral Plausibility**  \n   - Explicitly model how trial_type (contribution asymmetry) modulates fairness expectations  \n   - Account for magnitude effects (e.g., proportional vs. absolute inequity)  \n\n*Key Objective:* Improve parameter recovery (target r > 0.8) while maintaining BIC <45 through strategic non-linearities that better match human sensitivity thresholds.",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\nOkay, let's analyze the previous model's performance to figure out how to improve the instructions for the next run. The previous model had a BIC of around 47.92, which is okay, but there's room for improvement. The accuracy was about 59.4%, which is slightly better than chance but not great. The parameter recovery for alpha was moderate (r=0.631) and better for beta (r=0.729). \n\nFirst, the model used two parameters: alpha for sensitivity to deviation from contribution-based fairness and beta for inequity aversion. The BIC is a function of both the likelihood and the number of parameters. Since the model has two parameters, maybe adding another parameter could help if it significantly improves the fit, but we need to balance that with BIC's penalty for complexity. However, the current accuracy is low, so perhaps the model isn't capturing some key psychological factors.\n\nLooking at the parameter recovery, alpha's lower correlation suggests that it's harder to estimate accurately. This could be due to covariance between alpha and beta, or maybe the model's structure doesn't properly isolate the effects of each parameter. For example, if the terms involving alpha and beta are correlated in the data, the parameters might be harder to recover. \n\nThe previous instructions emphasized avoiding high covariance between parameters and a slight bias towards fewer parameters. The model had two parameters, which is reasonable. However, the moderate recovery and accuracy suggest that the model might be missing important components of the decision-making process.\n\nPossible improvements:\n\n1. **Non-linear Terms**: The current model is linear in alpha and beta. Introducing non-linear interactions (e.g., multiplicative terms, thresholds) might better capture how these factors combine. For example, maybe the effect of inequity aversion (beta) is only relevant when the participant's share is below a certain threshold.\n\n2. **Reference Points**: The model uses 3*token_self as the fair share. Perhaps participants have different reference points, such as equal split (combined_earning/2) or a combination of contribution and equal split. Adding a parameter to weight between these reference points could help.\n\n3. **Loss Aversion**: Participants might be more sensitive to losses (getting less than fair) than gains. Introducing a loss aversion parameter that amplifies the negative deviations could improve fit.\n\n4. **Intercept Term**: Including a baseline tendency to accept or reject (e.g., a constant term in the utility) might capture general response biases not explained by fairness or inequity.\n\n5. **Separate Parameters for Advantageous and Disadvantageous Inequity**: The current model uses a single beta for the difference (split_opp - split_self), which could be positive or negative. But people might react differently to being ahead vs. behind. Splitting beta into two parameters (e.g., beta_adv for when split_self > split_opp and beta_dis for the opposite) could capture this.\n\n6. **Interaction with Trial Type**: The trial_type variable indicates whether contributions were equal, opponent more, or participant more. Including interaction terms with trial_type might capture how fairness perceptions vary in these contexts.\n\n7. **Alternative Fairness Calculations**: The model assumes fairness is strictly proportional to contribution. Maybe participants consider other factors, like the ratio of contributions or absolute differences. For example, (token_self - token_opp) could be a term affecting fairness perception.\n\n8. **Temperature Parameter in Logistic Function**: The current model uses a logistic function with temperature 1. Adding a temperature parameter could allow varying decision noise, improving fit.\n\nHowever, adding parameters increases model complexity, which could hurt BIC unless the fit improves enough. The challenge is to find a balance. Since the previous model had two parameters, maybe adding one more could be justified if it significantly boosts accuracy and recovery.\n\nAnother angle: The current model's terms might not be scaled properly. For example, split_self - 3*token_self could be a large value compared to split_opp - split_self, leading to one parameter dominating. Standardizing the terms or introducing scaling factors might help.\n\nAlso, the model doesn't account for the total combined earning. Maybe participants care about the absolute amount they receive relative to the total. For example, split_self/combined_earning could be a term, but that's similar to splitperc_self, which is already a variable. However, including it might interact with fairness perceptions.\n\nIn the next instructions, I should encourage exploring these possibilities. Specifically, suggest considering non-linear interactions, alternative reference points, and separating advantageous/disadvantageous inequity. Also, mention the possibility of adding an intercept or temperature parameter. However, caution against overcomplicating the model without justification. Emphasize testing models that address potential covariance issues (e.g., orthogonal terms) and improve parameter identifiability.\n\nAdditionally, since the previous model had moderate parameter recovery for alpha, suggest ways to make the alpha term more identifiable. Maybe by including a term that only affects alpha's component, reducing its correlation with beta.\n\nFinally, encourage creativity but stress the importance of maintaining a balance between complexity and identifiability. Maybe suggest models with 2-3 parameters, exploring different psychological mechanisms beyond the initial fairness and inequity factors.\n</think>\n\n**Revised Instructions for Run 2/200:**\n\nDesign a model that explicitly addresses *non-linear interactions* between fairness and inequity components. Consider these enhancements:  \n1. **Mechanistic Innovations**  \n   - Explore asymmetric responses to advantageous vs. disadvantageous inequity (e.g., separate parameters for split_opp > split_self vs. split_self > split_opp)  \n   - Test hybrid fairness norms (e.g., weighted combinations of contribution-based and equal-split fairness)  \n   - Introduce a loss aversion coefficient for deviations below contribution-based fairness  \n\n2. **Identifiability Constraints**  \n   - Use orthogonal utility components (e.g., interaction terms that reduce covariance between parameters)  \n   - If adding parameters, ensure they control distinct behavioral phenomena (e.g., baseline acceptance bias vs. context-sensitive fairness)  \n\n3. **Parameterization Guidance**  \n   - Prioritize models with 2-3 parameters maximum  \n   - Allow non-linear transformations (e.g., sigmoidal scaling of fairness deviations)  \n   - Consider bounded parameters with psychological interpretability (e.g., [0,1] for weighting terms)  \n\n4. **Behavioral Plausibility**  \n   - Explicitly model how trial_type (contribution asymmetry) modulates fairness expectations  \n   - Account for magnitude effects (e.g., proportional vs. absolute inequity)  \n\n*Key Objective:* Improve parameter recovery (target r > 0.8) while maintaining BIC <45 through strategic non-linearities that better match human sensitivity thresholds.\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal. The model needs to focus on responder behavior, use the given variables appropriately, and ensure parameter recovery is possible. \n\nFirst, I need to identify which variables are relevant. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of accepting the proposal. \n\nFrom the dataset, key variables for the responder's decision might include:\n- split_self: the proposed share for the participant\n- split_opp: the proposed share for the opponent\n- token_self: participant's contribution (tokens found)\n- token_opp: opponent's contribution\n- combined_earning: total money, which is 3*(token_self + token_opp)\n- trial_type: whether contributions are equal, opponent more, or participant more\n\nThe model needs to calculate the utility of accepting the offer. The utility should be a function that combines fairness considerations and inequity aversion. \n\nFairness could be based on the participant's contribution. Since each token is \u00a33, the fair share for the participant would be 3*token_self. The difference between the proposed split_self and this fair share might influence utility. If split_self is less than 3*token_self, the participant might perceive it as unfair.\n\nInequity aversion refers to disliking unequal outcomes between oneself and others. The difference between split_opp and split_self could matter here. If the opponent is getting more (split_opp > split_self), the participant might have negative utility.\n\nSo, the utility function could have two components: one for deviation from the fair share and another for inequity. These components would be weighted by parameters (alpha and beta) that need to be learned.\n\nThe utility U could be modeled as:\nU = alpha*(split_self - 3*token_self) + beta*(split_self - split_opp)\n\nIf U is positive, the participant is more likely to accept; if negative, more likely to reject. The probability of accepting can be calculated using a logistic function: P(accept) = 1 / (1 + exp(-U)).\n\nBut wait, the problem states that the utility should predict the probability such that utility less than 0 corresponds to less than 50% chance. The logistic function with temperature 1 (which is the standard logistic function) does this, so that's correct.\n\nNow, parameters alpha and beta need to be bounded. Alpha could be positive since getting more than the fair share (split_self > 3*token_self) should increase utility. But maybe participants are sensitive to both over and under, so alpha could be any real number. However, to keep it bounded, perhaps alpha is constrained between -a and a. But the problem says bounds should be generous but finite. Let's say alpha is in [-10, 10]. Similarly for beta: if beta is positive, it means participants dislike inequity where the opponent gets more (since (split_self - split_opp) would be negative in that case, reducing utility). Alternatively, beta could be negative to penalize when split_opp > split_self. Hmm, maybe beta should be negative. Wait, let's think:\n\nIf split_self - split_opp is negative (opponent gets more), then a negative beta would make that term positive, increasing utility? Wait, no. Let's clarify. Suppose beta is a negative parameter. Then, if (split_self - split_opp) is negative (opponent gets more), multiplying by beta (negative) gives a positive contribution to utility. But that would mean the participant is happier when the opponent gets more, which contradicts inequity aversion. So perhaps the term should be (split_opp - split_self), and beta is negative. So:\n\nU = alpha*(split_self - fair_share) + beta*(split_opp - split_self)\n\nIf beta is negative, then when split_opp > split_self (opponent gets more), the term (split_opp - split_self) is positive, multiplied by beta (negative) gives a negative contribution, reducing utility. That makes sense for inequity aversion. So beta should be negative. But how to bound it? Let's say beta is in [-5, 0], for example.\n\nAlternatively, maybe the model should use absolute values or different formulations. But the key is to have parameters that can be recovered and make sense psychologically.\n\nAnother consideration: the fair share might not be exactly 3*token_self. Maybe participants have a different notion of fairness, like a combination of their contribution and equal split. But given the variables, using 3*token_self as the fair share is straightforward and aligns with the description that combined_earning is 3*(token_self + token_opp). So the fair share based on contribution would be (token_self / (token_self + token_opp)) * combined_earning, which simplifies to 3*token_self. So that's correct.\n\nNow, the variables in the model:\n\n- alpha: sensitivity to deviation from contribution-based fairness. If alpha is positive, participants prefer getting more than their fair share. If negative, they might prefer less (unlikely, but the parameter can be learned).\n\n- beta: sensitivity to inequity (difference between opponent's share and own share). As discussed, beta is expected to be negative, as participants dislike inequity where the opponent gets more.\n\nThese parameters need to be learned, with bounds. Let's set alpha between -10 and 10, beta between -5 and 0. These are generous but finite.\n\nThe utility function is then:\n\nU = alpha*(split_self - 3*token_self) + beta*(split_opp - split_self)\n\nThe probability of accepting is logistic(U). The model predicts 'accept' based on this probability.\n\nNow, check if all variables used are from the dataset. split_self, split_opp, token_self are all available. The other terms (3*token_self) are calculated from token_self, which is given.\n\nVariables in the dataset that are used: split_self, split_opp, token_self.\n\nVariables not used: trial_type, trial_role (but we're only modeling responder behavior, so trial_role is 1), token_opp, combined_earning, etc. But combined_earning is 3*(token_self + token_opp), which is already accounted for in the fair share calculation. However, in the model as formulated, combined_earning isn't directly used because the fair share is 3*token_self. Wait, but the fair share based on contributions would be (token_self / (token_self + token_opp)) * combined_earning. Since combined_earning is 3*(token_self + token_opp), this simplifies to 3*token_self. So the model correctly uses the contribution-based fair share without needing combined_earning as a separate variable.\n\nThus, the model uses only the necessary variables from the dataset.\n\nNow, variable descriptions:\n\n- alpha: learnable parameter, sensitivity to deviation from fair share (based on contribution). Bounds: [-10, 10].\n\n- beta: learnable parameter, sensitivity to inequity (opponent's share minus own share). Bounds: [-5, 0].\n\n- split_self: from data, proposed share for participant.\n\n- token_self: from data, participant's tokens.\n\n- split_opp: from data, proposed share for opponent.\n\nThe utility U is calculated from these variables and parameters.\n\nThe target variable is 'accept', which is binary. The model outputs the probability of accepting via logistic(U), and the actual prediction is based on that probability.\n\nNow, formalizing this into the required tags.\n</think>\n\n<MODEL>\nU = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviation from contribution-based fairness (3*token_self = fair share)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Inequity aversion sensitivity (penalty for opponent receiving more)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed \u00a3 amount for participant (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed \u00a3 amount for opponent (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA dual-component utility model where acceptance decisions depend on 1) deviation from contribution-based fairness (3\u00d7 tokens contributed) and 2) inequity aversion comparing shares. Uses two psychologically interpretable parameters (fairness sensitivity \u03b1 and inequity aversion \u03b2) with orthogonalized terms to improve parameter recovery. Directly maps to the task's token-to-currency conversion logic.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['alpha', 'beta']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviation from contribution-based fairness (3*token_self = fair share)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Inequity aversion sensitivity (penalty for opponent receiving more)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed \\u00a3 amount for participant (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed \\u00a3 amount for opponent (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, alpha=0, beta=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        split_opp = trial.get(\"split_opp\", 0)\n\n        U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\n        model_predictions.append(U)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n",
      "timestamp": 1744015403.082459
    }
  ],
  "learnable_parameters": {
    "alpha": {
      "description": "Sensitivity to deviation from contribution-based fairness (3*token_self = fair share)",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Inequity aversion sensitivity (penalty for opponent receiving more)",
      "range": {
        "min": -5,
        "max": 0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "alpha": {
      "description": "Sensitivity to deviation from contribution-based fairness (3*token_self = fair share)",
      "range": {
        "min": -10,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "beta": {
      "description": "Inequity aversion sensitivity (penalty for opponent receiving more)",
      "range": {
        "min": -5,
        "max": 0,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed \u00a3 amount for participant (data variable)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Participant's token contribution (data variable)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "split_opp": {
      "description": "Proposed \u00a3 amount for opponent (data variable)",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A dual-component utility model where acceptance decisions depend on 1) deviation from contribution-based fairness (3\u00d7 tokens contributed) and 2) inequity aversion comparing shares. Uses two psychologically interpretable parameters (fairness sensitivity \u03b1 and inequity aversion \u03b2) with orthogonalized terms to improve parameter recovery. Directly maps to the task's token-to-currency conversion logic.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal. The model needs to focus on responder behavior, use the given variables appropriately, and ensure parameter recovery is possible. \n\nFirst, I need to identify which variables are relevant. The target variable is \"accept\", which is binary (1 or 0). The model should predict this based on the utility of accepting the proposal. \n\nFrom the dataset, key variables for the responder's decision might include:\n- split_self: the proposed share for the participant\n- split_opp: the proposed share for the opponent\n- token_self: participant's contribution (tokens found)\n- token_opp: opponent's contribution\n- combined_earning: total money, which is 3*(token_self + token_opp)\n- trial_type: whether contributions are equal, opponent more, or participant more\n\nThe model needs to calculate the utility of accepting the offer. The utility should be a function that combines fairness considerations and inequity aversion. \n\nFairness could be based on the participant's contribution. Since each token is \u00a33, the fair share for the participant would be 3*token_self. The difference between the proposed split_self and this fair share might influence utility. If split_self is less than 3*token_self, the participant might perceive it as unfair.\n\nInequity aversion refers to disliking unequal outcomes between oneself and others. The difference between split_opp and split_self could matter here. If the opponent is getting more (split_opp > split_self), the participant might have negative utility.\n\nSo, the utility function could have two components: one for deviation from the fair share and another for inequity. These components would be weighted by parameters (alpha and beta) that need to be learned.\n\nThe utility U could be modeled as:\nU = alpha*(split_self - 3*token_self) + beta*(split_self - split_opp)\n\nIf U is positive, the participant is more likely to accept; if negative, more likely to reject. The probability of accepting can be calculated using a logistic function: P(accept) = 1 / (1 + exp(-U)).\n\nBut wait, the problem states that the utility should predict the probability such that utility less than 0 corresponds to less than 50% chance. The logistic function with temperature 1 (which is the standard logistic function) does this, so that's correct.\n\nNow, parameters alpha and beta need to be bounded. Alpha could be positive since getting more than the fair share (split_self > 3*token_self) should increase utility. But maybe participants are sensitive to both over and under, so alpha could be any real number. However, to keep it bounded, perhaps alpha is constrained between -a and a. But the problem says bounds should be generous but finite. Let's say alpha is in [-10, 10]. Similarly for beta: if beta is positive, it means participants dislike inequity where the opponent gets more (since (split_self - split_opp) would be negative in that case, reducing utility). Alternatively, beta could be negative to penalize when split_opp > split_self. Hmm, maybe beta should be negative. Wait, let's think:\n\nIf split_self - split_opp is negative (opponent gets more), then a negative beta would make that term positive, increasing utility? Wait, no. Let's clarify. Suppose beta is a negative parameter. Then, if (split_self - split_opp) is negative (opponent gets more), multiplying by beta (negative) gives a positive contribution to utility. But that would mean the participant is happier when the opponent gets more, which contradicts inequity aversion. So perhaps the term should be (split_opp - split_self), and beta is negative. So:\n\nU = alpha*(split_self - fair_share) + beta*(split_opp - split_self)\n\nIf beta is negative, then when split_opp > split_self (opponent gets more), the term (split_opp - split_self) is positive, multiplied by beta (negative) gives a negative contribution, reducing utility. That makes sense for inequity aversion. So beta should be negative. But how to bound it? Let's say beta is in [-5, 0], for example.\n\nAlternatively, maybe the model should use absolute values or different formulations. But the key is to have parameters that can be recovered and make sense psychologically.\n\nAnother consideration: the fair share might not be exactly 3*token_self. Maybe participants have a different notion of fairness, like a combination of their contribution and equal split. But given the variables, using 3*token_self as the fair share is straightforward and aligns with the description that combined_earning is 3*(token_self + token_opp). So the fair share based on contribution would be (token_self / (token_self + token_opp)) * combined_earning, which simplifies to 3*token_self. So that's correct.\n\nNow, the variables in the model:\n\n- alpha: sensitivity to deviation from contribution-based fairness. If alpha is positive, participants prefer getting more than their fair share. If negative, they might prefer less (unlikely, but the parameter can be learned).\n\n- beta: sensitivity to inequity (difference between opponent's share and own share). As discussed, beta is expected to be negative, as participants dislike inequity where the opponent gets more.\n\nThese parameters need to be learned, with bounds. Let's set alpha between -10 and 10, beta between -5 and 0. These are generous but finite.\n\nThe utility function is then:\n\nU = alpha*(split_self - 3*token_self) + beta*(split_opp - split_self)\n\nThe probability of accepting is logistic(U). The model predicts 'accept' based on this probability.\n\nNow, check if all variables used are from the dataset. split_self, split_opp, token_self are all available. The other terms (3*token_self) are calculated from token_self, which is given.\n\nVariables in the dataset that are used: split_self, split_opp, token_self.\n\nVariables not used: trial_type, trial_role (but we're only modeling responder behavior, so trial_role is 1), token_opp, combined_earning, etc. But combined_earning is 3*(token_self + token_opp), which is already accounted for in the fair share calculation. However, in the model as formulated, combined_earning isn't directly used because the fair share is 3*token_self. Wait, but the fair share based on contributions would be (token_self / (token_self + token_opp)) * combined_earning. Since combined_earning is 3*(token_self + token_opp), this simplifies to 3*token_self. So the model correctly uses the contribution-based fair share without needing combined_earning as a separate variable.\n\nThus, the model uses only the necessary variables from the dataset.\n\nNow, variable descriptions:\n\n- alpha: learnable parameter, sensitivity to deviation from fair share (based on contribution). Bounds: [-10, 10].\n\n- beta: learnable parameter, sensitivity to inequity (opponent's share minus own share). Bounds: [-5, 0].\n\n- split_self: from data, proposed share for participant.\n\n- token_self: from data, participant's tokens.\n\n- split_opp: from data, proposed share for opponent.\n\nThe utility U is calculated from these variables and parameters.\n\nThe target variable is 'accept', which is binary. The model outputs the probability of accepting via logistic(U), and the actual prediction is based on that probability.\n\nNow, formalizing this into the required tags.\n</think>\n\n<MODEL>\nU = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"alpha\": {\n      \"description\": \"Sensitivity to deviation from contribution-based fairness (3*token_self = fair share)\",\n      \"range\": {\n        \"min\": -10,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"beta\": {\n      \"description\": \"Inequity aversion sensitivity (penalty for opponent receiving more)\",\n      \"range\": {\n        \"min\": -5,\n        \"max\": 0,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed \u00a3 amount for participant (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Participant's token contribution (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"split_opp\": {\n      \"description\": \"Proposed \u00a3 amount for opponent (data variable)\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA dual-component utility model where acceptance decisions depend on 1) deviation from contribution-based fairness (3\u00d7 tokens contributed) and 2) inequity aversion comparing shares. Uses two psychologically interpretable parameters (fairness sensitivity \u03b1 and inequity aversion \u03b2) with orthogonalized terms to improve parameter recovery. Directly maps to the task's token-to-currency conversion logic.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\nSummary: A dual-component utility model where acceptance decisions depend on 1) deviation from contribution-based fairness (3\u00d7 tokens contributed) and 2) inequity aversion comparing shares. Uses two psychologically interpretable parameters (fairness sensitivity \u03b1 and inequity aversion \u03b2) with orthogonalized terms to improve parameter recovery. Directly maps to the task's token-to-currency conversion logic.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [],
  "current_retry": 0,
  "simulation_code": "def simulate_model(trial_data, alpha=0, beta=0):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        split_opp = trial.get(\"split_opp\", 0)\n\n        U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\n        model_predictions.append(U)\n    return model_predictions",
  "total_retries": 0,
  "skipped_participants": [],
  "num_skipped_participants": 0,
  "overall_accuracy": 0.6733821733821734,
  "fitting_results": [
    {
      "alpha": 0.0015281363927410062,
      "beta": -5.0,
      "success": true,
      "log_likelihood": -2.0821757198577306,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.2627005469234376,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.431437028314875,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.2929819798091149,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.93164743850439,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3771431529952203,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.48064997583258,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.4987966936148177,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -18.394471710888524,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.11434269157053921,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.402921678448667,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086781761156022,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943456,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.09604805730941601,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.560665573400307,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086746724877249,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445955405,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5469995682070792,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.610930219523404,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.48118573976529433,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -18.68842373446679,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5271916822142372,
      "beta": -0.5849570845033916,
      "success": true,
      "log_likelihood": -7.086838280368764,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5418784418656328,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.692595156883094,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086783317822947,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943556,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086781580196855,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943448,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086783716873257,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.9820834459435845,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086776228278209,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943537,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.2700719631492,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.31156806667825,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.2877815578599903,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.018760345917336,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.7086785414401535,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943774,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.23439228950859395,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.878551886190166,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.22984104643415773,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.948185745109306,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.1552651777063335,
      "beta": -0.3125745376074267,
      "success": true,
      "log_likelihood": -19.34667703645184,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.1803496744122226,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.654360845302953,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.37391617228256707,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.536979058438483,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.1445588756277526,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.092498574857483,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.12207146812435374,
      "beta": -0.048042492528044656,
      "success": true,
      "log_likelihood": -23.289172605125685,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.151064660811284,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -10.884737750887215,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.3117209525638482,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.61425364392183,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.11434267654624566,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.40292167842147,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.708678402531286,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.982083445943618,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8611111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.001528032956511676,
      "beta": -5.0,
      "success": true,
      "log_likelihood": -2.08217571985772,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.4324465323897324,
      "beta": -0.408166639934764,
      "success": true,
      "log_likelihood": -20.239470972152827,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3045225366324074,
      "beta": -0.07100251694021874,
      "success": true,
      "log_likelihood": -19.55055000677309,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.708678146464745,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -7.9820834459434415,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -3.221028307850451e-08,
      "beta": -0.0060859948459221465,
      "success": true,
      "log_likelihood": -24.94782174490065,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.039571173365997914,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.8851449542742,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.32565915823939773,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.37526648496079,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.04824617975852373,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.852215955119096,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.4726886884143012,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -18.831500337531168,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.13688482932842147,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.17692596014502,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.9152645736806628,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -12.878204230015156,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8333333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.9590797052664788,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -12.456654915125275,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -4.958318818621435e-07,
      "beta": -0.09044013571348714,
      "success": true,
      "log_likelihood": -23.827806243227005,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.11991263919677608,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.35021576085138,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.11249497810720765,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.419934451701465,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.125672079189557,
      "beta": -0.0642803738980376,
      "success": true,
      "log_likelihood": -22.793574285866697,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.27041929352788,
      "beta": -0.029057008816171556,
      "success": true,
      "log_likelihood": -21.45567403312066,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.5793651749943977,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.104286910978477,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6944444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.11180447318149603,
      "beta": -0.07736204657821223,
      "success": true,
      "log_likelihood": -24.80236627986326,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4166666666666667,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.04303636013290801,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.87275398699839,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.4548030188509991,
      "beta": -0.9850398471039222,
      "success": true,
      "log_likelihood": -8.047729140999445,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.11782915149022463,
      "beta": -0.1428320769233252,
      "success": true,
      "log_likelihood": -23.89606937805979,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.22433279104218637,
      "beta": -0.11526846332458417,
      "success": true,
      "log_likelihood": -24.617008648249552,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.3903348365330504,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -20.2504296895455,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8177290302355661,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.915564891139633,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8634570651302328,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.411480246844725,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.8885078228910724,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -13.148725351182133,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -7.206371254749265e-08,
      "beta": -1.0186741486320485,
      "success": true,
      "log_likelihood": -5.5878878565586545,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.26269858566906795,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.43143702840248,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.060465845861372776,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.79515053286388,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.32002590590240626,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -21.472117164160732,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.0015279060040922596,
      "beta": -5.0,
      "success": true,
      "log_likelihood": -2.082175719857725,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 1.0,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -6.577546342690586e-07,
      "beta": -0.11988253681128064,
      "success": true,
      "log_likelihood": -23.072377984642955,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.555084520606356,
      "beta": -0.22703878937420663,
      "success": true,
      "log_likelihood": -12.0472997077498,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.8055555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.0681711737212436,
      "beta": -0.8436197908268831,
      "success": true,
      "log_likelihood": -35.032774632052096,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.44833780549640706,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -19.24584132152089,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7222222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.26514372232487954,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.39184888035497,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -4.0046322450162585e-08,
      "beta": -0.0590377906122414,
      "success": true,
      "log_likelihood": -24.453851614975388,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6666666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.546999463032328,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.610930219061213,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 10.0,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -1.490098315440448,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.5499285266982528,
      "beta": -1.151368808181819,
      "success": true,
      "log_likelihood": -6.828158666715425,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.21206309775169993,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.213262138957113,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.20771874936601153,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -23.27622845393284,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.236946645767891e-07,
      "beta": -0.06120339550512889,
      "success": true,
      "log_likelihood": -24.41777977982234,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5555555555555556,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.04650808621366954,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.859322493518214,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.5967008307710299,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -16.839704783971097,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.1895737702294264e-06,
      "beta": -0.8746384941534718,
      "success": true,
      "log_likelihood": -6.717079523596017,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.06573425390349921,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.76675628383548,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5277777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.001527900270293627,
      "beta": -5.0,
      "success": true,
      "log_likelihood": -2.0821757198577258,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -1.1594733530871757e-07,
      "beta": -0.05580768854753422,
      "success": true,
      "log_likelihood": -24.50553045717759,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.5833333333333334,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.683256322290616,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -15.595101190414258,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -7.543187051050178e-07,
      "beta": -0.7225071763435996,
      "success": true,
      "log_likelihood": -8.37993529853897,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.8888888888888888,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.22983955085863178,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -22.94818574545743,
      "optimization_message": "CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH",
      "prediction_type": "utility",
      "accuracy": 0.6111111111111112,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.025760916529140015,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.92433667937856,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4444444444444444,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.8807538356662762,
      "beta": -0.8361946053354715,
      "success": true,
      "log_likelihood": -4.334243059647262,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.9166666666666666,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.01029291921783076,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.948667181602985,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.4722222222222222,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 0.7673342954133063,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -14.509544313535564,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.7777777777777778,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.5469998714172136,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -17.6109302146069,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.75,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": 1.266122066792351e-07,
      "beta": -0.11988217099823499,
      "success": true,
      "log_likelihood": -23.072377984704353,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.3888888888888889,
      "participant_id": null,
      "n_trials": 36
    },
    {
      "alpha": -0.09786068710790301,
      "beta": 0.0,
      "success": true,
      "log_likelihood": -24.546122417652867,
      "optimization_message": "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL",
      "prediction_type": "utility",
      "accuracy": 0.6388888888888888,
      "participant_id": null,
      "n_trials": 36
    }
  ],
  "parameter_recovery": {
    "correlations": {
      "alpha": {
        "r": 0.30048767973188534,
        "p": 0.3988879475179925
      },
      "beta": {
        "r": 0.6177415074295759,
        "p": 0.05701554804671924
      }
    },
    "plots_directory": "param_recovery_plots"
  },
  "average_bic": 42.825476529908755,
  "bic_results": {
    "average_bic": 42.825476529908755,
    "individual_bics": [
      11.331389316627682,
      52.02991193354197,
      51.030332753920995,
      48.12833782857738,
      43.95598129868927,
      55.97288123380955,
      23.13120476879913,
      56.28836902371283,
      23.131204768823032,
      42.388898315959025,
      44.5438853458458,
      21.340714437649748,
      42.552228190678406,
      23.131204768799332,
      23.131204768799115,
      23.13120476879939,
      23.131204768799293,
      51.79017401026872,
      51.20455856874689,
      23.13120476879977,
      52.92414164929255,
      53.06340936713083,
      45.8603919498159,
      54.475759567518125,
      48.240995993789184,
      55.352035026627185,
      53.74538308716359,
      28.936513378686648,
      50.39554516475588,
      55.97288123375516,
      23.131204768799456,
      11.33138931662766,
      47.64597982121787,
      46.2681378904584,
      23.1312047687991,
      57.06268136671352,
      56.93732778546062,
      49.9175708468338,
      56.87146978715041,
      44.83003855197455,
      55.52088979720226,
      32.92344633694253,
      32.08034770716277,
      54.82265036336623,
      55.86746939861498,
      56.00690678031515,
      52.75418644864561,
      50.078385943153535,
      41.37561169886917,
      56.77177043663874,
      56.912545850909,
      23.262496158911112,
      54.959176633031795,
      56.40105517341132,
      47.667897256003215,
      34.99816765919149,
      33.98999837060167,
      33.464488579276484,
      18.34281359002953,
      52.02991193371718,
      56.757338942639976,
      50.11127220523368,
      11.33138931662767,
      53.31179384619813,
      31.26163729241182,
      77.23258714101641,
      45.658720519953995,
      51.95073563762216,
      56.074741106862994,
      42.388898315034645,
      10.147234507793115,
      20.82335521034307,
      53.593562154826444,
      53.7194947847779,
      56.0025974365569,
      56.885682863948645,
      40.84644744485441,
      20.601196924104254,
      56.70055044458318,
      11.331389316627671,
      56.178098791267395,
      38.357240257740735,
      23.92690847399016,
      53.06340936782708,
      57.015711235669336,
      15.835523996206744,
      57.06437224011819,
      36.186126503983346,
      42.388898306126016,
      53.311793846320924,
      56.25928271221795
    ],
    "group_enabled": false,
    "group_bics": null,
    "num_parameters": 2,
    "prediction_type": "utility",
    "bic_formula": "BIC = -2 * log_likelihood + k * log(n_trials)"
  },
  "recovery_summary": "Parameter Recovery:\n- alpha: r = 0.300\n- beta: r = 0.618",
  "previous_models": [
    "Specification: U = alpha * (split_self - 3 * token_self) + beta * (split_opp - split_self)\nSummary: A dual-component utility model where acceptance decisions depend on 1) deviation from contribution-based fairness (3\u00d7 tokens contributed) and 2) inequity aversion comparing shares. Uses two psychologically interpretable parameters (fairness sensitivity \u03b1 and inequity aversion \u03b2) with orthogonalized terms to improve parameter recovery. Directly maps to the task's token-to-currency conversion logic.\nTarget Variable: accept\nPrediction Type: utility\nBIC: 42.825476529908755\nOverall Accuracy: 0.6734\n\nParameter Recovery:\n- alpha: r = 0.300\n- beta: r = 0.618"
  ]
}