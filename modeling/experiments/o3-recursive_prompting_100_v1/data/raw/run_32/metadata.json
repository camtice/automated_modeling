{
  "task_description": "In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "output_description": "Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.",
  "instructions": "<think>\nOkay, let's analyze the previous run. The model achieved a BIC of 32.76 and an accuracy of 80.7%, which is pretty good. The parameter recovery for alpha was excellent (0.914), but beta was lower (0.483). The main issue here is improving beta's recovery and possibly further lowering BIC.\n\nThe previous model used a loss term with a fixed exponent (1.5) and context-aware normalization for inequity. The high alpha recovery suggests the loss component is well-specified, but beta's lower recovery indicates the inequity term might not be capturing the right dynamics. Maybe the trial_type-dependent normalization isn't effective enough, or the inequity term isn't orthogonal to the loss term.\n\nTo improve beta's recovery, perhaps introduce a non-linear transformation for the inequity term. For example, using a sigmoid function to cap extreme values, which could reduce noise in parameter estimation. Alternatively, adjust the normalization method\u2014maybe scaling by the square root of combined_earning instead of the raw value to account for diminishing sensitivity to larger pots.\n\nAnother angle: The trial_type modulation in the inequity penalty might not be strong enough. Instead of a binary switch between 3*token_self and combined_earning, maybe use a continuous modulation based on the participant's contribution ratio. For instance, weight the inequity term by (token_self / (token_self + token_opp)) when trial_type is 3, making the penalty proportional to their contribution share.\n\nAlso, consider adding an interaction term between the loss and inequity components. For example, participants might be more sensitive to inequity when they're already receiving less than their fair share. This could be modeled by multiplying the inequity term by the loss indicator (1 if loss >0, else 0), enhancing identifiability of beta in loss scenarios.\n\nTo further lower BIC, reduce the number of parameters if possible. The current model has alpha, lambda, and beta. If lambda and alpha can be combined or one can be fixed based on literature (e.g., setting the loss exponent to a standard value from prospect theory), that might help without sacrificing much accuracy.\n\nAdditionally, explore dynamic bounds for parameters based on trial_type. For example, in trials where the participant contributed more, beta's upper bound could be higher, allowing the model to capture greater sensitivity in those cases.\n\nFinally, test a hybrid approach where the gain term is not linear but has a concave function (like a square root) to align with prospect theory's diminishing sensitivity to gains. This could improve the model's fit and parameter recovery by better capturing human decision-making patterns.\n</think>\n\n**Instructions for Run 32/200:**  \nDesign a *neurobehavioral hybrid model* with these innovations:  \n\n1. **Sigmoid-Capped Inequity**  \n   - Transform opponent advantage into bounded utility space:  \n     ```  \n     inequity_penalty = \u03b2 * tanh( (split_opp - split_self) / (combined_earning**0.75) )  \n     ```  \n     Compress extreme values while preserving sign, using \u221a(C) scaling for magnitude invariance.  \n\n2. **Contribution-Weighted Loss Context**  \n   - Amplify loss sensitivity when participants contributed majority tokens:  \n     ```  \n     loss_term = \u03bb * [max(3*token_self - split_self, 0)]^1.33 * (1 + token_self/(token_self + token_opp))  \n     ```  \n     Convex loss curvature (\u03c1=1.33) with dynamic weighting by contribution proportion.  \n\n3. **Dynamic Parameter Bounds**  \n   - Confine \u03b2 \u2208 [0,15] when trial_type=3 vs [0,5] otherwise  \n   - Lock \u03bb \u2208 [1.5,4] using meta-analytic loss aversion priors  \n\n**Identifiability Boosters:**  \n- Fix gain linearity (\u03b1 \u2208 [0,2]) but enable loss-gain crossover at 85% fair share  \n- Add asymmetric utility floor: U \u2265 -10 * log(combined_earning)  \n\n**Success Targets:**  \n- Achieve \u03b2 recovery r >0.85 via sigmoid compression  \n- Drive BIC <30 through hybrid gain-loss architecture  \n- Target 85%+ accuracy via context-aware nonlinearities",
  "dataset_info": "\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276",
  "complete_model_interaction": [
    {
      "solver": "model_design_solver",
      "input": "Task Description: In the  experiment, each participant is given 36 different proposals to respond to. Each is designated by a trial number in the data set This gives 36 instances for the learnable parameters to be trained. There is also a pretask where the participant finds a number of tokens that correspond to their contribution to the group. This is designated by the variable \"token_self\". The other variable, \"token_opp\", is the number of tokens found the opponent's and represents the opoonents contribution to the shared pot that will be later divided by the opponent.\n\nNote that in each trial there is a variable amount of money in the combined earning, so that two equal split_self variables do not represent the same \"fairness\".\n\nBelow is the description of each variable in the dataset, which will be followed by information about the data type of the variable:\n\ntrial_type = how much was the contribution [1 = equal, 2 = opponent more, 3 = participant more]\ntrial_role = the role of the participant [1 = responder, 2 = proposer]\ntoken_opp = number of tokens found by the opponent\ntoken_self = number of tokens found by the participant\ncombined_earning = amount of money earned in total (note that each token found is \u00a33)\nsplit_opp = the proposed share of the opponent (in \u00a3)\nsplit_self = the proposed share for the participant (in \u00a3)\nsplitperc_opp = same but in %\nsplit_perc_self = same but in %\naccept = whether the participant responded accept (1) or reject (0)\naccepted_amount = if accepted, what is the amount gain (in \u00a3)\naccepted_perc = same as above but in %\nproposed_perc = when participant is the proposer, what is the % proposed to the opponent\n\nDataset:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\nDesired Output Specification: Design a computational model for the described task. Your model should utilyze the given variables appropriately (but not necessarily all unless otherwise specified). \n\nThe model should:\n1. Predict only responder behavior (should target \"accept = whether the participant responded accept (1) or reject (0)\")\nwill have to pass parameter recovery tests. This should be roughly equal in priority to accuracy.\n2. Be applicable to the dataset given within the task description (i.e. the model should be able\nto be run using only the provided dataset structure).\n4. Predict utility, where less than 0 is less than 50% likely.\n\nFor any learnable parameters in your model, you must specify finite numerical bounds (it just can not be infinity) in the variable descriptions. However, this bound should be generous. The utility variable may be unbounded (-inf to inf).\n\nThen, provide your formal mathematical model between <MODEL> tags, followed by variable descriptions between <VARIABLES> tags. Additionally, specify the target variable that your model will predict. This should be one of the variables from the dataset above. Enclose it in <target_variable> tags.\nFor example: <target_variable>accept</target_variable> if your model is predicting whether a participant accepts or rejects a proposal. \n\nUse clear mathematical notation and ensure each variable is fully described. Every variable must be utilized within the mathematical formula provided between <MODEL> and </MODEL>, and only strictly the mathematical formula should be provided between these tags with no filler words or descriptions. For variable descriptions, provide them in a JSON format with the following structure: <VARIABLES> Bounds are by default inclusive. Please spell out the greek variable names instead of using the symbols. Finally, you should provide a short description of the model in the summary tags <SUMMARY> </SUMMARY>. This will be used to compare different computational models of the task; it should be concise and purely descriptive. Do not include generic information about the name of the tasks, since that is implied. \n\n{\n  \"variables\": {\n    \"variable_name\": {\n      \"description\": \"Clear description\",\n      \"range\": {\n        \"min\": value,\n        \"max\": value,\n        \"inclusive_min\": boolean,\n        \"inclusive_max\": boolean\n      },\n      \"distribution\": {\n        \"type\": \"distribution type\",\n        \"parameters\": {}\n      },\n      \"learnable\": boolean,\n      \"source\": \"learnable/data/calculated\"\n    }\n  }\n}\n</VARIABLES>\n\nExample #1: \n<EXAMPLE>\n(Model of a Random Choice Task):\nLet me think through this step by step...\n[your reasoning here]\n\n<MODEL>\nU_i = \u03b2 + \u03b5E + \u03b7N\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U_i\": {\n      \"description\": \"Utility of choosing action i\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"beta\": {\n      \"description\": \"Base tendency parameter (inherent preference)\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"epsilon\": {\n      \"description\": \"Environmental sensitivity parameter\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"E\": {\n      \"description\": \"Environmental cue value\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"eta\": {\n      \"description\": \"Noise parameter\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 1,\n        \"exclusive_max\": true\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"N\": {\n      \"description\": \"Random noise drawn from normal distribution N(0,1)\",\n      \"distribution\": {\n        \"type\": \"normal\",\n        \"mean\": 0,\n        \"std\": 1\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    }\n  }\n}\n</VARIABLES>\n<SUMMARY>\nA linear utility model combining base preference, environmental influence, and stochastic noise. The model uses two learnable parameters: a base tendency parameter (\u03b2) constrained to [0,1] and an unconstrained environmental sensitivity parameter (\u03b5). Environmental cues and normally distributed noise modify the base utility, allowing for both systematic and random variation in choice behavior.\n</SUMMARY>\n</EXAMPLE>\n\nPlease be sure to provide the mathematical formula for the model between <MODEL> and </MODEL>, and the variable descriptions between <VARIABLES> and </VARIABLES>. No description of the model should be provided within the <MODEL> tags.\n\nThe parameter names you choose in your <VARIABLES> section will be used exactly as specified in subsequent code generation. Please choose clear, non-reserved parameter names that can be used directly in Python code. For example, avoid Python reserved words like 'lambda' and use alternatives like 'learning_rate' or 'lambda_param'.\n\nModel Type: \nYour model should predict the utility of a binary choice. The utility will be converted to a probability using a logistic function with temperature 1, and then used to predict binary decisions.\n\n\nInstructions: <think>\nOkay, let's analyze the previous run. The model achieved a BIC of 32.76 and an accuracy of 80.7%, which is pretty good. The parameter recovery for alpha was excellent (0.914), but beta was lower (0.483). The main issue here is improving beta's recovery and possibly further lowering BIC.\n\nThe previous model used a loss term with a fixed exponent (1.5) and context-aware normalization for inequity. The high alpha recovery suggests the loss component is well-specified, but beta's lower recovery indicates the inequity term might not be capturing the right dynamics. Maybe the trial_type-dependent normalization isn't effective enough, or the inequity term isn't orthogonal to the loss term.\n\nTo improve beta's recovery, perhaps introduce a non-linear transformation for the inequity term. For example, using a sigmoid function to cap extreme values, which could reduce noise in parameter estimation. Alternatively, adjust the normalization method\u2014maybe scaling by the square root of combined_earning instead of the raw value to account for diminishing sensitivity to larger pots.\n\nAnother angle: The trial_type modulation in the inequity penalty might not be strong enough. Instead of a binary switch between 3*token_self and combined_earning, maybe use a continuous modulation based on the participant's contribution ratio. For instance, weight the inequity term by (token_self / (token_self + token_opp)) when trial_type is 3, making the penalty proportional to their contribution share.\n\nAlso, consider adding an interaction term between the loss and inequity components. For example, participants might be more sensitive to inequity when they're already receiving less than their fair share. This could be modeled by multiplying the inequity term by the loss indicator (1 if loss >0, else 0), enhancing identifiability of beta in loss scenarios.\n\nTo further lower BIC, reduce the number of parameters if possible. The current model has alpha, lambda, and beta. If lambda and alpha can be combined or one can be fixed based on literature (e.g., setting the loss exponent to a standard value from prospect theory), that might help without sacrificing much accuracy.\n\nAdditionally, explore dynamic bounds for parameters based on trial_type. For example, in trials where the participant contributed more, beta's upper bound could be higher, allowing the model to capture greater sensitivity in those cases.\n\nFinally, test a hybrid approach where the gain term is not linear but has a concave function (like a square root) to align with prospect theory's diminishing sensitivity to gains. This could improve the model's fit and parameter recovery by better capturing human decision-making patterns.\n</think>\n\n**Instructions for Run 32/200:**  \nDesign a *neurobehavioral hybrid model* with these innovations:  \n\n1. **Sigmoid-Capped Inequity**  \n   - Transform opponent advantage into bounded utility space:  \n     ```  \n     inequity_penalty = \u03b2 * tanh( (split_opp - split_self) / (combined_earning**0.75) )  \n     ```  \n     Compress extreme values while preserving sign, using \u221a(C) scaling for magnitude invariance.  \n\n2. **Contribution-Weighted Loss Context**  \n   - Amplify loss sensitivity when participants contributed majority tokens:  \n     ```  \n     loss_term = \u03bb * [max(3*token_self - split_self, 0)]^1.33 * (1 + token_self/(token_self + token_opp))  \n     ```  \n     Convex loss curvature (\u03c1=1.33) with dynamic weighting by contribution proportion.  \n\n3. **Dynamic Parameter Bounds**  \n   - Confine \u03b2 \u2208 [0,15] when trial_type=3 vs [0,5] otherwise  \n   - Lock \u03bb \u2208 [1.5,4] using meta-analytic loss aversion priors  \n\n**Identifiability Boosters:**  \n- Fix gain linearity (\u03b1 \u2208 [0,2]) but enable loss-gain crossover at 85% fair share  \n- Add asymmetric utility floor: U \u2265 -10 * log(combined_earning)  \n\n**Success Targets:**  \n- Achieve \u03b2 recovery r >0.85 via sigmoid compression  \n- Drive BIC <30 through hybrid gain-loss architecture  \n- Target 85%+ accuracy via context-aware nonlinearities\n\nPrevious Models:Not Provided\n\nPlease think through this step by step, then provide your model specification and variable descriptions.",
      "output": "<think>\nOkay, let's tackle this problem step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal in the described experiment. The model needs to focus on responder behavior, use the given variables appropriately, and ensure parameter recovery is feasible alongside accuracy.\n\nFirst, I need to identify which variables are relevant for the responder's decision. The target variable is \"accept\", which is binary (1 or 0). The key factors influencing this decision likely involve the proposed splits, the contributions (tokens) by both participants, and the total combined earnings. \n\nSince the task mentions that two equal split_self values don't represent the same fairness due to varying combined earnings, the model should account for the relative fairness of the split. This suggests that the utility might depend on the proportion of the split compared to what's fair based on contributions.\n\nI recall that in ultimatum game models, people often consider both their own payoff and the fairness of the offer. A common approach is to use a utility function that includes a term for the monetary gain and a term for inequity aversion. \n\nLet's break down the components:\n\n1. **Monetary Utility**: The participant's utility from the proposed split (split_self). This is straightforward\u2014higher split_self should increase the likelihood of acceptance.\n\n2. **Inequity Aversion**: The participant might dislike unequal splits, even if it means rejecting a positive offer. This can be modeled by comparing the proposed split to what would be considered fair. The fair share could be based on the participant's contribution (token_self) relative to the total tokens (token_self + token_opp). For example, if the participant contributed 60% of the tokens, a fair split might be 60% of the combined earnings.\n\n3. **Loss Aversion**: Participants might be more sensitive to receiving less than their fair share compared to receiving more. This can be modeled using a parameter that scales the negative deviation more strongly than the positive deviation.\n\nPutting this together, the utility function could be:\n\nUtility = (split_self) - \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nHere, \u03b1 represents the sensitivity to losses (receiving less than fair), and \u03b2 represents the sensitivity to gains (receiving more than fair). However, since the task specifies that the model should predict acceptance based on utility being less than 0 for <50% likelihood, we might need to frame it differently, perhaps using a logistic function to convert utility to probability.\n\nWait, the instructions mention that the utility variable can be unbounded, and the probability is determined via a logistic function. So the utility should be a linear combination of terms that influence the acceptance decision.\n\nAnother approach is to model the utility as the proposed split minus a reference point (like the fair share), with loss aversion. The reference point could be the fair share based on contributions. If the proposed split is below the reference, it's a loss, and the disutility is scaled by a loss aversion parameter.\n\nSo, let's define the fair share as (token_self / (token_self + token_opp)) * combined_earning. Then, the difference between the proposed split_self and the fair share is:\n\n\u0394 = split_self - fair_share\n\nIf \u0394 is negative, it's a loss, and the utility would be reduced by \u03bb * |\u0394|, where \u03bb > 1 indicates loss aversion. If \u0394 is positive, it's a gain, and the utility increases by \u0394. So the utility function could be:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nBut we also need to consider the absolute monetary value. Alternatively, the utility could be a combination of the monetary value and the inequity term. For example:\n\nU = split_self + \u03b8 * (split_self - fair_share)\n\nHere, \u03b8 could be a parameter that captures how much the participant cares about fairness. If \u03b8 is positive, they prefer more than fair; if negative, they penalize deviations from fairness.\n\nAlternatively, using a Fehr-Schmidt inequity aversion model, where utility depends on both advantageous and disadvantageous inequity. But since the responder is only evaluating their own split versus the opponent's, maybe focusing on the difference between their split and the fair share based on contributions.\n\nWait, the opponent's contribution is token_opp, and the combined_earning is 3*(token_self + token_opp). The fair share based on contribution would be (token_self / (token_self + token_opp)) * combined_earning. Let's call this fair_share.\n\nThen, the utility could be:\n\nU = split_self - \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nHere, \u03b1 is the loss aversion parameter for receiving less than fair, and \u03b2 is the gain parameter for receiving more than fair. However, in many models, \u03b2 is smaller than \u03b1, as people are more sensitive to losses than gains.\n\nBut the problem states that the model should predict utility where less than 0 corresponds to less than 50% likelihood of acceptance. So the utility U would be passed through a logistic function to get the probability of acceptance: P(accept) = 1 / (1 + exp(-U)).\n\nBut to ensure that U < 0 leads to P < 0.5, the model needs to structure U such that when the offer is unfavorable, U is negative.\n\nAlternatively, the utility could be defined as the net benefit of accepting, considering both the monetary gain and the fairness. For example:\n\nU = split_self - reference_point + fairness_term\n\nThe reference_point could be the fair_share, and the fairness_term could be a parameter multiplied by the deviation from fairness.\n\nBut perhaps a better approach is to model the utility as the monetary offer adjusted by a fairness factor. For example, if the offer is considered unfair, it reduces the utility.\n\nAnother angle: the participant's decision may depend on whether the offer meets a minimum acceptable threshold, which could be influenced by their contribution. The threshold could be a fraction of their fair share. For example, they might accept if split_self >= \u03b3 * fair_share, where \u03b3 is a parameter between 0 and 1. But this would be a deterministic model, whereas we need a probabilistic one.\n\nTo make it probabilistic, we can model the utility as the difference between the proposed split and the minimum acceptable threshold, with noise. For example:\n\nU = split_self - \u03b3 * fair_share\n\nThen, the probability of acceptance is logistic(U / \u03c4), where \u03c4 is a temperature parameter. However, the problem states that the temperature is fixed at 1, so we can omit \u03c4.\n\nBut this doesn't account for loss aversion. Maybe the threshold \u03b3 is influenced by the participant's contribution and loss aversion. Alternatively, the utility could be:\n\nU = split_self - \u03bb * (fair_share - split_self) if split_self < fair_share\nU = split_self - \u03b4 * (split_self - fair_share) if split_self >= fair_share\n\nHere, \u03bb > \u03b4 would indicate loss aversion. But this introduces piecewise functions, which might complicate parameter recovery.\n\nAlternatively, use a linear loss aversion term:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nThis way, any deficit from the fair share is penalized with weight \u03bb. If \u03bb is high, even small deficits lead to rejection.\n\nBut perhaps combining both the absolute offer and the relative fairness. For example:\n\nU = \u03b1 * split_self + \u03b2 * (split_self / fair_share - 1)\n\nHere, \u03b1 is the weight on the absolute amount, and \u03b2 is the weight on the relative fairness. If split_self equals fair_share, the second term is zero. If it's more, the term is positive; if less, negative.\n\nBut this might not capture loss aversion adequately. Alternatively, use a prospect theory approach where losses (relative to fair share) are weighted more than gains.\n\nSo, U = split_self + \u03b8 * (split_self - fair_share) if split_self >= fair_share\nU = split_self + \u03bb * \u03b8 * (split_self - fair_share) if split_self < fair_share\n\nHere, \u03bb > 1 is the loss aversion parameter. But this is piecewise again.\n\nTo avoid piecewise functions, perhaps use a power function where losses are exponentiated. For example:\n\n\u0394 = split_self - fair_share\nU = split_self + \u03b1 * \u0394 - \u03b2 * (-\u0394)^gamma if \u0394 < 0\nU = split_self + \u03b1 * \u0394 if \u0394 >= 0\n\nBut this complicates the model with multiple parameters. Given the need for parameter recovery, simplicity is key.\n\nLet's consider a parsimonious model with two parameters: one for the sensitivity to the monetary offer and one for the sensitivity to inequity.\n\nThe fair_share is calculated as (token_self / (token_self + token_opp)) * combined_earning.\n\nThe inequity term could be the difference between the proposed split and the fair_share, scaled by a parameter. For example:\n\nU = \u03b1 * split_self + \u03b2 * (split_self - fair_share)\n\nHere, \u03b1 represents the utility per pound received, and \u03b2 represents the additional utility from receiving more than fair (or disutility if negative). If \u03b2 is positive, participants prefer offers above their fair share; if negative, they penalize deviations from fairness.\n\nAlternatively, the model could use a non-linear function for the inequity term. For example, using a quadratic term to penalize deviations from fairness:\n\nU = \u03b1 * split_self - \u03b2 * (split_self - fair_share)^2\n\nThis would mean that participants prefer offers close to their fair share, with \u03b2 controlling the strength of this preference. However, this might not capture loss aversion, as both positive and negative deviations are penalized equally.\n\nGiven the task's emphasis on parameter recovery and the need to predict acceptance, a linear model with loss aversion might be more suitable. Let's try:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nHere, \u03bb is the loss aversion parameter. If the offer is below the fair share, the utility is reduced by \u03bb times the deficit. If the offer is above, the utility is just the split_self. This model has one learnable parameter, \u03bb, which must be positive.\n\nBut perhaps adding a term for the absolute fair share. Alternatively, normalize the terms by the combined earning to account for scale.\n\nWait, the combined earning is 3*(token_self + token_opp), so the fair_share in pounds is (token_self / (token_self + token_opp)) * 3*(token_self + token_opp) ) = 3*token_self. Wait, that's interesting. Because combined_earning is 3*(token_self + token_opp), so fair_share based on tokens would be 3*token_self. Because each token is \u00a33, so the participant's contribution is worth 3*token_self, and the opponent's is 3*token_opp. So the fair split based on contribution would be 3*token_self for the participant and 3*token_opp for the opponent. But the proposed split_self is part of the combined_earning, which is 3*(token_self + token_opp). So the fair_share is 3*token_self, and the proposed split_self is what the participant gets. So the difference between split_self and 3*token_self is the deviation from the fair share.\n\nWait, this is a key insight. The fair share based on contribution is exactly 3*token_self, because each token is worth \u00a33. So if the participant contributed token_self tokens, their fair share is 3*token_self. The combined_earning is 3*(token_self + token_opp), so the opponent's fair share is 3*token_opp. Therefore, any proposed split_self that is less than 3*token_self is a loss relative to their contribution, and more than that is a gain.\n\nThis simplifies the model because the fair_share is directly 3*token_self, not a proportion of the combined_earning. So the deviation from fairness is split_self - 3*token_self.\n\nThus, the utility function could be:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03bb is the loss aversion parameter. When split_self is less than 3*token_self, the participant experiences a loss, which reduces the utility by \u03bb times the deficit. If split_self is equal to or greater than 3*token_self, the utility is just split_self.\n\nThis model has one parameter, \u03bb, which should be positive. The probability of acceptance is then logistic(U), where U is the utility. If U is positive, the probability is greater than 0.5; if negative, less than 0.5.\n\nBut perhaps the participant also cares about the opponent's share relative to their contribution. For example, if the opponent is getting more than their fair share (split_opp > 3*token_opp), the participant might find this unfair. However, since the task specifies that the model should predict responder behavior (accept/reject), and the responder's decision is based on their own split and the context, maybe including the opponent's split relative to their fair share could be important.\n\nAlternatively, the inequity could be the difference between the participant's split and their fair share, and the opponent's split and their fair share. For example:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0) - \u03b3 * max(3*token_opp - split_opp, 0)\n\nHere, \u03b3 represents aversion to the opponent receiving less than their fair share (if the participant cares about the opponent's fairness). But this adds another parameter, which might complicate parameter recovery. Given the need for simplicity and recoverability, maybe stick to the one-parameter model first.\n\nHowever, the problem states that the model should utilize the given variables appropriately but not necessarily all. Since the opponent's token_opp and split_opp are available, perhaps the model should consider both self and opponent's fairness.\n\nWait, but in the task description, when the participant is the responder, the trial_role is 1. The proposer's split is split_opp (the opponent's proposed share for themselves) and split_self (the proposer's offer to the participant). So as a responder, the participant is evaluating the offer split_self against their own contribution and the total.\n\nAlternatively, the participant might compare their received split_self to the proposer's split_opp, but since the proposer's contribution is token_opp, their fair share would be 3*token_opp. So if the proposer is keeping split_opp, which is more than their fair share, that could influence the participant's decision.\n\nBut this complicates the model. To keep it focused on the responder's perspective, perhaps the key factors are:\n\n1. The participant's own split (split_self) compared to their fair share (3*token_self).\n2. The total combined earning, which might affect the scaling of the parameters.\n\nWait, the problem mentions that two equal split_self values don't represent the same fairness because the combined earning varies. For example, a split_self of \u00a310 when combined_earning is \u00a320 (fair share \u00a315) is different from when combined_earning is \u00a330 (fair share \u00a315). Wait, no\u2014if combined_earning is \u00a330, then 3*(token_self + token_opp) =30, so token_self + token_opp=10. If the participant's fair share is 3*token_self, then split_self=10 would be compared to 3*token_self, which depends on their contribution. So the model must normalize based on the participant's contribution.\n\nBut given that the fair share is 3*token_self, the model can directly compute the difference between split_self and 3*token_self.\n\nSo, the utility function could be:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis captures the idea that the participant values the offered amount but penalizes offers below their fair share (3*token_self) with a loss aversion parameter \u03bb.\n\nHowever, this model doesn't account for the total combined earning. For instance, if the combined earning is very large, maybe the participant's sensitivity to the same absolute deficit (3*token_self - split_self) changes. To address this, we could normalize the loss term by the combined earning:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / combined_earning)\n\nThis way, the loss term is scaled by the total pot, making the parameter \u03bb unitless and comparable across trials. But the problem states that the utility can be unbounded, so normalization might not be necessary. However, for parameter recovery, scaling could help.\n\nAlternatively, use a non-linear function, such as a power function, to model diminishing sensitivity to larger losses:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0))^\u03b1\n\nHere, \u03b1 could be a parameter controlling the curvature. But this adds another parameter, which might complicate recovery.\n\nGiven the need for parameter recovery and simplicity, let's stick to the linear loss aversion model with one parameter:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis model has one learnable parameter, \u03bb, which should have a positive range. The probability of acceptance is then 1 / (1 + exp(-U)).\n\nBut wait, the utility U here is in pounds. If split_self is \u00a310 and \u03bb=2, then a deficit of \u00a35 would reduce utility by \u00a310, making U=10-10=0, leading to a 50% chance of acceptance. This might not capture the psychometric function well. Perhaps scaling the loss term by a factor that makes \u03bb dimensionless.\n\nAlternatively, express the loss term as a proportion of the fair share:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self))\n\nThis way, the loss term is a fraction of the fair share, and \u03bb is a unitless parameter. For example, if the fair share is \u00a315 and the offer is \u00a310, the loss is \u00a35, which is 1/3 of the fair share. \u03bb=3 would make the utility 10 - 3*(5/15)*15 = 10 -5=5. Wait, no\u2014this scaling might not be necessary. Alternatively, the division by fair share makes the term unitless:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self)) * combined_earning\n\nBut this complicates the model. Maybe it's better to keep the loss term in absolute terms but allow \u03bb to scale it appropriately.\n\nAnother consideration: the participant's decision might also depend on the proposer's role. However, since the model is only for the responder's behavior (trial_role=1), we don't need to consider when the participant is the proposer.\n\nIncluding the trial_type (1=equal, 2=opponent more, 3=participant more) might help. For example, participants might have different sensitivities depending on whether the trial type is them contributing more or less. But the model should use the variables appropriately, and trial_type is an experimental condition. However, the problem states that the model should use the provided variables, but not necessarily all. Since trial_type is a categorical variable, incorporating it would require dummy variables or separate parameters, which complicates the model. For simplicity, let's omit trial_type unless necessary.\n\nPutting it all together, the model would be:\n\nUtility = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThe probability of acceptance is the logistic of this utility. The parameter \u03bb must be positive, so we can set bounds like [0, 10] to be generous.\n\nBut wait, the problem requires that the model's utility when less than 0 corresponds to less than 50% likelihood. With the logistic function, if U < 0, then P(accept) = 1/(1 + exp(-U)) < 0.5, which aligns with the requirement.\n\nNow, for parameter recovery, we need to ensure that \u03bb is identifiable. If the data includes cases where split_self is both above and below 3*token_self, the model can estimate \u03bb based on the rejection rate when offers are below the fair share.\n\nAnother consideration: the intercept. Maybe participants have a baseline tendency to accept or reject, so adding a constant term:\n\nU = \u03b20 + split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 is a bias term. If \u03b20 is positive, it increases the baseline acceptance probability. However, the problem states that the utility variable may be unbounded, so including \u03b20 is acceptable. But this adds another parameter, which might affect parameter recovery. Since the task emphasizes parameter recovery, a model with fewer parameters is better. Let's start with one parameter (\u03bb) and see if that suffices.\n\nAlternatively, if the model without an intercept cannot capture the baseline acceptance rate, adding \u03b20 might be necessary. For example, some participants might have a general tendency to reject offers regardless of fairness. Including \u03b20 would allow for that.\n\nBut given the task's emphasis on parameter recovery and the need to keep the model simple, perhaps including both \u03b20 and \u03bb. However, the problem says \"any learnable parameters must have finite bounds.\" So we need to define ranges for each.\n\nLet's proceed with:\n\nU = \u03b20 + \u03b21 * split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 is the intercept, \u03b21 scales the split_self, and \u03bb is the loss aversion parameter. However, this introduces three parameters, which might be too many for 36 trials per participant. With 36 data points, a model with 3 parameters could be overfitting. \n\nAlternatively, fix \u03b21 to 1, assuming linear utility for the split_self, and have \u03b20 and \u03bb as parameters. But \u03b20 would represent a baseline bias. For example:\n\nU = split_self + \u03b20 - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 could be positive or negative. If \u03b20 is positive, it increases the likelihood of acceptance across all offers. But this might not be necessary if the main driver is the split_self and the loss term.\n\nGiven the task's mention that parameter recovery is roughly equal in priority to accuracy, a parsimonious model is better. Let's try the one-parameter model first:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis model has a single parameter \u03bb, which can be bounded between 0 and a large value, say 10, to cover possible loss aversion factors.\n\nBut wait, in prospect theory, loss aversion \u03bb is typically around 2. So setting a bound of [0, 5] would be reasonable, allowing for some variability.\n\nAlternatively, if we include an intercept \u03b20, the model becomes:\n\nU = \u03b20 + split_self - \u03bb * max(3*token_self - split_self, 0)\n\nWith \u03b20 \u2208 [-10, 10] and \u03bb \u2208 [0, 5]. This allows for a baseline tendency to accept or reject, plus loss aversion.\n\nHowever, with 36 trials per participant, estimating two parameters might be feasible. Let's proceed with this two-parameter model.\n\nAnother consideration: the split_self is in pounds, and its coefficient is 1. If we include \u03b21 as a parameter scaling split_self, the model becomes:\n\nU = \u03b21 * split_self - \u03bb * max(3*token_self - split_self, 0) + \u03b20\n\nBut this adds more parameters. To avoid overcomplicating, perhaps assume that the utility is linear in split_self with a unit coefficient, as in the initial model.\n\nAlternatively, normalize split_self by the combined_earning to make the parameter scale-invariant. For example:\n\nU = (split_self / combined_earning) - \u03bb * (max(3*token_self - split_self, 0) / combined_earning)\n\nThis makes both terms unitless and scaled by the total pot. However, combined_earning is 3*(token_self + token_opp), which is known. This normalization might help in parameter recovery by making the parameters independent of the stake size.\n\nBut the problem states that the model should be applicable to the dataset as provided, so using combined_earning is acceptable.\n\nAlternatively, the fair share is 3*token_self, and the maximum possible split_self is combined_earning (if the proposer offers everything). So the deficit (3*token_self - split_self) can be as large as 3*token_self (if split_self=0) or as small as 0. To normalize, perhaps divide by 3*token_self, making the term range from 0 to 1:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self)) * combined_earning\n\nBut this complicates the model. Alternatively, use the ratio of the deficit to the fair share:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self))\n\nThis way, \u03bb represents the disutility per unit of proportional deficit. For example, if the participant is offered half their fair share, the deficit is 0.5, and \u03bb scales this.\n\nBut this introduces division by token_self, which could be zero. However, in the dataset, token_self is the participant's contribution, so it's at least 1 (assuming they contributed something). The problem states that token_self is the number of tokens found by the participant, so it's possible for token_self to be zero, but in practice, participants likely have at least one token. If token_self is zero, the fair share is zero, and any positive split_self would be a gain. But this edge case can be handled by the model.\n\nAlternatively, replace 3*token_self with (token_self / (token_self + token_opp)) * combined_earning to compute the fair share as a proportion of contributions. Wait, but earlier calculation shows that 3*token_self is exactly the fair share based on contributions. Because each token is worth \u00a33, so the participant's contribution is worth 3*token_self, and the total combined_earning is 3*(token_self + token_opp). So the fair share is indeed 3*token_self.\n\nThus, the deficit is max(3*token_self - split_self, 0), and the utility is split_self minus lambda times this deficit.\n\nThis model has one parameter, lambda, which must be positive. The bounds for lambda can be [0, 10], inclusive.\n\nBut perhaps participants also care about the proposer's share relative to their own contribution. For example, if the proposer (opponent) is keeping split_opp, which is more than their fair share (3*token_opp), the participant might find this unfair. However, since the participant is the responder, they only observe the offer split_self and split_opp, but their decision is based on their own split. Including the opponent's fairness might complicate the model but could improve accuracy.\n\nThe opponent's fair share is 3*token_opp. The proposer's kept amount is split_opp. So the opponent's deficit is max(3*token_opp - split_opp, 0). If the participant cares about the opponent's fairness, they might have a term for that. For example:\n\nU = split_self - \u03bb_self * max(3*token_self - split_self, 0) - \u03bb_opp * max(3*token_opp - split_opp, 0)\n\nHere, \u03bb_self is loss aversion for self, and \u03bb_opp is aversion to the opponent receiving less than their fair share. But this adds another parameter. Given the parameter recovery priority, a two-parameter model might still be manageable.\n\nAlternatively, the participant might only care about their own fairness, making the model simpler.\n\nGiven the trade-off between model complexity and parameter recovery, the single-parameter model is preferable. However, if including the opponent's fairness significantly improves model fit, it's worth considering. But without prior knowledge, it's safer to start with the simpler model.\n\nAnother angle: the participant's decision might depend on the percentage split (splitperc_self) rather than the absolute amount. However, the problem states that two equal split_self values can represent different fairness levels due to varying combined_earning, so the absolute split_self isn't sufficient\u2014context matters. Hence, the model should incorporate the context via the fair share (3*token_self).\n\nIn conclusion, the model will predict the utility as:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nWith \u03bb as the learnable parameter, bounded between 0 and 10. The probability of acceptance is the logistic function of U.\n\nNow, let's formalize this in the required tags.\n</think>\n\n<MODEL>\nU = split_self - lambda * max(3 * token_self - split_self, 0)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA loss-averse utility model where participants evaluate offers relative to their contribution-based fair share (3*token_self). Utility decreases linearly with deficits below this reference point, scaled by a learnable loss aversion parameter (lambda). The model converts utility to acceptance probability via logistic function.\n</SUMMARY>"
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['lambda']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self - lambda * max(3 * token_self - split_self, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "\n\n```python\nimport json\nimport math\n\ndef simulate_model(trial_data, lambda_val=1):\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n        \n        fair_share = 3 * token_self\n        \n        utility = split_self - lambda_val * max(fair_share - split_self, 0)\n        \n        model_predictions.append(utility)\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744017432.344921
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['lambda']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self - lambda * max(3 * token_self - split_self, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "```python\nimport json\nimport math\n\ndef simulate_model(trial_data, lambda_val=1):\n    \"\"\"\n    Simulates the utility of accepting a proposal based on loss aversion.\n\n    Args:\n        trial_data (list of dict): A list of dictionaries, where each dictionary\n            represents a trial and contains the following keys:\n            - split_self (float64): Proposed share for the participant in \u00a3.\n            - token_self (int64): Number of tokens found by the participant.\n        lambda_val (float): Loss aversion parameter.\n\n    Returns:\n        list of float: A list of model predictions (utilities) for each trial.\n    \"\"\"\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        # Calculate utility\n        utility = split_self - lambda_val * max(3 * token_self - split_self, 0)\n        model_predictions.append(utility)\n\n    return model_predictions\n\n# Data as list of dictionaries\ndata_json = '[{\"ID\": 1, \"group\": \"group1\", \"trial_number\": 1, \"trial_type\": 1, \"trial_role\": 1, \"token_opp\": 5, \"token_self\": 5, \"combined_earning\": 30, \"split_opp\": 15.0, \"split_self\": 15.0, \"splitperc_opp\": 50, \"splitperc_self\": 50, \"accept\": 1.0, \"accepted_amount\": 15.0, \"accepted_perc\": 50.0, \"proposed_perc\": 50.0, \"proposed_amount\": 15.0}, {\"ID\": 2, \"group\": \"group1\", \"trial_number\": 2, \"trial_type\": 2, \"trial_role\": 1, \"token_opp\": 7, \"token_self\": 3, \"combined_earning\": 30, \"split_opp\": 21.0, \"split_self\": 9.0, \"splitperc_opp\": 70, \"splitperc_self\": 30, \"accept\": 0.0, \"accepted_amount\": 0.0, \"accepted_perc\": 0.0, \"proposed_perc\": 30.0, \"proposed_amount\": 9.0}, {\"ID\": 3, \"group\": \"group1\", \"trial_number\": 3, \"trial_type\": 3, \"trial_role\": 1, \"token_opp\": 3, \"token_self\": 7, \"combined_earning\": 30, \"split_opp\": 9.0, \"split_self\": 21.0, \"splitperc_opp\": 30, \"splitperc_self\": 70, \"accept\": 1.0, \"accepted_amount\": 21.0, \"accepted_perc\": 70.0, \"proposed_perc\": 70.0, \"proposed_amount\": 21.0}]'\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data, lambda_val=0.5)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n```",
      "timestamp": 1744017436.443655
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['lambda']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self - lambda * max(3 * token_self - split_self, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "",
      "timestamp": 1744017437.092695
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['lambda']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self - lambda * max(3 * token_self - split_self, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "",
      "timestamp": 1744017437.8038988
    },
    {
      "solver": "simulate_model_solver",
      "input": "\n                Write Python code to simulate the following mathematical model using only Python standard library (no pandas or numpy).\n                The code should take a list of dictionaries as input (each dictionary representing a trial) and return a value for each trial.\n\n                IMPORTANT: Use these exact parameter names for learnable parameters: ['lambda']\n\n                Please write a function called `simulate_model` that:\n                1. Takes a list of dictionaries as input (each dictionary contains trial data)\n                2. Has parameter names that matches the variable descriptions exactly\n                3. Implements the mathematical model above using only standard Python math operations\n                4. Returns a list of model_predictions for each trial (please use the exact name \"model_predictions\" as the return value)\n\n                Your code will be implemented within the following code block (please do not include any code outside of this code block, for instance, you should not include data_json = # imported from .json dumps, or data = json.loads(data_json)):\n\n                ```python\nimport json\nimport math\n\n[YOUR SIMULATE_MODEL FUNCTION HERE]\n\n# Data as list of dictionaries\ndata_json = # imported from .json dumps\ndata = json.loads(data_json)\n\n# Get results for the data\nresults = simulate_model(data)\nprint(json.dumps({\"results\": results}))  # Output as JSON for reliable parsing\n'''\n\nBelow is an example for you to follow:\n<EXAMPLE>\nModel Specification:\nU_i = \u03b2 + \u03b5E + \u03b7N\n\nVariable Descriptions:\nU_i: Utility (probability) of choosing action i \u03b2: [learnable] Base tendency parameter (0-1) representing inherent preference \u03b5: [learnable] Environmental sensitivity parameter (0-1) E: Environmental cue value (-1 to 1) \u03b7: Noise parameter (0-1) N: Random noise drawn from normal distribution N(0,1)\n\nDataset Structure:\nVariables available:\n- trial_id (int64)\n- environmental_cue (float64)\n- beta (float64)\n- epsilon (float64)\n- eta (float64)\n- utility (float64)\n- choice_made (int64)\n- trial_number (int64)\n- participant_id (int64)\n\n\n<YOUR RESPONSE>\ndef simulate_model(trial_data, beta=1, epsilon=1, eta=1):\n    model_predictions = []\n    for trial in trial_data:\n        E = trial.get(\"environmental_cue\", 0)\n        u1, u2 = random.random(), random.random()\n        N = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n        model_predictions.append(beta + (epsilon * E) + (eta * N))\n    return model_predictions\n</YOUR RESPONSE>\n\nNow, create a simulate_model function for the following model incorporating the information provided. DO NOT OUTPUT ANYTHING AFTER YOU RETURN THE MODEL PREDICTIONS.\n                Model Specification:\n                U = split_self - lambda * max(3 * token_self - split_self, 0)\n\n                Variable Descriptions:\n                {\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \\u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"distribution\": null,\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n\nDataset Structure:\n\nDataset Structure:\nVariables available:\n- ID (int64)\n- group (object)\n- trial_number (int64)\n- trial_type (int64)\n- trial_role (int64)\n- token_opp (int64)\n- token_self (int64)\n- combined_earning (int64)\n- split_opp (float64)\n- split_self (float64)\n- splitperc_opp (int64)\n- splitperc_self (int64)\n- accept (float64)\n- accepted_amount (float64)\n- accepted_perc (float64)\n- proposed_perc (float64)\n- proposed_amount (float64)\n\nNumber of observations: 3276\n\n                ",
      "output": "",
      "timestamp": 1744017438.388747
    }
  ],
  "learnable_parameters": {
    "lambda": {
      "description": "Loss aversion parameter scaling disutility from receiving less than fair share",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform"
      },
      "learnable": true,
      "source": "learnable"
    }
  },
  "model_specification": "U = split_self - lambda * max(3 * token_self - split_self, 0)",
  "variable_descriptions": {
    "U": {
      "description": "Utility of accepting the proposal",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "calculated"
    },
    "lambda": {
      "description": "Loss aversion parameter scaling disutility from receiving less than fair share",
      "range": {
        "min": 0,
        "max": 10,
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": {
        "type": "uniform"
      },
      "learnable": true,
      "source": "learnable"
    },
    "split_self": {
      "description": "Proposed share for the participant in \u00a3",
      "range": {
        "min": "-inf",
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": true
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    },
    "token_self": {
      "description": "Number of tokens found by the participant",
      "range": {
        "min": 0,
        "max": "inf",
        "inclusive_min": true,
        "inclusive_max": false
      },
      "distribution": null,
      "learnable": false,
      "source": "data"
    }
  },
  "model_summary": "A loss-averse utility model where participants evaluate offers relative to their contribution-based fair share (3*token_self). Utility decreases linearly with deficits below this reference point, scaled by a learnable loss aversion parameter (lambda). The model converts utility to acceptance probability via logistic function.",
  "target_variable": "accept",
  "full_reasoning": "<think>\nOkay, let's tackle this problem step by step. The goal is to design a computational model that predicts whether a participant (as the responder) accepts or rejects a proposal in the described experiment. The model needs to focus on responder behavior, use the given variables appropriately, and ensure parameter recovery is feasible alongside accuracy.\n\nFirst, I need to identify which variables are relevant for the responder's decision. The target variable is \"accept\", which is binary (1 or 0). The key factors influencing this decision likely involve the proposed splits, the contributions (tokens) by both participants, and the total combined earnings. \n\nSince the task mentions that two equal split_self values don't represent the same fairness due to varying combined earnings, the model should account for the relative fairness of the split. This suggests that the utility might depend on the proportion of the split compared to what's fair based on contributions.\n\nI recall that in ultimatum game models, people often consider both their own payoff and the fairness of the offer. A common approach is to use a utility function that includes a term for the monetary gain and a term for inequity aversion. \n\nLet's break down the components:\n\n1. **Monetary Utility**: The participant's utility from the proposed split (split_self). This is straightforward\u2014higher split_self should increase the likelihood of acceptance.\n\n2. **Inequity Aversion**: The participant might dislike unequal splits, even if it means rejecting a positive offer. This can be modeled by comparing the proposed split to what would be considered fair. The fair share could be based on the participant's contribution (token_self) relative to the total tokens (token_self + token_opp). For example, if the participant contributed 60% of the tokens, a fair split might be 60% of the combined earnings.\n\n3. **Loss Aversion**: Participants might be more sensitive to receiving less than their fair share compared to receiving more. This can be modeled using a parameter that scales the negative deviation more strongly than the positive deviation.\n\nPutting this together, the utility function could be:\n\nUtility = (split_self) - \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nHere, \u03b1 represents the sensitivity to losses (receiving less than fair), and \u03b2 represents the sensitivity to gains (receiving more than fair). However, since the task specifies that the model should predict acceptance based on utility being less than 0 for <50% likelihood, we might need to frame it differently, perhaps using a logistic function to convert utility to probability.\n\nWait, the instructions mention that the utility variable can be unbounded, and the probability is determined via a logistic function. So the utility should be a linear combination of terms that influence the acceptance decision.\n\nAnother approach is to model the utility as the proposed split minus a reference point (like the fair share), with loss aversion. The reference point could be the fair share based on contributions. If the proposed split is below the reference, it's a loss, and the disutility is scaled by a loss aversion parameter.\n\nSo, let's define the fair share as (token_self / (token_self + token_opp)) * combined_earning. Then, the difference between the proposed split_self and the fair share is:\n\n\u0394 = split_self - fair_share\n\nIf \u0394 is negative, it's a loss, and the utility would be reduced by \u03bb * |\u0394|, where \u03bb > 1 indicates loss aversion. If \u0394 is positive, it's a gain, and the utility increases by \u0394. So the utility function could be:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nBut we also need to consider the absolute monetary value. Alternatively, the utility could be a combination of the monetary value and the inequity term. For example:\n\nU = split_self + \u03b8 * (split_self - fair_share)\n\nHere, \u03b8 could be a parameter that captures how much the participant cares about fairness. If \u03b8 is positive, they prefer more than fair; if negative, they penalize deviations from fairness.\n\nAlternatively, using a Fehr-Schmidt inequity aversion model, where utility depends on both advantageous and disadvantageous inequity. But since the responder is only evaluating their own split versus the opponent's, maybe focusing on the difference between their split and the fair share based on contributions.\n\nWait, the opponent's contribution is token_opp, and the combined_earning is 3*(token_self + token_opp). The fair share based on contribution would be (token_self / (token_self + token_opp)) * combined_earning. Let's call this fair_share.\n\nThen, the utility could be:\n\nU = split_self - \u03b1 * max(fair_share - split_self, 0) + \u03b2 * max(split_self - fair_share, 0)\n\nHere, \u03b1 is the loss aversion parameter for receiving less than fair, and \u03b2 is the gain parameter for receiving more than fair. However, in many models, \u03b2 is smaller than \u03b1, as people are more sensitive to losses than gains.\n\nBut the problem states that the model should predict utility where less than 0 corresponds to less than 50% likelihood of acceptance. So the utility U would be passed through a logistic function to get the probability of acceptance: P(accept) = 1 / (1 + exp(-U)).\n\nBut to ensure that U < 0 leads to P < 0.5, the model needs to structure U such that when the offer is unfavorable, U is negative.\n\nAlternatively, the utility could be defined as the net benefit of accepting, considering both the monetary gain and the fairness. For example:\n\nU = split_self - reference_point + fairness_term\n\nThe reference_point could be the fair_share, and the fairness_term could be a parameter multiplied by the deviation from fairness.\n\nBut perhaps a better approach is to model the utility as the monetary offer adjusted by a fairness factor. For example, if the offer is considered unfair, it reduces the utility.\n\nAnother angle: the participant's decision may depend on whether the offer meets a minimum acceptable threshold, which could be influenced by their contribution. The threshold could be a fraction of their fair share. For example, they might accept if split_self >= \u03b3 * fair_share, where \u03b3 is a parameter between 0 and 1. But this would be a deterministic model, whereas we need a probabilistic one.\n\nTo make it probabilistic, we can model the utility as the difference between the proposed split and the minimum acceptable threshold, with noise. For example:\n\nU = split_self - \u03b3 * fair_share\n\nThen, the probability of acceptance is logistic(U / \u03c4), where \u03c4 is a temperature parameter. However, the problem states that the temperature is fixed at 1, so we can omit \u03c4.\n\nBut this doesn't account for loss aversion. Maybe the threshold \u03b3 is influenced by the participant's contribution and loss aversion. Alternatively, the utility could be:\n\nU = split_self - \u03bb * (fair_share - split_self) if split_self < fair_share\nU = split_self - \u03b4 * (split_self - fair_share) if split_self >= fair_share\n\nHere, \u03bb > \u03b4 would indicate loss aversion. But this introduces piecewise functions, which might complicate parameter recovery.\n\nAlternatively, use a linear loss aversion term:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nThis way, any deficit from the fair share is penalized with weight \u03bb. If \u03bb is high, even small deficits lead to rejection.\n\nBut perhaps combining both the absolute offer and the relative fairness. For example:\n\nU = \u03b1 * split_self + \u03b2 * (split_self / fair_share - 1)\n\nHere, \u03b1 is the weight on the absolute amount, and \u03b2 is the weight on the relative fairness. If split_self equals fair_share, the second term is zero. If it's more, the term is positive; if less, negative.\n\nBut this might not capture loss aversion adequately. Alternatively, use a prospect theory approach where losses (relative to fair share) are weighted more than gains.\n\nSo, U = split_self + \u03b8 * (split_self - fair_share) if split_self >= fair_share\nU = split_self + \u03bb * \u03b8 * (split_self - fair_share) if split_self < fair_share\n\nHere, \u03bb > 1 is the loss aversion parameter. But this is piecewise again.\n\nTo avoid piecewise functions, perhaps use a power function where losses are exponentiated. For example:\n\n\u0394 = split_self - fair_share\nU = split_self + \u03b1 * \u0394 - \u03b2 * (-\u0394)^gamma if \u0394 < 0\nU = split_self + \u03b1 * \u0394 if \u0394 >= 0\n\nBut this complicates the model with multiple parameters. Given the need for parameter recovery, simplicity is key.\n\nLet's consider a parsimonious model with two parameters: one for the sensitivity to the monetary offer and one for the sensitivity to inequity.\n\nThe fair_share is calculated as (token_self / (token_self + token_opp)) * combined_earning.\n\nThe inequity term could be the difference between the proposed split and the fair_share, scaled by a parameter. For example:\n\nU = \u03b1 * split_self + \u03b2 * (split_self - fair_share)\n\nHere, \u03b1 represents the utility per pound received, and \u03b2 represents the additional utility from receiving more than fair (or disutility if negative). If \u03b2 is positive, participants prefer offers above their fair share; if negative, they penalize deviations from fairness.\n\nAlternatively, the model could use a non-linear function for the inequity term. For example, using a quadratic term to penalize deviations from fairness:\n\nU = \u03b1 * split_self - \u03b2 * (split_self - fair_share)^2\n\nThis would mean that participants prefer offers close to their fair share, with \u03b2 controlling the strength of this preference. However, this might not capture loss aversion, as both positive and negative deviations are penalized equally.\n\nGiven the task's emphasis on parameter recovery and the need to predict acceptance, a linear model with loss aversion might be more suitable. Let's try:\n\nU = split_self - \u03bb * max(fair_share - split_self, 0)\n\nHere, \u03bb is the loss aversion parameter. If the offer is below the fair share, the utility is reduced by \u03bb times the deficit. If the offer is above, the utility is just the split_self. This model has one learnable parameter, \u03bb, which must be positive.\n\nBut perhaps adding a term for the absolute fair share. Alternatively, normalize the terms by the combined earning to account for scale.\n\nWait, the combined earning is 3*(token_self + token_opp), so the fair_share in pounds is (token_self / (token_self + token_opp)) * 3*(token_self + token_opp) ) = 3*token_self. Wait, that's interesting. Because combined_earning is 3*(token_self + token_opp), so fair_share based on tokens would be 3*token_self. Because each token is \u00a33, so the participant's contribution is worth 3*token_self, and the opponent's is 3*token_opp. So the fair split based on contribution would be 3*token_self for the participant and 3*token_opp for the opponent. But the proposed split_self is part of the combined_earning, which is 3*(token_self + token_opp). So the fair_share is 3*token_self, and the proposed split_self is what the participant gets. So the difference between split_self and 3*token_self is the deviation from the fair share.\n\nWait, this is a key insight. The fair share based on contribution is exactly 3*token_self, because each token is worth \u00a33. So if the participant contributed token_self tokens, their fair share is 3*token_self. The combined_earning is 3*(token_self + token_opp), so the opponent's fair share is 3*token_opp. Therefore, any proposed split_self that is less than 3*token_self is a loss relative to their contribution, and more than that is a gain.\n\nThis simplifies the model because the fair_share is directly 3*token_self, not a proportion of the combined_earning. So the deviation from fairness is split_self - 3*token_self.\n\nThus, the utility function could be:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03bb is the loss aversion parameter. When split_self is less than 3*token_self, the participant experiences a loss, which reduces the utility by \u03bb times the deficit. If split_self is equal to or greater than 3*token_self, the utility is just split_self.\n\nThis model has one parameter, \u03bb, which should be positive. The probability of acceptance is then logistic(U), where U is the utility. If U is positive, the probability is greater than 0.5; if negative, less than 0.5.\n\nBut perhaps the participant also cares about the opponent's share relative to their contribution. For example, if the opponent is getting more than their fair share (split_opp > 3*token_opp), the participant might find this unfair. However, since the task specifies that the model should predict responder behavior (accept/reject), and the responder's decision is based on their own split and the context, maybe including the opponent's split relative to their fair share could be important.\n\nAlternatively, the inequity could be the difference between the participant's split and their fair share, and the opponent's split and their fair share. For example:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0) - \u03b3 * max(3*token_opp - split_opp, 0)\n\nHere, \u03b3 represents aversion to the opponent receiving less than their fair share (if the participant cares about the opponent's fairness). But this adds another parameter, which might complicate parameter recovery. Given the need for simplicity and recoverability, maybe stick to the one-parameter model first.\n\nHowever, the problem states that the model should utilize the given variables appropriately but not necessarily all. Since the opponent's token_opp and split_opp are available, perhaps the model should consider both self and opponent's fairness.\n\nWait, but in the task description, when the participant is the responder, the trial_role is 1. The proposer's split is split_opp (the opponent's proposed share for themselves) and split_self (the proposer's offer to the participant). So as a responder, the participant is evaluating the offer split_self against their own contribution and the total.\n\nAlternatively, the participant might compare their received split_self to the proposer's split_opp, but since the proposer's contribution is token_opp, their fair share would be 3*token_opp. So if the proposer is keeping split_opp, which is more than their fair share, that could influence the participant's decision.\n\nBut this complicates the model. To keep it focused on the responder's perspective, perhaps the key factors are:\n\n1. The participant's own split (split_self) compared to their fair share (3*token_self).\n2. The total combined earning, which might affect the scaling of the parameters.\n\nWait, the problem mentions that two equal split_self values don't represent the same fairness because the combined earning varies. For example, a split_self of \u00a310 when combined_earning is \u00a320 (fair share \u00a315) is different from when combined_earning is \u00a330 (fair share \u00a315). Wait, no\u2014if combined_earning is \u00a330, then 3*(token_self + token_opp) =30, so token_self + token_opp=10. If the participant's fair share is 3*token_self, then split_self=10 would be compared to 3*token_self, which depends on their contribution. So the model must normalize based on the participant's contribution.\n\nBut given that the fair share is 3*token_self, the model can directly compute the difference between split_self and 3*token_self.\n\nSo, the utility function could be:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis captures the idea that the participant values the offered amount but penalizes offers below their fair share (3*token_self) with a loss aversion parameter \u03bb.\n\nHowever, this model doesn't account for the total combined earning. For instance, if the combined earning is very large, maybe the participant's sensitivity to the same absolute deficit (3*token_self - split_self) changes. To address this, we could normalize the loss term by the combined earning:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / combined_earning)\n\nThis way, the loss term is scaled by the total pot, making the parameter \u03bb unitless and comparable across trials. But the problem states that the utility can be unbounded, so normalization might not be necessary. However, for parameter recovery, scaling could help.\n\nAlternatively, use a non-linear function, such as a power function, to model diminishing sensitivity to larger losses:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0))^\u03b1\n\nHere, \u03b1 could be a parameter controlling the curvature. But this adds another parameter, which might complicate recovery.\n\nGiven the need for parameter recovery and simplicity, let's stick to the linear loss aversion model with one parameter:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis model has one learnable parameter, \u03bb, which should have a positive range. The probability of acceptance is then 1 / (1 + exp(-U)).\n\nBut wait, the utility U here is in pounds. If split_self is \u00a310 and \u03bb=2, then a deficit of \u00a35 would reduce utility by \u00a310, making U=10-10=0, leading to a 50% chance of acceptance. This might not capture the psychometric function well. Perhaps scaling the loss term by a factor that makes \u03bb dimensionless.\n\nAlternatively, express the loss term as a proportion of the fair share:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self))\n\nThis way, the loss term is a fraction of the fair share, and \u03bb is a unitless parameter. For example, if the fair share is \u00a315 and the offer is \u00a310, the loss is \u00a35, which is 1/3 of the fair share. \u03bb=3 would make the utility 10 - 3*(5/15)*15 = 10 -5=5. Wait, no\u2014this scaling might not be necessary. Alternatively, the division by fair share makes the term unitless:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self)) * combined_earning\n\nBut this complicates the model. Maybe it's better to keep the loss term in absolute terms but allow \u03bb to scale it appropriately.\n\nAnother consideration: the participant's decision might also depend on the proposer's role. However, since the model is only for the responder's behavior (trial_role=1), we don't need to consider when the participant is the proposer.\n\nIncluding the trial_type (1=equal, 2=opponent more, 3=participant more) might help. For example, participants might have different sensitivities depending on whether the trial type is them contributing more or less. But the model should use the variables appropriately, and trial_type is an experimental condition. However, the problem states that the model should use the provided variables, but not necessarily all. Since trial_type is a categorical variable, incorporating it would require dummy variables or separate parameters, which complicates the model. For simplicity, let's omit trial_type unless necessary.\n\nPutting it all together, the model would be:\n\nUtility = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThe probability of acceptance is the logistic of this utility. The parameter \u03bb must be positive, so we can set bounds like [0, 10] to be generous.\n\nBut wait, the problem requires that the model's utility when less than 0 corresponds to less than 50% likelihood. With the logistic function, if U < 0, then P(accept) = 1/(1 + exp(-U)) < 0.5, which aligns with the requirement.\n\nNow, for parameter recovery, we need to ensure that \u03bb is identifiable. If the data includes cases where split_self is both above and below 3*token_self, the model can estimate \u03bb based on the rejection rate when offers are below the fair share.\n\nAnother consideration: the intercept. Maybe participants have a baseline tendency to accept or reject, so adding a constant term:\n\nU = \u03b20 + split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 is a bias term. If \u03b20 is positive, it increases the baseline acceptance probability. However, the problem states that the utility variable may be unbounded, so including \u03b20 is acceptable. But this adds another parameter, which might affect parameter recovery. Since the task emphasizes parameter recovery, a model with fewer parameters is better. Let's start with one parameter (\u03bb) and see if that suffices.\n\nAlternatively, if the model without an intercept cannot capture the baseline acceptance rate, adding \u03b20 might be necessary. For example, some participants might have a general tendency to reject offers regardless of fairness. Including \u03b20 would allow for that.\n\nBut given the task's emphasis on parameter recovery and the need to keep the model simple, perhaps including both \u03b20 and \u03bb. However, the problem says \"any learnable parameters must have finite bounds.\" So we need to define ranges for each.\n\nLet's proceed with:\n\nU = \u03b20 + \u03b21 * split_self - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 is the intercept, \u03b21 scales the split_self, and \u03bb is the loss aversion parameter. However, this introduces three parameters, which might be too many for 36 trials per participant. With 36 data points, a model with 3 parameters could be overfitting. \n\nAlternatively, fix \u03b21 to 1, assuming linear utility for the split_self, and have \u03b20 and \u03bb as parameters. But \u03b20 would represent a baseline bias. For example:\n\nU = split_self + \u03b20 - \u03bb * max(3*token_self - split_self, 0)\n\nHere, \u03b20 could be positive or negative. If \u03b20 is positive, it increases the likelihood of acceptance across all offers. But this might not be necessary if the main driver is the split_self and the loss term.\n\nGiven the task's mention that parameter recovery is roughly equal in priority to accuracy, a parsimonious model is better. Let's try the one-parameter model first:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nThis model has a single parameter \u03bb, which can be bounded between 0 and a large value, say 10, to cover possible loss aversion factors.\n\nBut wait, in prospect theory, loss aversion \u03bb is typically around 2. So setting a bound of [0, 5] would be reasonable, allowing for some variability.\n\nAlternatively, if we include an intercept \u03b20, the model becomes:\n\nU = \u03b20 + split_self - \u03bb * max(3*token_self - split_self, 0)\n\nWith \u03b20 \u2208 [-10, 10] and \u03bb \u2208 [0, 5]. This allows for a baseline tendency to accept or reject, plus loss aversion.\n\nHowever, with 36 trials per participant, estimating two parameters might be feasible. Let's proceed with this two-parameter model.\n\nAnother consideration: the split_self is in pounds, and its coefficient is 1. If we include \u03b21 as a parameter scaling split_self, the model becomes:\n\nU = \u03b21 * split_self - \u03bb * max(3*token_self - split_self, 0) + \u03b20\n\nBut this adds more parameters. To avoid overcomplicating, perhaps assume that the utility is linear in split_self with a unit coefficient, as in the initial model.\n\nAlternatively, normalize split_self by the combined_earning to make the parameter scale-invariant. For example:\n\nU = (split_self / combined_earning) - \u03bb * (max(3*token_self - split_self, 0) / combined_earning)\n\nThis makes both terms unitless and scaled by the total pot. However, combined_earning is 3*(token_self + token_opp), which is known. This normalization might help in parameter recovery by making the parameters independent of the stake size.\n\nBut the problem states that the model should be applicable to the dataset as provided, so using combined_earning is acceptable.\n\nAlternatively, the fair share is 3*token_self, and the maximum possible split_self is combined_earning (if the proposer offers everything). So the deficit (3*token_self - split_self) can be as large as 3*token_self (if split_self=0) or as small as 0. To normalize, perhaps divide by 3*token_self, making the term range from 0 to 1:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self)) * combined_earning\n\nBut this complicates the model. Alternatively, use the ratio of the deficit to the fair share:\n\nU = split_self - \u03bb * (max(3*token_self - split_self, 0) / (3*token_self))\n\nThis way, \u03bb represents the disutility per unit of proportional deficit. For example, if the participant is offered half their fair share, the deficit is 0.5, and \u03bb scales this.\n\nBut this introduces division by token_self, which could be zero. However, in the dataset, token_self is the participant's contribution, so it's at least 1 (assuming they contributed something). The problem states that token_self is the number of tokens found by the participant, so it's possible for token_self to be zero, but in practice, participants likely have at least one token. If token_self is zero, the fair share is zero, and any positive split_self would be a gain. But this edge case can be handled by the model.\n\nAlternatively, replace 3*token_self with (token_self / (token_self + token_opp)) * combined_earning to compute the fair share as a proportion of contributions. Wait, but earlier calculation shows that 3*token_self is exactly the fair share based on contributions. Because each token is worth \u00a33, so the participant's contribution is worth 3*token_self, and the total combined_earning is 3*(token_self + token_opp). So the fair share is indeed 3*token_self.\n\nThus, the deficit is max(3*token_self - split_self, 0), and the utility is split_self minus lambda times this deficit.\n\nThis model has one parameter, lambda, which must be positive. The bounds for lambda can be [0, 10], inclusive.\n\nBut perhaps participants also care about the proposer's share relative to their own contribution. For example, if the proposer (opponent) is keeping split_opp, which is more than their fair share (3*token_opp), the participant might find this unfair. However, since the participant is the responder, they only observe the offer split_self and split_opp, but their decision is based on their own split. Including the opponent's fairness might complicate the model but could improve accuracy.\n\nThe opponent's fair share is 3*token_opp. The proposer's kept amount is split_opp. So the opponent's deficit is max(3*token_opp - split_opp, 0). If the participant cares about the opponent's fairness, they might have a term for that. For example:\n\nU = split_self - \u03bb_self * max(3*token_self - split_self, 0) - \u03bb_opp * max(3*token_opp - split_opp, 0)\n\nHere, \u03bb_self is loss aversion for self, and \u03bb_opp is aversion to the opponent receiving less than their fair share. But this adds another parameter. Given the parameter recovery priority, a two-parameter model might still be manageable.\n\nAlternatively, the participant might only care about their own fairness, making the model simpler.\n\nGiven the trade-off between model complexity and parameter recovery, the single-parameter model is preferable. However, if including the opponent's fairness significantly improves model fit, it's worth considering. But without prior knowledge, it's safer to start with the simpler model.\n\nAnother angle: the participant's decision might depend on the percentage split (splitperc_self) rather than the absolute amount. However, the problem states that two equal split_self values can represent different fairness levels due to varying combined_earning, so the absolute split_self isn't sufficient\u2014context matters. Hence, the model should incorporate the context via the fair share (3*token_self).\n\nIn conclusion, the model will predict the utility as:\n\nU = split_self - \u03bb * max(3*token_self - split_self, 0)\n\nWith \u03bb as the learnable parameter, bounded between 0 and 10. The probability of acceptance is the logistic function of U.\n\nNow, let's formalize this in the required tags.\n</think>\n\n<MODEL>\nU = split_self - lambda * max(3 * token_self - split_self, 0)\n</MODEL>\n\n<VARIABLES>\n{\n  \"variables\": {\n    \"U\": {\n      \"description\": \"Utility of accepting the proposal\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"calculated\"\n    },\n    \"lambda\": {\n      \"description\": \"Loss aversion parameter scaling disutility from receiving less than fair share\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": 10,\n        \"inclusive_min\": true,\n        \"inclusive_max\": true\n      },\n      \"distribution\": {\n        \"type\": \"uniform\"\n      },\n      \"learnable\": true,\n      \"source\": \"learnable\"\n    },\n    \"split_self\": {\n      \"description\": \"Proposed share for the participant in \u00a3\",\n      \"range\": {\n        \"min\": \"-inf\",\n        \"max\": \"inf\"\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    },\n    \"token_self\": {\n      \"description\": \"Number of tokens found by the participant\",\n      \"range\": {\n        \"min\": 0,\n        \"max\": \"inf\",\n        \"inclusive_min\": true,\n        \"inclusive_max\": false\n      },\n      \"learnable\": false,\n      \"source\": \"data\"\n    }\n  }\n}\n</VARIABLES>\n\n<target_variable>accept</target_variable>\n\n<SUMMARY>\nA loss-averse utility model where participants evaluate offers relative to their contribution-based fair share (3*token_self). Utility decreases linearly with deficits below this reference point, scaled by a learnable loss aversion parameter (lambda). The model converts utility to acceptance probability via logistic function.\n</SUMMARY>",
  "prediction_type": "utility",
  "current_model": "Specification: U = split_self - lambda * max(3 * token_self - split_self, 0)\nSummary: A loss-averse utility model where participants evaluate offers relative to their contribution-based fair share (3*token_self). Utility decreases linearly with deficits below this reference point, scaled by a learnable loss aversion parameter (lambda). The model converts utility to acceptance probability via logistic function.\nTarget Variable: accept\nPrediction Type: utility",
  "simulation_errors": [
    {
      "retry_number": 0,
      "error": "  File \"<string>\", line 23\n    results = simulate_model(data, lambda=0.5)\n                                         ^\nSyntaxError: invalid syntax\n",
      "timestamp": 1744017432.414627
    },
    {
      "retry_number": 1,
      "error": "  File \"<string>\", line 35\n    results = simulate_model(data, lambda=0.5)\n                                         ^\nSyntaxError: invalid syntax\n",
      "timestamp": 1744017436.479729
    },
    {
      "retry_number": 2,
      "error": "Could not extract simulate_model function from generated code",
      "timestamp": 1744017437.092748
    },
    {
      "retry_number": 3,
      "error": "Could not extract simulate_model function from generated code",
      "timestamp": 1744017437.803927
    },
    {
      "retry_number": 4,
      "error": "Could not extract simulate_model function from generated code",
      "timestamp": 1744017438.388769
    }
  ],
  "current_retry": 4,
  "simulation_error": "Failed after maximum retries",
  "simulation_code": "def simulate_model(trial_data, lambda_val=1):\n    \"\"\"\n    Simulates the utility of accepting a proposal based on loss aversion.\n\n    Args:\n        trial_data (list of dict): A list of dictionaries, where each dictionary\n            represents a trial and contains the following keys:\n            - split_self (float64): Proposed share for the participant in \u00a3.\n            - token_self (int64): Number of tokens found by the participant.\n        lambda_val (float): Loss aversion parameter.\n\n    Returns:\n        list of float: A list of model predictions (utilities) for each trial.\n    \"\"\"\n    model_predictions = []\n    for trial in trial_data:\n        split_self = trial.get(\"split_self\", 0)\n        token_self = trial.get(\"token_self\", 0)\n\n        # Calculate utility\n        utility = split_self - lambda_val * max(3 * token_self - split_self, 0)\n        model_predictions.append(utility)\n\n    return model_predictions",
  "total_retries": 5,
  "fitting_warnings": [
    "Error fitting participant 1001: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2633425804298746}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.798189960902578}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.3320957091381658}\"]",
    "Error fitting participant 1002: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.2492579655530567}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.3234120281245905}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.232684506782757}\"]",
    "Error fitting participant 1003: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.609618673110018}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.1590391954200436}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.407609936066294}\"]",
    "Error fitting participant 1004: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8847355867447178}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.209471780141138}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.8826525468315545}\"]",
    "Error fitting participant 1005: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.178624395948081}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.139361694164874}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.577192651796791}\"]",
    "Error fitting participant 1006: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.005389624972297}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.6582875047403858}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.374412719181659}\"]",
    "Error fitting participant 1007: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.676840093828595}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9587003457592413}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.530377043940801}\"]",
    "Error fitting participant 1008: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.573665498605196}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.34274586081030844}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.876413446955097}\"]",
    "Error fitting participant 1009: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.831218371037968}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8763147032303198}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.171481356393597}\"]",
    "Error fitting participant 1010: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.061530922209065}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2698966207278337}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.614404559665749}\"]",
    "Error fitting participant 1011: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.735827487936064}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.1582901467019635}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.88502719988072}\"]",
    "Error fitting participant 1012: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.363798286757315}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.244742171316441}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.195136163017924}\"]",
    "Error fitting participant 1013: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.491217976255372}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8860629062253516}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.169595936352433}\"]",
    "Error fitting participant 1015: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.28500766175765}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.845724258951201}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.3646980887688678}\"]",
    "Error fitting participant 1016: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.291380874031225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.46887182347089}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.857939575593939}\"]",
    "Error fitting participant 1017: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.650498646243536}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.127859443225078}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.7307206334134655}\"]",
    "Error fitting participant 1018: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.457812233756751}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.2226338690613545}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.786647120557922}\"]",
    "Error fitting participant 1019: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.3758237976776577}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.156336753179945}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.4272926968257895}\"]",
    "Error fitting participant 1020: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.598511320992678}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.531005351171697}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.085734670793908}\"]",
    "Error fitting participant 1021: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.028043802994016}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.995579978105098}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.1468940318666965}\"]",
    "Error fitting participant 1022: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.034598313944864}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.9453618283514462}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.792106904999724}\"]",
    "Error fitting participant 1023: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.964397999356687}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.466376642191163}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.10929030490403946}\"]",
    "Error fitting participant 1024: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.522362795989283}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.039997642554646}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.659934924828283}\"]",
    "Error fitting participant 1025: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.381199534987244}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.997502660886291}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9166175391548581}\"]",
    "Error fitting participant 1026: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.20332903467011}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.903246719339658}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.681371928394581}\"]",
    "Error fitting participant 1027: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.119283451036157}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.786358303277337}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.120299148639744}\"]",
    "Error fitting participant 1028: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.350625812648222}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.7838398981628387}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.501839343667099}\"]",
    "Error fitting participant 1029: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.503068957550525}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.417667341064714}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.720353121789549}\"]",
    "Error fitting participant 1030: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.0630290771287507}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.1939288146605005}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.15695571568236977}\"]",
    "Error fitting participant 1031: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.721657914266222}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.4019302165588423}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.461661185594052}\"]",
    "Error fitting participant 1032: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.9377349786732543}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.097024543939256}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.98209998709363}\"]",
    "Error fitting participant 1033: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.0219175536846814}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.894817374245411}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.166048642357046}\"]",
    "Error fitting participant 1034: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.017611029410572}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.334323985302799}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.3131838115388734}\"]",
    "Error fitting participant 1035: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.20113750131482}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.092243449861547}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.797626540538054}\"]",
    "Error fitting participant 1036: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.204112802231667}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.670873058140062}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.97580248674021}\"]",
    "Error fitting participant 1037: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.32686798748458}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2850001905901696}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.08643734044809337}\"]",
    "Error fitting participant 1038: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.299672272680805}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.159247099049498}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.298010117133499}\"]",
    "Error fitting participant 1039: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.095445866281638}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5905020139540023}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.270277522131487}\"]",
    "Error fitting participant 1040: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.6855746724693133}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.88542949378973}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.524990139155724}\"]",
    "Error fitting participant 1041: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.144311488176385}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.481584475161714}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.979958364411363}\"]",
    "Error fitting participant 1042: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.7655790687104025}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.549999879082971}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.6341486100375935}\"]",
    "Error fitting participant 1043: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8646088102060263}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.531108884856396}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.463035582674755}\"]",
    "Error fitting participant 1044: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.238397973862752}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.814996475680872}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.6629458493851403}\"]",
    "Error fitting participant 2001: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.0142346490593424}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.69973404158944}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.512554557651763}\"]",
    "Error fitting participant 2002: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.428080744443105}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.286902756173069}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.356826313684993}\"]",
    "Error fitting participant 2003: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.194790737395074}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.850502488394606}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.308912328781297}\"]",
    "Error fitting participant 2004: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.467183981424104}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.25081295108126955}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.953315433435424}\"]",
    "Error fitting participant 2005: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5192096167164655}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.014659757766626}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.12512022472403}\"]",
    "Error fitting participant 2006: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9636178097574466}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.780795569447022}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.230587205846694}\"]",
    "Error fitting participant 2007: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.795632136350308}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.460786986948523}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.307164814220553}\"]",
    "Error fitting participant 2008: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.940854112794156}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.2727532089691715}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.483345074698897}\"]",
    "Error fitting participant 2009: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.527620598270536}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.129798183965168}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.830620159287423}\"]",
    "Error fitting participant 2010: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.1664200500285127}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.63438786544359}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.056423049772438}\"]",
    "Error fitting participant 2011: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.493985240792619}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.91427312906741}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.020563813277806}\"]",
    "Error fitting participant 2012: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.797744665141054}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.991848057374688}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.137054884489454}\"]",
    "Error fitting participant 2013: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.1889124780194784}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.850290104193488}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.9387606813379863}\"]",
    "Error fitting participant 2014: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.790469837959645}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.74667295788819}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.523188378040729}\"]",
    "Error fitting participant 2015: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.889069721546531}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.2312541217176098}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.874112902654405}\"]",
    "Error fitting participant 2016: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8060399890769274}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.943286272928109}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.80922639881957}\"]",
    "Error fitting participant 2017: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.462829048446212}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.771951386678349}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9411871774325442}\"]",
    "Error fitting participant 2018: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.888412885846612}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.894586672649918}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.935990006690635}\"]",
    "Error fitting participant 2019: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.061116839388323}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.887284335695189}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.318146837747415}\"]",
    "Error fitting participant 2020: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.3450912704505225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.7768143382663064}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.4621548450774697}\"]",
    "Error fitting participant 2021: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.307404671937378}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.646184588164854}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.893430550348543}\"]",
    "Error fitting participant 2022: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.097725753994428}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.763927777105682}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8041990549751246}\"]",
    "Error fitting participant 2023: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.753300673811577}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.620446993118845}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.132129460564508}\"]",
    "Error fitting participant 2024: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.053647568350479}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.990025999795271}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.2988302325880947}\"]",
    "Error fitting participant 2025: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.611266832209632}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.900171891351442}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.18779792453422095}\"]",
    "Error fitting participant 2026: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.6373863734916245}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8078268499397212}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.123277812427341}\"]",
    "Error fitting participant 2027: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.741434157739797}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.9754016051441976}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.146048645543512}\"]",
    "Error fitting participant 2028: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.659438192351455}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.990395345761006}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.10016973737526}\"]",
    "Error fitting participant 2029: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8315263846350318}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.9391447423719232}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.001291935098186}\"]",
    "Error fitting participant 2030: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.938588087294238}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.782630955297471}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.499695897335192}\"]",
    "Error fitting participant 2031: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8151852932332657}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.9614047171028215}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.906136687509918}\"]",
    "Error fitting participant 2032: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.696724598722149}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.51322883914788}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.980737108437305}\"]",
    "Error fitting participant 2033: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.97595962235451}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.9837053821837225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.0306667759952193}\"]",
    "Error fitting participant 2034: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.7384246220557553}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.645454144787136}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.709760722259515}\"]",
    "Error fitting participant 2035: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.088917063530217}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.022003742251819}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.6689073954927878}\"]",
    "Error fitting participant 2036: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.032603772088566}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.638185488504079}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5582762647887622}\"]",
    "Error fitting participant 2037: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.266375524023662}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.444611937376843}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8011494880504852}\"]",
    "Error fitting participant 2038: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.895083325169232}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.853498842582951}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.705252258960874}\"]",
    "Error fitting participant 2039: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.2996172821958485}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.2276437286916035}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.463592018350965}\"]",
    "Error fitting participant 2040: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.988759355042728}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.4769723933179826}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.670351809918837}\"]",
    "Error fitting participant 2041: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.980467630012822}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.1806763009901773}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.664604718527372}\"]",
    "Error fitting participant 2042: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.98620421933938}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.430750109842654}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.583038031826202}\"]",
    "Error fitting participant 2043: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.529828592523415}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.073441573849928}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.847143235702271}\"]",
    "Error fitting participant 2044: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.2810498590058286}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.421748418689823}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.842712039666651}\"]",
    "Error fitting participant 2045: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.225676475604796}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.612951770086003}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.195427438572641}\"]",
    "Error fitting participant 2046: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2179165323897534}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.219662648676065}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.637164453475526}\"]",
    "Error fitting participant 2047: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5763606543230586}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.839903267218425}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.06284199316792}\"]",
    "Error fitting participant 2048: Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.770857519066965}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.9130787527864195}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.523629973649859}\"]"
  ],
  "skipped_participants": [
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2633425804298746}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.798189960902578}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.3320957091381658}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.2492579655530567}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.3234120281245905}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.232684506782757}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.609618673110018}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.1590391954200436}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.407609936066294}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8847355867447178}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.209471780141138}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.8826525468315545}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.178624395948081}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.139361694164874}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.577192651796791}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.005389624972297}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.6582875047403858}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.374412719181659}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.676840093828595}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9587003457592413}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.530377043940801}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.573665498605196}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.34274586081030844}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.876413446955097}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.831218371037968}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8763147032303198}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.171481356393597}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.061530922209065}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2698966207278337}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.614404559665749}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.735827487936064}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.1582901467019635}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.88502719988072}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.363798286757315}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.244742171316441}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.195136163017924}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.491217976255372}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8860629062253516}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.169595936352433}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.28500766175765}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.845724258951201}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.3646980887688678}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.291380874031225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.46887182347089}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.857939575593939}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.650498646243536}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.127859443225078}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.7307206334134655}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.457812233756751}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.2226338690613545}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.786647120557922}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.3758237976776577}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.156336753179945}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.4272926968257895}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.598511320992678}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.531005351171697}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.085734670793908}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.028043802994016}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.995579978105098}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.1468940318666965}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.034598313944864}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.9453618283514462}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.792106904999724}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.964397999356687}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.466376642191163}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.10929030490403946}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.522362795989283}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.039997642554646}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.659934924828283}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.381199534987244}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.997502660886291}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9166175391548581}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.20332903467011}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.903246719339658}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.681371928394581}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.119283451036157}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.786358303277337}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.120299148639744}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.350625812648222}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.7838398981628387}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.501839343667099}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.503068957550525}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.417667341064714}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.720353121789549}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.0630290771287507}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.1939288146605005}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.15695571568236977}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.721657914266222}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.4019302165588423}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.461661185594052}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.9377349786732543}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.097024543939256}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.98209998709363}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.0219175536846814}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.894817374245411}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.166048642357046}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.017611029410572}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.334323985302799}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.3131838115388734}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.20113750131482}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.092243449861547}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.797626540538054}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.204112802231667}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.670873058140062}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.97580248674021}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.32686798748458}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2850001905901696}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.08643734044809337}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.299672272680805}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.159247099049498}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.298010117133499}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.095445866281638}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5905020139540023}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.270277522131487}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.6855746724693133}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.88542949378973}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.524990139155724}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.144311488176385}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.481584475161714}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.979958364411363}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.7655790687104025}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.549999879082971}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.6341486100375935}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8646088102060263}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.531108884856396}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.463035582674755}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.238397973862752}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.814996475680872}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.6629458493851403}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.0142346490593424}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.69973404158944}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.512554557651763}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.428080744443105}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.286902756173069}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.356826313684993}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.194790737395074}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.850502488394606}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.308912328781297}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.467183981424104}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.25081295108126955}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.953315433435424}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5192096167164655}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.014659757766626}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.12512022472403}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9636178097574466}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.780795569447022}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.230587205846694}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.795632136350308}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.460786986948523}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.307164814220553}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.940854112794156}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.2727532089691715}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.483345074698897}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.527620598270536}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.129798183965168}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.830620159287423}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.1664200500285127}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.63438786544359}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.056423049772438}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.493985240792619}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.91427312906741}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.020563813277806}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.797744665141054}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.991848057374688}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.137054884489454}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.1889124780194784}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.850290104193488}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.9387606813379863}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.790469837959645}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.74667295788819}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.523188378040729}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.889069721546531}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.2312541217176098}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.874112902654405}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8060399890769274}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.943286272928109}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.80922639881957}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.462829048446212}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.771951386678349}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.9411871774325442}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.888412885846612}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.894586672649918}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.935990006690635}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.061116839388323}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.887284335695189}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.318146837747415}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.3450912704505225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.7768143382663064}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.4621548450774697}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.307404671937378}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.646184588164854}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.893430550348543}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.097725753994428}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.763927777105682}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.8041990549751246}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.753300673811577}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.620446993118845}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.132129460564508}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.053647568350479}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.990025999795271}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.2988302325880947}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.611266832209632}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.900171891351442}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.18779792453422095}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.6373863734916245}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8078268499397212}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.123277812427341}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.741434157739797}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.9754016051441976}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.146048645543512}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.659438192351455}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.990395345761006}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.10016973737526}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.8315263846350318}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.9391447423719232}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.001291935098186}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.938588087294238}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.782630955297471}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.499695897335192}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8151852932332657}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.9614047171028215}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.906136687509918}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.696724598722149}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.51322883914788}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.980737108437305}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.97595962235451}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.9837053821837225}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.0306667759952193}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.7384246220557553}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.645454144787136}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.709760722259515}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.088917063530217}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.022003742251819}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.6689073954927878}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.032603772088566}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.638185488504079}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5582762647887622}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.266375524023662}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.444611937376843}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.8011494880504852}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.895083325169232}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.853498842582951}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.705252258960874}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.2996172821958485}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.2276437286916035}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.463592018350965}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.988759355042728}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.4769723933179826}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.670351809918837}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.980467630012822}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.1806763009901773}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.664604718527372}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.98620421933938}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.430750109842654}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.583038031826202}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.529828592523415}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.073441573849928}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 1.847143235702271}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 0.2810498590058286}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 5.421748418689823}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.842712039666651}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 8.225676475604796}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.612951770086003}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.195427438572641}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.2179165323897534}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.219662648676065}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 7.637164453475526}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 3.5763606543230586}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 6.839903267218425}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 9.06284199316792}\"]"
    },
    {
      "participant_id": null,
      "error": "Error in parameter fitting: All optimization attempts failed. Errors: [\"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.770857519066965}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 4.9130787527864195}\", \"Error in likelihood calculation: simulate_model() got an unexpected keyword argument 'lambda'\\nParams: {'lambda': 2.523629973649859}\"]"
    }
  ],
  "num_skipped_participants": 91,
  "fitting_error": "No successful parameter fits obtained",
  "recovery_error": "No fitting results found",
  "previous_models": [
    "Specification: U = split_self - lambda * max(3 * token_self - split_self, 0)\nSummary: A loss-averse utility model where participants evaluate offers relative to their contribution-based fair share (3*token_self). Utility decreases linearly with deficits below this reference point, scaled by a learnable loss aversion parameter (lambda). The model converts utility to acceptance probability via logistic function.\nTarget Variable: accept\nPrediction Type: utility"
  ]
}