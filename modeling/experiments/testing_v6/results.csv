run_number,average_bic,model_specification,model_summary,version,beta_recovery,lambda_param_recovery,gamma_param_recovery
1,,"U_accept = beta + split_self - alpha * max((token_self / (token_self + token_opp)) * combined_earning - split_self, 0)","This utility model for responder behavior computes the acceptance utility by combining the offered monetary gain (split_self) with a fairness adjustment. A fair share is calculated based on the ratio of participant tokens to total tokens multiplied by the combined earnings. If the offer falls below this fair share, a disutility proportional to the shortfall (scaled by learnable parameter alpha) is subtracted, with an additive baseline bias captured by learnable parameter beta.",v6,,,
2,,U_accept = beta + split_self - lambda_param * ((token_self / (token_self + token_opp)) * combined_earning - split_self)^2,"A quadratic fairness comparison model for responder behavior. The model computes a fairness benchmark from token ratios and combined earnings; then, it generates the utility of accepting by adding the monetary offer (split_self) and subtracting a quadratic penalty for deviations from this fair share. Two learnable parameters capture baseline bias (beta) and sensitivity to fairness deviations (lambda_param).",v6,0.9393381974601048,0.5719416654330552,
3,,"Let F = (token_self / (token_self + token_opp)) * combined_earning

U_accept = beta + split_self - gamma_param * ((max(F - split_self, 0)^2) / F)","A normalized quadratic fairness model for responder utility that uses the monetary offer and a fairness benchmark computed from token counts and total earnings. The model applies a penalty—scaled by gamma_param—to offers that fall short of the fair share, with a baseline bias beta added. This yields a utility signal that is high for offers meeting or exceeding the fairness benchmark and reduced when offers are below it.",v6,0.8814121495450942,,0.04711166543720369
